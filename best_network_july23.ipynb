{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The Best Model As Of July 23 2020\n",
    "\n",
    "10 jets, #nofilter, PtEtaPhi network, restricted dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting data by tag\n",
      "287645\n",
      "creating default model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 700)               21700     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 408       \n",
      "=================================================================\n",
      "Total params: 558,988\n",
      "Trainable params: 558,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 201351 samples, validate on 28765 samples\n",
      "Epoch 1/800\n",
      "201351/201351 [==============================] - 11s 55us/step - loss: 1.0230 - acc: 0.6002 - val_loss: 0.8273 - val_acc: 0.6175\n",
      "Epoch 2/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.7979 - acc: 0.6303 - val_loss: 0.7625 - val_acc: 0.6494\n",
      "Epoch 3/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.7505 - acc: 0.6510 - val_loss: 0.7274 - val_acc: 0.6670\n",
      "Epoch 4/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.7276 - acc: 0.6631 - val_loss: 0.7126 - val_acc: 0.6759\n",
      "Epoch 5/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.7124 - acc: 0.6715 - val_loss: 0.6994 - val_acc: 0.6805\n",
      "Epoch 6/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.7012 - acc: 0.6776 - val_loss: 0.6887 - val_acc: 0.6866\n",
      "Epoch 7/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6917 - acc: 0.6831 - val_loss: 0.6795 - val_acc: 0.6924\n",
      "Epoch 8/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6841 - acc: 0.6865 - val_loss: 0.6743 - val_acc: 0.6945\n",
      "Epoch 9/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.6764 - acc: 0.6917 - val_loss: 0.6665 - val_acc: 0.6984\n",
      "Epoch 10/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.6701 - acc: 0.6947 - val_loss: 0.6621 - val_acc: 0.7013\n",
      "Epoch 11/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6645 - acc: 0.6971 - val_loss: 0.6562 - val_acc: 0.7035\n",
      "Epoch 12/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6595 - acc: 0.6991 - val_loss: 0.6516 - val_acc: 0.7074\n",
      "Epoch 13/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6552 - acc: 0.7004 - val_loss: 0.6471 - val_acc: 0.7078\n",
      "Epoch 14/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.6503 - acc: 0.7028 - val_loss: 0.6443 - val_acc: 0.7092\n",
      "Epoch 15/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6465 - acc: 0.7051 - val_loss: 0.6390 - val_acc: 0.7108\n",
      "Epoch 16/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6423 - acc: 0.7069 - val_loss: 0.6355 - val_acc: 0.7130\n",
      "Epoch 17/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6391 - acc: 0.7083 - val_loss: 0.6317 - val_acc: 0.7142\n",
      "Epoch 18/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6354 - acc: 0.7093 - val_loss: 0.6295 - val_acc: 0.7159\n",
      "Epoch 19/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6316 - acc: 0.7122 - val_loss: 0.6254 - val_acc: 0.7189\n",
      "Epoch 20/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6284 - acc: 0.7141 - val_loss: 0.6221 - val_acc: 0.7203\n",
      "Epoch 21/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6246 - acc: 0.7146 - val_loss: 0.6187 - val_acc: 0.7207\n",
      "Epoch 22/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6210 - acc: 0.7168 - val_loss: 0.6146 - val_acc: 0.7225\n",
      "Epoch 23/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.6181 - acc: 0.7189 - val_loss: 0.6117 - val_acc: 0.7246\n",
      "Epoch 24/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.6147 - acc: 0.7200 - val_loss: 0.6098 - val_acc: 0.7264\n",
      "Epoch 25/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.6120 - acc: 0.7206 - val_loss: 0.6054 - val_acc: 0.7289\n",
      "Epoch 26/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6085 - acc: 0.7233 - val_loss: 0.6021 - val_acc: 0.7287\n",
      "Epoch 27/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.6055 - acc: 0.7249 - val_loss: 0.5982 - val_acc: 0.7322\n",
      "Epoch 28/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.6028 - acc: 0.7262 - val_loss: 0.5954 - val_acc: 0.7318\n",
      "Epoch 29/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.5995 - acc: 0.7275 - val_loss: 0.5923 - val_acc: 0.7346\n",
      "Epoch 30/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5970 - acc: 0.7289 - val_loss: 0.5884 - val_acc: 0.7372\n",
      "Epoch 31/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.5936 - acc: 0.7312 - val_loss: 0.5857 - val_acc: 0.7387\n",
      "Epoch 32/800\n",
      "201351/201351 [==============================] - 10s 51us/step - loss: 0.5905 - acc: 0.7325 - val_loss: 0.5854 - val_acc: 0.7387\n",
      "Epoch 33/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.5879 - acc: 0.7349 - val_loss: 0.5821 - val_acc: 0.7400\n",
      "Epoch 34/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.5849 - acc: 0.7354 - val_loss: 0.5775 - val_acc: 0.7427\n",
      "Epoch 35/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.5824 - acc: 0.7377 - val_loss: 0.5748 - val_acc: 0.7434\n",
      "Epoch 36/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5798 - acc: 0.7384 - val_loss: 0.5723 - val_acc: 0.7443\n",
      "Epoch 37/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.5773 - acc: 0.7408 - val_loss: 0.5699 - val_acc: 0.7451\n",
      "Epoch 38/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5746 - acc: 0.7425 - val_loss: 0.5686 - val_acc: 0.7471\n",
      "Epoch 39/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5723 - acc: 0.7431 - val_loss: 0.5656 - val_acc: 0.7497\n",
      "Epoch 40/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.5701 - acc: 0.7447 - val_loss: 0.5621 - val_acc: 0.7521\n",
      "Epoch 41/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5679 - acc: 0.7453 - val_loss: 0.5605 - val_acc: 0.7512\n",
      "Epoch 42/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5654 - acc: 0.7462 - val_loss: 0.5589 - val_acc: 0.7532\n",
      "Epoch 43/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.5628 - acc: 0.7481 - val_loss: 0.5578 - val_acc: 0.7531\n",
      "Epoch 44/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5608 - acc: 0.7487 - val_loss: 0.5555 - val_acc: 0.7537\n",
      "Epoch 45/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5590 - acc: 0.7502 - val_loss: 0.5535 - val_acc: 0.7553\n",
      "Epoch 46/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.5568 - acc: 0.7510 - val_loss: 0.5502 - val_acc: 0.7572\n",
      "Epoch 47/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5557 - acc: 0.7518 - val_loss: 0.5491 - val_acc: 0.7570\n",
      "Epoch 48/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5537 - acc: 0.7535 - val_loss: 0.5469 - val_acc: 0.7572\n",
      "Epoch 49/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.5516 - acc: 0.7543 - val_loss: 0.5449 - val_acc: 0.7597\n",
      "Epoch 50/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5501 - acc: 0.7547 - val_loss: 0.5454 - val_acc: 0.7579\n",
      "Epoch 51/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.5477 - acc: 0.7564 - val_loss: 0.5414 - val_acc: 0.7625\n",
      "Epoch 52/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5459 - acc: 0.7572 - val_loss: 0.5393 - val_acc: 0.7632\n",
      "Epoch 53/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.5442 - acc: 0.7576 - val_loss: 0.5385 - val_acc: 0.7628\n",
      "Epoch 54/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.5424 - acc: 0.7582 - val_loss: 0.5375 - val_acc: 0.7629\n",
      "Epoch 55/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.5401 - acc: 0.7597 - val_loss: 0.5345 - val_acc: 0.7652\n",
      "Epoch 56/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5388 - acc: 0.7605 - val_loss: 0.5342 - val_acc: 0.7638\n",
      "Epoch 57/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5368 - acc: 0.7621 - val_loss: 0.5315 - val_acc: 0.7674\n",
      "Epoch 58/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5356 - acc: 0.7619 - val_loss: 0.5298 - val_acc: 0.7676\n",
      "Epoch 59/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5335 - acc: 0.7631 - val_loss: 0.5280 - val_acc: 0.7682\n",
      "Epoch 60/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5316 - acc: 0.7642 - val_loss: 0.5270 - val_acc: 0.7686\n",
      "Epoch 61/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5297 - acc: 0.7650 - val_loss: 0.5236 - val_acc: 0.7703\n",
      "Epoch 62/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5283 - acc: 0.7661 - val_loss: 0.5231 - val_acc: 0.7708\n",
      "Epoch 63/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.5260 - acc: 0.7667 - val_loss: 0.5206 - val_acc: 0.7720\n",
      "Epoch 64/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.5249 - acc: 0.7667 - val_loss: 0.5184 - val_acc: 0.7738\n",
      "Epoch 65/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.5228 - acc: 0.7681 - val_loss: 0.5177 - val_acc: 0.7739\n",
      "Epoch 66/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.5211 - acc: 0.7696 - val_loss: 0.5164 - val_acc: 0.7747\n",
      "Epoch 67/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5194 - acc: 0.7700 - val_loss: 0.5141 - val_acc: 0.7772\n",
      "Epoch 68/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5177 - acc: 0.7711 - val_loss: 0.5126 - val_acc: 0.7767\n",
      "Epoch 69/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.5159 - acc: 0.7717 - val_loss: 0.5106 - val_acc: 0.7778\n",
      "Epoch 70/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5146 - acc: 0.7730 - val_loss: 0.5097 - val_acc: 0.7784\n",
      "Epoch 71/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.5119 - acc: 0.7744 - val_loss: 0.5068 - val_acc: 0.7787\n",
      "Epoch 72/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.5103 - acc: 0.7747 - val_loss: 0.5055 - val_acc: 0.7804\n",
      "Epoch 73/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5097 - acc: 0.7752 - val_loss: 0.5037 - val_acc: 0.7819\n",
      "Epoch 74/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5071 - acc: 0.7764 - val_loss: 0.5023 - val_acc: 0.7818\n",
      "Epoch 75/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5060 - acc: 0.7769 - val_loss: 0.5009 - val_acc: 0.7841\n",
      "Epoch 76/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5044 - acc: 0.7775 - val_loss: 0.4991 - val_acc: 0.7844\n",
      "Epoch 77/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.5023 - acc: 0.7788 - val_loss: 0.4996 - val_acc: 0.7840\n",
      "Epoch 78/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.5012 - acc: 0.7800 - val_loss: 0.4964 - val_acc: 0.7849\n",
      "Epoch 79/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4990 - acc: 0.7806 - val_loss: 0.4938 - val_acc: 0.7852\n",
      "Epoch 80/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4980 - acc: 0.7814 - val_loss: 0.4930 - val_acc: 0.7870\n",
      "Epoch 81/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4967 - acc: 0.7822 - val_loss: 0.4915 - val_acc: 0.7875\n",
      "Epoch 82/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4949 - acc: 0.7832 - val_loss: 0.4926 - val_acc: 0.7867\n",
      "Epoch 83/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4930 - acc: 0.7836 - val_loss: 0.4919 - val_acc: 0.7872\n",
      "Epoch 84/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4914 - acc: 0.7853 - val_loss: 0.4875 - val_acc: 0.7883\n",
      "Epoch 85/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4903 - acc: 0.7843 - val_loss: 0.4881 - val_acc: 0.7873\n",
      "Epoch 86/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4884 - acc: 0.7858 - val_loss: 0.4855 - val_acc: 0.7912\n",
      "Epoch 87/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4877 - acc: 0.7867 - val_loss: 0.4836 - val_acc: 0.7905\n",
      "Epoch 88/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4862 - acc: 0.7873 - val_loss: 0.4824 - val_acc: 0.7917\n",
      "Epoch 89/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4842 - acc: 0.7874 - val_loss: 0.4813 - val_acc: 0.7929\n",
      "Epoch 90/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4833 - acc: 0.7888 - val_loss: 0.4804 - val_acc: 0.7928\n",
      "Epoch 91/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4820 - acc: 0.7890 - val_loss: 0.4782 - val_acc: 0.7928\n",
      "Epoch 92/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4804 - acc: 0.7898 - val_loss: 0.4773 - val_acc: 0.7942\n",
      "Epoch 93/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4786 - acc: 0.7918 - val_loss: 0.4741 - val_acc: 0.7954\n",
      "Epoch 94/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4778 - acc: 0.7912 - val_loss: 0.4747 - val_acc: 0.7948\n",
      "Epoch 95/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4761 - acc: 0.7927 - val_loss: 0.4741 - val_acc: 0.7965\n",
      "Epoch 96/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4750 - acc: 0.7932 - val_loss: 0.4726 - val_acc: 0.7981\n",
      "Epoch 97/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4736 - acc: 0.7935 - val_loss: 0.4699 - val_acc: 0.7986\n",
      "Epoch 98/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4719 - acc: 0.7948 - val_loss: 0.4697 - val_acc: 0.7977\n",
      "Epoch 99/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4711 - acc: 0.7946 - val_loss: 0.4679 - val_acc: 0.7989\n",
      "Epoch 100/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4696 - acc: 0.7953 - val_loss: 0.4671 - val_acc: 0.8000\n",
      "Epoch 101/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.4685 - acc: 0.7966 - val_loss: 0.4663 - val_acc: 0.7994\n",
      "Epoch 102/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4660 - acc: 0.7974 - val_loss: 0.4645 - val_acc: 0.8015\n",
      "Epoch 103/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4650 - acc: 0.7976 - val_loss: 0.4636 - val_acc: 0.8019\n",
      "Epoch 104/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4644 - acc: 0.7982 - val_loss: 0.4616 - val_acc: 0.8032\n",
      "Epoch 105/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4632 - acc: 0.7996 - val_loss: 0.4606 - val_acc: 0.8036\n",
      "Epoch 106/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.4630 - acc: 0.7996 - val_loss: 0.4594 - val_acc: 0.8044\n",
      "Epoch 107/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4595 - acc: 0.8017 - val_loss: 0.4575 - val_acc: 0.8049\n",
      "Epoch 108/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4592 - acc: 0.8008 - val_loss: 0.4575 - val_acc: 0.8042\n",
      "Epoch 109/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4576 - acc: 0.8021 - val_loss: 0.4571 - val_acc: 0.8039\n",
      "Epoch 110/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4579 - acc: 0.8022 - val_loss: 0.4561 - val_acc: 0.8044\n",
      "Epoch 111/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4547 - acc: 0.8029 - val_loss: 0.4545 - val_acc: 0.8063\n",
      "Epoch 112/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4546 - acc: 0.8037 - val_loss: 0.4521 - val_acc: 0.8079\n",
      "Epoch 113/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4522 - acc: 0.8042 - val_loss: 0.4517 - val_acc: 0.8081\n",
      "Epoch 114/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4525 - acc: 0.8043 - val_loss: 0.4537 - val_acc: 0.8094\n",
      "Epoch 115/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4506 - acc: 0.8059 - val_loss: 0.4480 - val_acc: 0.8098\n",
      "Epoch 116/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4497 - acc: 0.8060 - val_loss: 0.4480 - val_acc: 0.8104\n",
      "Epoch 117/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4489 - acc: 0.8073 - val_loss: 0.4471 - val_acc: 0.8097\n",
      "Epoch 118/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4478 - acc: 0.8068 - val_loss: 0.4487 - val_acc: 0.8100\n",
      "Epoch 119/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4461 - acc: 0.8079 - val_loss: 0.4436 - val_acc: 0.8132\n",
      "Epoch 120/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4449 - acc: 0.8084 - val_loss: 0.4431 - val_acc: 0.8136\n",
      "Epoch 121/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4441 - acc: 0.8080 - val_loss: 0.4433 - val_acc: 0.8128\n",
      "Epoch 122/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.4422 - acc: 0.8093 - val_loss: 0.4417 - val_acc: 0.8132\n",
      "Epoch 123/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4424 - acc: 0.8091 - val_loss: 0.4403 - val_acc: 0.8150\n",
      "Epoch 124/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4404 - acc: 0.8104 - val_loss: 0.4411 - val_acc: 0.8149\n",
      "Epoch 125/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4389 - acc: 0.8114 - val_loss: 0.4393 - val_acc: 0.8160\n",
      "Epoch 126/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4384 - acc: 0.8117 - val_loss: 0.4387 - val_acc: 0.8152\n",
      "Epoch 127/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4374 - acc: 0.8117 - val_loss: 0.4371 - val_acc: 0.8161\n",
      "Epoch 128/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4355 - acc: 0.8122 - val_loss: 0.4362 - val_acc: 0.8176\n",
      "Epoch 129/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4356 - acc: 0.8134 - val_loss: 0.4344 - val_acc: 0.8203\n",
      "Epoch 130/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4336 - acc: 0.8141 - val_loss: 0.4356 - val_acc: 0.8173\n",
      "Epoch 131/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.4320 - acc: 0.8135 - val_loss: 0.4335 - val_acc: 0.8205\n",
      "Epoch 132/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4325 - acc: 0.8143 - val_loss: 0.4326 - val_acc: 0.8202\n",
      "Epoch 133/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4303 - acc: 0.8145 - val_loss: 0.4305 - val_acc: 0.8212\n",
      "Epoch 134/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4287 - acc: 0.8160 - val_loss: 0.4296 - val_acc: 0.8229\n",
      "Epoch 135/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4287 - acc: 0.8160 - val_loss: 0.4287 - val_acc: 0.8217\n",
      "Epoch 136/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.4282 - acc: 0.8167 - val_loss: 0.4285 - val_acc: 0.8220\n",
      "Epoch 137/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4265 - acc: 0.8163 - val_loss: 0.4310 - val_acc: 0.8207\n",
      "Epoch 138/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4253 - acc: 0.8178 - val_loss: 0.4268 - val_acc: 0.8223\n",
      "Epoch 139/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4230 - acc: 0.8192 - val_loss: 0.4267 - val_acc: 0.8225\n",
      "Epoch 140/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4227 - acc: 0.8196 - val_loss: 0.4240 - val_acc: 0.8239\n",
      "Epoch 141/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4212 - acc: 0.8190 - val_loss: 0.4224 - val_acc: 0.8252\n",
      "Epoch 142/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4206 - acc: 0.8204 - val_loss: 0.4218 - val_acc: 0.8249\n",
      "Epoch 143/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4193 - acc: 0.8205 - val_loss: 0.4207 - val_acc: 0.8270\n",
      "Epoch 144/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.4199 - acc: 0.8208 - val_loss: 0.4204 - val_acc: 0.8274\n",
      "Epoch 145/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4165 - acc: 0.8218 - val_loss: 0.4201 - val_acc: 0.8281\n",
      "Epoch 146/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4169 - acc: 0.8217 - val_loss: 0.4180 - val_acc: 0.8279\n",
      "Epoch 147/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4152 - acc: 0.8234 - val_loss: 0.4209 - val_acc: 0.8280\n",
      "Epoch 148/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4137 - acc: 0.8219 - val_loss: 0.4183 - val_acc: 0.8280\n",
      "Epoch 149/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4125 - acc: 0.8238 - val_loss: 0.4160 - val_acc: 0.8309\n",
      "Epoch 150/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4109 - acc: 0.8245 - val_loss: 0.4157 - val_acc: 0.8306\n",
      "Epoch 151/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4112 - acc: 0.8240 - val_loss: 0.4147 - val_acc: 0.8302\n",
      "Epoch 152/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4090 - acc: 0.8260 - val_loss: 0.4152 - val_acc: 0.8313\n",
      "Epoch 153/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4092 - acc: 0.8251 - val_loss: 0.4132 - val_acc: 0.8323\n",
      "Epoch 154/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4068 - acc: 0.8263 - val_loss: 0.4129 - val_acc: 0.8308\n",
      "Epoch 155/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4068 - acc: 0.8262 - val_loss: 0.4115 - val_acc: 0.8331\n",
      "Epoch 156/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4053 - acc: 0.8274 - val_loss: 0.4110 - val_acc: 0.8335\n",
      "Epoch 157/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4038 - acc: 0.8284 - val_loss: 0.4108 - val_acc: 0.8329\n",
      "Epoch 158/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4034 - acc: 0.8287 - val_loss: 0.4090 - val_acc: 0.8325\n",
      "Epoch 159/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4026 - acc: 0.8285 - val_loss: 0.4092 - val_acc: 0.8341\n",
      "Epoch 160/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.4019 - acc: 0.8287 - val_loss: 0.4066 - val_acc: 0.8364\n",
      "Epoch 161/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.4002 - acc: 0.8297 - val_loss: 0.4064 - val_acc: 0.8356\n",
      "Epoch 162/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3992 - acc: 0.8298 - val_loss: 0.4068 - val_acc: 0.8362\n",
      "Epoch 163/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3978 - acc: 0.8303 - val_loss: 0.4050 - val_acc: 0.8364\n",
      "Epoch 164/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3968 - acc: 0.8313 - val_loss: 0.4062 - val_acc: 0.8357\n",
      "Epoch 165/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3958 - acc: 0.8318 - val_loss: 0.4047 - val_acc: 0.8383\n",
      "Epoch 166/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3955 - acc: 0.8324 - val_loss: 0.4028 - val_acc: 0.8376\n",
      "Epoch 167/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3934 - acc: 0.8335 - val_loss: 0.4013 - val_acc: 0.8393\n",
      "Epoch 168/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3925 - acc: 0.8333 - val_loss: 0.4008 - val_acc: 0.8390\n",
      "Epoch 169/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3914 - acc: 0.8334 - val_loss: 0.4029 - val_acc: 0.8374\n",
      "Epoch 170/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3906 - acc: 0.8340 - val_loss: 0.4021 - val_acc: 0.8378\n",
      "Epoch 171/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3896 - acc: 0.8353 - val_loss: 0.3989 - val_acc: 0.8402\n",
      "Epoch 172/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3893 - acc: 0.8347 - val_loss: 0.3977 - val_acc: 0.8410\n",
      "Epoch 173/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3872 - acc: 0.8366 - val_loss: 0.3979 - val_acc: 0.8411\n",
      "Epoch 174/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3866 - acc: 0.8365 - val_loss: 0.3977 - val_acc: 0.8416\n",
      "Epoch 175/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3857 - acc: 0.8371 - val_loss: 0.3963 - val_acc: 0.8425\n",
      "Epoch 176/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3846 - acc: 0.8372 - val_loss: 0.3962 - val_acc: 0.8424\n",
      "Epoch 177/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3835 - acc: 0.8377 - val_loss: 0.3961 - val_acc: 0.8434\n",
      "Epoch 178/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3830 - acc: 0.8372 - val_loss: 0.3944 - val_acc: 0.8432\n",
      "Epoch 179/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3818 - acc: 0.8382 - val_loss: 0.3946 - val_acc: 0.8437\n",
      "Epoch 180/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3814 - acc: 0.8391 - val_loss: 0.3937 - val_acc: 0.8447\n",
      "Epoch 181/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3801 - acc: 0.8397 - val_loss: 0.3922 - val_acc: 0.8454\n",
      "Epoch 182/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3776 - acc: 0.8411 - val_loss: 0.3890 - val_acc: 0.8472\n",
      "Epoch 183/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3770 - acc: 0.8402 - val_loss: 0.3912 - val_acc: 0.8467\n",
      "Epoch 184/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3765 - acc: 0.8412 - val_loss: 0.3885 - val_acc: 0.8479\n",
      "Epoch 185/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3750 - acc: 0.8418 - val_loss: 0.3903 - val_acc: 0.8469\n",
      "Epoch 186/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3739 - acc: 0.8421 - val_loss: 0.3888 - val_acc: 0.8482\n",
      "Epoch 187/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3738 - acc: 0.8427 - val_loss: 0.3897 - val_acc: 0.8461\n",
      "Epoch 188/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3730 - acc: 0.8442 - val_loss: 0.3862 - val_acc: 0.8499\n",
      "Epoch 189/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3720 - acc: 0.8432 - val_loss: 0.3866 - val_acc: 0.8484\n",
      "Epoch 190/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3718 - acc: 0.8432 - val_loss: 0.3849 - val_acc: 0.8496\n",
      "Epoch 191/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3703 - acc: 0.8442 - val_loss: 0.3835 - val_acc: 0.8504\n",
      "Epoch 192/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3683 - acc: 0.8457 - val_loss: 0.3861 - val_acc: 0.8478\n",
      "Epoch 193/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3674 - acc: 0.8456 - val_loss: 0.3847 - val_acc: 0.8507\n",
      "Epoch 194/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3671 - acc: 0.8452 - val_loss: 0.3837 - val_acc: 0.8513\n",
      "Epoch 195/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3655 - acc: 0.8465 - val_loss: 0.3833 - val_acc: 0.8516\n",
      "Epoch 196/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3652 - acc: 0.8466 - val_loss: 0.3815 - val_acc: 0.8518\n",
      "Epoch 197/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3631 - acc: 0.8468 - val_loss: 0.3817 - val_acc: 0.8516\n",
      "Epoch 198/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3628 - acc: 0.8480 - val_loss: 0.3795 - val_acc: 0.8523\n",
      "Epoch 199/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3612 - acc: 0.8483 - val_loss: 0.3802 - val_acc: 0.8535\n",
      "Epoch 200/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3616 - acc: 0.8489 - val_loss: 0.3786 - val_acc: 0.8553\n",
      "Epoch 201/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3596 - acc: 0.8490 - val_loss: 0.3792 - val_acc: 0.8528\n",
      "Epoch 202/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3579 - acc: 0.8510 - val_loss: 0.3789 - val_acc: 0.8540\n",
      "Epoch 203/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3571 - acc: 0.8497 - val_loss: 0.3794 - val_acc: 0.8538\n",
      "Epoch 204/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3565 - acc: 0.8507 - val_loss: 0.3785 - val_acc: 0.8534\n",
      "Epoch 205/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3568 - acc: 0.8507 - val_loss: 0.3790 - val_acc: 0.8538\n",
      "Epoch 206/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3549 - acc: 0.8515 - val_loss: 0.3755 - val_acc: 0.8555\n",
      "Epoch 207/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3558 - acc: 0.8509 - val_loss: 0.3756 - val_acc: 0.8558\n",
      "Epoch 208/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3527 - acc: 0.8527 - val_loss: 0.3727 - val_acc: 0.8566\n",
      "Epoch 209/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3540 - acc: 0.8520 - val_loss: 0.3729 - val_acc: 0.8583\n",
      "Epoch 210/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3502 - acc: 0.8543 - val_loss: 0.3734 - val_acc: 0.8580\n",
      "Epoch 211/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3507 - acc: 0.8531 - val_loss: 0.3741 - val_acc: 0.8581\n",
      "Epoch 212/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3498 - acc: 0.8543 - val_loss: 0.3723 - val_acc: 0.8599\n",
      "Epoch 213/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3479 - acc: 0.8544 - val_loss: 0.3722 - val_acc: 0.8595\n",
      "Epoch 214/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3473 - acc: 0.8548 - val_loss: 0.3711 - val_acc: 0.8599\n",
      "Epoch 215/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3459 - acc: 0.8556 - val_loss: 0.3690 - val_acc: 0.8619\n",
      "Epoch 216/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3447 - acc: 0.8563 - val_loss: 0.3706 - val_acc: 0.8604\n",
      "Epoch 217/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3457 - acc: 0.8554 - val_loss: 0.3711 - val_acc: 0.8604\n",
      "Epoch 218/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3446 - acc: 0.8566 - val_loss: 0.3689 - val_acc: 0.8615\n",
      "Epoch 219/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3431 - acc: 0.8570 - val_loss: 0.3704 - val_acc: 0.8616\n",
      "Epoch 220/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3417 - acc: 0.8584 - val_loss: 0.3690 - val_acc: 0.8612\n",
      "Epoch 221/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3416 - acc: 0.8571 - val_loss: 0.3684 - val_acc: 0.8626\n",
      "Epoch 222/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3395 - acc: 0.8586 - val_loss: 0.3670 - val_acc: 0.8633\n",
      "Epoch 223/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3407 - acc: 0.8582 - val_loss: 0.3709 - val_acc: 0.8610\n",
      "Epoch 224/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3380 - acc: 0.8594 - val_loss: 0.3661 - val_acc: 0.8636\n",
      "Epoch 225/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3380 - acc: 0.8590 - val_loss: 0.3663 - val_acc: 0.8638\n",
      "Epoch 226/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3347 - acc: 0.8604 - val_loss: 0.3659 - val_acc: 0.8636\n",
      "Epoch 227/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3362 - acc: 0.8604 - val_loss: 0.3654 - val_acc: 0.8625\n",
      "Epoch 228/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3359 - acc: 0.8597 - val_loss: 0.3645 - val_acc: 0.8651\n",
      "Epoch 229/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3343 - acc: 0.8610 - val_loss: 0.3633 - val_acc: 0.8658\n",
      "Epoch 230/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3324 - acc: 0.8618 - val_loss: 0.3622 - val_acc: 0.8664\n",
      "Epoch 231/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3327 - acc: 0.8620 - val_loss: 0.3625 - val_acc: 0.8665\n",
      "Epoch 232/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3312 - acc: 0.8626 - val_loss: 0.3618 - val_acc: 0.8667\n",
      "Epoch 233/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3311 - acc: 0.8622 - val_loss: 0.3637 - val_acc: 0.8654\n",
      "Epoch 234/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3295 - acc: 0.8632 - val_loss: 0.3625 - val_acc: 0.8662\n",
      "Epoch 235/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3289 - acc: 0.8636 - val_loss: 0.3628 - val_acc: 0.8661\n",
      "Epoch 236/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3275 - acc: 0.8635 - val_loss: 0.3621 - val_acc: 0.8669\n",
      "Epoch 237/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3272 - acc: 0.8642 - val_loss: 0.3623 - val_acc: 0.8667\n",
      "Epoch 238/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3280 - acc: 0.8640 - val_loss: 0.3608 - val_acc: 0.8685\n",
      "Epoch 239/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3253 - acc: 0.8648 - val_loss: 0.3608 - val_acc: 0.8687\n",
      "Epoch 240/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3252 - acc: 0.8651 - val_loss: 0.3603 - val_acc: 0.8692\n",
      "Epoch 241/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3243 - acc: 0.8655 - val_loss: 0.3606 - val_acc: 0.8681\n",
      "Epoch 242/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3227 - acc: 0.8654 - val_loss: 0.3599 - val_acc: 0.8669\n",
      "Epoch 243/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3215 - acc: 0.8666 - val_loss: 0.3600 - val_acc: 0.8675\n",
      "Epoch 244/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3234 - acc: 0.8660 - val_loss: 0.3578 - val_acc: 0.8693\n",
      "Epoch 245/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3213 - acc: 0.8667 - val_loss: 0.3571 - val_acc: 0.8698\n",
      "Epoch 246/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3204 - acc: 0.8667 - val_loss: 0.3603 - val_acc: 0.8688\n",
      "Epoch 247/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3189 - acc: 0.8678 - val_loss: 0.3597 - val_acc: 0.8703\n",
      "Epoch 248/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3183 - acc: 0.8682 - val_loss: 0.3567 - val_acc: 0.8710\n",
      "Epoch 249/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3170 - acc: 0.8683 - val_loss: 0.3567 - val_acc: 0.8709\n",
      "Epoch 250/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3151 - acc: 0.8694 - val_loss: 0.3576 - val_acc: 0.8708\n",
      "Epoch 251/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3152 - acc: 0.8699 - val_loss: 0.3571 - val_acc: 0.8718\n",
      "Epoch 252/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.3141 - acc: 0.8706 - val_loss: 0.3579 - val_acc: 0.8713\n",
      "Epoch 253/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3144 - acc: 0.8702 - val_loss: 0.3563 - val_acc: 0.8714\n",
      "Epoch 254/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3134 - acc: 0.8696 - val_loss: 0.3558 - val_acc: 0.8725\n",
      "Epoch 255/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3136 - acc: 0.8701 - val_loss: 0.3582 - val_acc: 0.8713\n",
      "Epoch 256/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3128 - acc: 0.8707 - val_loss: 0.3542 - val_acc: 0.8734\n",
      "Epoch 257/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3100 - acc: 0.8717 - val_loss: 0.3556 - val_acc: 0.8723\n",
      "Epoch 258/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3102 - acc: 0.8720 - val_loss: 0.3547 - val_acc: 0.8735\n",
      "Epoch 259/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3092 - acc: 0.8719 - val_loss: 0.3566 - val_acc: 0.8720\n",
      "Epoch 260/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3098 - acc: 0.8719 - val_loss: 0.3535 - val_acc: 0.8735\n",
      "Epoch 261/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3087 - acc: 0.8729 - val_loss: 0.3538 - val_acc: 0.8731\n",
      "Epoch 262/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3074 - acc: 0.8735 - val_loss: 0.3537 - val_acc: 0.8739\n",
      "Epoch 263/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3061 - acc: 0.8731 - val_loss: 0.3524 - val_acc: 0.8751\n",
      "Epoch 264/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3057 - acc: 0.8740 - val_loss: 0.3503 - val_acc: 0.8761\n",
      "Epoch 265/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3039 - acc: 0.8744 - val_loss: 0.3533 - val_acc: 0.8749\n",
      "Epoch 266/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3036 - acc: 0.8754 - val_loss: 0.3524 - val_acc: 0.8743\n",
      "Epoch 267/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3031 - acc: 0.8748 - val_loss: 0.3531 - val_acc: 0.8757\n",
      "Epoch 268/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3020 - acc: 0.8750 - val_loss: 0.3494 - val_acc: 0.8760\n",
      "Epoch 269/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.3027 - acc: 0.8749 - val_loss: 0.3504 - val_acc: 0.8778\n",
      "Epoch 270/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3023 - acc: 0.8758 - val_loss: 0.3518 - val_acc: 0.8764\n",
      "Epoch 271/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.3003 - acc: 0.8764 - val_loss: 0.3519 - val_acc: 0.8773\n",
      "Epoch 272/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2989 - acc: 0.8760 - val_loss: 0.3483 - val_acc: 0.8782\n",
      "Epoch 273/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2986 - acc: 0.8777 - val_loss: 0.3488 - val_acc: 0.8758\n",
      "Epoch 274/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.2977 - acc: 0.8781 - val_loss: 0.3482 - val_acc: 0.8768\n",
      "Epoch 275/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.2982 - acc: 0.8772 - val_loss: 0.3475 - val_acc: 0.8788\n",
      "Epoch 276/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2971 - acc: 0.8770 - val_loss: 0.3484 - val_acc: 0.8772\n",
      "Epoch 277/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2962 - acc: 0.8780 - val_loss: 0.3490 - val_acc: 0.8767\n",
      "Epoch 278/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2952 - acc: 0.8788 - val_loss: 0.3484 - val_acc: 0.8790\n",
      "Epoch 279/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2939 - acc: 0.8785 - val_loss: 0.3494 - val_acc: 0.8792\n",
      "Epoch 280/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.2935 - acc: 0.8787 - val_loss: 0.3501 - val_acc: 0.8786\n",
      "Epoch 281/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2930 - acc: 0.8798 - val_loss: 0.3495 - val_acc: 0.8774\n",
      "Epoch 282/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2928 - acc: 0.8798 - val_loss: 0.3451 - val_acc: 0.8809\n",
      "Epoch 283/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2915 - acc: 0.8808 - val_loss: 0.3480 - val_acc: 0.8787\n",
      "Epoch 284/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2912 - acc: 0.8800 - val_loss: 0.3476 - val_acc: 0.8795\n",
      "Epoch 285/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2905 - acc: 0.8807 - val_loss: 0.3458 - val_acc: 0.8810\n",
      "Epoch 286/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2910 - acc: 0.8803 - val_loss: 0.3452 - val_acc: 0.8809\n",
      "Epoch 287/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2889 - acc: 0.8808 - val_loss: 0.3468 - val_acc: 0.8794\n",
      "Epoch 288/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2889 - acc: 0.8812 - val_loss: 0.3449 - val_acc: 0.8800\n",
      "Epoch 289/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2874 - acc: 0.8822 - val_loss: 0.3449 - val_acc: 0.8809\n",
      "Epoch 290/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.2886 - acc: 0.8817 - val_loss: 0.3451 - val_acc: 0.8814\n",
      "Epoch 291/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.2868 - acc: 0.8821 - val_loss: 0.3449 - val_acc: 0.8807\n",
      "Epoch 292/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2846 - acc: 0.8833 - val_loss: 0.3456 - val_acc: 0.8823\n",
      "Epoch 293/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2849 - acc: 0.8839 - val_loss: 0.3449 - val_acc: 0.8817\n",
      "Epoch 294/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2853 - acc: 0.8834 - val_loss: 0.3471 - val_acc: 0.8812\n",
      "Epoch 295/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2839 - acc: 0.8827 - val_loss: 0.3452 - val_acc: 0.8831\n",
      "Epoch 296/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2834 - acc: 0.8838 - val_loss: 0.3441 - val_acc: 0.8818\n",
      "Epoch 297/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2842 - acc: 0.8831 - val_loss: 0.3423 - val_acc: 0.8823\n",
      "Epoch 298/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2827 - acc: 0.8844 - val_loss: 0.3464 - val_acc: 0.8798\n",
      "Epoch 299/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2800 - acc: 0.8857 - val_loss: 0.3439 - val_acc: 0.8832\n",
      "Epoch 300/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2811 - acc: 0.8854 - val_loss: 0.3459 - val_acc: 0.8815\n",
      "Epoch 301/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2816 - acc: 0.8847 - val_loss: 0.3434 - val_acc: 0.8831\n",
      "Epoch 302/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2788 - acc: 0.8859 - val_loss: 0.3475 - val_acc: 0.8807\n",
      "Epoch 303/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2795 - acc: 0.8856 - val_loss: 0.3443 - val_acc: 0.8826\n",
      "Epoch 304/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2777 - acc: 0.8870 - val_loss: 0.3455 - val_acc: 0.8827\n",
      "Epoch 305/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2772 - acc: 0.8873 - val_loss: 0.3421 - val_acc: 0.8843\n",
      "Epoch 306/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.2766 - acc: 0.8865 - val_loss: 0.3431 - val_acc: 0.8829\n",
      "Epoch 307/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.2782 - acc: 0.8865 - val_loss: 0.3431 - val_acc: 0.8845\n",
      "Epoch 308/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2760 - acc: 0.8873 - val_loss: 0.3422 - val_acc: 0.8847\n",
      "Epoch 309/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2769 - acc: 0.8865 - val_loss: 0.3424 - val_acc: 0.8840\n",
      "Epoch 310/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2759 - acc: 0.8879 - val_loss: 0.3424 - val_acc: 0.8846\n",
      "Epoch 311/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2740 - acc: 0.8885 - val_loss: 0.3402 - val_acc: 0.8859\n",
      "Epoch 312/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2735 - acc: 0.8881 - val_loss: 0.3425 - val_acc: 0.8849\n",
      "Epoch 313/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2732 - acc: 0.8883 - val_loss: 0.3412 - val_acc: 0.8861\n",
      "Epoch 314/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2718 - acc: 0.8890 - val_loss: 0.3393 - val_acc: 0.8871\n",
      "Epoch 315/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2716 - acc: 0.8885 - val_loss: 0.3398 - val_acc: 0.8879\n",
      "Epoch 316/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.2713 - acc: 0.8884 - val_loss: 0.3438 - val_acc: 0.8861\n",
      "Epoch 317/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2703 - acc: 0.8901 - val_loss: 0.3419 - val_acc: 0.8872\n",
      "Epoch 318/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2708 - acc: 0.8895 - val_loss: 0.3401 - val_acc: 0.8869\n",
      "Epoch 319/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2682 - acc: 0.8897 - val_loss: 0.3400 - val_acc: 0.8893\n",
      "Epoch 320/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2694 - acc: 0.8901 - val_loss: 0.3395 - val_acc: 0.8880\n",
      "Epoch 321/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2679 - acc: 0.8904 - val_loss: 0.3427 - val_acc: 0.8872\n",
      "Epoch 322/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2667 - acc: 0.8906 - val_loss: 0.3424 - val_acc: 0.8867\n",
      "Epoch 323/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2666 - acc: 0.8911 - val_loss: 0.3424 - val_acc: 0.8873\n",
      "Epoch 324/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2674 - acc: 0.8908 - val_loss: 0.3385 - val_acc: 0.8876\n",
      "Epoch 325/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2667 - acc: 0.8915 - val_loss: 0.3418 - val_acc: 0.8872\n",
      "Epoch 326/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2647 - acc: 0.8914 - val_loss: 0.3418 - val_acc: 0.8871\n",
      "Epoch 327/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2640 - acc: 0.8926 - val_loss: 0.3407 - val_acc: 0.8871\n",
      "Epoch 328/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2624 - acc: 0.8934 - val_loss: 0.3437 - val_acc: 0.8865\n",
      "Epoch 329/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2637 - acc: 0.8917 - val_loss: 0.3391 - val_acc: 0.8893\n",
      "Epoch 330/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2633 - acc: 0.8926 - val_loss: 0.3392 - val_acc: 0.8884\n",
      "Epoch 331/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2634 - acc: 0.8931 - val_loss: 0.3398 - val_acc: 0.8873\n",
      "Epoch 332/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.2624 - acc: 0.8933 - val_loss: 0.3413 - val_acc: 0.8873\n",
      "Epoch 333/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2616 - acc: 0.8946 - val_loss: 0.3391 - val_acc: 0.8871\n",
      "Epoch 334/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.2603 - acc: 0.8945 - val_loss: 0.3386 - val_acc: 0.8877\n",
      "Epoch 335/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.2596 - acc: 0.8945 - val_loss: 0.3392 - val_acc: 0.8883\n",
      "Epoch 336/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.2611 - acc: 0.8934 - val_loss: 0.3382 - val_acc: 0.8883\n",
      "Epoch 337/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2589 - acc: 0.8949 - val_loss: 0.3388 - val_acc: 0.8893\n",
      "Epoch 338/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2584 - acc: 0.8949 - val_loss: 0.3389 - val_acc: 0.8884\n",
      "Epoch 339/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2566 - acc: 0.8953 - val_loss: 0.3391 - val_acc: 0.8903\n",
      "Epoch 340/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2583 - acc: 0.8949 - val_loss: 0.3378 - val_acc: 0.8897\n",
      "Epoch 341/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2562 - acc: 0.8960 - val_loss: 0.3375 - val_acc: 0.8910\n",
      "Epoch 342/800\n",
      "201351/201351 [==============================] - 11s 53us/step - loss: 0.2544 - acc: 0.8958 - val_loss: 0.3388 - val_acc: 0.8891\n",
      "Epoch 343/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2557 - acc: 0.8959 - val_loss: 0.3352 - val_acc: 0.8925\n",
      "Epoch 344/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2551 - acc: 0.8957 - val_loss: 0.3367 - val_acc: 0.8917\n",
      "Epoch 345/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2543 - acc: 0.8965 - val_loss: 0.3374 - val_acc: 0.8908\n",
      "Epoch 346/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2547 - acc: 0.8960 - val_loss: 0.3356 - val_acc: 0.8902\n",
      "Epoch 347/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2538 - acc: 0.8970 - val_loss: 0.3355 - val_acc: 0.8913\n",
      "Epoch 348/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2535 - acc: 0.8974 - val_loss: 0.3329 - val_acc: 0.8931\n",
      "Epoch 349/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2522 - acc: 0.8970 - val_loss: 0.3366 - val_acc: 0.8911\n",
      "Epoch 350/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2523 - acc: 0.8976 - val_loss: 0.3359 - val_acc: 0.8907\n",
      "Epoch 351/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2530 - acc: 0.8968 - val_loss: 0.3372 - val_acc: 0.8914\n",
      "Epoch 352/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2514 - acc: 0.8980 - val_loss: 0.3370 - val_acc: 0.8911\n",
      "Epoch 353/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2512 - acc: 0.8982 - val_loss: 0.3357 - val_acc: 0.8923\n",
      "Epoch 354/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2496 - acc: 0.8980 - val_loss: 0.3377 - val_acc: 0.8907\n",
      "Epoch 355/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2492 - acc: 0.8981 - val_loss: 0.3371 - val_acc: 0.8918\n",
      "Epoch 356/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2501 - acc: 0.8980 - val_loss: 0.3385 - val_acc: 0.8898\n",
      "Epoch 357/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2502 - acc: 0.8977 - val_loss: 0.3351 - val_acc: 0.8921\n",
      "Epoch 358/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2492 - acc: 0.8985 - val_loss: 0.3367 - val_acc: 0.8913\n",
      "Epoch 359/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2483 - acc: 0.8990 - val_loss: 0.3366 - val_acc: 0.8902\n",
      "Epoch 360/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2462 - acc: 0.8998 - val_loss: 0.3382 - val_acc: 0.8916\n",
      "Epoch 361/800\n",
      "201351/201351 [==============================] - 10s 51us/step - loss: 0.2473 - acc: 0.9001 - val_loss: 0.3396 - val_acc: 0.8910\n",
      "Epoch 362/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2497 - acc: 0.8987 - val_loss: 0.3321 - val_acc: 0.8944\n",
      "Epoch 363/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2466 - acc: 0.9000 - val_loss: 0.3366 - val_acc: 0.8927\n",
      "Epoch 364/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2445 - acc: 0.9007 - val_loss: 0.3334 - val_acc: 0.8942\n",
      "Epoch 365/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2457 - acc: 0.8998 - val_loss: 0.3371 - val_acc: 0.8926\n",
      "Epoch 366/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2453 - acc: 0.8995 - val_loss: 0.3359 - val_acc: 0.8940\n",
      "Epoch 367/800\n",
      "201351/201351 [==============================] - 10s 51us/step - loss: 0.2439 - acc: 0.9011 - val_loss: 0.3344 - val_acc: 0.8944\n",
      "Epoch 368/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2449 - acc: 0.9006 - val_loss: 0.3361 - val_acc: 0.8922\n",
      "Epoch 369/800\n",
      "201351/201351 [==============================] - 10s 51us/step - loss: 0.2427 - acc: 0.9017 - val_loss: 0.3355 - val_acc: 0.8940\n",
      "Epoch 370/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2423 - acc: 0.9016 - val_loss: 0.3365 - val_acc: 0.8949\n",
      "Epoch 371/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2429 - acc: 0.9014 - val_loss: 0.3350 - val_acc: 0.8965\n",
      "Epoch 372/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2431 - acc: 0.9015 - val_loss: 0.3365 - val_acc: 0.8938\n",
      "Epoch 373/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2417 - acc: 0.9025 - val_loss: 0.3356 - val_acc: 0.8949\n",
      "Epoch 374/800\n",
      "201351/201351 [==============================] - 10s 51us/step - loss: 0.2410 - acc: 0.9026 - val_loss: 0.3365 - val_acc: 0.8954\n",
      "Epoch 375/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2391 - acc: 0.9032 - val_loss: 0.3333 - val_acc: 0.8949\n",
      "Epoch 376/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2389 - acc: 0.9022 - val_loss: 0.3371 - val_acc: 0.8944\n",
      "Epoch 377/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2407 - acc: 0.9023 - val_loss: 0.3345 - val_acc: 0.8950\n",
      "Epoch 378/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2373 - acc: 0.9038 - val_loss: 0.3361 - val_acc: 0.8954\n",
      "Epoch 379/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2394 - acc: 0.9033 - val_loss: 0.3368 - val_acc: 0.8940\n",
      "Epoch 380/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2386 - acc: 0.9030 - val_loss: 0.3350 - val_acc: 0.8952\n",
      "Epoch 381/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2372 - acc: 0.9040 - val_loss: 0.3373 - val_acc: 0.8944\n",
      "Epoch 382/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2372 - acc: 0.9041 - val_loss: 0.3338 - val_acc: 0.8955\n",
      "Epoch 383/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2364 - acc: 0.9033 - val_loss: 0.3346 - val_acc: 0.8959\n",
      "Epoch 384/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2367 - acc: 0.9044 - val_loss: 0.3337 - val_acc: 0.8952\n",
      "Epoch 385/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2367 - acc: 0.9039 - val_loss: 0.3351 - val_acc: 0.8955\n",
      "Epoch 386/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2352 - acc: 0.9043 - val_loss: 0.3338 - val_acc: 0.8961\n",
      "Epoch 387/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2335 - acc: 0.9049 - val_loss: 0.3349 - val_acc: 0.8976\n",
      "Epoch 388/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2355 - acc: 0.9044 - val_loss: 0.3353 - val_acc: 0.8959\n",
      "Epoch 389/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2360 - acc: 0.9048 - val_loss: 0.3336 - val_acc: 0.8976\n",
      "Epoch 390/800\n",
      "201351/201351 [==============================] - 10s 51us/step - loss: 0.2327 - acc: 0.9051 - val_loss: 0.3321 - val_acc: 0.8969\n",
      "Epoch 391/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2327 - acc: 0.9051 - val_loss: 0.3362 - val_acc: 0.8960\n",
      "Epoch 392/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2329 - acc: 0.9056 - val_loss: 0.3357 - val_acc: 0.8963\n",
      "Epoch 393/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2329 - acc: 0.9059 - val_loss: 0.3349 - val_acc: 0.8974\n",
      "Epoch 394/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2317 - acc: 0.9062 - val_loss: 0.3343 - val_acc: 0.8967\n",
      "Epoch 395/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2322 - acc: 0.9062 - val_loss: 0.3344 - val_acc: 0.8971\n",
      "Epoch 396/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2314 - acc: 0.9060 - val_loss: 0.3332 - val_acc: 0.8973\n",
      "Epoch 397/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2304 - acc: 0.9074 - val_loss: 0.3349 - val_acc: 0.8982\n",
      "Epoch 398/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2301 - acc: 0.9064 - val_loss: 0.3360 - val_acc: 0.8962\n",
      "Epoch 399/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2299 - acc: 0.9069 - val_loss: 0.3354 - val_acc: 0.8983\n",
      "Epoch 400/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2303 - acc: 0.9072 - val_loss: 0.3335 - val_acc: 0.8978\n",
      "Epoch 401/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2291 - acc: 0.9074 - val_loss: 0.3332 - val_acc: 0.8984\n",
      "Epoch 402/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2297 - acc: 0.9078 - val_loss: 0.3328 - val_acc: 0.8975\n",
      "Epoch 403/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2287 - acc: 0.9078 - val_loss: 0.3331 - val_acc: 0.8987\n",
      "Epoch 404/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2293 - acc: 0.9069 - val_loss: 0.3320 - val_acc: 0.8989\n",
      "Epoch 405/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2288 - acc: 0.9079 - val_loss: 0.3327 - val_acc: 0.8982\n",
      "Epoch 406/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2274 - acc: 0.9084 - val_loss: 0.3308 - val_acc: 0.8980\n",
      "Epoch 407/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2270 - acc: 0.9085 - val_loss: 0.3316 - val_acc: 0.8992\n",
      "Epoch 408/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2266 - acc: 0.9080 - val_loss: 0.3319 - val_acc: 0.8982\n",
      "Epoch 409/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2263 - acc: 0.9084 - val_loss: 0.3355 - val_acc: 0.8969\n",
      "Epoch 410/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2262 - acc: 0.9084 - val_loss: 0.3328 - val_acc: 0.8991\n",
      "Epoch 411/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2259 - acc: 0.9085 - val_loss: 0.3328 - val_acc: 0.8987\n",
      "Epoch 412/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2249 - acc: 0.9095 - val_loss: 0.3346 - val_acc: 0.8986\n",
      "Epoch 413/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2245 - acc: 0.9095 - val_loss: 0.3320 - val_acc: 0.8998\n",
      "Epoch 414/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2237 - acc: 0.9097 - val_loss: 0.3335 - val_acc: 0.8984\n",
      "Epoch 415/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2240 - acc: 0.9092 - val_loss: 0.3332 - val_acc: 0.8984\n",
      "Epoch 416/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2222 - acc: 0.9103 - val_loss: 0.3325 - val_acc: 0.8998\n",
      "Epoch 417/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2232 - acc: 0.9103 - val_loss: 0.3343 - val_acc: 0.8983\n",
      "Epoch 418/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2224 - acc: 0.9104 - val_loss: 0.3343 - val_acc: 0.8993\n",
      "Epoch 419/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2226 - acc: 0.9097 - val_loss: 0.3318 - val_acc: 0.9000\n",
      "Epoch 420/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2214 - acc: 0.9110 - val_loss: 0.3347 - val_acc: 0.8984\n",
      "Epoch 421/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2227 - acc: 0.9104 - val_loss: 0.3329 - val_acc: 0.9015\n",
      "Epoch 422/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2198 - acc: 0.9118 - val_loss: 0.3345 - val_acc: 0.8997\n",
      "Epoch 423/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2207 - acc: 0.9113 - val_loss: 0.3348 - val_acc: 0.8979\n",
      "Epoch 424/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2196 - acc: 0.9117 - val_loss: 0.3342 - val_acc: 0.8991\n",
      "Epoch 425/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2192 - acc: 0.9111 - val_loss: 0.3344 - val_acc: 0.8996\n",
      "Epoch 426/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2194 - acc: 0.9118 - val_loss: 0.3331 - val_acc: 0.8990\n",
      "Epoch 427/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2175 - acc: 0.9124 - val_loss: 0.3337 - val_acc: 0.8992\n",
      "Epoch 428/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2193 - acc: 0.9115 - val_loss: 0.3339 - val_acc: 0.8990\n",
      "Epoch 429/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2173 - acc: 0.9131 - val_loss: 0.3338 - val_acc: 0.8996\n",
      "Epoch 430/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2171 - acc: 0.9130 - val_loss: 0.3358 - val_acc: 0.9000\n",
      "Epoch 431/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2178 - acc: 0.9121 - val_loss: 0.3347 - val_acc: 0.9005\n",
      "Epoch 432/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2190 - acc: 0.9124 - val_loss: 0.3349 - val_acc: 0.8994\n",
      "Epoch 433/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2180 - acc: 0.9119 - val_loss: 0.3351 - val_acc: 0.8985\n",
      "Epoch 434/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2171 - acc: 0.9125 - val_loss: 0.3330 - val_acc: 0.8999\n",
      "Epoch 435/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2161 - acc: 0.9129 - val_loss: 0.3313 - val_acc: 0.9005\n",
      "Epoch 436/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2167 - acc: 0.9126 - val_loss: 0.3335 - val_acc: 0.9004\n",
      "Epoch 437/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2165 - acc: 0.9118 - val_loss: 0.3314 - val_acc: 0.9013\n",
      "Epoch 438/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2145 - acc: 0.9133 - val_loss: 0.3333 - val_acc: 0.9011\n",
      "Epoch 439/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2167 - acc: 0.9131 - val_loss: 0.3348 - val_acc: 0.9003\n",
      "Epoch 440/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2156 - acc: 0.9134 - val_loss: 0.3330 - val_acc: 0.9010\n",
      "Epoch 441/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2165 - acc: 0.9135 - val_loss: 0.3321 - val_acc: 0.9016\n",
      "Epoch 442/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2148 - acc: 0.9136 - val_loss: 0.3311 - val_acc: 0.9013\n",
      "Epoch 443/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2129 - acc: 0.9143 - val_loss: 0.3316 - val_acc: 0.9014\n",
      "Epoch 444/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2124 - acc: 0.9150 - val_loss: 0.3307 - val_acc: 0.9006\n",
      "Epoch 445/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2132 - acc: 0.9142 - val_loss: 0.3312 - val_acc: 0.9004\n",
      "Epoch 446/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2130 - acc: 0.9148 - val_loss: 0.3315 - val_acc: 0.9016\n",
      "Epoch 447/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2115 - acc: 0.9145 - val_loss: 0.3335 - val_acc: 0.9022\n",
      "Epoch 448/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2135 - acc: 0.9146 - val_loss: 0.3298 - val_acc: 0.9020\n",
      "Epoch 449/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2115 - acc: 0.9150 - val_loss: 0.3322 - val_acc: 0.9024\n",
      "Epoch 450/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2102 - acc: 0.9152 - val_loss: 0.3315 - val_acc: 0.9022\n",
      "Epoch 451/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2117 - acc: 0.9151 - val_loss: 0.3330 - val_acc: 0.9019\n",
      "Epoch 452/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2109 - acc: 0.9155 - val_loss: 0.3312 - val_acc: 0.9024\n",
      "Epoch 453/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2101 - acc: 0.9158 - val_loss: 0.3357 - val_acc: 0.9025\n",
      "Epoch 454/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2086 - acc: 0.9168 - val_loss: 0.3326 - val_acc: 0.9014\n",
      "Epoch 455/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2083 - acc: 0.9166 - val_loss: 0.3330 - val_acc: 0.9013\n",
      "Epoch 456/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2085 - acc: 0.9160 - val_loss: 0.3349 - val_acc: 0.9010\n",
      "Epoch 457/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2100 - acc: 0.9157 - val_loss: 0.3345 - val_acc: 0.9008\n",
      "Epoch 458/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2088 - acc: 0.9164 - val_loss: 0.3350 - val_acc: 0.9021\n",
      "Epoch 459/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2088 - acc: 0.9162 - val_loss: 0.3301 - val_acc: 0.9031\n",
      "Epoch 460/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2078 - acc: 0.9166 - val_loss: 0.3337 - val_acc: 0.9030\n",
      "Epoch 461/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2082 - acc: 0.9160 - val_loss: 0.3337 - val_acc: 0.9021\n",
      "Epoch 462/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2088 - acc: 0.9165 - val_loss: 0.3312 - val_acc: 0.9033\n",
      "Epoch 463/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2075 - acc: 0.9166 - val_loss: 0.3302 - val_acc: 0.9037\n",
      "Epoch 464/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2065 - acc: 0.9164 - val_loss: 0.3318 - val_acc: 0.9033\n",
      "Epoch 465/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2072 - acc: 0.9170 - val_loss: 0.3304 - val_acc: 0.9029\n",
      "Epoch 466/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2063 - acc: 0.9171 - val_loss: 0.3309 - val_acc: 0.9029\n",
      "Epoch 467/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2061 - acc: 0.9167 - val_loss: 0.3319 - val_acc: 0.9037\n",
      "Epoch 468/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2066 - acc: 0.9168 - val_loss: 0.3319 - val_acc: 0.9044\n",
      "Epoch 469/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2044 - acc: 0.9181 - val_loss: 0.3332 - val_acc: 0.9037\n",
      "Epoch 470/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2050 - acc: 0.9175 - val_loss: 0.3341 - val_acc: 0.9021\n",
      "Epoch 471/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.2047 - acc: 0.9179 - val_loss: 0.3353 - val_acc: 0.9020\n",
      "Epoch 472/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2043 - acc: 0.9179 - val_loss: 0.3340 - val_acc: 0.9039\n",
      "Epoch 473/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2059 - acc: 0.9175 - val_loss: 0.3321 - val_acc: 0.9044\n",
      "Epoch 474/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2042 - acc: 0.9176 - val_loss: 0.3332 - val_acc: 0.9037\n",
      "Epoch 475/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2031 - acc: 0.9185 - val_loss: 0.3303 - val_acc: 0.9050\n",
      "Epoch 476/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2039 - acc: 0.9180 - val_loss: 0.3300 - val_acc: 0.9044\n",
      "Epoch 477/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2047 - acc: 0.9178 - val_loss: 0.3338 - val_acc: 0.9034\n",
      "Epoch 478/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.2041 - acc: 0.9175 - val_loss: 0.3321 - val_acc: 0.9057\n",
      "Epoch 479/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1646 - acc: 0.9353 - val_loss: 0.3468 - val_acc: 0.9107\n",
      "Epoch 659/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1636 - acc: 0.9356 - val_loss: 0.3428 - val_acc: 0.9114\n",
      "Epoch 660/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1634 - acc: 0.9355 - val_loss: 0.3459 - val_acc: 0.9107\n",
      "Epoch 661/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1631 - acc: 0.9363 - val_loss: 0.3448 - val_acc: 0.9121\n",
      "Epoch 662/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1644 - acc: 0.9350 - val_loss: 0.3467 - val_acc: 0.9127\n",
      "Epoch 663/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1634 - acc: 0.9365 - val_loss: 0.3438 - val_acc: 0.9126\n",
      "Epoch 664/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1616 - acc: 0.9365 - val_loss: 0.3481 - val_acc: 0.9122\n",
      "Epoch 665/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1631 - acc: 0.9359 - val_loss: 0.3429 - val_acc: 0.9140\n",
      "Epoch 666/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1618 - acc: 0.9363 - val_loss: 0.3456 - val_acc: 0.9131\n",
      "Epoch 667/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1631 - acc: 0.9356 - val_loss: 0.3435 - val_acc: 0.9120\n",
      "Epoch 668/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.1630 - acc: 0.9362 - val_loss: 0.3429 - val_acc: 0.9127\n",
      "Epoch 669/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.1623 - acc: 0.9362 - val_loss: 0.3442 - val_acc: 0.9117\n",
      "Epoch 670/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1608 - acc: 0.9371 - val_loss: 0.3504 - val_acc: 0.9117\n",
      "Epoch 671/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.1605 - acc: 0.9375 - val_loss: 0.3426 - val_acc: 0.9136\n",
      "Epoch 672/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1605 - acc: 0.9371 - val_loss: 0.3468 - val_acc: 0.9119\n",
      "Epoch 673/800\n",
      "201351/201351 [==============================] - 11s 52us/step - loss: 0.1631 - acc: 0.9362 - val_loss: 0.3478 - val_acc: 0.9122\n",
      "Epoch 674/800\n",
      "144200/201351 [====================>.........] - ETA: 2s - loss: 0.1599 - acc: 0.9371"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1527 - acc: 0.9406 - val_loss: 0.3484 - val_acc: 0.9143\n",
      "Epoch 736/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1526 - acc: 0.9403 - val_loss: 0.3482 - val_acc: 0.9136\n",
      "Epoch 737/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1533 - acc: 0.9404 - val_loss: 0.3469 - val_acc: 0.9134\n",
      "Epoch 738/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1521 - acc: 0.9413 - val_loss: 0.3491 - val_acc: 0.9139\n",
      "Epoch 739/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1521 - acc: 0.9409 - val_loss: 0.3469 - val_acc: 0.9150\n",
      "Epoch 740/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1523 - acc: 0.9406 - val_loss: 0.3477 - val_acc: 0.9141\n",
      "Epoch 741/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1521 - acc: 0.9405 - val_loss: 0.3486 - val_acc: 0.9147\n",
      "Epoch 742/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1508 - acc: 0.9411 - val_loss: 0.3488 - val_acc: 0.9155\n",
      "Epoch 743/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1526 - acc: 0.9403 - val_loss: 0.3460 - val_acc: 0.9141\n",
      "Epoch 744/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1505 - acc: 0.9417 - val_loss: 0.3479 - val_acc: 0.9151\n",
      "Epoch 745/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1507 - acc: 0.9411 - val_loss: 0.3451 - val_acc: 0.9139\n",
      "Epoch 746/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1522 - acc: 0.9410 - val_loss: 0.3464 - val_acc: 0.9147\n",
      "Epoch 747/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1532 - acc: 0.9406 - val_loss: 0.3482 - val_acc: 0.9140\n",
      "Epoch 748/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1508 - acc: 0.9409 - val_loss: 0.3451 - val_acc: 0.9146\n",
      "Epoch 749/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1503 - acc: 0.9414 - val_loss: 0.3438 - val_acc: 0.9151\n",
      "Epoch 750/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1498 - acc: 0.9418 - val_loss: 0.3485 - val_acc: 0.9146\n",
      "Epoch 751/800\n",
      "201351/201351 [==============================] - 10s 52us/step - loss: 0.1510 - acc: 0.9415 - val_loss: 0.3482 - val_acc: 0.9146\n",
      "Epoch 752/800\n",
      "  4400/201351 [..............................] - ETA: 10s - loss: 0.1470 - acc: 0.9455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "sys.path.append(os.path.realpath(\"../../\"))\n",
    "import ptetaphi_nn\n",
    "import tools\n",
    "\n",
    "# get data file path\n",
    "with open(\"/home/cmccracken/start_tf/bbb/filepath.txt\", 'r') as f:\n",
    "    filename = f.read()\n",
    "    \n",
    "s_table = tools.open_file(filename, sort_by=\"tag\", pt_cut=40, eta_cut=2.5)\n",
    "\n",
    "# filter for events with 3 b tags\n",
    "nt3 = s_table.nbtags==3 \n",
    "events = s_table[nt3]\n",
    "print(len(events))\n",
    "\n",
    "cutoff = 10  # not many events have >10 jets\n",
    "# \"pad\" = ensure all events have same length, cut off ends if needed\n",
    "events = tools.pad(events, cutoff)\n",
    "\n",
    "# make and train network\n",
    "nn = ptetaphi_nn.PtEtaPhiNN(events, chop=0, print_summary=True)\n",
    "nn.learn(epochs=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57529/57529 [00:00<00:00, 113509.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 91.53 percent\n",
      "ignoring 1.40 percent (808 events) of 57529 events\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(savename=\"with_cuts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the architecture string to a file\n",
    "models_dir = \"/home/cmccracken/start_tf/bbb/models/\"\n",
    "with open(models_dir+'architecture_23_07_2020.json', 'w') as arch_file:\n",
    "    arch_file.write(nn.model.to_json())\n",
    "# now save the weights as an HDF5 file\n",
    "nn.model.save_weights(models_dir+'weights_23_07_2020.h5')\n",
    "# use nn_tester to get csv!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
