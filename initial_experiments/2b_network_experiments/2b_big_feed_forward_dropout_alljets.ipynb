{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The Best Model As Of July 2 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting data by tag\n",
      "308955\n",
      "303925\n",
      "creating default model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 700)               21700     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 408       \n",
      "=================================================================\n",
      "Total params: 558,988\n",
      "Trainable params: 558,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 212747 samples, validate on 30393 samples\n",
      "Epoch 1/800\n",
      "212747/212747 [==============================] - 12s 56us/step - loss: 1.2386 - acc: 0.4887 - val_loss: 1.0900 - val_acc: 0.5385\n",
      "Epoch 2/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 1.0763 - acc: 0.5404 - val_loss: 1.0428 - val_acc: 0.5581\n",
      "Epoch 3/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 1.0416 - acc: 0.5575 - val_loss: 1.0130 - val_acc: 0.5712\n",
      "Epoch 4/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 1.0187 - acc: 0.5675 - val_loss: 0.9944 - val_acc: 0.5801\n",
      "Epoch 5/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 1.0024 - acc: 0.5732 - val_loss: 0.9788 - val_acc: 0.5857\n",
      "Epoch 6/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.9888 - acc: 0.5790 - val_loss: 0.9673 - val_acc: 0.5911\n",
      "Epoch 7/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.9772 - acc: 0.5845 - val_loss: 0.9558 - val_acc: 0.5941\n",
      "Epoch 8/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.9679 - acc: 0.5871 - val_loss: 0.9473 - val_acc: 0.5989\n",
      "Epoch 9/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.9580 - acc: 0.5915 - val_loss: 0.9386 - val_acc: 0.6012\n",
      "Epoch 10/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.9504 - acc: 0.5946 - val_loss: 0.9307 - val_acc: 0.6033\n",
      "Epoch 11/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.9423 - acc: 0.5983 - val_loss: 0.9241 - val_acc: 0.6038\n",
      "Epoch 12/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.9352 - acc: 0.6008 - val_loss: 0.9147 - val_acc: 0.6104\n",
      "Epoch 13/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.9287 - acc: 0.6029 - val_loss: 0.9077 - val_acc: 0.6122\n",
      "Epoch 14/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.9225 - acc: 0.6058 - val_loss: 0.9018 - val_acc: 0.6168\n",
      "Epoch 15/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.9159 - acc: 0.6085 - val_loss: 0.8967 - val_acc: 0.6184\n",
      "Epoch 16/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.9108 - acc: 0.6117 - val_loss: 0.8905 - val_acc: 0.6219\n",
      "Epoch 17/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.9057 - acc: 0.6137 - val_loss: 0.8870 - val_acc: 0.6238\n",
      "Epoch 18/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.9001 - acc: 0.6160 - val_loss: 0.8820 - val_acc: 0.6254\n",
      "Epoch 19/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.8955 - acc: 0.6183 - val_loss: 0.8772 - val_acc: 0.6272\n",
      "Epoch 20/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8911 - acc: 0.6201 - val_loss: 0.8722 - val_acc: 0.6301\n",
      "Epoch 21/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.8864 - acc: 0.6226 - val_loss: 0.8674 - val_acc: 0.6322\n",
      "Epoch 22/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8825 - acc: 0.6245 - val_loss: 0.8632 - val_acc: 0.6348\n",
      "Epoch 23/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8778 - acc: 0.6263 - val_loss: 0.8593 - val_acc: 0.6375\n",
      "Epoch 24/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8734 - acc: 0.6290 - val_loss: 0.8541 - val_acc: 0.6411\n",
      "Epoch 25/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8688 - acc: 0.6326 - val_loss: 0.8518 - val_acc: 0.6413\n",
      "Epoch 26/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8652 - acc: 0.6333 - val_loss: 0.8471 - val_acc: 0.6429\n",
      "Epoch 27/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.8621 - acc: 0.6341 - val_loss: 0.8425 - val_acc: 0.6463\n",
      "Epoch 28/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.8581 - acc: 0.6369 - val_loss: 0.8386 - val_acc: 0.6468\n",
      "Epoch 29/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8546 - acc: 0.6380 - val_loss: 0.8354 - val_acc: 0.6495\n",
      "Epoch 30/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8509 - acc: 0.6397 - val_loss: 0.8318 - val_acc: 0.6503\n",
      "Epoch 31/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8480 - acc: 0.6410 - val_loss: 0.8328 - val_acc: 0.6490\n",
      "Epoch 32/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8438 - acc: 0.6431 - val_loss: 0.8260 - val_acc: 0.6524\n",
      "Epoch 33/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8415 - acc: 0.6442 - val_loss: 0.8231 - val_acc: 0.6544\n",
      "Epoch 34/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8384 - acc: 0.6450 - val_loss: 0.8189 - val_acc: 0.6569\n",
      "Epoch 35/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8353 - acc: 0.6466 - val_loss: 0.8193 - val_acc: 0.6537\n",
      "Epoch 36/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8323 - acc: 0.6478 - val_loss: 0.8136 - val_acc: 0.6566\n",
      "Epoch 37/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8294 - acc: 0.6490 - val_loss: 0.8093 - val_acc: 0.6597\n",
      "Epoch 38/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8272 - acc: 0.6508 - val_loss: 0.8069 - val_acc: 0.6606\n",
      "Epoch 39/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.8243 - acc: 0.6511 - val_loss: 0.8085 - val_acc: 0.6602\n",
      "Epoch 40/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8220 - acc: 0.6526 - val_loss: 0.8059 - val_acc: 0.6611\n",
      "Epoch 41/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8191 - acc: 0.6534 - val_loss: 0.8015 - val_acc: 0.6640\n",
      "Epoch 42/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.8173 - acc: 0.6541 - val_loss: 0.7975 - val_acc: 0.6662\n",
      "Epoch 43/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8140 - acc: 0.6558 - val_loss: 0.7940 - val_acc: 0.6666\n",
      "Epoch 44/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8121 - acc: 0.6571 - val_loss: 0.7939 - val_acc: 0.6678\n",
      "Epoch 45/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8098 - acc: 0.6578 - val_loss: 0.7906 - val_acc: 0.6700\n",
      "Epoch 46/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8077 - acc: 0.6587 - val_loss: 0.7875 - val_acc: 0.6692\n",
      "Epoch 47/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8055 - acc: 0.6601 - val_loss: 0.7858 - val_acc: 0.6699\n",
      "Epoch 48/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.8032 - acc: 0.6609 - val_loss: 0.7829 - val_acc: 0.6713\n",
      "Epoch 49/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.8010 - acc: 0.6617 - val_loss: 0.7832 - val_acc: 0.6716\n",
      "Epoch 50/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7996 - acc: 0.6626 - val_loss: 0.7796 - val_acc: 0.6739\n",
      "Epoch 51/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7981 - acc: 0.6629 - val_loss: 0.7774 - val_acc: 0.6750\n",
      "Epoch 52/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7952 - acc: 0.6640 - val_loss: 0.7758 - val_acc: 0.6767\n",
      "Epoch 53/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7929 - acc: 0.6657 - val_loss: 0.7749 - val_acc: 0.6755\n",
      "Epoch 54/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7915 - acc: 0.6665 - val_loss: 0.7723 - val_acc: 0.6780\n",
      "Epoch 55/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7895 - acc: 0.6662 - val_loss: 0.7717 - val_acc: 0.6775\n",
      "Epoch 56/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7877 - acc: 0.6674 - val_loss: 0.7690 - val_acc: 0.6789\n",
      "Epoch 57/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.7859 - acc: 0.6683 - val_loss: 0.7662 - val_acc: 0.6793\n",
      "Epoch 58/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7840 - acc: 0.6690 - val_loss: 0.7662 - val_acc: 0.6781\n",
      "Epoch 59/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7805 - acc: 0.6709 - val_loss: 0.7635 - val_acc: 0.6814\n",
      "Epoch 60/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7790 - acc: 0.6718 - val_loss: 0.7600 - val_acc: 0.6823\n",
      "Epoch 61/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7778 - acc: 0.6713 - val_loss: 0.7590 - val_acc: 0.6839\n",
      "Epoch 62/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.7755 - acc: 0.6729 - val_loss: 0.7588 - val_acc: 0.6834\n",
      "Epoch 63/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7741 - acc: 0.6740 - val_loss: 0.7581 - val_acc: 0.6829\n",
      "Epoch 64/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7716 - acc: 0.6745 - val_loss: 0.7555 - val_acc: 0.6837\n",
      "Epoch 65/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.7700 - acc: 0.6757 - val_loss: 0.7512 - val_acc: 0.6878\n",
      "Epoch 66/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.7680 - acc: 0.6757 - val_loss: 0.7490 - val_acc: 0.6877\n",
      "Epoch 67/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7655 - acc: 0.6778 - val_loss: 0.7462 - val_acc: 0.6899\n",
      "Epoch 68/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7630 - acc: 0.6785 - val_loss: 0.7450 - val_acc: 0.6896\n",
      "Epoch 69/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7618 - acc: 0.6794 - val_loss: 0.7430 - val_acc: 0.6906\n",
      "Epoch 70/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7599 - acc: 0.6803 - val_loss: 0.7416 - val_acc: 0.6908\n",
      "Epoch 71/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7576 - acc: 0.6804 - val_loss: 0.7397 - val_acc: 0.6935\n",
      "Epoch 72/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7557 - acc: 0.6816 - val_loss: 0.7387 - val_acc: 0.6909\n",
      "Epoch 73/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7543 - acc: 0.6820 - val_loss: 0.7361 - val_acc: 0.6954\n",
      "Epoch 74/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7526 - acc: 0.6834 - val_loss: 0.7346 - val_acc: 0.6956\n",
      "Epoch 75/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7504 - acc: 0.6832 - val_loss: 0.7312 - val_acc: 0.6978\n",
      "Epoch 76/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7475 - acc: 0.6853 - val_loss: 0.7310 - val_acc: 0.6964\n",
      "Epoch 77/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7455 - acc: 0.6860 - val_loss: 0.7286 - val_acc: 0.6984\n",
      "Epoch 78/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7447 - acc: 0.6859 - val_loss: 0.7266 - val_acc: 0.6985\n",
      "Epoch 79/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7424 - acc: 0.6874 - val_loss: 0.7276 - val_acc: 0.6979\n",
      "Epoch 80/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.7418 - acc: 0.6877 - val_loss: 0.7242 - val_acc: 0.6986\n",
      "Epoch 81/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7391 - acc: 0.6894 - val_loss: 0.7214 - val_acc: 0.7008\n",
      "Epoch 82/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7374 - acc: 0.6898 - val_loss: 0.7186 - val_acc: 0.7015\n",
      "Epoch 83/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7350 - acc: 0.6905 - val_loss: 0.7192 - val_acc: 0.7012\n",
      "Epoch 84/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7337 - acc: 0.6910 - val_loss: 0.7186 - val_acc: 0.7004\n",
      "Epoch 85/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7325 - acc: 0.6912 - val_loss: 0.7137 - val_acc: 0.7039\n",
      "Epoch 86/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7298 - acc: 0.6922 - val_loss: 0.7139 - val_acc: 0.7036\n",
      "Epoch 87/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7283 - acc: 0.6940 - val_loss: 0.7134 - val_acc: 0.7033\n",
      "Epoch 88/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7256 - acc: 0.6947 - val_loss: 0.7115 - val_acc: 0.7046\n",
      "Epoch 89/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7251 - acc: 0.6948 - val_loss: 0.7090 - val_acc: 0.7048\n",
      "Epoch 90/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7232 - acc: 0.6957 - val_loss: 0.7062 - val_acc: 0.7059\n",
      "Epoch 91/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7221 - acc: 0.6959 - val_loss: 0.7061 - val_acc: 0.7065\n",
      "Epoch 92/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7202 - acc: 0.6971 - val_loss: 0.7056 - val_acc: 0.7057\n",
      "Epoch 93/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7176 - acc: 0.6980 - val_loss: 0.7027 - val_acc: 0.7082\n",
      "Epoch 94/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7159 - acc: 0.6987 - val_loss: 0.7010 - val_acc: 0.7084\n",
      "Epoch 95/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7138 - acc: 0.6997 - val_loss: 0.6993 - val_acc: 0.7092\n",
      "Epoch 96/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7135 - acc: 0.6999 - val_loss: 0.6988 - val_acc: 0.7087\n",
      "Epoch 97/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7113 - acc: 0.7007 - val_loss: 0.6959 - val_acc: 0.7106\n",
      "Epoch 98/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7101 - acc: 0.7012 - val_loss: 0.6947 - val_acc: 0.7096\n",
      "Epoch 99/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7081 - acc: 0.7014 - val_loss: 0.6922 - val_acc: 0.7115\n",
      "Epoch 100/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7068 - acc: 0.7024 - val_loss: 0.6909 - val_acc: 0.7126\n",
      "Epoch 101/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7051 - acc: 0.7038 - val_loss: 0.6904 - val_acc: 0.7126\n",
      "Epoch 102/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7028 - acc: 0.7046 - val_loss: 0.6884 - val_acc: 0.7125\n",
      "Epoch 103/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7023 - acc: 0.7042 - val_loss: 0.6876 - val_acc: 0.7143\n",
      "Epoch 104/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.7004 - acc: 0.7053 - val_loss: 0.6878 - val_acc: 0.7132\n",
      "Epoch 105/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6989 - acc: 0.7056 - val_loss: 0.6841 - val_acc: 0.7165\n",
      "Epoch 106/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6977 - acc: 0.7069 - val_loss: 0.6821 - val_acc: 0.7158\n",
      "Epoch 107/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6969 - acc: 0.7070 - val_loss: 0.6817 - val_acc: 0.7178\n",
      "Epoch 108/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6941 - acc: 0.7081 - val_loss: 0.6797 - val_acc: 0.7159\n",
      "Epoch 109/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6924 - acc: 0.7089 - val_loss: 0.6779 - val_acc: 0.7168\n",
      "Epoch 110/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6905 - acc: 0.7096 - val_loss: 0.6764 - val_acc: 0.7191\n",
      "Epoch 111/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6890 - acc: 0.7112 - val_loss: 0.6762 - val_acc: 0.7171\n",
      "Epoch 112/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6879 - acc: 0.7113 - val_loss: 0.6764 - val_acc: 0.7186\n",
      "Epoch 113/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6868 - acc: 0.7105 - val_loss: 0.6717 - val_acc: 0.7186\n",
      "Epoch 114/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6846 - acc: 0.7116 - val_loss: 0.6716 - val_acc: 0.7207\n",
      "Epoch 115/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6843 - acc: 0.7119 - val_loss: 0.6723 - val_acc: 0.7201\n",
      "Epoch 116/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6812 - acc: 0.7132 - val_loss: 0.6691 - val_acc: 0.7199\n",
      "Epoch 117/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6800 - acc: 0.7138 - val_loss: 0.6670 - val_acc: 0.7218\n",
      "Epoch 118/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6788 - acc: 0.7154 - val_loss: 0.6665 - val_acc: 0.7227\n",
      "Epoch 119/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6775 - acc: 0.7147 - val_loss: 0.6671 - val_acc: 0.7218\n",
      "Epoch 120/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6756 - acc: 0.7155 - val_loss: 0.6636 - val_acc: 0.7230\n",
      "Epoch 121/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6748 - acc: 0.7160 - val_loss: 0.6638 - val_acc: 0.7249\n",
      "Epoch 122/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6723 - acc: 0.7181 - val_loss: 0.6608 - val_acc: 0.7252\n",
      "Epoch 123/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6714 - acc: 0.7166 - val_loss: 0.6592 - val_acc: 0.7272\n",
      "Epoch 124/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6709 - acc: 0.7180 - val_loss: 0.6575 - val_acc: 0.7281\n",
      "Epoch 125/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6691 - acc: 0.7186 - val_loss: 0.6574 - val_acc: 0.7274\n",
      "Epoch 126/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6666 - acc: 0.7195 - val_loss: 0.6540 - val_acc: 0.7303\n",
      "Epoch 127/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6652 - acc: 0.7192 - val_loss: 0.6542 - val_acc: 0.7295\n",
      "Epoch 128/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6645 - acc: 0.7207 - val_loss: 0.6541 - val_acc: 0.7293\n",
      "Epoch 129/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6627 - acc: 0.7207 - val_loss: 0.6521 - val_acc: 0.7297\n",
      "Epoch 130/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6609 - acc: 0.7216 - val_loss: 0.6516 - val_acc: 0.7280\n",
      "Epoch 131/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6608 - acc: 0.7221 - val_loss: 0.6499 - val_acc: 0.7306\n",
      "Epoch 132/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6576 - acc: 0.7230 - val_loss: 0.6482 - val_acc: 0.7320\n",
      "Epoch 133/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6570 - acc: 0.7230 - val_loss: 0.6475 - val_acc: 0.7327\n",
      "Epoch 134/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6560 - acc: 0.7246 - val_loss: 0.6465 - val_acc: 0.7327\n",
      "Epoch 135/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6538 - acc: 0.7247 - val_loss: 0.6455 - val_acc: 0.7340\n",
      "Epoch 136/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6515 - acc: 0.7260 - val_loss: 0.6444 - val_acc: 0.7347\n",
      "Epoch 137/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6505 - acc: 0.7260 - val_loss: 0.6441 - val_acc: 0.7329\n",
      "Epoch 138/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6501 - acc: 0.7265 - val_loss: 0.6428 - val_acc: 0.7340\n",
      "Epoch 139/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6481 - acc: 0.7283 - val_loss: 0.6428 - val_acc: 0.7347\n",
      "Epoch 140/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6479 - acc: 0.7276 - val_loss: 0.6382 - val_acc: 0.7387\n",
      "Epoch 141/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6458 - acc: 0.7285 - val_loss: 0.6395 - val_acc: 0.7368\n",
      "Epoch 142/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6432 - acc: 0.7297 - val_loss: 0.6388 - val_acc: 0.7378\n",
      "Epoch 143/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6422 - acc: 0.7295 - val_loss: 0.6360 - val_acc: 0.7389\n",
      "Epoch 144/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6422 - acc: 0.7301 - val_loss: 0.6351 - val_acc: 0.7380\n",
      "Epoch 145/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6406 - acc: 0.7298 - val_loss: 0.6359 - val_acc: 0.7391\n",
      "Epoch 146/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6368 - acc: 0.7315 - val_loss: 0.6337 - val_acc: 0.7382\n",
      "Epoch 147/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6371 - acc: 0.7319 - val_loss: 0.6324 - val_acc: 0.7411\n",
      "Epoch 148/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6351 - acc: 0.7335 - val_loss: 0.6300 - val_acc: 0.7415\n",
      "Epoch 149/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6336 - acc: 0.7334 - val_loss: 0.6287 - val_acc: 0.7418\n",
      "Epoch 150/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6323 - acc: 0.7341 - val_loss: 0.6299 - val_acc: 0.7426\n",
      "Epoch 151/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6312 - acc: 0.7341 - val_loss: 0.6263 - val_acc: 0.7442\n",
      "Epoch 152/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6298 - acc: 0.7352 - val_loss: 0.6289 - val_acc: 0.7415\n",
      "Epoch 153/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6281 - acc: 0.7358 - val_loss: 0.6247 - val_acc: 0.7457\n",
      "Epoch 154/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6277 - acc: 0.7355 - val_loss: 0.6219 - val_acc: 0.7477\n",
      "Epoch 155/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6254 - acc: 0.7363 - val_loss: 0.6226 - val_acc: 0.7453\n",
      "Epoch 156/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6240 - acc: 0.7369 - val_loss: 0.6226 - val_acc: 0.7439\n",
      "Epoch 157/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6230 - acc: 0.7379 - val_loss: 0.6218 - val_acc: 0.7459\n",
      "Epoch 158/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6202 - acc: 0.7392 - val_loss: 0.6196 - val_acc: 0.7477\n",
      "Epoch 159/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6198 - acc: 0.7400 - val_loss: 0.6206 - val_acc: 0.7468\n",
      "Epoch 160/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6191 - acc: 0.7397 - val_loss: 0.6173 - val_acc: 0.7496\n",
      "Epoch 161/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6170 - acc: 0.7401 - val_loss: 0.6154 - val_acc: 0.7494\n",
      "Epoch 162/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6150 - acc: 0.7421 - val_loss: 0.6143 - val_acc: 0.7494\n",
      "Epoch 163/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6143 - acc: 0.7409 - val_loss: 0.6158 - val_acc: 0.7503\n",
      "Epoch 164/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6113 - acc: 0.7429 - val_loss: 0.6129 - val_acc: 0.7520\n",
      "Epoch 165/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6111 - acc: 0.7434 - val_loss: 0.6107 - val_acc: 0.7517\n",
      "Epoch 166/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6105 - acc: 0.7426 - val_loss: 0.6124 - val_acc: 0.7528\n",
      "Epoch 167/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6090 - acc: 0.7445 - val_loss: 0.6089 - val_acc: 0.7540\n",
      "Epoch 168/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6071 - acc: 0.7439 - val_loss: 0.6083 - val_acc: 0.7537\n",
      "Epoch 169/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6056 - acc: 0.7465 - val_loss: 0.6072 - val_acc: 0.7543\n",
      "Epoch 170/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6042 - acc: 0.7466 - val_loss: 0.6072 - val_acc: 0.7533\n",
      "Epoch 171/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6038 - acc: 0.7461 - val_loss: 0.6054 - val_acc: 0.7568\n",
      "Epoch 172/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.6024 - acc: 0.7475 - val_loss: 0.6062 - val_acc: 0.7552\n",
      "Epoch 173/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.6008 - acc: 0.7473 - val_loss: 0.6060 - val_acc: 0.7564\n",
      "Epoch 174/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5984 - acc: 0.7484 - val_loss: 0.6047 - val_acc: 0.7551\n",
      "Epoch 175/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5970 - acc: 0.7493 - val_loss: 0.6038 - val_acc: 0.7557\n",
      "Epoch 176/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5976 - acc: 0.7495 - val_loss: 0.6022 - val_acc: 0.7577\n",
      "Epoch 177/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5963 - acc: 0.7497 - val_loss: 0.6003 - val_acc: 0.7587\n",
      "Epoch 178/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5930 - acc: 0.7511 - val_loss: 0.5999 - val_acc: 0.7588\n",
      "Epoch 179/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5922 - acc: 0.7516 - val_loss: 0.5998 - val_acc: 0.7596\n",
      "Epoch 180/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5918 - acc: 0.7511 - val_loss: 0.5972 - val_acc: 0.7597\n",
      "Epoch 181/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5906 - acc: 0.7522 - val_loss: 0.5965 - val_acc: 0.7602\n",
      "Epoch 182/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5894 - acc: 0.7517 - val_loss: 0.5966 - val_acc: 0.7607\n",
      "Epoch 183/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5868 - acc: 0.7533 - val_loss: 0.5946 - val_acc: 0.7630\n",
      "Epoch 184/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5861 - acc: 0.7534 - val_loss: 0.5952 - val_acc: 0.7641\n",
      "Epoch 185/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5835 - acc: 0.7561 - val_loss: 0.5948 - val_acc: 0.7612\n",
      "Epoch 186/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5834 - acc: 0.7548 - val_loss: 0.5910 - val_acc: 0.7650\n",
      "Epoch 187/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5815 - acc: 0.7568 - val_loss: 0.5912 - val_acc: 0.7668\n",
      "Epoch 188/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5803 - acc: 0.7574 - val_loss: 0.5892 - val_acc: 0.7674\n",
      "Epoch 189/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5801 - acc: 0.7558 - val_loss: 0.5884 - val_acc: 0.7662\n",
      "Epoch 190/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5778 - acc: 0.7571 - val_loss: 0.5877 - val_acc: 0.7658\n",
      "Epoch 191/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5766 - acc: 0.7591 - val_loss: 0.5860 - val_acc: 0.7698\n",
      "Epoch 192/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5753 - acc: 0.7584 - val_loss: 0.5855 - val_acc: 0.7687\n",
      "Epoch 193/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5727 - acc: 0.7593 - val_loss: 0.5852 - val_acc: 0.7673\n",
      "Epoch 194/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5735 - acc: 0.7598 - val_loss: 0.5838 - val_acc: 0.7710\n",
      "Epoch 195/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5728 - acc: 0.7592 - val_loss: 0.5861 - val_acc: 0.7693\n",
      "Epoch 196/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5707 - acc: 0.7597 - val_loss: 0.5806 - val_acc: 0.7727\n",
      "Epoch 197/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5686 - acc: 0.7606 - val_loss: 0.5818 - val_acc: 0.7733\n",
      "Epoch 198/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5693 - acc: 0.7624 - val_loss: 0.5802 - val_acc: 0.7730\n",
      "Epoch 199/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5667 - acc: 0.7625 - val_loss: 0.5814 - val_acc: 0.7705\n",
      "Epoch 200/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5650 - acc: 0.7632 - val_loss: 0.5787 - val_acc: 0.7742\n",
      "Epoch 201/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5644 - acc: 0.7635 - val_loss: 0.5778 - val_acc: 0.7765\n",
      "Epoch 202/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5639 - acc: 0.7643 - val_loss: 0.5781 - val_acc: 0.7734\n",
      "Epoch 203/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5615 - acc: 0.7650 - val_loss: 0.5778 - val_acc: 0.7756\n",
      "Epoch 204/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5610 - acc: 0.7650 - val_loss: 0.5778 - val_acc: 0.7737\n",
      "Epoch 205/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5585 - acc: 0.7651 - val_loss: 0.5759 - val_acc: 0.7758\n",
      "Epoch 206/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5585 - acc: 0.7658 - val_loss: 0.5763 - val_acc: 0.7755\n",
      "Epoch 207/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5579 - acc: 0.7664 - val_loss: 0.5733 - val_acc: 0.7772\n",
      "Epoch 208/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5546 - acc: 0.7682 - val_loss: 0.5738 - val_acc: 0.7780\n",
      "Epoch 209/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5542 - acc: 0.7671 - val_loss: 0.5722 - val_acc: 0.7785\n",
      "Epoch 210/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5522 - acc: 0.7691 - val_loss: 0.5727 - val_acc: 0.7794\n",
      "Epoch 211/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5520 - acc: 0.7700 - val_loss: 0.5697 - val_acc: 0.7808\n",
      "Epoch 212/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5506 - acc: 0.7690 - val_loss: 0.5702 - val_acc: 0.7793\n",
      "Epoch 213/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5483 - acc: 0.7699 - val_loss: 0.5692 - val_acc: 0.7828\n",
      "Epoch 214/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5477 - acc: 0.7705 - val_loss: 0.5674 - val_acc: 0.7819\n",
      "Epoch 215/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5471 - acc: 0.7711 - val_loss: 0.5678 - val_acc: 0.7815\n",
      "Epoch 216/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5463 - acc: 0.7711 - val_loss: 0.5670 - val_acc: 0.7820\n",
      "Epoch 217/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5450 - acc: 0.7721 - val_loss: 0.5668 - val_acc: 0.7827\n",
      "Epoch 218/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5444 - acc: 0.7723 - val_loss: 0.5647 - val_acc: 0.7839\n",
      "Epoch 219/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5426 - acc: 0.7730 - val_loss: 0.5641 - val_acc: 0.7852\n",
      "Epoch 220/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5402 - acc: 0.7736 - val_loss: 0.5636 - val_acc: 0.7852\n",
      "Epoch 221/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5397 - acc: 0.7738 - val_loss: 0.5618 - val_acc: 0.7854\n",
      "Epoch 222/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5389 - acc: 0.7747 - val_loss: 0.5613 - val_acc: 0.7846\n",
      "Epoch 223/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5369 - acc: 0.7752 - val_loss: 0.5605 - val_acc: 0.7868\n",
      "Epoch 224/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5363 - acc: 0.7760 - val_loss: 0.5603 - val_acc: 0.7857\n",
      "Epoch 225/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5363 - acc: 0.7764 - val_loss: 0.5574 - val_acc: 0.7893\n",
      "Epoch 226/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5331 - acc: 0.7770 - val_loss: 0.5589 - val_acc: 0.7874\n",
      "Epoch 227/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5314 - acc: 0.7780 - val_loss: 0.5584 - val_acc: 0.7896\n",
      "Epoch 228/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5299 - acc: 0.7783 - val_loss: 0.5565 - val_acc: 0.7895\n",
      "Epoch 229/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5306 - acc: 0.7779 - val_loss: 0.5571 - val_acc: 0.7892\n",
      "Epoch 230/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5288 - acc: 0.7797 - val_loss: 0.5582 - val_acc: 0.7898\n",
      "Epoch 231/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5290 - acc: 0.7792 - val_loss: 0.5578 - val_acc: 0.7889\n",
      "Epoch 232/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5261 - acc: 0.7802 - val_loss: 0.5548 - val_acc: 0.7910\n",
      "Epoch 233/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5259 - acc: 0.7804 - val_loss: 0.5540 - val_acc: 0.7921\n",
      "Epoch 234/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5248 - acc: 0.7810 - val_loss: 0.5527 - val_acc: 0.7941\n",
      "Epoch 235/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5249 - acc: 0.7805 - val_loss: 0.5525 - val_acc: 0.7933\n",
      "Epoch 236/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5218 - acc: 0.7823 - val_loss: 0.5507 - val_acc: 0.7948\n",
      "Epoch 237/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5208 - acc: 0.7831 - val_loss: 0.5506 - val_acc: 0.7937\n",
      "Epoch 238/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5201 - acc: 0.7825 - val_loss: 0.5510 - val_acc: 0.7951\n",
      "Epoch 239/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5198 - acc: 0.7840 - val_loss: 0.5497 - val_acc: 0.7946\n",
      "Epoch 240/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5167 - acc: 0.7834 - val_loss: 0.5484 - val_acc: 0.7961\n",
      "Epoch 241/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5164 - acc: 0.7840 - val_loss: 0.5490 - val_acc: 0.7943\n",
      "Epoch 242/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5162 - acc: 0.7848 - val_loss: 0.5475 - val_acc: 0.7959\n",
      "Epoch 243/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5143 - acc: 0.7856 - val_loss: 0.5490 - val_acc: 0.7982\n",
      "Epoch 244/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5137 - acc: 0.7856 - val_loss: 0.5479 - val_acc: 0.7973\n",
      "Epoch 245/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5131 - acc: 0.7859 - val_loss: 0.5458 - val_acc: 0.7969\n",
      "Epoch 246/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5101 - acc: 0.7865 - val_loss: 0.5436 - val_acc: 0.7989\n",
      "Epoch 247/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5096 - acc: 0.7863 - val_loss: 0.5446 - val_acc: 0.7994\n",
      "Epoch 248/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5097 - acc: 0.7874 - val_loss: 0.5466 - val_acc: 0.7983\n",
      "Epoch 249/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5088 - acc: 0.7880 - val_loss: 0.5425 - val_acc: 0.7997\n",
      "Epoch 250/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5078 - acc: 0.7885 - val_loss: 0.5454 - val_acc: 0.7971\n",
      "Epoch 251/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5068 - acc: 0.7893 - val_loss: 0.5410 - val_acc: 0.8003\n",
      "Epoch 252/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5045 - acc: 0.7890 - val_loss: 0.5424 - val_acc: 0.8007\n",
      "Epoch 253/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5051 - acc: 0.7893 - val_loss: 0.5393 - val_acc: 0.8023\n",
      "Epoch 254/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5036 - acc: 0.7897 - val_loss: 0.5416 - val_acc: 0.8009\n",
      "Epoch 255/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5006 - acc: 0.7912 - val_loss: 0.5405 - val_acc: 0.8009\n",
      "Epoch 256/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5001 - acc: 0.7914 - val_loss: 0.5409 - val_acc: 0.8006\n",
      "Epoch 257/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.5000 - acc: 0.7915 - val_loss: 0.5382 - val_acc: 0.8039\n",
      "Epoch 258/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.5000 - acc: 0.7914 - val_loss: 0.5422 - val_acc: 0.7998\n",
      "Epoch 259/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4965 - acc: 0.7932 - val_loss: 0.5407 - val_acc: 0.8012\n",
      "Epoch 260/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4960 - acc: 0.7938 - val_loss: 0.5384 - val_acc: 0.8057\n",
      "Epoch 261/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4959 - acc: 0.7929 - val_loss: 0.5374 - val_acc: 0.8053\n",
      "Epoch 262/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4963 - acc: 0.7934 - val_loss: 0.5376 - val_acc: 0.8042\n",
      "Epoch 263/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4935 - acc: 0.7943 - val_loss: 0.5363 - val_acc: 0.8061\n",
      "Epoch 264/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4938 - acc: 0.7935 - val_loss: 0.5377 - val_acc: 0.8070\n",
      "Epoch 265/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4928 - acc: 0.7950 - val_loss: 0.5376 - val_acc: 0.8049\n",
      "Epoch 266/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4900 - acc: 0.7963 - val_loss: 0.5373 - val_acc: 0.8044\n",
      "Epoch 267/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4882 - acc: 0.7964 - val_loss: 0.5349 - val_acc: 0.8076\n",
      "Epoch 268/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4881 - acc: 0.7963 - val_loss: 0.5340 - val_acc: 0.8073\n",
      "Epoch 269/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4872 - acc: 0.7965 - val_loss: 0.5334 - val_acc: 0.8092\n",
      "Epoch 270/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4861 - acc: 0.7978 - val_loss: 0.5346 - val_acc: 0.8072\n",
      "Epoch 271/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4866 - acc: 0.7980 - val_loss: 0.5340 - val_acc: 0.8088\n",
      "Epoch 272/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4836 - acc: 0.7996 - val_loss: 0.5343 - val_acc: 0.8088\n",
      "Epoch 273/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4844 - acc: 0.7990 - val_loss: 0.5337 - val_acc: 0.8073\n",
      "Epoch 274/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4825 - acc: 0.7993 - val_loss: 0.5324 - val_acc: 0.8087\n",
      "Epoch 275/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4816 - acc: 0.7994 - val_loss: 0.5328 - val_acc: 0.8089\n",
      "Epoch 276/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4803 - acc: 0.8005 - val_loss: 0.5313 - val_acc: 0.8107\n",
      "Epoch 277/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4803 - acc: 0.8008 - val_loss: 0.5318 - val_acc: 0.8099\n",
      "Epoch 278/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4787 - acc: 0.8004 - val_loss: 0.5296 - val_acc: 0.8092\n",
      "Epoch 279/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4782 - acc: 0.8016 - val_loss: 0.5309 - val_acc: 0.8099\n",
      "Epoch 280/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4770 - acc: 0.8011 - val_loss: 0.5282 - val_acc: 0.8119\n",
      "Epoch 281/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4758 - acc: 0.8024 - val_loss: 0.5274 - val_acc: 0.8109\n",
      "Epoch 282/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4766 - acc: 0.8020 - val_loss: 0.5259 - val_acc: 0.8122\n",
      "Epoch 283/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4756 - acc: 0.8018 - val_loss: 0.5266 - val_acc: 0.8134\n",
      "Epoch 284/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4724 - acc: 0.8039 - val_loss: 0.5281 - val_acc: 0.8128\n",
      "Epoch 285/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4711 - acc: 0.8049 - val_loss: 0.5255 - val_acc: 0.8143\n",
      "Epoch 286/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4712 - acc: 0.8046 - val_loss: 0.5259 - val_acc: 0.8116\n",
      "Epoch 287/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4701 - acc: 0.8056 - val_loss: 0.5253 - val_acc: 0.8125\n",
      "Epoch 288/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4701 - acc: 0.8039 - val_loss: 0.5246 - val_acc: 0.8134\n",
      "Epoch 289/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4682 - acc: 0.8064 - val_loss: 0.5251 - val_acc: 0.8136\n",
      "Epoch 290/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4671 - acc: 0.8066 - val_loss: 0.5239 - val_acc: 0.8155\n",
      "Epoch 291/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4655 - acc: 0.8071 - val_loss: 0.5250 - val_acc: 0.8158\n",
      "Epoch 292/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4655 - acc: 0.8064 - val_loss: 0.5239 - val_acc: 0.8155\n",
      "Epoch 293/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4655 - acc: 0.8066 - val_loss: 0.5211 - val_acc: 0.8157\n",
      "Epoch 294/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4623 - acc: 0.8077 - val_loss: 0.5241 - val_acc: 0.8147\n",
      "Epoch 295/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4646 - acc: 0.8067 - val_loss: 0.5203 - val_acc: 0.8169\n",
      "Epoch 296/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4614 - acc: 0.8091 - val_loss: 0.5227 - val_acc: 0.8171\n",
      "Epoch 297/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4618 - acc: 0.8084 - val_loss: 0.5216 - val_acc: 0.8159\n",
      "Epoch 298/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4613 - acc: 0.8089 - val_loss: 0.5199 - val_acc: 0.8186\n",
      "Epoch 299/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4612 - acc: 0.8099 - val_loss: 0.5202 - val_acc: 0.8182\n",
      "Epoch 300/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4602 - acc: 0.8089 - val_loss: 0.5212 - val_acc: 0.8177\n",
      "Epoch 301/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4577 - acc: 0.8112 - val_loss: 0.5203 - val_acc: 0.8191\n",
      "Epoch 302/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4571 - acc: 0.8106 - val_loss: 0.5179 - val_acc: 0.8182\n",
      "Epoch 303/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4553 - acc: 0.8110 - val_loss: 0.5170 - val_acc: 0.8215\n",
      "Epoch 304/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4561 - acc: 0.8106 - val_loss: 0.5215 - val_acc: 0.8177\n",
      "Epoch 305/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4560 - acc: 0.8114 - val_loss: 0.5171 - val_acc: 0.8201\n",
      "Epoch 306/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4532 - acc: 0.8116 - val_loss: 0.5174 - val_acc: 0.8219\n",
      "Epoch 307/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4528 - acc: 0.8123 - val_loss: 0.5160 - val_acc: 0.8209\n",
      "Epoch 308/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4518 - acc: 0.8128 - val_loss: 0.5149 - val_acc: 0.8221\n",
      "Epoch 309/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4530 - acc: 0.8131 - val_loss: 0.5156 - val_acc: 0.8217\n",
      "Epoch 310/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4495 - acc: 0.8138 - val_loss: 0.5155 - val_acc: 0.8207\n",
      "Epoch 311/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4499 - acc: 0.8139 - val_loss: 0.5147 - val_acc: 0.8232\n",
      "Epoch 312/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4486 - acc: 0.8147 - val_loss: 0.5163 - val_acc: 0.8201\n",
      "Epoch 313/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4470 - acc: 0.8156 - val_loss: 0.5136 - val_acc: 0.8228\n",
      "Epoch 314/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4490 - acc: 0.8143 - val_loss: 0.5150 - val_acc: 0.8236\n",
      "Epoch 315/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4474 - acc: 0.8158 - val_loss: 0.5115 - val_acc: 0.8250\n",
      "Epoch 316/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4456 - acc: 0.8156 - val_loss: 0.5147 - val_acc: 0.8226\n",
      "Epoch 317/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4439 - acc: 0.8166 - val_loss: 0.5164 - val_acc: 0.8231\n",
      "Epoch 318/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4440 - acc: 0.8167 - val_loss: 0.5119 - val_acc: 0.8248\n",
      "Epoch 319/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4428 - acc: 0.8170 - val_loss: 0.5134 - val_acc: 0.8243\n",
      "Epoch 320/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4429 - acc: 0.8170 - val_loss: 0.5127 - val_acc: 0.8238\n",
      "Epoch 321/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4419 - acc: 0.8172 - val_loss: 0.5156 - val_acc: 0.8232\n",
      "Epoch 322/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4400 - acc: 0.8182 - val_loss: 0.5117 - val_acc: 0.8256\n",
      "Epoch 323/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4410 - acc: 0.8177 - val_loss: 0.5118 - val_acc: 0.8257\n",
      "Epoch 324/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4405 - acc: 0.8177 - val_loss: 0.5096 - val_acc: 0.8263\n",
      "Epoch 325/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4386 - acc: 0.8186 - val_loss: 0.5113 - val_acc: 0.8253\n",
      "Epoch 326/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4384 - acc: 0.8178 - val_loss: 0.5094 - val_acc: 0.8269\n",
      "Epoch 327/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4382 - acc: 0.8191 - val_loss: 0.5092 - val_acc: 0.8257\n",
      "Epoch 328/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4358 - acc: 0.8201 - val_loss: 0.5068 - val_acc: 0.8276\n",
      "Epoch 329/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4346 - acc: 0.8199 - val_loss: 0.5080 - val_acc: 0.8263\n",
      "Epoch 330/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4346 - acc: 0.8213 - val_loss: 0.5092 - val_acc: 0.8256\n",
      "Epoch 331/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4345 - acc: 0.8214 - val_loss: 0.5087 - val_acc: 0.8276\n",
      "Epoch 332/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4322 - acc: 0.8224 - val_loss: 0.5123 - val_acc: 0.8259\n",
      "Epoch 333/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4332 - acc: 0.8207 - val_loss: 0.5094 - val_acc: 0.8278\n",
      "Epoch 334/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4327 - acc: 0.8225 - val_loss: 0.5079 - val_acc: 0.8287\n",
      "Epoch 335/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4313 - acc: 0.8217 - val_loss: 0.5088 - val_acc: 0.8290\n",
      "Epoch 336/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4300 - acc: 0.8235 - val_loss: 0.5080 - val_acc: 0.8284\n",
      "Epoch 337/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4292 - acc: 0.8233 - val_loss: 0.5061 - val_acc: 0.8304\n",
      "Epoch 338/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4245 - acc: 0.8251 - val_loss: 0.5059 - val_acc: 0.8306\n",
      "Epoch 339/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4263 - acc: 0.8245 - val_loss: 0.5047 - val_acc: 0.8302\n",
      "Epoch 340/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4287 - acc: 0.8227 - val_loss: 0.5056 - val_acc: 0.8303\n",
      "Epoch 341/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4274 - acc: 0.8232 - val_loss: 0.5046 - val_acc: 0.8314\n",
      "Epoch 342/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4243 - acc: 0.8256 - val_loss: 0.5053 - val_acc: 0.8295\n",
      "Epoch 343/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4261 - acc: 0.8248 - val_loss: 0.5050 - val_acc: 0.8320\n",
      "Epoch 344/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4242 - acc: 0.8245 - val_loss: 0.5052 - val_acc: 0.8295\n",
      "Epoch 345/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4239 - acc: 0.8260 - val_loss: 0.5039 - val_acc: 0.8324\n",
      "Epoch 346/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4214 - acc: 0.8264 - val_loss: 0.5050 - val_acc: 0.8312\n",
      "Epoch 347/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4207 - acc: 0.8274 - val_loss: 0.5028 - val_acc: 0.8322\n",
      "Epoch 348/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4191 - acc: 0.8267 - val_loss: 0.5041 - val_acc: 0.8316\n",
      "Epoch 349/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4211 - acc: 0.8260 - val_loss: 0.5029 - val_acc: 0.8327\n",
      "Epoch 350/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4209 - acc: 0.8257 - val_loss: 0.5014 - val_acc: 0.8319\n",
      "Epoch 351/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4204 - acc: 0.8269 - val_loss: 0.5025 - val_acc: 0.8343\n",
      "Epoch 352/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4164 - acc: 0.8283 - val_loss: 0.5002 - val_acc: 0.8327\n",
      "Epoch 353/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4164 - acc: 0.8289 - val_loss: 0.5017 - val_acc: 0.8326\n",
      "Epoch 354/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4182 - acc: 0.8280 - val_loss: 0.5039 - val_acc: 0.8327\n",
      "Epoch 355/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4162 - acc: 0.8290 - val_loss: 0.5007 - val_acc: 0.8346\n",
      "Epoch 356/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4146 - acc: 0.8289 - val_loss: 0.5038 - val_acc: 0.8333\n",
      "Epoch 357/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4141 - acc: 0.8300 - val_loss: 0.5021 - val_acc: 0.8332\n",
      "Epoch 358/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4125 - acc: 0.8302 - val_loss: 0.5032 - val_acc: 0.8335\n",
      "Epoch 359/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4120 - acc: 0.8309 - val_loss: 0.5023 - val_acc: 0.8349\n",
      "Epoch 360/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4111 - acc: 0.8320 - val_loss: 0.5032 - val_acc: 0.8354\n",
      "Epoch 361/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4118 - acc: 0.8306 - val_loss: 0.4995 - val_acc: 0.8333\n",
      "Epoch 362/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4130 - acc: 0.8302 - val_loss: 0.5007 - val_acc: 0.8362\n",
      "Epoch 363/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4111 - acc: 0.8314 - val_loss: 0.4988 - val_acc: 0.8370\n",
      "Epoch 364/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4093 - acc: 0.8317 - val_loss: 0.5012 - val_acc: 0.8350\n",
      "Epoch 365/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4103 - acc: 0.8315 - val_loss: 0.4997 - val_acc: 0.8358\n",
      "Epoch 366/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4103 - acc: 0.8316 - val_loss: 0.4985 - val_acc: 0.8381\n",
      "Epoch 367/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4075 - acc: 0.8326 - val_loss: 0.4992 - val_acc: 0.8374\n",
      "Epoch 368/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4092 - acc: 0.8316 - val_loss: 0.5003 - val_acc: 0.8367\n",
      "Epoch 369/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4081 - acc: 0.8326 - val_loss: 0.5009 - val_acc: 0.8362\n",
      "Epoch 370/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4070 - acc: 0.8327 - val_loss: 0.4986 - val_acc: 0.8371\n",
      "Epoch 371/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4066 - acc: 0.8326 - val_loss: 0.4986 - val_acc: 0.8368\n",
      "Epoch 372/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4045 - acc: 0.8334 - val_loss: 0.5007 - val_acc: 0.8381\n",
      "Epoch 373/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4050 - acc: 0.8344 - val_loss: 0.4978 - val_acc: 0.8375\n",
      "Epoch 374/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4033 - acc: 0.8344 - val_loss: 0.4968 - val_acc: 0.8377\n",
      "Epoch 375/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4038 - acc: 0.8340 - val_loss: 0.5002 - val_acc: 0.8379\n",
      "Epoch 376/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.4029 - acc: 0.8343 - val_loss: 0.4952 - val_acc: 0.8393\n",
      "Epoch 377/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4041 - acc: 0.8344 - val_loss: 0.4976 - val_acc: 0.8385\n",
      "Epoch 378/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4018 - acc: 0.8357 - val_loss: 0.4967 - val_acc: 0.8375\n",
      "Epoch 379/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4008 - acc: 0.8354 - val_loss: 0.4982 - val_acc: 0.8384\n",
      "Epoch 380/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4013 - acc: 0.8363 - val_loss: 0.4989 - val_acc: 0.8382\n",
      "Epoch 381/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.4004 - acc: 0.8358 - val_loss: 0.4964 - val_acc: 0.8418\n",
      "Epoch 382/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3986 - acc: 0.8368 - val_loss: 0.4968 - val_acc: 0.8407\n",
      "Epoch 383/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3985 - acc: 0.8363 - val_loss: 0.4989 - val_acc: 0.8395\n",
      "Epoch 384/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3984 - acc: 0.8369 - val_loss: 0.4963 - val_acc: 0.8410\n",
      "Epoch 385/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3974 - acc: 0.8370 - val_loss: 0.4943 - val_acc: 0.8409\n",
      "Epoch 386/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3968 - acc: 0.8377 - val_loss: 0.4937 - val_acc: 0.8429\n",
      "Epoch 387/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3961 - acc: 0.8382 - val_loss: 0.4952 - val_acc: 0.8415\n",
      "Epoch 388/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3955 - acc: 0.8382 - val_loss: 0.4966 - val_acc: 0.8410\n",
      "Epoch 389/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3943 - acc: 0.8392 - val_loss: 0.4946 - val_acc: 0.8413\n",
      "Epoch 390/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3943 - acc: 0.8376 - val_loss: 0.4957 - val_acc: 0.8416\n",
      "Epoch 391/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3929 - acc: 0.8393 - val_loss: 0.4954 - val_acc: 0.8417\n",
      "Epoch 392/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3960 - acc: 0.8383 - val_loss: 0.4952 - val_acc: 0.8411\n",
      "Epoch 393/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3928 - acc: 0.8394 - val_loss: 0.4922 - val_acc: 0.8427\n",
      "Epoch 394/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3904 - acc: 0.8407 - val_loss: 0.4950 - val_acc: 0.8406\n",
      "Epoch 395/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3910 - acc: 0.8402 - val_loss: 0.4956 - val_acc: 0.8405\n",
      "Epoch 396/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3920 - acc: 0.8397 - val_loss: 0.4928 - val_acc: 0.8431\n",
      "Epoch 397/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3884 - acc: 0.8414 - val_loss: 0.4928 - val_acc: 0.8437\n",
      "Epoch 398/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3879 - acc: 0.8413 - val_loss: 0.4947 - val_acc: 0.8426\n",
      "Epoch 399/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3885 - acc: 0.8411 - val_loss: 0.4947 - val_acc: 0.8434\n",
      "Epoch 400/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3869 - acc: 0.8411 - val_loss: 0.4924 - val_acc: 0.8428\n",
      "Epoch 401/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3868 - acc: 0.8413 - val_loss: 0.4908 - val_acc: 0.8438\n",
      "Epoch 402/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3879 - acc: 0.8412 - val_loss: 0.4941 - val_acc: 0.8430\n",
      "Epoch 403/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3876 - acc: 0.8415 - val_loss: 0.4938 - val_acc: 0.8428\n",
      "Epoch 404/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3879 - acc: 0.8412 - val_loss: 0.4906 - val_acc: 0.8444\n",
      "Epoch 405/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3858 - acc: 0.8417 - val_loss: 0.4924 - val_acc: 0.8448\n",
      "Epoch 406/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3840 - acc: 0.8430 - val_loss: 0.4915 - val_acc: 0.8439\n",
      "Epoch 407/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3846 - acc: 0.8432 - val_loss: 0.4946 - val_acc: 0.8415\n",
      "Epoch 408/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3867 - acc: 0.8416 - val_loss: 0.4914 - val_acc: 0.8436\n",
      "Epoch 409/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3830 - acc: 0.8435 - val_loss: 0.4915 - val_acc: 0.8450\n",
      "Epoch 410/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3837 - acc: 0.8429 - val_loss: 0.4904 - val_acc: 0.8466\n",
      "Epoch 411/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3812 - acc: 0.8441 - val_loss: 0.4917 - val_acc: 0.8456\n",
      "Epoch 412/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3822 - acc: 0.8439 - val_loss: 0.4929 - val_acc: 0.8433\n",
      "Epoch 413/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3815 - acc: 0.8449 - val_loss: 0.4904 - val_acc: 0.8458\n",
      "Epoch 414/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3826 - acc: 0.8449 - val_loss: 0.4911 - val_acc: 0.8457\n",
      "Epoch 415/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3812 - acc: 0.8444 - val_loss: 0.4892 - val_acc: 0.8464\n",
      "Epoch 416/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3804 - acc: 0.8452 - val_loss: 0.4911 - val_acc: 0.8447\n",
      "Epoch 417/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3799 - acc: 0.8446 - val_loss: 0.4873 - val_acc: 0.8470\n",
      "Epoch 418/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3778 - acc: 0.8459 - val_loss: 0.4884 - val_acc: 0.8472\n",
      "Epoch 419/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3793 - acc: 0.8450 - val_loss: 0.4889 - val_acc: 0.8472\n",
      "Epoch 420/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3774 - acc: 0.8461 - val_loss: 0.4922 - val_acc: 0.8468\n",
      "Epoch 421/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3773 - acc: 0.8452 - val_loss: 0.4910 - val_acc: 0.8462\n",
      "Epoch 422/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3767 - acc: 0.8461 - val_loss: 0.4910 - val_acc: 0.8482\n",
      "Epoch 423/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3761 - acc: 0.8465 - val_loss: 0.4895 - val_acc: 0.8474\n",
      "Epoch 424/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3759 - acc: 0.8471 - val_loss: 0.4894 - val_acc: 0.8474\n",
      "Epoch 425/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3761 - acc: 0.8461 - val_loss: 0.4907 - val_acc: 0.8489\n",
      "Epoch 426/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3750 - acc: 0.8472 - val_loss: 0.4891 - val_acc: 0.8475\n",
      "Epoch 427/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3745 - acc: 0.8475 - val_loss: 0.4890 - val_acc: 0.8472\n",
      "Epoch 428/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3734 - acc: 0.8480 - val_loss: 0.4892 - val_acc: 0.8501\n",
      "Epoch 429/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3730 - acc: 0.8484 - val_loss: 0.4898 - val_acc: 0.8482\n",
      "Epoch 430/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3730 - acc: 0.8478 - val_loss: 0.4883 - val_acc: 0.8497\n",
      "Epoch 431/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3730 - acc: 0.8484 - val_loss: 0.4889 - val_acc: 0.8475\n",
      "Epoch 432/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3732 - acc: 0.8495 - val_loss: 0.4873 - val_acc: 0.8486\n",
      "Epoch 433/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3724 - acc: 0.8483 - val_loss: 0.4898 - val_acc: 0.8493\n",
      "Epoch 434/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3711 - acc: 0.8495 - val_loss: 0.4917 - val_acc: 0.8473\n",
      "Epoch 435/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3722 - acc: 0.8480 - val_loss: 0.4891 - val_acc: 0.8482\n",
      "Epoch 436/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3712 - acc: 0.8492 - val_loss: 0.4885 - val_acc: 0.8489\n",
      "Epoch 437/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3703 - acc: 0.8496 - val_loss: 0.4888 - val_acc: 0.8493\n",
      "Epoch 438/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3680 - acc: 0.8499 - val_loss: 0.4856 - val_acc: 0.8511\n",
      "Epoch 439/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3677 - acc: 0.8502 - val_loss: 0.4901 - val_acc: 0.8501\n",
      "Epoch 440/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3689 - acc: 0.8500 - val_loss: 0.4858 - val_acc: 0.8525\n",
      "Epoch 441/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3687 - acc: 0.8502 - val_loss: 0.4883 - val_acc: 0.8489\n",
      "Epoch 442/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3698 - acc: 0.8503 - val_loss: 0.4880 - val_acc: 0.8493\n",
      "Epoch 443/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3682 - acc: 0.8510 - val_loss: 0.4877 - val_acc: 0.8508\n",
      "Epoch 444/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3678 - acc: 0.8508 - val_loss: 0.4872 - val_acc: 0.8512\n",
      "Epoch 445/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3672 - acc: 0.8507 - val_loss: 0.4879 - val_acc: 0.8495\n",
      "Epoch 446/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3665 - acc: 0.8503 - val_loss: 0.4897 - val_acc: 0.8482\n",
      "Epoch 447/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3638 - acc: 0.8518 - val_loss: 0.4890 - val_acc: 0.8491\n",
      "Epoch 448/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3655 - acc: 0.8509 - val_loss: 0.4872 - val_acc: 0.8508\n",
      "Epoch 449/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3635 - acc: 0.8523 - val_loss: 0.4869 - val_acc: 0.8514\n",
      "Epoch 450/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3638 - acc: 0.8525 - val_loss: 0.4885 - val_acc: 0.8506\n",
      "Epoch 451/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3634 - acc: 0.8510 - val_loss: 0.4877 - val_acc: 0.8495\n",
      "Epoch 452/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3631 - acc: 0.8526 - val_loss: 0.4860 - val_acc: 0.8506\n",
      "Epoch 453/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3633 - acc: 0.8522 - val_loss: 0.4855 - val_acc: 0.8505\n",
      "Epoch 454/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3636 - acc: 0.8529 - val_loss: 0.4865 - val_acc: 0.8498\n",
      "Epoch 455/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3613 - acc: 0.8530 - val_loss: 0.4849 - val_acc: 0.8517\n",
      "Epoch 456/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3594 - acc: 0.8542 - val_loss: 0.4864 - val_acc: 0.8515\n",
      "Epoch 457/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3583 - acc: 0.8549 - val_loss: 0.4871 - val_acc: 0.8515\n",
      "Epoch 458/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3597 - acc: 0.8543 - val_loss: 0.4850 - val_acc: 0.8514\n",
      "Epoch 459/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3579 - acc: 0.8543 - val_loss: 0.4873 - val_acc: 0.8511\n",
      "Epoch 460/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3585 - acc: 0.8556 - val_loss: 0.4861 - val_acc: 0.8518\n",
      "Epoch 461/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3571 - acc: 0.8562 - val_loss: 0.4868 - val_acc: 0.8511\n",
      "Epoch 462/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3576 - acc: 0.8548 - val_loss: 0.4852 - val_acc: 0.8531\n",
      "Epoch 463/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3562 - acc: 0.8548 - val_loss: 0.4881 - val_acc: 0.8521\n",
      "Epoch 464/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3581 - acc: 0.8546 - val_loss: 0.4877 - val_acc: 0.8519\n",
      "Epoch 465/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3566 - acc: 0.8554 - val_loss: 0.4845 - val_acc: 0.8519\n",
      "Epoch 466/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3561 - acc: 0.8564 - val_loss: 0.4845 - val_acc: 0.8524\n",
      "Epoch 467/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3576 - acc: 0.8553 - val_loss: 0.4836 - val_acc: 0.8516\n",
      "Epoch 468/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3577 - acc: 0.8554 - val_loss: 0.4826 - val_acc: 0.8535\n",
      "Epoch 469/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3556 - acc: 0.8563 - val_loss: 0.4837 - val_acc: 0.8545\n",
      "Epoch 470/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3555 - acc: 0.8560 - val_loss: 0.4846 - val_acc: 0.8539\n",
      "Epoch 471/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3540 - acc: 0.8573 - val_loss: 0.4845 - val_acc: 0.8531\n",
      "Epoch 472/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3533 - acc: 0.8571 - val_loss: 0.4844 - val_acc: 0.8548\n",
      "Epoch 473/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3552 - acc: 0.8560 - val_loss: 0.4849 - val_acc: 0.8518\n",
      "Epoch 474/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3546 - acc: 0.8560 - val_loss: 0.4852 - val_acc: 0.8533\n",
      "Epoch 475/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3528 - acc: 0.8581 - val_loss: 0.4860 - val_acc: 0.8535\n",
      "Epoch 476/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3520 - acc: 0.8576 - val_loss: 0.4819 - val_acc: 0.8537\n",
      "Epoch 477/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3522 - acc: 0.8576 - val_loss: 0.4858 - val_acc: 0.8544\n",
      "Epoch 478/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3515 - acc: 0.8568 - val_loss: 0.4872 - val_acc: 0.8521\n",
      "Epoch 479/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3508 - acc: 0.8575 - val_loss: 0.4854 - val_acc: 0.8541\n",
      "Epoch 480/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3519 - acc: 0.8580 - val_loss: 0.4849 - val_acc: 0.8551\n",
      "Epoch 481/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3519 - acc: 0.8578 - val_loss: 0.4847 - val_acc: 0.8549\n",
      "Epoch 482/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3480 - acc: 0.8589 - val_loss: 0.4869 - val_acc: 0.8534\n",
      "Epoch 483/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3512 - acc: 0.8572 - val_loss: 0.4839 - val_acc: 0.8539\n",
      "Epoch 484/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3495 - acc: 0.8583 - val_loss: 0.4829 - val_acc: 0.8557\n",
      "Epoch 485/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3489 - acc: 0.8589 - val_loss: 0.4859 - val_acc: 0.8542\n",
      "Epoch 486/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3492 - acc: 0.8589 - val_loss: 0.4838 - val_acc: 0.8549\n",
      "Epoch 487/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3506 - acc: 0.8586 - val_loss: 0.4850 - val_acc: 0.8537\n",
      "Epoch 488/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3456 - acc: 0.8601 - val_loss: 0.4859 - val_acc: 0.8555\n",
      "Epoch 489/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3476 - acc: 0.8603 - val_loss: 0.4832 - val_acc: 0.8547\n",
      "Epoch 490/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3452 - acc: 0.8601 - val_loss: 0.4844 - val_acc: 0.8546\n",
      "Epoch 491/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3461 - acc: 0.8603 - val_loss: 0.4851 - val_acc: 0.8547\n",
      "Epoch 492/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3487 - acc: 0.8593 - val_loss: 0.4828 - val_acc: 0.8545\n",
      "Epoch 493/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3469 - acc: 0.8591 - val_loss: 0.4819 - val_acc: 0.8543\n",
      "Epoch 494/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3455 - acc: 0.8604 - val_loss: 0.4816 - val_acc: 0.8562\n",
      "Epoch 495/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3457 - acc: 0.8602 - val_loss: 0.4830 - val_acc: 0.8561\n",
      "Epoch 496/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3470 - acc: 0.8596 - val_loss: 0.4820 - val_acc: 0.8575\n",
      "Epoch 497/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3461 - acc: 0.8605 - val_loss: 0.4839 - val_acc: 0.8569\n",
      "Epoch 498/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3437 - acc: 0.8612 - val_loss: 0.4827 - val_acc: 0.8567\n",
      "Epoch 499/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3444 - acc: 0.8609 - val_loss: 0.4815 - val_acc: 0.8567\n",
      "Epoch 500/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3451 - acc: 0.8611 - val_loss: 0.4789 - val_acc: 0.8555\n",
      "Epoch 501/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3431 - acc: 0.8623 - val_loss: 0.4810 - val_acc: 0.8544\n",
      "Epoch 502/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3458 - acc: 0.8603 - val_loss: 0.4810 - val_acc: 0.8565\n",
      "Epoch 503/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3420 - acc: 0.8618 - val_loss: 0.4807 - val_acc: 0.8562\n",
      "Epoch 504/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3405 - acc: 0.8623 - val_loss: 0.4841 - val_acc: 0.8578\n",
      "Epoch 505/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3410 - acc: 0.8620 - val_loss: 0.4810 - val_acc: 0.8569\n",
      "Epoch 506/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3409 - acc: 0.8625 - val_loss: 0.4828 - val_acc: 0.8562\n",
      "Epoch 507/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3420 - acc: 0.8622 - val_loss: 0.4822 - val_acc: 0.8564\n",
      "Epoch 508/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3403 - acc: 0.8629 - val_loss: 0.4808 - val_acc: 0.8580\n",
      "Epoch 509/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3401 - acc: 0.8632 - val_loss: 0.4814 - val_acc: 0.8558\n",
      "Epoch 510/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3410 - acc: 0.8618 - val_loss: 0.4825 - val_acc: 0.8554\n",
      "Epoch 511/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3402 - acc: 0.8623 - val_loss: 0.4821 - val_acc: 0.8571\n",
      "Epoch 512/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3406 - acc: 0.8625 - val_loss: 0.4807 - val_acc: 0.8580\n",
      "Epoch 513/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3397 - acc: 0.8633 - val_loss: 0.4819 - val_acc: 0.8572\n",
      "Epoch 514/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3375 - acc: 0.8647 - val_loss: 0.4811 - val_acc: 0.8577\n",
      "Epoch 515/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3355 - acc: 0.8647 - val_loss: 0.4823 - val_acc: 0.8577\n",
      "Epoch 516/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3374 - acc: 0.8637 - val_loss: 0.4819 - val_acc: 0.8581\n",
      "Epoch 517/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3379 - acc: 0.8637 - val_loss: 0.4834 - val_acc: 0.8567\n",
      "Epoch 518/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3370 - acc: 0.8644 - val_loss: 0.4811 - val_acc: 0.8588\n",
      "Epoch 519/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3367 - acc: 0.8643 - val_loss: 0.4783 - val_acc: 0.8561\n",
      "Epoch 520/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3361 - acc: 0.8651 - val_loss: 0.4800 - val_acc: 0.8587\n",
      "Epoch 521/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3348 - acc: 0.8648 - val_loss: 0.4812 - val_acc: 0.8586\n",
      "Epoch 522/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3353 - acc: 0.8643 - val_loss: 0.4806 - val_acc: 0.8566\n",
      "Epoch 523/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3345 - acc: 0.8658 - val_loss: 0.4825 - val_acc: 0.8562\n",
      "Epoch 524/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3341 - acc: 0.8655 - val_loss: 0.4801 - val_acc: 0.8592\n",
      "Epoch 525/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3341 - acc: 0.8659 - val_loss: 0.4826 - val_acc: 0.8575\n",
      "Epoch 526/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3342 - acc: 0.8656 - val_loss: 0.4806 - val_acc: 0.8602\n",
      "Epoch 527/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3317 - acc: 0.8666 - val_loss: 0.4811 - val_acc: 0.8585\n",
      "Epoch 528/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3325 - acc: 0.8657 - val_loss: 0.4803 - val_acc: 0.8592\n",
      "Epoch 529/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3305 - acc: 0.8674 - val_loss: 0.4809 - val_acc: 0.8586\n",
      "Epoch 530/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3320 - acc: 0.8661 - val_loss: 0.4807 - val_acc: 0.8596\n",
      "Epoch 531/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3322 - acc: 0.8667 - val_loss: 0.4786 - val_acc: 0.8603\n",
      "Epoch 532/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3306 - acc: 0.8671 - val_loss: 0.4811 - val_acc: 0.8598\n",
      "Epoch 533/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3325 - acc: 0.8663 - val_loss: 0.4831 - val_acc: 0.8582\n",
      "Epoch 534/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3308 - acc: 0.8670 - val_loss: 0.4792 - val_acc: 0.8602\n",
      "Epoch 535/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3332 - acc: 0.8654 - val_loss: 0.4799 - val_acc: 0.8603\n",
      "Epoch 536/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3320 - acc: 0.8665 - val_loss: 0.4818 - val_acc: 0.8586\n",
      "Epoch 537/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3305 - acc: 0.8669 - val_loss: 0.4793 - val_acc: 0.8597\n",
      "Epoch 538/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3308 - acc: 0.8666 - val_loss: 0.4772 - val_acc: 0.8615\n",
      "Epoch 539/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3309 - acc: 0.8678 - val_loss: 0.4789 - val_acc: 0.8602\n",
      "Epoch 540/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3304 - acc: 0.8675 - val_loss: 0.4801 - val_acc: 0.8600\n",
      "Epoch 541/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3309 - acc: 0.8668 - val_loss: 0.4800 - val_acc: 0.8612\n",
      "Epoch 542/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3298 - acc: 0.8682 - val_loss: 0.4785 - val_acc: 0.8616\n",
      "Epoch 543/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3288 - acc: 0.8685 - val_loss: 0.4814 - val_acc: 0.8607\n",
      "Epoch 544/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3281 - acc: 0.8684 - val_loss: 0.4806 - val_acc: 0.8588\n",
      "Epoch 545/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3289 - acc: 0.8680 - val_loss: 0.4807 - val_acc: 0.8589\n",
      "Epoch 546/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3302 - acc: 0.8673 - val_loss: 0.4785 - val_acc: 0.8609\n",
      "Epoch 547/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3274 - acc: 0.8693 - val_loss: 0.4799 - val_acc: 0.8606\n",
      "Epoch 548/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3286 - acc: 0.8679 - val_loss: 0.4781 - val_acc: 0.8608\n",
      "Epoch 549/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3285 - acc: 0.8684 - val_loss: 0.4784 - val_acc: 0.8613\n",
      "Epoch 550/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3268 - acc: 0.8690 - val_loss: 0.4818 - val_acc: 0.8606\n",
      "Epoch 551/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3255 - acc: 0.8699 - val_loss: 0.4803 - val_acc: 0.8615\n",
      "Epoch 552/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3275 - acc: 0.8688 - val_loss: 0.4817 - val_acc: 0.8586\n",
      "Epoch 553/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3263 - acc: 0.8697 - val_loss: 0.4814 - val_acc: 0.8613\n",
      "Epoch 554/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3256 - acc: 0.8697 - val_loss: 0.4805 - val_acc: 0.8618\n",
      "Epoch 555/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3246 - acc: 0.8695 - val_loss: 0.4798 - val_acc: 0.8622\n",
      "Epoch 556/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3241 - acc: 0.8709 - val_loss: 0.4794 - val_acc: 0.8611\n",
      "Epoch 557/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3246 - acc: 0.8690 - val_loss: 0.4830 - val_acc: 0.8601\n",
      "Epoch 558/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3237 - acc: 0.8702 - val_loss: 0.4815 - val_acc: 0.8606\n",
      "Epoch 559/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3243 - acc: 0.8710 - val_loss: 0.4801 - val_acc: 0.8619\n",
      "Epoch 560/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3218 - acc: 0.8704 - val_loss: 0.4802 - val_acc: 0.8625\n",
      "Epoch 561/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3265 - acc: 0.8694 - val_loss: 0.4801 - val_acc: 0.8613\n",
      "Epoch 562/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3228 - acc: 0.8705 - val_loss: 0.4805 - val_acc: 0.8608\n",
      "Epoch 563/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3211 - acc: 0.8713 - val_loss: 0.4816 - val_acc: 0.8602\n",
      "Epoch 564/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3220 - acc: 0.8704 - val_loss: 0.4835 - val_acc: 0.8608\n",
      "Epoch 565/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3213 - acc: 0.8709 - val_loss: 0.4806 - val_acc: 0.8620\n",
      "Epoch 566/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3214 - acc: 0.8710 - val_loss: 0.4817 - val_acc: 0.8628\n",
      "Epoch 567/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3219 - acc: 0.8711 - val_loss: 0.4821 - val_acc: 0.8608\n",
      "Epoch 568/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3217 - acc: 0.8713 - val_loss: 0.4825 - val_acc: 0.8611\n",
      "Epoch 569/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3205 - acc: 0.8715 - val_loss: 0.4857 - val_acc: 0.8616\n",
      "Epoch 570/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3189 - acc: 0.8724 - val_loss: 0.4815 - val_acc: 0.8614\n",
      "Epoch 571/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3209 - acc: 0.8709 - val_loss: 0.4807 - val_acc: 0.8620\n",
      "Epoch 572/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3198 - acc: 0.8720 - val_loss: 0.4781 - val_acc: 0.8613\n",
      "Epoch 573/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3211 - acc: 0.8717 - val_loss: 0.4804 - val_acc: 0.8625\n",
      "Epoch 574/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3170 - acc: 0.8725 - val_loss: 0.4815 - val_acc: 0.8634\n",
      "Epoch 575/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3185 - acc: 0.8728 - val_loss: 0.4803 - val_acc: 0.8622\n",
      "Epoch 576/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3192 - acc: 0.8717 - val_loss: 0.4810 - val_acc: 0.8622\n",
      "Epoch 577/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3166 - acc: 0.8734 - val_loss: 0.4817 - val_acc: 0.8629\n",
      "Epoch 578/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3184 - acc: 0.8720 - val_loss: 0.4804 - val_acc: 0.8633\n",
      "Epoch 579/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3174 - acc: 0.8730 - val_loss: 0.4805 - val_acc: 0.8618\n",
      "Epoch 580/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3182 - acc: 0.8727 - val_loss: 0.4800 - val_acc: 0.8635\n",
      "Epoch 581/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3174 - acc: 0.8733 - val_loss: 0.4777 - val_acc: 0.8633\n",
      "Epoch 582/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3160 - acc: 0.8730 - val_loss: 0.4808 - val_acc: 0.8637\n",
      "Epoch 583/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3172 - acc: 0.8733 - val_loss: 0.4786 - val_acc: 0.8631\n",
      "Epoch 584/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3171 - acc: 0.8738 - val_loss: 0.4823 - val_acc: 0.8628\n",
      "Epoch 585/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3149 - acc: 0.8742 - val_loss: 0.4817 - val_acc: 0.8617\n",
      "Epoch 586/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3151 - acc: 0.8737 - val_loss: 0.4807 - val_acc: 0.8638\n",
      "Epoch 587/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3178 - acc: 0.8736 - val_loss: 0.4780 - val_acc: 0.8650\n",
      "Epoch 588/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3165 - acc: 0.8735 - val_loss: 0.4793 - val_acc: 0.8645\n",
      "Epoch 589/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3148 - acc: 0.8745 - val_loss: 0.4783 - val_acc: 0.8648\n",
      "Epoch 590/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3160 - acc: 0.8734 - val_loss: 0.4802 - val_acc: 0.8639\n",
      "Epoch 591/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3169 - acc: 0.8731 - val_loss: 0.4819 - val_acc: 0.8628\n",
      "Epoch 592/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3123 - acc: 0.8751 - val_loss: 0.4806 - val_acc: 0.8641\n",
      "Epoch 593/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3145 - acc: 0.8746 - val_loss: 0.4789 - val_acc: 0.8654\n",
      "Epoch 594/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3147 - acc: 0.8744 - val_loss: 0.4805 - val_acc: 0.8631\n",
      "Epoch 595/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3140 - acc: 0.8744 - val_loss: 0.4786 - val_acc: 0.8649\n",
      "Epoch 596/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3130 - acc: 0.8747 - val_loss: 0.4820 - val_acc: 0.8628\n",
      "Epoch 597/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3141 - acc: 0.8752 - val_loss: 0.4808 - val_acc: 0.8635\n",
      "Epoch 598/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3121 - acc: 0.8757 - val_loss: 0.4791 - val_acc: 0.8634\n",
      "Epoch 599/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3117 - acc: 0.8761 - val_loss: 0.4798 - val_acc: 0.8636\n",
      "Epoch 600/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3134 - acc: 0.8759 - val_loss: 0.4802 - val_acc: 0.8644\n",
      "Epoch 601/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3117 - acc: 0.8760 - val_loss: 0.4821 - val_acc: 0.8634\n",
      "Epoch 602/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3110 - acc: 0.8760 - val_loss: 0.4788 - val_acc: 0.8643\n",
      "Epoch 603/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3085 - acc: 0.8761 - val_loss: 0.4823 - val_acc: 0.8634\n",
      "Epoch 604/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3118 - acc: 0.8753 - val_loss: 0.4822 - val_acc: 0.8641\n",
      "Epoch 605/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3108 - acc: 0.8759 - val_loss: 0.4828 - val_acc: 0.8639\n",
      "Epoch 606/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3107 - acc: 0.8761 - val_loss: 0.4812 - val_acc: 0.8638\n",
      "Epoch 607/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3091 - acc: 0.8762 - val_loss: 0.4810 - val_acc: 0.8625\n",
      "Epoch 608/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3109 - acc: 0.8757 - val_loss: 0.4803 - val_acc: 0.8640\n",
      "Epoch 609/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3101 - acc: 0.8768 - val_loss: 0.4805 - val_acc: 0.8634\n",
      "Epoch 610/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3108 - acc: 0.8762 - val_loss: 0.4810 - val_acc: 0.8626\n",
      "Epoch 611/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3081 - acc: 0.8769 - val_loss: 0.4796 - val_acc: 0.8649\n",
      "Epoch 612/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3085 - acc: 0.8772 - val_loss: 0.4837 - val_acc: 0.8643\n",
      "Epoch 613/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3092 - acc: 0.8766 - val_loss: 0.4803 - val_acc: 0.8649\n",
      "Epoch 614/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3096 - acc: 0.8767 - val_loss: 0.4808 - val_acc: 0.8631\n",
      "Epoch 615/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3072 - acc: 0.8771 - val_loss: 0.4796 - val_acc: 0.8645\n",
      "Epoch 616/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3088 - acc: 0.8770 - val_loss: 0.4817 - val_acc: 0.8648\n",
      "Epoch 617/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3105 - acc: 0.8760 - val_loss: 0.4791 - val_acc: 0.8633\n",
      "Epoch 618/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3077 - acc: 0.8773 - val_loss: 0.4768 - val_acc: 0.8652\n",
      "Epoch 619/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3073 - acc: 0.8783 - val_loss: 0.4798 - val_acc: 0.8644\n",
      "Epoch 620/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3071 - acc: 0.8772 - val_loss: 0.4778 - val_acc: 0.8656\n",
      "Epoch 621/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3067 - acc: 0.8776 - val_loss: 0.4788 - val_acc: 0.8660\n",
      "Epoch 622/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3064 - acc: 0.8782 - val_loss: 0.4787 - val_acc: 0.8656\n",
      "Epoch 623/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3080 - acc: 0.8769 - val_loss: 0.4804 - val_acc: 0.8642\n",
      "Epoch 624/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3057 - acc: 0.8781 - val_loss: 0.4791 - val_acc: 0.8647\n",
      "Epoch 625/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3053 - acc: 0.8776 - val_loss: 0.4788 - val_acc: 0.8664\n",
      "Epoch 626/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3039 - acc: 0.8785 - val_loss: 0.4846 - val_acc: 0.8656\n",
      "Epoch 627/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3052 - acc: 0.8781 - val_loss: 0.4834 - val_acc: 0.8631\n",
      "Epoch 628/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3061 - acc: 0.8782 - val_loss: 0.4797 - val_acc: 0.8638\n",
      "Epoch 629/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3032 - acc: 0.8793 - val_loss: 0.4791 - val_acc: 0.8655\n",
      "Epoch 630/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3034 - acc: 0.8802 - val_loss: 0.4774 - val_acc: 0.8661\n",
      "Epoch 631/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3049 - acc: 0.8786 - val_loss: 0.4802 - val_acc: 0.8666\n",
      "Epoch 632/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3036 - acc: 0.8798 - val_loss: 0.4783 - val_acc: 0.8651\n",
      "Epoch 633/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3036 - acc: 0.8789 - val_loss: 0.4810 - val_acc: 0.8655\n",
      "Epoch 634/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3056 - acc: 0.8776 - val_loss: 0.4771 - val_acc: 0.8650\n",
      "Epoch 635/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3048 - acc: 0.8787 - val_loss: 0.4768 - val_acc: 0.8671\n",
      "Epoch 636/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3023 - acc: 0.8796 - val_loss: 0.4796 - val_acc: 0.8664\n",
      "Epoch 637/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3044 - acc: 0.8794 - val_loss: 0.4791 - val_acc: 0.8653\n",
      "Epoch 638/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3026 - acc: 0.8796 - val_loss: 0.4786 - val_acc: 0.8661\n",
      "Epoch 639/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3020 - acc: 0.8794 - val_loss: 0.4791 - val_acc: 0.8672\n",
      "Epoch 640/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3023 - acc: 0.8801 - val_loss: 0.4749 - val_acc: 0.8666\n",
      "Epoch 641/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3012 - acc: 0.8805 - val_loss: 0.4782 - val_acc: 0.8665\n",
      "Epoch 642/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3023 - acc: 0.8800 - val_loss: 0.4789 - val_acc: 0.8657\n",
      "Epoch 643/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3044 - acc: 0.8785 - val_loss: 0.4762 - val_acc: 0.8674\n",
      "Epoch 644/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3005 - acc: 0.8809 - val_loss: 0.4764 - val_acc: 0.8679\n",
      "Epoch 645/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.3008 - acc: 0.8804 - val_loss: 0.4809 - val_acc: 0.8652\n",
      "Epoch 646/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2999 - acc: 0.8811 - val_loss: 0.4803 - val_acc: 0.8674\n",
      "Epoch 647/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3004 - acc: 0.8805 - val_loss: 0.4794 - val_acc: 0.8667\n",
      "Epoch 648/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3015 - acc: 0.8801 - val_loss: 0.4774 - val_acc: 0.8687\n",
      "Epoch 649/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3015 - acc: 0.8803 - val_loss: 0.4802 - val_acc: 0.8673\n",
      "Epoch 650/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3001 - acc: 0.8807 - val_loss: 0.4799 - val_acc: 0.8659\n",
      "Epoch 651/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2980 - acc: 0.8814 - val_loss: 0.4792 - val_acc: 0.8674\n",
      "Epoch 652/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2989 - acc: 0.8806 - val_loss: 0.4770 - val_acc: 0.8677\n",
      "Epoch 653/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2996 - acc: 0.8808 - val_loss: 0.4776 - val_acc: 0.8653\n",
      "Epoch 654/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2986 - acc: 0.8810 - val_loss: 0.4790 - val_acc: 0.8677\n",
      "Epoch 655/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.3002 - acc: 0.8809 - val_loss: 0.4791 - val_acc: 0.8668\n",
      "Epoch 656/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2997 - acc: 0.8805 - val_loss: 0.4787 - val_acc: 0.8673\n",
      "Epoch 657/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2991 - acc: 0.8811 - val_loss: 0.4824 - val_acc: 0.8661\n",
      "Epoch 658/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2978 - acc: 0.8821 - val_loss: 0.4795 - val_acc: 0.8685\n",
      "Epoch 659/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2981 - acc: 0.8823 - val_loss: 0.4804 - val_acc: 0.8672\n",
      "Epoch 660/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2982 - acc: 0.8819 - val_loss: 0.4815 - val_acc: 0.8685\n",
      "Epoch 661/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2969 - acc: 0.8822 - val_loss: 0.4801 - val_acc: 0.8674\n",
      "Epoch 662/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2994 - acc: 0.8814 - val_loss: 0.4787 - val_acc: 0.8684\n",
      "Epoch 663/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2980 - acc: 0.8817 - val_loss: 0.4790 - val_acc: 0.8664\n",
      "Epoch 664/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2985 - acc: 0.8824 - val_loss: 0.4813 - val_acc: 0.8666\n",
      "Epoch 665/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2963 - acc: 0.8822 - val_loss: 0.4813 - val_acc: 0.8668\n",
      "Epoch 666/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2957 - acc: 0.8825 - val_loss: 0.4798 - val_acc: 0.8686\n",
      "Epoch 667/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2955 - acc: 0.8827 - val_loss: 0.4806 - val_acc: 0.8664\n",
      "Epoch 668/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2974 - acc: 0.8823 - val_loss: 0.4791 - val_acc: 0.8680\n",
      "Epoch 669/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2965 - acc: 0.8820 - val_loss: 0.4798 - val_acc: 0.8682\n",
      "Epoch 670/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2965 - acc: 0.8821 - val_loss: 0.4795 - val_acc: 0.8683\n",
      "Epoch 671/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2953 - acc: 0.8825 - val_loss: 0.4766 - val_acc: 0.8687\n",
      "Epoch 672/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2985 - acc: 0.8815 - val_loss: 0.4814 - val_acc: 0.8680\n",
      "Epoch 673/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2947 - acc: 0.8826 - val_loss: 0.4784 - val_acc: 0.8687\n",
      "Epoch 674/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2968 - acc: 0.8820 - val_loss: 0.4793 - val_acc: 0.8678\n",
      "Epoch 675/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2955 - acc: 0.8829 - val_loss: 0.4778 - val_acc: 0.8695\n",
      "Epoch 676/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2938 - acc: 0.8837 - val_loss: 0.4803 - val_acc: 0.8674\n",
      "Epoch 677/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2931 - acc: 0.8836 - val_loss: 0.4816 - val_acc: 0.8682\n",
      "Epoch 678/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2925 - acc: 0.8846 - val_loss: 0.4806 - val_acc: 0.8676\n",
      "Epoch 679/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2946 - acc: 0.8836 - val_loss: 0.4803 - val_acc: 0.8680\n",
      "Epoch 680/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2950 - acc: 0.8823 - val_loss: 0.4783 - val_acc: 0.8692\n",
      "Epoch 681/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2956 - acc: 0.8830 - val_loss: 0.4773 - val_acc: 0.8682\n",
      "Epoch 682/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2923 - acc: 0.8842 - val_loss: 0.4807 - val_acc: 0.8689\n",
      "Epoch 683/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2900 - acc: 0.8850 - val_loss: 0.4809 - val_acc: 0.8688\n",
      "Epoch 684/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2937 - acc: 0.8834 - val_loss: 0.4814 - val_acc: 0.8692\n",
      "Epoch 685/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2941 - acc: 0.8837 - val_loss: 0.4782 - val_acc: 0.8698\n",
      "Epoch 686/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2913 - acc: 0.8853 - val_loss: 0.4808 - val_acc: 0.8695\n",
      "Epoch 687/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2916 - acc: 0.8845 - val_loss: 0.4798 - val_acc: 0.8688\n",
      "Epoch 688/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2917 - acc: 0.8846 - val_loss: 0.4818 - val_acc: 0.8688\n",
      "Epoch 689/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2901 - acc: 0.8852 - val_loss: 0.4810 - val_acc: 0.8705\n",
      "Epoch 690/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2916 - acc: 0.8842 - val_loss: 0.4812 - val_acc: 0.8690\n",
      "Epoch 691/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2930 - acc: 0.8839 - val_loss: 0.4787 - val_acc: 0.8691\n",
      "Epoch 692/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2922 - acc: 0.8839 - val_loss: 0.4769 - val_acc: 0.8697\n",
      "Epoch 693/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2915 - acc: 0.8847 - val_loss: 0.4810 - val_acc: 0.8688\n",
      "Epoch 694/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2928 - acc: 0.8844 - val_loss: 0.4792 - val_acc: 0.8690\n",
      "Epoch 695/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2910 - acc: 0.8857 - val_loss: 0.4818 - val_acc: 0.8674\n",
      "Epoch 696/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2909 - acc: 0.8849 - val_loss: 0.4794 - val_acc: 0.8676\n",
      "Epoch 697/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2911 - acc: 0.8846 - val_loss: 0.4772 - val_acc: 0.8694\n",
      "Epoch 698/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2894 - acc: 0.8864 - val_loss: 0.4804 - val_acc: 0.8686\n",
      "Epoch 699/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2900 - acc: 0.8854 - val_loss: 0.4784 - val_acc: 0.8688\n",
      "Epoch 700/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2911 - acc: 0.8848 - val_loss: 0.4800 - val_acc: 0.8685\n",
      "Epoch 701/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2899 - acc: 0.8852 - val_loss: 0.4760 - val_acc: 0.8701\n",
      "Epoch 702/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2890 - acc: 0.8861 - val_loss: 0.4795 - val_acc: 0.8694\n",
      "Epoch 703/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2899 - acc: 0.8846 - val_loss: 0.4800 - val_acc: 0.8681\n",
      "Epoch 704/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2885 - acc: 0.8861 - val_loss: 0.4785 - val_acc: 0.8684\n",
      "Epoch 705/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2898 - acc: 0.8852 - val_loss: 0.4754 - val_acc: 0.8686\n",
      "Epoch 706/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2885 - acc: 0.8863 - val_loss: 0.4787 - val_acc: 0.8690\n",
      "Epoch 707/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2890 - acc: 0.8857 - val_loss: 0.4823 - val_acc: 0.8683\n",
      "Epoch 708/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2876 - acc: 0.8862 - val_loss: 0.4778 - val_acc: 0.8687\n",
      "Epoch 709/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2848 - acc: 0.8879 - val_loss: 0.4793 - val_acc: 0.8698\n",
      "Epoch 710/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2877 - acc: 0.8862 - val_loss: 0.4807 - val_acc: 0.8691\n",
      "Epoch 711/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2891 - acc: 0.8851 - val_loss: 0.4796 - val_acc: 0.8698\n",
      "Epoch 712/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2873 - acc: 0.8866 - val_loss: 0.4801 - val_acc: 0.8698\n",
      "Epoch 713/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2889 - acc: 0.8853 - val_loss: 0.4793 - val_acc: 0.8699\n",
      "Epoch 714/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2875 - acc: 0.8870 - val_loss: 0.4771 - val_acc: 0.8707\n",
      "Epoch 715/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2881 - acc: 0.8859 - val_loss: 0.4772 - val_acc: 0.8696\n",
      "Epoch 716/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2871 - acc: 0.8873 - val_loss: 0.4798 - val_acc: 0.8683\n",
      "Epoch 717/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2864 - acc: 0.8866 - val_loss: 0.4778 - val_acc: 0.8700\n",
      "Epoch 718/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2874 - acc: 0.8858 - val_loss: 0.4778 - val_acc: 0.8712\n",
      "Epoch 719/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2871 - acc: 0.8865 - val_loss: 0.4795 - val_acc: 0.8709\n",
      "Epoch 720/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2864 - acc: 0.8872 - val_loss: 0.4801 - val_acc: 0.8707\n",
      "Epoch 721/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2856 - acc: 0.8872 - val_loss: 0.4800 - val_acc: 0.8713\n",
      "Epoch 722/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2865 - acc: 0.8866 - val_loss: 0.4803 - val_acc: 0.8714\n",
      "Epoch 723/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2860 - acc: 0.8867 - val_loss: 0.4803 - val_acc: 0.8695\n",
      "Epoch 724/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2870 - acc: 0.8870 - val_loss: 0.4805 - val_acc: 0.8701\n",
      "Epoch 725/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2871 - acc: 0.8865 - val_loss: 0.4757 - val_acc: 0.8700\n",
      "Epoch 726/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2848 - acc: 0.8864 - val_loss: 0.4800 - val_acc: 0.8701\n",
      "Epoch 727/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2868 - acc: 0.8873 - val_loss: 0.4783 - val_acc: 0.8693\n",
      "Epoch 728/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2841 - acc: 0.8880 - val_loss: 0.4784 - val_acc: 0.8708\n",
      "Epoch 729/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2852 - acc: 0.8870 - val_loss: 0.4796 - val_acc: 0.8722\n",
      "Epoch 730/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2851 - acc: 0.8872 - val_loss: 0.4790 - val_acc: 0.8699\n",
      "Epoch 731/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2867 - acc: 0.8865 - val_loss: 0.4784 - val_acc: 0.8701\n",
      "Epoch 732/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2861 - acc: 0.8870 - val_loss: 0.4774 - val_acc: 0.8706\n",
      "Epoch 733/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2841 - acc: 0.8874 - val_loss: 0.4802 - val_acc: 0.8701\n",
      "Epoch 734/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2855 - acc: 0.8871 - val_loss: 0.4753 - val_acc: 0.8706\n",
      "Epoch 735/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2820 - acc: 0.8885 - val_loss: 0.4782 - val_acc: 0.8697\n",
      "Epoch 736/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2838 - acc: 0.8878 - val_loss: 0.4799 - val_acc: 0.8704\n",
      "Epoch 737/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2826 - acc: 0.8886 - val_loss: 0.4823 - val_acc: 0.8712\n",
      "Epoch 738/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2847 - acc: 0.8879 - val_loss: 0.4780 - val_acc: 0.8714\n",
      "Epoch 739/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2810 - acc: 0.8894 - val_loss: 0.4803 - val_acc: 0.8709\n",
      "Epoch 740/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2836 - acc: 0.8884 - val_loss: 0.4826 - val_acc: 0.8704\n",
      "Epoch 741/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2840 - acc: 0.8878 - val_loss: 0.4803 - val_acc: 0.8691\n",
      "Epoch 742/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2833 - acc: 0.8885 - val_loss: 0.4817 - val_acc: 0.8708\n",
      "Epoch 743/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2806 - acc: 0.8888 - val_loss: 0.4839 - val_acc: 0.8713\n",
      "Epoch 744/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2821 - acc: 0.8886 - val_loss: 0.4810 - val_acc: 0.8706\n",
      "Epoch 745/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2826 - acc: 0.8887 - val_loss: 0.4802 - val_acc: 0.8716\n",
      "Epoch 746/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2837 - acc: 0.8883 - val_loss: 0.4798 - val_acc: 0.8719\n",
      "Epoch 747/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2806 - acc: 0.8893 - val_loss: 0.4802 - val_acc: 0.8716\n",
      "Epoch 748/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2812 - acc: 0.8899 - val_loss: 0.4831 - val_acc: 0.8719\n",
      "Epoch 749/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2824 - acc: 0.8884 - val_loss: 0.4807 - val_acc: 0.8708\n",
      "Epoch 750/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2804 - acc: 0.8896 - val_loss: 0.4812 - val_acc: 0.8715\n",
      "Epoch 751/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2810 - acc: 0.8897 - val_loss: 0.4816 - val_acc: 0.8696\n",
      "Epoch 752/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2808 - acc: 0.8897 - val_loss: 0.4820 - val_acc: 0.8698\n",
      "Epoch 753/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2792 - acc: 0.8903 - val_loss: 0.4838 - val_acc: 0.8698\n",
      "Epoch 754/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2806 - acc: 0.8896 - val_loss: 0.4792 - val_acc: 0.8712\n",
      "Epoch 755/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2818 - acc: 0.8889 - val_loss: 0.4805 - val_acc: 0.8700\n",
      "Epoch 756/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2752 - acc: 0.8923 - val_loss: 0.4807 - val_acc: 0.8715\n",
      "Epoch 757/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2788 - acc: 0.8899 - val_loss: 0.4805 - val_acc: 0.8714\n",
      "Epoch 758/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2798 - acc: 0.8903 - val_loss: 0.4826 - val_acc: 0.8712\n",
      "Epoch 759/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2801 - acc: 0.8904 - val_loss: 0.4805 - val_acc: 0.8715\n",
      "Epoch 760/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2772 - acc: 0.8906 - val_loss: 0.4793 - val_acc: 0.8724\n",
      "Epoch 761/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2797 - acc: 0.8898 - val_loss: 0.4808 - val_acc: 0.8704\n",
      "Epoch 762/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2792 - acc: 0.8894 - val_loss: 0.4797 - val_acc: 0.8709\n",
      "Epoch 763/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2805 - acc: 0.8896 - val_loss: 0.4789 - val_acc: 0.8727\n",
      "Epoch 764/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2779 - acc: 0.8911 - val_loss: 0.4797 - val_acc: 0.8705\n",
      "Epoch 765/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2756 - acc: 0.8919 - val_loss: 0.4809 - val_acc: 0.8710\n",
      "Epoch 766/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2776 - acc: 0.8905 - val_loss: 0.4827 - val_acc: 0.8692\n",
      "Epoch 767/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2790 - acc: 0.8901 - val_loss: 0.4793 - val_acc: 0.8715\n",
      "Epoch 768/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2775 - acc: 0.8902 - val_loss: 0.4768 - val_acc: 0.8724\n",
      "Epoch 769/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2799 - acc: 0.8902 - val_loss: 0.4759 - val_acc: 0.8728\n",
      "Epoch 770/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2766 - acc: 0.8908 - val_loss: 0.4788 - val_acc: 0.8713\n",
      "Epoch 771/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2788 - acc: 0.8906 - val_loss: 0.4770 - val_acc: 0.8715\n",
      "Epoch 772/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2751 - acc: 0.8919 - val_loss: 0.4811 - val_acc: 0.8730\n",
      "Epoch 773/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2759 - acc: 0.8921 - val_loss: 0.4772 - val_acc: 0.8711\n",
      "Epoch 774/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2767 - acc: 0.8911 - val_loss: 0.4779 - val_acc: 0.8713\n",
      "Epoch 775/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2777 - acc: 0.8912 - val_loss: 0.4839 - val_acc: 0.8694\n",
      "Epoch 776/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2761 - acc: 0.8915 - val_loss: 0.4795 - val_acc: 0.8717\n",
      "Epoch 777/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2779 - acc: 0.8902 - val_loss: 0.4808 - val_acc: 0.8720\n",
      "Epoch 778/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2774 - acc: 0.8913 - val_loss: 0.4815 - val_acc: 0.8709\n",
      "Epoch 779/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2768 - acc: 0.8917 - val_loss: 0.4803 - val_acc: 0.8712\n",
      "Epoch 780/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2754 - acc: 0.8914 - val_loss: 0.4788 - val_acc: 0.8730\n",
      "Epoch 781/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2775 - acc: 0.8913 - val_loss: 0.4801 - val_acc: 0.8720\n",
      "Epoch 782/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2753 - acc: 0.8917 - val_loss: 0.4792 - val_acc: 0.8714\n",
      "Epoch 783/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2781 - acc: 0.8906 - val_loss: 0.4790 - val_acc: 0.8704\n",
      "Epoch 784/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2738 - acc: 0.8931 - val_loss: 0.4834 - val_acc: 0.8720\n",
      "Epoch 785/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2733 - acc: 0.8924 - val_loss: 0.4809 - val_acc: 0.8718\n",
      "Epoch 786/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2764 - acc: 0.8918 - val_loss: 0.4801 - val_acc: 0.8713\n",
      "Epoch 787/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2753 - acc: 0.8914 - val_loss: 0.4809 - val_acc: 0.8713\n",
      "Epoch 788/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2734 - acc: 0.8928 - val_loss: 0.4836 - val_acc: 0.8716\n",
      "Epoch 789/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2755 - acc: 0.8914 - val_loss: 0.4793 - val_acc: 0.8718\n",
      "Epoch 790/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2749 - acc: 0.8920 - val_loss: 0.4789 - val_acc: 0.8720\n",
      "Epoch 791/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2723 - acc: 0.8931 - val_loss: 0.4806 - val_acc: 0.8717\n",
      "Epoch 792/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2736 - acc: 0.8922 - val_loss: 0.4800 - val_acc: 0.8727\n",
      "Epoch 793/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2750 - acc: 0.8919 - val_loss: 0.4783 - val_acc: 0.8736\n",
      "Epoch 794/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2745 - acc: 0.8921 - val_loss: 0.4812 - val_acc: 0.8709\n",
      "Epoch 795/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2739 - acc: 0.8920 - val_loss: 0.4808 - val_acc: 0.8720\n",
      "Epoch 796/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2748 - acc: 0.8922 - val_loss: 0.4797 - val_acc: 0.8735\n",
      "Epoch 797/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2738 - acc: 0.8924 - val_loss: 0.4799 - val_acc: 0.8727\n",
      "Epoch 798/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2734 - acc: 0.8923 - val_loss: 0.4801 - val_acc: 0.8719\n",
      "Epoch 799/800\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 0.2735 - acc: 0.8923 - val_loss: 0.4793 - val_acc: 0.8729\n",
      "Epoch 800/800\n",
      "212747/212747 [==============================] - 11s 52us/step - loss: 0.2747 - acc: 0.8923 - val_loss: 0.4801 - val_acc: 0.8724\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "sys.path.append(os.path.realpath(\"../../\"))\n",
    "import ptetaphi_nn\n",
    "import tools\n",
    "with open(\"/home/cmccracken/start_tf/bbb/filepath.txt\", 'r') as f:\n",
    "    filename = f.read()\n",
    "    \n",
    "s_table = tools.open_file(filename, sort_by=\"tag\")\n",
    "# filter by realistic situation where we have 3 tags and 3 or 4 jets.\n",
    "# ignore the case where there may be >4 since those are pretty rare\n",
    "nb4 = (s_table.nbjets == 3) | (s_table.nbjets == 4) # 3 or 4 b-jets exist\n",
    "nt3 = s_table.nbtags==3  # 3 b tags\n",
    "nb4nt3 = nb4 & nt3\n",
    "events = s_table[nb4nt3]\n",
    "print(len(events))\n",
    "\n",
    "# and ensure that the 3 tags are actually correct\n",
    "# this results in very little event loss\n",
    "events = events[events.truth[:,0] == 1]\n",
    "events = events[events.truth[:,1] == 1]\n",
    "events = events[events.truth[:,2] == 1]\n",
    "print(len(events))\n",
    "\n",
    "cutoff = 10  # not many events have >10 jets\n",
    "# \"pad\" = ensure all events have same length, cut off ends if needed\n",
    "events = tools.pad(events, cutoff)\n",
    "\n",
    "import importlib\n",
    "importlib.reload(ptetaphi_nn)\n",
    "nn = ptetaphi_nn.PtEtaPhiNN(events, chop=0, print_summary=True)\n",
    "nn.learn(epochs=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60785/60785 [00:00<00:00, 171319.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 89.05 percent\n",
      "ignoring 0.00 percent (0 events) of 60785 events\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(savename=\"best_with_all_jets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1383898e+00, -9.1206354e-01, -5.6130493e-01, ...,\n",
       "        -3.9141234e-03,  1.3328490e-03,  2.2829163e-03],\n",
       "       [-2.2350993e-02,  5.4453796e-01, -8.5422295e-01, ...,\n",
       "        -3.9141234e-03,  1.3328490e-03,  2.2829163e-03],\n",
       "       [ 5.7765067e-01,  1.5442677e+00, -8.4189606e-01, ...,\n",
       "        -3.9141234e-03,  1.3328490e-03,  2.2829163e-03],\n",
       "       ...,\n",
       "       [ 4.2004883e-01,  4.4985023e-01,  3.6350715e-01, ...,\n",
       "        -3.8165338e+00,  8.4538841e+00,  6.1675253e+00],\n",
       "       [-3.4913829e-01, -1.6886887e-01,  7.5339997e-01, ...,\n",
       "        -3.9141234e-03,  1.3328490e-03,  2.2829163e-03],\n",
       "       [ 3.4535319e-01,  1.2522689e-01,  4.4298139e-01, ...,\n",
       "        -1.0616757e+00,  1.3328490e-03,  2.2829163e-03]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the architecture string to a file\n",
    "models_dir = \"/home/cmccracken/start_tf/bbb/models/\"\n",
    "with open(models_dir+'architecture_02_07_2020.json', 'w') as arch_file:\n",
    "    arch_file.write(nn.model.to_json())\n",
    "# now save the weights as an HDF5 file\n",
    "nn.model.save_weights(models_dir+'weights_02_07_2020.h5')\n",
    "# and print csv\n",
    "tools.scale_nn_input(events, chop=0, save_csv=models_dir+\"scaling_parameters_02_07_2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
