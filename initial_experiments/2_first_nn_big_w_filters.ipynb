{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The A2 Big network with the filters from resolved_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting data by tag\n",
      "filtering from 777150 events\n",
      "307055\n",
      "307055\n",
      "scaling\n",
      "DATA FOR .csv file:\n",
      "pt_mean,pt_mean,pt_var,eta_mean,eta_var,phi_mean,phi_var\n",
      "256.11149752858006,27916.901125095617,-0.0014992219260515209,1.0677470288555424,0.005690458419218211,3.294358926131252\n",
      "164.86561670332696,14612.4925384995,-0.005093684343904041,1.1350676873768522,-0.003788391127691907,3.2521407108903593\n",
      "71.18310004621601,2599.657714345263,-0.0007020347165962389,0.948686931082751,7.804521853106575e-05,2.712787621020359\n",
      "150.26323922515658,22397.587779157522,-0.1506258762399934,1.5888654209540234,0.009877966251750877,2.7656118537515018\n",
      "46.90408456008538,4780.308629897803,-0.14653969271759043,1.1602086184801772,0.001791804223719425,1.59342684619721\n",
      "14.505335345705168,1098.7986691879564,-0.07913734843136995,0.5722631730012789,8.753826660580214e-07,0.6762211067418402\n",
      "3.99437359294937,254.39851805473623,-0.03038944530818026,0.2053642550098717,0.0008098143287622032,0.2249127154012072\n",
      "0.9509270640775735,54.45787351567776,-0.008510538030600385,0.05569763754507978,0.0008905834010886491,0.06008066312805069\n",
      "0.1906812826587929,10.223097468145681,-0.0018911028311147117,0.011873292618613255,0.00012580330172694303,0.012220242209722327\n",
      "0.031230829858855225,1.6229911886948343,-0.00028171706887985447,0.0020426043063287943,-0.00013843422273157217,0.002177124252596176\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 700)               15400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 408       \n",
      "=================================================================\n",
      "Total params: 552,220\n",
      "Trainable params: 552,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 214938 samples, validate on 30706 samples\n",
      "Epoch 1/1000\n",
      "214938/214938 [==============================] - 12s 54us/step - loss: 1.1826 - acc: 0.4917 - val_loss: 1.1485 - val_acc: 0.5089\n",
      "Epoch 2/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1521 - acc: 0.5087 - val_loss: 1.1404 - val_acc: 0.5147\n",
      "Epoch 3/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1473 - acc: 0.5115 - val_loss: 1.1419 - val_acc: 0.5161\n",
      "Epoch 4/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 1.1451 - acc: 0.5116 - val_loss: 1.1371 - val_acc: 0.5158\n",
      "Epoch 5/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1439 - acc: 0.5121 - val_loss: 1.1352 - val_acc: 0.5164\n",
      "Epoch 6/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 1.1427 - acc: 0.5137 - val_loss: 1.1361 - val_acc: 0.5168\n",
      "Epoch 7/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 1.1410 - acc: 0.5132 - val_loss: 1.1343 - val_acc: 0.5149\n",
      "Epoch 8/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1404 - acc: 0.5142 - val_loss: 1.1348 - val_acc: 0.5189\n",
      "Epoch 9/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1393 - acc: 0.5142 - val_loss: 1.1324 - val_acc: 0.5158\n",
      "Epoch 10/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1380 - acc: 0.5144 - val_loss: 1.1320 - val_acc: 0.5170\n",
      "Epoch 11/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1371 - acc: 0.5156 - val_loss: 1.1314 - val_acc: 0.5189\n",
      "Epoch 12/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1368 - acc: 0.5152 - val_loss: 1.1303 - val_acc: 0.5218\n",
      "Epoch 13/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1357 - acc: 0.5151 - val_loss: 1.1301 - val_acc: 0.5186\n",
      "Epoch 14/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1349 - acc: 0.5166 - val_loss: 1.1295 - val_acc: 0.5189\n",
      "Epoch 15/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1345 - acc: 0.5165 - val_loss: 1.1282 - val_acc: 0.5220\n",
      "Epoch 16/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1325 - acc: 0.5172 - val_loss: 1.1289 - val_acc: 0.5213\n",
      "Epoch 17/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 1.1326 - acc: 0.5172 - val_loss: 1.1319 - val_acc: 0.5157\n",
      "Epoch 18/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1320 - acc: 0.5170 - val_loss: 1.1281 - val_acc: 0.5214\n",
      "Epoch 19/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1313 - acc: 0.5181 - val_loss: 1.1256 - val_acc: 0.5207\n",
      "Epoch 20/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1299 - acc: 0.5184 - val_loss: 1.1281 - val_acc: 0.5187\n",
      "Epoch 21/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 1.1289 - acc: 0.5186 - val_loss: 1.1248 - val_acc: 0.5221\n",
      "Epoch 22/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1281 - acc: 0.5196 - val_loss: 1.1234 - val_acc: 0.5215\n",
      "Epoch 23/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 1.1269 - acc: 0.5187 - val_loss: 1.1229 - val_acc: 0.5220\n",
      "Epoch 24/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1261 - acc: 0.5200 - val_loss: 1.1221 - val_acc: 0.5233\n",
      "Epoch 25/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1251 - acc: 0.5209 - val_loss: 1.1238 - val_acc: 0.5229\n",
      "Epoch 26/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1237 - acc: 0.5209 - val_loss: 1.1223 - val_acc: 0.5226\n",
      "Epoch 27/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1228 - acc: 0.5223 - val_loss: 1.1213 - val_acc: 0.5222\n",
      "Epoch 28/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1214 - acc: 0.5218 - val_loss: 1.1199 - val_acc: 0.5229\n",
      "Epoch 29/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1201 - acc: 0.5224 - val_loss: 1.1197 - val_acc: 0.5245\n",
      "Epoch 30/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1193 - acc: 0.5229 - val_loss: 1.1207 - val_acc: 0.5229\n",
      "Epoch 31/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1178 - acc: 0.5228 - val_loss: 1.1184 - val_acc: 0.5236\n",
      "Epoch 32/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1167 - acc: 0.5245 - val_loss: 1.1178 - val_acc: 0.5247\n",
      "Epoch 33/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1146 - acc: 0.5248 - val_loss: 1.1160 - val_acc: 0.5264\n",
      "Epoch 34/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1134 - acc: 0.5253 - val_loss: 1.1165 - val_acc: 0.5251\n",
      "Epoch 35/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1118 - acc: 0.5265 - val_loss: 1.1146 - val_acc: 0.5275\n",
      "Epoch 36/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1108 - acc: 0.5256 - val_loss: 1.1129 - val_acc: 0.5272\n",
      "Epoch 37/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 1.1084 - acc: 0.5276 - val_loss: 1.1128 - val_acc: 0.5279\n",
      "Epoch 38/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1071 - acc: 0.5281 - val_loss: 1.1112 - val_acc: 0.5267\n",
      "Epoch 39/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1058 - acc: 0.5284 - val_loss: 1.1119 - val_acc: 0.5267\n",
      "Epoch 40/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.1040 - acc: 0.5289 - val_loss: 1.1086 - val_acc: 0.5286\n",
      "Epoch 41/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 1.1023 - acc: 0.5309 - val_loss: 1.1089 - val_acc: 0.5286\n",
      "Epoch 42/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 1.1006 - acc: 0.5315 - val_loss: 1.1079 - val_acc: 0.5288\n",
      "Epoch 43/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0989 - acc: 0.5317 - val_loss: 1.1085 - val_acc: 0.5292\n",
      "Epoch 44/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0973 - acc: 0.5318 - val_loss: 1.1031 - val_acc: 0.5293\n",
      "Epoch 45/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0960 - acc: 0.5322 - val_loss: 1.1035 - val_acc: 0.5331\n",
      "Epoch 46/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0937 - acc: 0.5336 - val_loss: 1.1038 - val_acc: 0.5335\n",
      "Epoch 47/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0923 - acc: 0.5338 - val_loss: 1.1019 - val_acc: 0.5338\n",
      "Epoch 48/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0898 - acc: 0.5350 - val_loss: 1.1017 - val_acc: 0.5355\n",
      "Epoch 49/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0892 - acc: 0.5358 - val_loss: 1.0988 - val_acc: 0.5326\n",
      "Epoch 50/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0868 - acc: 0.5363 - val_loss: 1.0972 - val_acc: 0.5361\n",
      "Epoch 51/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0851 - acc: 0.5376 - val_loss: 1.0997 - val_acc: 0.5350\n",
      "Epoch 52/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0826 - acc: 0.5390 - val_loss: 1.0978 - val_acc: 0.5375\n",
      "Epoch 53/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 1.0812 - acc: 0.5392 - val_loss: 1.0943 - val_acc: 0.5381\n",
      "Epoch 54/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0797 - acc: 0.5402 - val_loss: 1.0932 - val_acc: 0.5391\n",
      "Epoch 55/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 1.0790 - acc: 0.5404 - val_loss: 1.0919 - val_acc: 0.5410\n",
      "Epoch 56/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0768 - acc: 0.5417 - val_loss: 1.0917 - val_acc: 0.5402\n",
      "Epoch 57/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 1.0755 - acc: 0.5419 - val_loss: 1.0910 - val_acc: 0.5397\n",
      "Epoch 58/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0729 - acc: 0.5435 - val_loss: 1.0885 - val_acc: 0.5419\n",
      "Epoch 59/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0721 - acc: 0.5428 - val_loss: 1.0883 - val_acc: 0.5429\n",
      "Epoch 60/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0692 - acc: 0.5442 - val_loss: 1.0881 - val_acc: 0.5417\n",
      "Epoch 61/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 1.0682 - acc: 0.5449 - val_loss: 1.0876 - val_acc: 0.5426\n",
      "Epoch 62/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0665 - acc: 0.5449 - val_loss: 1.0882 - val_acc: 0.5414\n",
      "Epoch 63/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0644 - acc: 0.5457 - val_loss: 1.0841 - val_acc: 0.5446\n",
      "Epoch 64/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0627 - acc: 0.5464 - val_loss: 1.0816 - val_acc: 0.5450\n",
      "Epoch 65/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 1.0612 - acc: 0.5471 - val_loss: 1.0825 - val_acc: 0.5462\n",
      "Epoch 66/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 1.0584 - acc: 0.5479 - val_loss: 1.0805 - val_acc: 0.5476\n",
      "Epoch 67/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0574 - acc: 0.5496 - val_loss: 1.0809 - val_acc: 0.5467\n",
      "Epoch 68/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 1.0559 - acc: 0.5503 - val_loss: 1.0798 - val_acc: 0.5498\n",
      "Epoch 69/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0544 - acc: 0.5510 - val_loss: 1.0786 - val_acc: 0.5482\n",
      "Epoch 70/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 1.0532 - acc: 0.5509 - val_loss: 1.0776 - val_acc: 0.5503\n",
      "Epoch 71/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0518 - acc: 0.5524 - val_loss: 1.0738 - val_acc: 0.5517\n",
      "Epoch 72/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0500 - acc: 0.5524 - val_loss: 1.0774 - val_acc: 0.5514\n",
      "Epoch 73/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0492 - acc: 0.5542 - val_loss: 1.0755 - val_acc: 0.5526\n",
      "Epoch 74/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0478 - acc: 0.5537 - val_loss: 1.0754 - val_acc: 0.5549\n",
      "Epoch 75/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0459 - acc: 0.5552 - val_loss: 1.0730 - val_acc: 0.5547\n",
      "Epoch 76/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 1.0448 - acc: 0.5541 - val_loss: 1.0729 - val_acc: 0.5532\n",
      "Epoch 77/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0423 - acc: 0.5563 - val_loss: 1.0747 - val_acc: 0.5539\n",
      "Epoch 78/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0417 - acc: 0.5567 - val_loss: 1.0711 - val_acc: 0.5562\n",
      "Epoch 79/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0402 - acc: 0.5579 - val_loss: 1.0729 - val_acc: 0.5560\n",
      "Epoch 80/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0397 - acc: 0.5578 - val_loss: 1.0704 - val_acc: 0.5578\n",
      "Epoch 81/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0377 - acc: 0.5585 - val_loss: 1.0674 - val_acc: 0.5566\n",
      "Epoch 82/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0356 - acc: 0.5598 - val_loss: 1.0722 - val_acc: 0.5564\n",
      "Epoch 83/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 1.0340 - acc: 0.5599 - val_loss: 1.0682 - val_acc: 0.5580\n",
      "Epoch 84/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0344 - acc: 0.5607 - val_loss: 1.0676 - val_acc: 0.5595\n",
      "Epoch 85/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 1.0331 - acc: 0.5606 - val_loss: 1.0664 - val_acc: 0.5603\n",
      "Epoch 86/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0299 - acc: 0.5624 - val_loss: 1.0633 - val_acc: 0.5596\n",
      "Epoch 87/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0279 - acc: 0.5629 - val_loss: 1.0674 - val_acc: 0.5592\n",
      "Epoch 88/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0278 - acc: 0.5632 - val_loss: 1.0621 - val_acc: 0.5631\n",
      "Epoch 89/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0261 - acc: 0.5641 - val_loss: 1.0608 - val_acc: 0.5642\n",
      "Epoch 90/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0248 - acc: 0.5640 - val_loss: 1.0597 - val_acc: 0.5642\n",
      "Epoch 91/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0241 - acc: 0.5647 - val_loss: 1.0603 - val_acc: 0.5632\n",
      "Epoch 92/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0221 - acc: 0.5662 - val_loss: 1.0635 - val_acc: 0.5617\n",
      "Epoch 93/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0207 - acc: 0.5663 - val_loss: 1.0610 - val_acc: 0.5638\n",
      "Epoch 94/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 1.0196 - acc: 0.5673 - val_loss: 1.0617 - val_acc: 0.5663\n",
      "Epoch 95/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 1.0191 - acc: 0.5667 - val_loss: 1.0596 - val_acc: 0.5638\n",
      "Epoch 96/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0183 - acc: 0.5670 - val_loss: 1.0573 - val_acc: 0.5644\n",
      "Epoch 97/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0174 - acc: 0.5684 - val_loss: 1.0568 - val_acc: 0.5660\n",
      "Epoch 98/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0146 - acc: 0.5700 - val_loss: 1.0594 - val_acc: 0.5672\n",
      "Epoch 99/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0146 - acc: 0.5694 - val_loss: 1.0543 - val_acc: 0.5668\n",
      "Epoch 100/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 1.0139 - acc: 0.5695 - val_loss: 1.0600 - val_acc: 0.5664\n",
      "Epoch 101/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0117 - acc: 0.5709 - val_loss: 1.0644 - val_acc: 0.5674\n",
      "Epoch 102/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0112 - acc: 0.5707 - val_loss: 1.0551 - val_acc: 0.5688\n",
      "Epoch 103/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0090 - acc: 0.5721 - val_loss: 1.0553 - val_acc: 0.5677\n",
      "Epoch 104/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0081 - acc: 0.5718 - val_loss: 1.0538 - val_acc: 0.5692\n",
      "Epoch 105/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0079 - acc: 0.5728 - val_loss: 1.0519 - val_acc: 0.5712\n",
      "Epoch 106/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0056 - acc: 0.5725 - val_loss: 1.0532 - val_acc: 0.5695\n",
      "Epoch 107/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 1.0055 - acc: 0.5736 - val_loss: 1.0523 - val_acc: 0.5698\n",
      "Epoch 108/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 1.0033 - acc: 0.5740 - val_loss: 1.0555 - val_acc: 0.5708\n",
      "Epoch 109/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 1.0023 - acc: 0.5745 - val_loss: 1.0528 - val_acc: 0.5706\n",
      "Epoch 110/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 1.0018 - acc: 0.5750 - val_loss: 1.0533 - val_acc: 0.5710\n",
      "Epoch 111/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9995 - acc: 0.5762 - val_loss: 1.0492 - val_acc: 0.5724\n",
      "Epoch 112/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9999 - acc: 0.5746 - val_loss: 1.0498 - val_acc: 0.5729\n",
      "Epoch 113/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9981 - acc: 0.5767 - val_loss: 1.0485 - val_acc: 0.5758\n",
      "Epoch 114/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9976 - acc: 0.5771 - val_loss: 1.0496 - val_acc: 0.5719\n",
      "Epoch 115/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9978 - acc: 0.5777 - val_loss: 1.0479 - val_acc: 0.5757\n",
      "Epoch 116/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9950 - acc: 0.5789 - val_loss: 1.0462 - val_acc: 0.5761\n",
      "Epoch 117/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9927 - acc: 0.5788 - val_loss: 1.0448 - val_acc: 0.5759\n",
      "Epoch 118/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9929 - acc: 0.5791 - val_loss: 1.0424 - val_acc: 0.5739\n",
      "Epoch 119/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9931 - acc: 0.5790 - val_loss: 1.0445 - val_acc: 0.5737\n",
      "Epoch 120/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9894 - acc: 0.5804 - val_loss: 1.0464 - val_acc: 0.5756\n",
      "Epoch 121/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9896 - acc: 0.5807 - val_loss: 1.0465 - val_acc: 0.5774\n",
      "Epoch 122/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9898 - acc: 0.5810 - val_loss: 1.0440 - val_acc: 0.5776\n",
      "Epoch 123/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9892 - acc: 0.5809 - val_loss: 1.0431 - val_acc: 0.5804\n",
      "Epoch 124/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9873 - acc: 0.5812 - val_loss: 1.0447 - val_acc: 0.5761\n",
      "Epoch 125/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9865 - acc: 0.5820 - val_loss: 1.0427 - val_acc: 0.5798\n",
      "Epoch 126/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9856 - acc: 0.5834 - val_loss: 1.0457 - val_acc: 0.5792\n",
      "Epoch 127/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9835 - acc: 0.5835 - val_loss: 1.0404 - val_acc: 0.5791\n",
      "Epoch 128/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9839 - acc: 0.5838 - val_loss: 1.0424 - val_acc: 0.5807\n",
      "Epoch 129/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9828 - acc: 0.5834 - val_loss: 1.0416 - val_acc: 0.5808\n",
      "Epoch 130/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9811 - acc: 0.5855 - val_loss: 1.0419 - val_acc: 0.5807\n",
      "Epoch 131/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9801 - acc: 0.5838 - val_loss: 1.0427 - val_acc: 0.5796\n",
      "Epoch 132/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9796 - acc: 0.5859 - val_loss: 1.0366 - val_acc: 0.5824\n",
      "Epoch 133/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9805 - acc: 0.5855 - val_loss: 1.0401 - val_acc: 0.5806\n",
      "Epoch 134/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9775 - acc: 0.5863 - val_loss: 1.0420 - val_acc: 0.5814\n",
      "Epoch 135/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9781 - acc: 0.5875 - val_loss: 1.0391 - val_acc: 0.5820\n",
      "Epoch 136/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9764 - acc: 0.5867 - val_loss: 1.0381 - val_acc: 0.5817\n",
      "Epoch 137/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9748 - acc: 0.5873 - val_loss: 1.0379 - val_acc: 0.5843\n",
      "Epoch 138/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.9749 - acc: 0.5872 - val_loss: 1.0395 - val_acc: 0.5842\n",
      "Epoch 139/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.9727 - acc: 0.5882 - val_loss: 1.0359 - val_acc: 0.5852\n",
      "Epoch 140/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9717 - acc: 0.5886 - val_loss: 1.0373 - val_acc: 0.5851\n",
      "Epoch 141/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9726 - acc: 0.5892 - val_loss: 1.0320 - val_acc: 0.5869\n",
      "Epoch 142/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9708 - acc: 0.5890 - val_loss: 1.0373 - val_acc: 0.5869\n",
      "Epoch 143/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9715 - acc: 0.5893 - val_loss: 1.0343 - val_acc: 0.5860\n",
      "Epoch 144/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9696 - acc: 0.5902 - val_loss: 1.0327 - val_acc: 0.5865\n",
      "Epoch 145/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9678 - acc: 0.5895 - val_loss: 1.0322 - val_acc: 0.5874\n",
      "Epoch 146/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9684 - acc: 0.5905 - val_loss: 1.0324 - val_acc: 0.5871\n",
      "Epoch 147/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9675 - acc: 0.5913 - val_loss: 1.0295 - val_acc: 0.5890\n",
      "Epoch 148/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9659 - acc: 0.5911 - val_loss: 1.0317 - val_acc: 0.5868\n",
      "Epoch 149/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9665 - acc: 0.5914 - val_loss: 1.0339 - val_acc: 0.5852\n",
      "Epoch 150/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9653 - acc: 0.5925 - val_loss: 1.0289 - val_acc: 0.5877\n",
      "Epoch 151/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9633 - acc: 0.5929 - val_loss: 1.0312 - val_acc: 0.5888\n",
      "Epoch 152/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9642 - acc: 0.5921 - val_loss: 1.0289 - val_acc: 0.5897\n",
      "Epoch 153/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.9631 - acc: 0.5933 - val_loss: 1.0300 - val_acc: 0.5895\n",
      "Epoch 154/1000\n",
      "214938/214938 [==============================] - 9s 41us/step - loss: 0.9622 - acc: 0.5940 - val_loss: 1.0276 - val_acc: 0.5904\n",
      "Epoch 155/1000\n",
      "214938/214938 [==============================] - 9s 40us/step - loss: 0.9617 - acc: 0.5933 - val_loss: 1.0304 - val_acc: 0.5899\n",
      "Epoch 156/1000\n",
      "214938/214938 [==============================] - 9s 41us/step - loss: 0.9608 - acc: 0.5944 - val_loss: 1.0319 - val_acc: 0.5887\n",
      "Epoch 157/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.9615 - acc: 0.5940 - val_loss: 1.0273 - val_acc: 0.5910\n",
      "Epoch 158/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9590 - acc: 0.5949 - val_loss: 1.0278 - val_acc: 0.5911\n",
      "Epoch 159/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9590 - acc: 0.5953 - val_loss: 1.0277 - val_acc: 0.5910\n",
      "Epoch 160/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9569 - acc: 0.5958 - val_loss: 1.0283 - val_acc: 0.5912\n",
      "Epoch 161/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9556 - acc: 0.5963 - val_loss: 1.0251 - val_acc: 0.5917\n",
      "Epoch 162/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9557 - acc: 0.5959 - val_loss: 1.0347 - val_acc: 0.5890\n",
      "Epoch 163/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9553 - acc: 0.5975 - val_loss: 1.0262 - val_acc: 0.5912\n",
      "Epoch 164/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9554 - acc: 0.5971 - val_loss: 1.0299 - val_acc: 0.5904\n",
      "Epoch 165/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9545 - acc: 0.5968 - val_loss: 1.0296 - val_acc: 0.5919\n",
      "Epoch 166/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9541 - acc: 0.5969 - val_loss: 1.0254 - val_acc: 0.5930\n",
      "Epoch 167/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9526 - acc: 0.5982 - val_loss: 1.0265 - val_acc: 0.5895\n",
      "Epoch 168/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.9523 - acc: 0.5987 - val_loss: 1.0245 - val_acc: 0.5940\n",
      "Epoch 169/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9506 - acc: 0.5995 - val_loss: 1.0213 - val_acc: 0.5926\n",
      "Epoch 170/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9513 - acc: 0.5983 - val_loss: 1.0243 - val_acc: 0.5930\n",
      "Epoch 171/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9538 - acc: 0.5976 - val_loss: 1.0220 - val_acc: 0.5913\n",
      "Epoch 172/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9491 - acc: 0.5997 - val_loss: 1.0257 - val_acc: 0.5917\n",
      "Epoch 173/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9494 - acc: 0.6000 - val_loss: 1.0223 - val_acc: 0.5932\n",
      "Epoch 174/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9476 - acc: 0.6004 - val_loss: 1.0236 - val_acc: 0.5928\n",
      "Epoch 175/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9467 - acc: 0.6005 - val_loss: 1.0245 - val_acc: 0.5930\n",
      "Epoch 176/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9470 - acc: 0.6015 - val_loss: 1.0246 - val_acc: 0.5935\n",
      "Epoch 177/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9471 - acc: 0.6014 - val_loss: 1.0252 - val_acc: 0.5943\n",
      "Epoch 178/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9452 - acc: 0.6008 - val_loss: 1.0240 - val_acc: 0.5943\n",
      "Epoch 179/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9468 - acc: 0.6004 - val_loss: 1.0240 - val_acc: 0.5942\n",
      "Epoch 180/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9444 - acc: 0.6016 - val_loss: 1.0213 - val_acc: 0.5977\n",
      "Epoch 181/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9458 - acc: 0.6013 - val_loss: 1.0225 - val_acc: 0.5960\n",
      "Epoch 182/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9427 - acc: 0.6025 - val_loss: 1.0207 - val_acc: 0.5966\n",
      "Epoch 183/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9445 - acc: 0.6027 - val_loss: 1.0242 - val_acc: 0.5957\n",
      "Epoch 184/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9432 - acc: 0.6024 - val_loss: 1.0228 - val_acc: 0.5961\n",
      "Epoch 185/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9416 - acc: 0.6034 - val_loss: 1.0187 - val_acc: 0.5940\n",
      "Epoch 186/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9412 - acc: 0.6040 - val_loss: 1.0227 - val_acc: 0.5962\n",
      "Epoch 187/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9413 - acc: 0.6034 - val_loss: 1.0228 - val_acc: 0.5952\n",
      "Epoch 188/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9412 - acc: 0.6027 - val_loss: 1.0171 - val_acc: 0.5982\n",
      "Epoch 189/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9389 - acc: 0.6045 - val_loss: 1.0159 - val_acc: 0.6000\n",
      "Epoch 190/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9370 - acc: 0.6051 - val_loss: 1.0168 - val_acc: 0.5997\n",
      "Epoch 191/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9386 - acc: 0.6047 - val_loss: 1.0208 - val_acc: 0.5990\n",
      "Epoch 192/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9372 - acc: 0.6049 - val_loss: 1.0192 - val_acc: 0.5980\n",
      "Epoch 193/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.9374 - acc: 0.6043 - val_loss: 1.0231 - val_acc: 0.5988\n",
      "Epoch 194/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9363 - acc: 0.6056 - val_loss: 1.0233 - val_acc: 0.5989\n",
      "Epoch 195/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9357 - acc: 0.6060 - val_loss: 1.0188 - val_acc: 0.6004\n",
      "Epoch 196/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9353 - acc: 0.6057 - val_loss: 1.0167 - val_acc: 0.6020\n",
      "Epoch 197/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9343 - acc: 0.6059 - val_loss: 1.0192 - val_acc: 0.5992\n",
      "Epoch 198/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9346 - acc: 0.6063 - val_loss: 1.0212 - val_acc: 0.5989\n",
      "Epoch 199/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9338 - acc: 0.6073 - val_loss: 1.0206 - val_acc: 0.6000\n",
      "Epoch 200/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9333 - acc: 0.6077 - val_loss: 1.0180 - val_acc: 0.6000\n",
      "Epoch 201/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9344 - acc: 0.6069 - val_loss: 1.0168 - val_acc: 0.6007\n",
      "Epoch 202/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9311 - acc: 0.6085 - val_loss: 1.0163 - val_acc: 0.6018\n",
      "Epoch 203/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9298 - acc: 0.6085 - val_loss: 1.0190 - val_acc: 0.6000\n",
      "Epoch 204/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9308 - acc: 0.6080 - val_loss: 1.0187 - val_acc: 0.6011\n",
      "Epoch 205/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9307 - acc: 0.6082 - val_loss: 1.0213 - val_acc: 0.6037\n",
      "Epoch 206/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9281 - acc: 0.6091 - val_loss: 1.0197 - val_acc: 0.6014\n",
      "Epoch 207/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9284 - acc: 0.6094 - val_loss: 1.0173 - val_acc: 0.6023\n",
      "Epoch 208/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9285 - acc: 0.6098 - val_loss: 1.0176 - val_acc: 0.6035\n",
      "Epoch 209/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9285 - acc: 0.6092 - val_loss: 1.0176 - val_acc: 0.6033\n",
      "Epoch 210/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9278 - acc: 0.6089 - val_loss: 1.0174 - val_acc: 0.6033\n",
      "Epoch 211/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9267 - acc: 0.6103 - val_loss: 1.0151 - val_acc: 0.6034\n",
      "Epoch 212/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9284 - acc: 0.6101 - val_loss: 1.0168 - val_acc: 0.6019\n",
      "Epoch 213/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9285 - acc: 0.6103 - val_loss: 1.0114 - val_acc: 0.6040\n",
      "Epoch 214/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9256 - acc: 0.6106 - val_loss: 1.0123 - val_acc: 0.6042\n",
      "Epoch 215/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9260 - acc: 0.6100 - val_loss: 1.0180 - val_acc: 0.6030\n",
      "Epoch 216/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9234 - acc: 0.6113 - val_loss: 1.0167 - val_acc: 0.6037\n",
      "Epoch 217/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9246 - acc: 0.6112 - val_loss: 1.0147 - val_acc: 0.6054\n",
      "Epoch 218/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9246 - acc: 0.6106 - val_loss: 1.0135 - val_acc: 0.6048\n",
      "Epoch 219/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9250 - acc: 0.6110 - val_loss: 1.0134 - val_acc: 0.6063\n",
      "Epoch 220/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9236 - acc: 0.6117 - val_loss: 1.0138 - val_acc: 0.6058\n",
      "Epoch 221/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9208 - acc: 0.6127 - val_loss: 1.0140 - val_acc: 0.6054\n",
      "Epoch 222/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9229 - acc: 0.6127 - val_loss: 1.0152 - val_acc: 0.6028\n",
      "Epoch 223/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9234 - acc: 0.6117 - val_loss: 1.0075 - val_acc: 0.6051\n",
      "Epoch 224/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.9226 - acc: 0.6119 - val_loss: 1.0118 - val_acc: 0.6069\n",
      "Epoch 225/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9194 - acc: 0.6132 - val_loss: 1.0109 - val_acc: 0.6054\n",
      "Epoch 226/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9200 - acc: 0.6141 - val_loss: 1.0109 - val_acc: 0.6073\n",
      "Epoch 227/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9196 - acc: 0.6132 - val_loss: 1.0093 - val_acc: 0.6078\n",
      "Epoch 228/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9189 - acc: 0.6135 - val_loss: 1.0075 - val_acc: 0.6097\n",
      "Epoch 229/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9180 - acc: 0.6139 - val_loss: 1.0085 - val_acc: 0.6074\n",
      "Epoch 230/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9194 - acc: 0.6132 - val_loss: 1.0138 - val_acc: 0.6075\n",
      "Epoch 231/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9186 - acc: 0.6138 - val_loss: 1.0117 - val_acc: 0.6075\n",
      "Epoch 232/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9181 - acc: 0.6143 - val_loss: 1.0102 - val_acc: 0.6076\n",
      "Epoch 233/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9159 - acc: 0.6146 - val_loss: 1.0119 - val_acc: 0.6064\n",
      "Epoch 234/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9154 - acc: 0.6153 - val_loss: 1.0078 - val_acc: 0.6064\n",
      "Epoch 235/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9167 - acc: 0.6146 - val_loss: 1.0061 - val_acc: 0.6079\n",
      "Epoch 236/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9164 - acc: 0.6136 - val_loss: 1.0075 - val_acc: 0.6076\n",
      "Epoch 237/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9150 - acc: 0.6157 - val_loss: 1.0084 - val_acc: 0.6075\n",
      "Epoch 238/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9150 - acc: 0.6153 - val_loss: 1.0091 - val_acc: 0.6083\n",
      "Epoch 239/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9132 - acc: 0.6162 - val_loss: 1.0128 - val_acc: 0.6082\n",
      "Epoch 240/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9130 - acc: 0.6162 - val_loss: 1.0098 - val_acc: 0.6104\n",
      "Epoch 241/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9128 - acc: 0.6159 - val_loss: 1.0086 - val_acc: 0.6092\n",
      "Epoch 242/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9139 - acc: 0.6152 - val_loss: 1.0127 - val_acc: 0.6099\n",
      "Epoch 243/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9130 - acc: 0.6165 - val_loss: 1.0101 - val_acc: 0.6079\n",
      "Epoch 244/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9106 - acc: 0.6181 - val_loss: 1.0157 - val_acc: 0.6067\n",
      "Epoch 245/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9098 - acc: 0.6177 - val_loss: 1.0065 - val_acc: 0.6112\n",
      "Epoch 246/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9126 - acc: 0.6173 - val_loss: 1.0127 - val_acc: 0.6094\n",
      "Epoch 247/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.9107 - acc: 0.6171 - val_loss: 1.0066 - val_acc: 0.6130\n",
      "Epoch 248/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9103 - acc: 0.6186 - val_loss: 1.0112 - val_acc: 0.6091\n",
      "Epoch 249/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9093 - acc: 0.6183 - val_loss: 1.0035 - val_acc: 0.6108\n",
      "Epoch 250/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9110 - acc: 0.6174 - val_loss: 1.0042 - val_acc: 0.6093\n",
      "Epoch 251/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9104 - acc: 0.6187 - val_loss: 1.0092 - val_acc: 0.6111\n",
      "Epoch 252/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9083 - acc: 0.6184 - val_loss: 1.0065 - val_acc: 0.6116\n",
      "Epoch 253/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9089 - acc: 0.6186 - val_loss: 1.0093 - val_acc: 0.6133\n",
      "Epoch 254/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9083 - acc: 0.6184 - val_loss: 1.0117 - val_acc: 0.6105\n",
      "Epoch 255/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9080 - acc: 0.6189 - val_loss: 1.0067 - val_acc: 0.6107\n",
      "Epoch 256/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9056 - acc: 0.6201 - val_loss: 1.0135 - val_acc: 0.6113\n",
      "Epoch 257/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9063 - acc: 0.6204 - val_loss: 1.0081 - val_acc: 0.6109\n",
      "Epoch 258/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9073 - acc: 0.6185 - val_loss: 1.0133 - val_acc: 0.6101\n",
      "Epoch 259/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9069 - acc: 0.6194 - val_loss: 1.0083 - val_acc: 0.6119\n",
      "Epoch 260/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9069 - acc: 0.6197 - val_loss: 1.0079 - val_acc: 0.6115\n",
      "Epoch 261/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9056 - acc: 0.6209 - val_loss: 1.0060 - val_acc: 0.6108\n",
      "Epoch 262/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9057 - acc: 0.6201 - val_loss: 1.0057 - val_acc: 0.6107\n",
      "Epoch 263/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9033 - acc: 0.6202 - val_loss: 1.0048 - val_acc: 0.6137\n",
      "Epoch 264/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9063 - acc: 0.6200 - val_loss: 1.0063 - val_acc: 0.6120\n",
      "Epoch 265/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9037 - acc: 0.6213 - val_loss: 1.0059 - val_acc: 0.6112\n",
      "Epoch 266/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9042 - acc: 0.6207 - val_loss: 1.0016 - val_acc: 0.6152\n",
      "Epoch 267/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9044 - acc: 0.6218 - val_loss: 1.0004 - val_acc: 0.6128\n",
      "Epoch 268/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9023 - acc: 0.6223 - val_loss: 1.0036 - val_acc: 0.6146\n",
      "Epoch 269/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9033 - acc: 0.6214 - val_loss: 0.9995 - val_acc: 0.6150\n",
      "Epoch 270/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9031 - acc: 0.6216 - val_loss: 0.9987 - val_acc: 0.6128\n",
      "Epoch 271/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9022 - acc: 0.6216 - val_loss: 1.0020 - val_acc: 0.6152\n",
      "Epoch 272/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.9010 - acc: 0.6222 - val_loss: 1.0056 - val_acc: 0.6134\n",
      "Epoch 273/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9012 - acc: 0.6220 - val_loss: 1.0029 - val_acc: 0.6124\n",
      "Epoch 274/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.9010 - acc: 0.6215 - val_loss: 1.0023 - val_acc: 0.6138\n",
      "Epoch 275/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9012 - acc: 0.6217 - val_loss: 1.0022 - val_acc: 0.6127\n",
      "Epoch 276/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8985 - acc: 0.6236 - val_loss: 1.0059 - val_acc: 0.6147\n",
      "Epoch 277/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8989 - acc: 0.6232 - val_loss: 1.0033 - val_acc: 0.6150\n",
      "Epoch 278/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8984 - acc: 0.6231 - val_loss: 1.0036 - val_acc: 0.6130\n",
      "Epoch 279/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8991 - acc: 0.6231 - val_loss: 1.0072 - val_acc: 0.6151\n",
      "Epoch 280/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8983 - acc: 0.6233 - val_loss: 1.0025 - val_acc: 0.6154\n",
      "Epoch 281/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.9001 - acc: 0.6239 - val_loss: 0.9990 - val_acc: 0.6149\n",
      "Epoch 282/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8968 - acc: 0.6236 - val_loss: 0.9988 - val_acc: 0.6148\n",
      "Epoch 283/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8984 - acc: 0.6231 - val_loss: 1.0003 - val_acc: 0.6174\n",
      "Epoch 284/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8959 - acc: 0.6253 - val_loss: 1.0028 - val_acc: 0.6132\n",
      "Epoch 285/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8972 - acc: 0.6241 - val_loss: 0.9998 - val_acc: 0.6178\n",
      "Epoch 286/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8952 - acc: 0.6248 - val_loss: 1.0018 - val_acc: 0.6165\n",
      "Epoch 287/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8968 - acc: 0.6232 - val_loss: 1.0000 - val_acc: 0.6162\n",
      "Epoch 288/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8979 - acc: 0.6234 - val_loss: 0.9971 - val_acc: 0.6157\n",
      "Epoch 289/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8954 - acc: 0.6241 - val_loss: 1.0007 - val_acc: 0.6152\n",
      "Epoch 290/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8966 - acc: 0.6246 - val_loss: 1.0012 - val_acc: 0.6170\n",
      "Epoch 291/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8950 - acc: 0.6246 - val_loss: 1.0073 - val_acc: 0.6150\n",
      "Epoch 292/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8944 - acc: 0.6251 - val_loss: 1.0035 - val_acc: 0.6179\n",
      "Epoch 293/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8933 - acc: 0.6251 - val_loss: 1.0025 - val_acc: 0.6167\n",
      "Epoch 294/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8939 - acc: 0.6248 - val_loss: 1.0004 - val_acc: 0.6159\n",
      "Epoch 295/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8937 - acc: 0.6260 - val_loss: 1.0043 - val_acc: 0.6161\n",
      "Epoch 296/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8913 - acc: 0.6275 - val_loss: 1.0014 - val_acc: 0.6155\n",
      "Epoch 297/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8936 - acc: 0.6257 - val_loss: 1.0018 - val_acc: 0.6179\n",
      "Epoch 298/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8925 - acc: 0.6272 - val_loss: 0.9975 - val_acc: 0.6168\n",
      "Epoch 299/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8913 - acc: 0.6262 - val_loss: 1.0016 - val_acc: 0.6189\n",
      "Epoch 300/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8907 - acc: 0.6276 - val_loss: 1.0005 - val_acc: 0.6190\n",
      "Epoch 301/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8905 - acc: 0.6275 - val_loss: 1.0019 - val_acc: 0.6177\n",
      "Epoch 302/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8913 - acc: 0.6267 - val_loss: 1.0058 - val_acc: 0.6145\n",
      "Epoch 303/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8906 - acc: 0.6270 - val_loss: 1.0022 - val_acc: 0.6176\n",
      "Epoch 304/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8898 - acc: 0.6277 - val_loss: 1.0007 - val_acc: 0.6154\n",
      "Epoch 305/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8907 - acc: 0.6274 - val_loss: 0.9978 - val_acc: 0.6191\n",
      "Epoch 306/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8899 - acc: 0.6272 - val_loss: 0.9976 - val_acc: 0.6189\n",
      "Epoch 307/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8894 - acc: 0.6276 - val_loss: 0.9959 - val_acc: 0.6201\n",
      "Epoch 308/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8902 - acc: 0.6283 - val_loss: 0.9968 - val_acc: 0.6181\n",
      "Epoch 309/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8891 - acc: 0.6283 - val_loss: 1.0012 - val_acc: 0.6191\n",
      "Epoch 310/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8884 - acc: 0.6278 - val_loss: 1.0018 - val_acc: 0.6186\n",
      "Epoch 311/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8905 - acc: 0.6266 - val_loss: 0.9952 - val_acc: 0.6202\n",
      "Epoch 312/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8889 - acc: 0.6288 - val_loss: 0.9963 - val_acc: 0.6198\n",
      "Epoch 313/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8892 - acc: 0.6284 - val_loss: 0.9966 - val_acc: 0.6180\n",
      "Epoch 314/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8879 - acc: 0.6288 - val_loss: 1.0023 - val_acc: 0.6195\n",
      "Epoch 315/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8857 - acc: 0.6296 - val_loss: 1.0037 - val_acc: 0.6192\n",
      "Epoch 316/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8870 - acc: 0.6293 - val_loss: 1.0011 - val_acc: 0.6195\n",
      "Epoch 317/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8887 - acc: 0.6289 - val_loss: 0.9962 - val_acc: 0.6189\n",
      "Epoch 318/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8871 - acc: 0.6290 - val_loss: 0.9965 - val_acc: 0.6210\n",
      "Epoch 319/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8864 - acc: 0.6288 - val_loss: 0.9944 - val_acc: 0.6211\n",
      "Epoch 320/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8861 - acc: 0.6292 - val_loss: 0.9950 - val_acc: 0.6193\n",
      "Epoch 321/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8857 - acc: 0.6293 - val_loss: 0.9970 - val_acc: 0.6213\n",
      "Epoch 322/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8854 - acc: 0.6296 - val_loss: 1.0033 - val_acc: 0.6204\n",
      "Epoch 323/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8841 - acc: 0.6300 - val_loss: 0.9983 - val_acc: 0.6206\n",
      "Epoch 324/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8846 - acc: 0.6298 - val_loss: 0.9977 - val_acc: 0.6207\n",
      "Epoch 325/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8829 - acc: 0.6311 - val_loss: 1.0003 - val_acc: 0.6202\n",
      "Epoch 326/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8860 - acc: 0.6297 - val_loss: 0.9988 - val_acc: 0.6185\n",
      "Epoch 327/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8859 - acc: 0.6298 - val_loss: 0.9982 - val_acc: 0.6206\n",
      "Epoch 328/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8829 - acc: 0.6316 - val_loss: 1.0042 - val_acc: 0.6189\n",
      "Epoch 329/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8850 - acc: 0.6310 - val_loss: 0.9919 - val_acc: 0.6203\n",
      "Epoch 330/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8817 - acc: 0.6314 - val_loss: 0.9964 - val_acc: 0.6197\n",
      "Epoch 331/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8828 - acc: 0.6296 - val_loss: 0.9934 - val_acc: 0.6200\n",
      "Epoch 332/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8820 - acc: 0.6325 - val_loss: 0.9978 - val_acc: 0.6212\n",
      "Epoch 333/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8823 - acc: 0.6313 - val_loss: 1.0079 - val_acc: 0.6199\n",
      "Epoch 334/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8830 - acc: 0.6309 - val_loss: 1.0017 - val_acc: 0.6201\n",
      "Epoch 335/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8834 - acc: 0.6321 - val_loss: 0.9966 - val_acc: 0.6185\n",
      "Epoch 336/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8807 - acc: 0.6319 - val_loss: 0.9980 - val_acc: 0.6193\n",
      "Epoch 337/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8831 - acc: 0.6313 - val_loss: 1.0000 - val_acc: 0.6219\n",
      "Epoch 338/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8806 - acc: 0.6314 - val_loss: 0.9975 - val_acc: 0.6202\n",
      "Epoch 339/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8807 - acc: 0.6321 - val_loss: 0.9951 - val_acc: 0.6228\n",
      "Epoch 340/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8784 - acc: 0.6335 - val_loss: 0.9962 - val_acc: 0.6222\n",
      "Epoch 341/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8817 - acc: 0.6313 - val_loss: 1.0000 - val_acc: 0.6232\n",
      "Epoch 342/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8817 - acc: 0.6315 - val_loss: 0.9956 - val_acc: 0.6220\n",
      "Epoch 343/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8795 - acc: 0.6331 - val_loss: 0.9953 - val_acc: 0.6215\n",
      "Epoch 344/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8805 - acc: 0.6325 - val_loss: 0.9975 - val_acc: 0.6240\n",
      "Epoch 345/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8808 - acc: 0.6315 - val_loss: 0.9962 - val_acc: 0.6222\n",
      "Epoch 346/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8787 - acc: 0.6324 - val_loss: 1.0006 - val_acc: 0.6238\n",
      "Epoch 347/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8761 - acc: 0.6348 - val_loss: 0.9990 - val_acc: 0.6207\n",
      "Epoch 348/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8789 - acc: 0.6333 - val_loss: 0.9936 - val_acc: 0.6237\n",
      "Epoch 349/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8779 - acc: 0.6332 - val_loss: 0.9935 - val_acc: 0.6226\n",
      "Epoch 350/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8780 - acc: 0.6336 - val_loss: 0.9986 - val_acc: 0.6224\n",
      "Epoch 351/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8765 - acc: 0.6344 - val_loss: 0.9912 - val_acc: 0.6232\n",
      "Epoch 352/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8756 - acc: 0.6344 - val_loss: 0.9948 - val_acc: 0.6224\n",
      "Epoch 353/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8769 - acc: 0.6347 - val_loss: 0.9948 - val_acc: 0.6239\n",
      "Epoch 354/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8760 - acc: 0.6348 - val_loss: 0.9935 - val_acc: 0.6231\n",
      "Epoch 355/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8757 - acc: 0.6340 - val_loss: 0.9962 - val_acc: 0.6239\n",
      "Epoch 356/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8766 - acc: 0.6337 - val_loss: 0.9890 - val_acc: 0.6258\n",
      "Epoch 357/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8746 - acc: 0.6349 - val_loss: 0.9942 - val_acc: 0.6239\n",
      "Epoch 358/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8758 - acc: 0.6325 - val_loss: 0.9969 - val_acc: 0.6246\n",
      "Epoch 359/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8747 - acc: 0.6345 - val_loss: 0.9941 - val_acc: 0.6234\n",
      "Epoch 360/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8764 - acc: 0.6336 - val_loss: 0.9913 - val_acc: 0.6254\n",
      "Epoch 361/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8743 - acc: 0.6350 - val_loss: 0.9956 - val_acc: 0.6255\n",
      "Epoch 362/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8766 - acc: 0.6343 - val_loss: 0.9910 - val_acc: 0.6223\n",
      "Epoch 363/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8735 - acc: 0.6356 - val_loss: 0.9926 - val_acc: 0.6236\n",
      "Epoch 364/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8735 - acc: 0.6356 - val_loss: 0.9899 - val_acc: 0.6238\n",
      "Epoch 365/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8727 - acc: 0.6350 - val_loss: 0.9911 - val_acc: 0.6268\n",
      "Epoch 366/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8743 - acc: 0.6361 - val_loss: 0.9940 - val_acc: 0.6239\n",
      "Epoch 367/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8748 - acc: 0.6352 - val_loss: 0.9916 - val_acc: 0.6266\n",
      "Epoch 368/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8750 - acc: 0.6355 - val_loss: 0.9930 - val_acc: 0.6245\n",
      "Epoch 369/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8717 - acc: 0.6366 - val_loss: 0.9939 - val_acc: 0.6251\n",
      "Epoch 370/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8736 - acc: 0.6357 - val_loss: 0.9949 - val_acc: 0.6247\n",
      "Epoch 371/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8727 - acc: 0.6360 - val_loss: 0.9935 - val_acc: 0.6242\n",
      "Epoch 372/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8738 - acc: 0.6362 - val_loss: 0.9859 - val_acc: 0.6272\n",
      "Epoch 373/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8730 - acc: 0.6360 - val_loss: 0.9958 - val_acc: 0.6238\n",
      "Epoch 374/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8719 - acc: 0.6357 - val_loss: 0.9927 - val_acc: 0.6264\n",
      "Epoch 375/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8709 - acc: 0.6361 - val_loss: 0.9987 - val_acc: 0.6256\n",
      "Epoch 376/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8723 - acc: 0.6362 - val_loss: 0.9950 - val_acc: 0.6265\n",
      "Epoch 377/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8725 - acc: 0.6365 - val_loss: 0.9920 - val_acc: 0.6258\n",
      "Epoch 378/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8702 - acc: 0.6364 - val_loss: 0.9954 - val_acc: 0.6259\n",
      "Epoch 379/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8690 - acc: 0.6376 - val_loss: 0.9965 - val_acc: 0.6268\n",
      "Epoch 380/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8698 - acc: 0.6380 - val_loss: 0.9888 - val_acc: 0.6272\n",
      "Epoch 381/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8704 - acc: 0.6372 - val_loss: 0.9886 - val_acc: 0.6280\n",
      "Epoch 382/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8707 - acc: 0.6359 - val_loss: 0.9902 - val_acc: 0.6245\n",
      "Epoch 383/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8678 - acc: 0.6375 - val_loss: 0.9926 - val_acc: 0.6267\n",
      "Epoch 384/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8683 - acc: 0.6378 - val_loss: 0.9844 - val_acc: 0.6253\n",
      "Epoch 385/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8711 - acc: 0.6373 - val_loss: 0.9890 - val_acc: 0.6272\n",
      "Epoch 386/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8702 - acc: 0.6367 - val_loss: 0.9882 - val_acc: 0.6265\n",
      "Epoch 387/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8679 - acc: 0.6379 - val_loss: 0.9952 - val_acc: 0.6271\n",
      "Epoch 388/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8699 - acc: 0.6370 - val_loss: 0.9950 - val_acc: 0.6273\n",
      "Epoch 389/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8672 - acc: 0.6380 - val_loss: 0.9903 - val_acc: 0.6273\n",
      "Epoch 390/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8683 - acc: 0.6383 - val_loss: 0.9930 - val_acc: 0.6265\n",
      "Epoch 391/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8688 - acc: 0.6373 - val_loss: 0.9849 - val_acc: 0.6277\n",
      "Epoch 392/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8675 - acc: 0.6388 - val_loss: 0.9889 - val_acc: 0.6252\n",
      "Epoch 393/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8707 - acc: 0.6383 - val_loss: 0.9820 - val_acc: 0.6276\n",
      "Epoch 394/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8662 - acc: 0.6391 - val_loss: 0.9898 - val_acc: 0.6254\n",
      "Epoch 395/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8678 - acc: 0.6383 - val_loss: 0.9874 - val_acc: 0.6273\n",
      "Epoch 396/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8675 - acc: 0.6388 - val_loss: 0.9910 - val_acc: 0.6261\n",
      "Epoch 397/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8670 - acc: 0.6393 - val_loss: 0.9849 - val_acc: 0.6268\n",
      "Epoch 398/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8665 - acc: 0.6383 - val_loss: 0.9942 - val_acc: 0.6280\n",
      "Epoch 399/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8673 - acc: 0.6394 - val_loss: 0.9914 - val_acc: 0.6297\n",
      "Epoch 400/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8690 - acc: 0.6386 - val_loss: 0.9909 - val_acc: 0.6264\n",
      "Epoch 401/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8667 - acc: 0.6393 - val_loss: 0.9888 - val_acc: 0.6285\n",
      "Epoch 402/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8665 - acc: 0.6391 - val_loss: 0.9922 - val_acc: 0.6274\n",
      "Epoch 403/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8651 - acc: 0.6401 - val_loss: 0.9917 - val_acc: 0.6284\n",
      "Epoch 404/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8648 - acc: 0.6394 - val_loss: 0.9884 - val_acc: 0.6270\n",
      "Epoch 405/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8647 - acc: 0.6400 - val_loss: 0.9885 - val_acc: 0.6287\n",
      "Epoch 406/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8622 - acc: 0.6408 - val_loss: 0.9874 - val_acc: 0.6297\n",
      "Epoch 407/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8657 - acc: 0.6407 - val_loss: 0.9844 - val_acc: 0.6300\n",
      "Epoch 408/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8642 - acc: 0.6403 - val_loss: 0.9877 - val_acc: 0.6285\n",
      "Epoch 409/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8619 - acc: 0.6404 - val_loss: 0.9917 - val_acc: 0.6291\n",
      "Epoch 410/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8634 - acc: 0.6403 - val_loss: 0.9921 - val_acc: 0.6279\n",
      "Epoch 411/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8623 - acc: 0.6401 - val_loss: 0.9880 - val_acc: 0.6288\n",
      "Epoch 412/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8654 - acc: 0.6396 - val_loss: 0.9846 - val_acc: 0.6317\n",
      "Epoch 413/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8639 - acc: 0.6404 - val_loss: 0.9933 - val_acc: 0.6290\n",
      "Epoch 414/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8619 - acc: 0.6414 - val_loss: 0.9867 - val_acc: 0.6282\n",
      "Epoch 415/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8637 - acc: 0.6401 - val_loss: 0.9876 - val_acc: 0.6310\n",
      "Epoch 416/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8618 - acc: 0.6419 - val_loss: 0.9899 - val_acc: 0.6288\n",
      "Epoch 417/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8615 - acc: 0.6413 - val_loss: 0.9851 - val_acc: 0.6294\n",
      "Epoch 418/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8609 - acc: 0.6419 - val_loss: 0.9837 - val_acc: 0.6276\n",
      "Epoch 419/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8595 - acc: 0.6416 - val_loss: 0.9885 - val_acc: 0.6292\n",
      "Epoch 420/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8603 - acc: 0.6420 - val_loss: 0.9858 - val_acc: 0.6309\n",
      "Epoch 421/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8614 - acc: 0.6421 - val_loss: 0.9922 - val_acc: 0.6274\n",
      "Epoch 422/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8607 - acc: 0.6420 - val_loss: 0.9851 - val_acc: 0.6276\n",
      "Epoch 423/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8604 - acc: 0.6423 - val_loss: 0.9841 - val_acc: 0.6294\n",
      "Epoch 424/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8599 - acc: 0.6421 - val_loss: 0.9847 - val_acc: 0.6313\n",
      "Epoch 425/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8601 - acc: 0.6415 - val_loss: 0.9912 - val_acc: 0.6309\n",
      "Epoch 426/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8590 - acc: 0.6437 - val_loss: 0.9819 - val_acc: 0.6309\n",
      "Epoch 427/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8603 - acc: 0.6416 - val_loss: 0.9849 - val_acc: 0.6305\n",
      "Epoch 428/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8584 - acc: 0.6432 - val_loss: 0.9835 - val_acc: 0.6322\n",
      "Epoch 429/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8610 - acc: 0.6415 - val_loss: 0.9840 - val_acc: 0.6298\n",
      "Epoch 430/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8586 - acc: 0.6426 - val_loss: 0.9848 - val_acc: 0.6297\n",
      "Epoch 431/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8582 - acc: 0.6437 - val_loss: 0.9844 - val_acc: 0.6288\n",
      "Epoch 432/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8599 - acc: 0.6420 - val_loss: 0.9825 - val_acc: 0.6310\n",
      "Epoch 433/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8570 - acc: 0.6434 - val_loss: 0.9838 - val_acc: 0.6299\n",
      "Epoch 434/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8567 - acc: 0.6429 - val_loss: 0.9840 - val_acc: 0.6308\n",
      "Epoch 435/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8571 - acc: 0.6427 - val_loss: 0.9895 - val_acc: 0.6319\n",
      "Epoch 436/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8571 - acc: 0.6431 - val_loss: 0.9897 - val_acc: 0.6300\n",
      "Epoch 437/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8572 - acc: 0.6438 - val_loss: 0.9872 - val_acc: 0.6323\n",
      "Epoch 438/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8594 - acc: 0.6425 - val_loss: 0.9826 - val_acc: 0.6314\n",
      "Epoch 439/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8563 - acc: 0.6443 - val_loss: 0.9871 - val_acc: 0.6321\n",
      "Epoch 440/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8575 - acc: 0.6428 - val_loss: 0.9821 - val_acc: 0.6313\n",
      "Epoch 441/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8563 - acc: 0.6448 - val_loss: 0.9852 - val_acc: 0.6324\n",
      "Epoch 442/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8568 - acc: 0.6436 - val_loss: 0.9811 - val_acc: 0.6322\n",
      "Epoch 443/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8594 - acc: 0.6428 - val_loss: 0.9833 - val_acc: 0.6311\n",
      "Epoch 444/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8557 - acc: 0.6448 - val_loss: 0.9796 - val_acc: 0.6324\n",
      "Epoch 445/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8565 - acc: 0.6441 - val_loss: 0.9832 - val_acc: 0.6309\n",
      "Epoch 446/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8554 - acc: 0.6444 - val_loss: 0.9971 - val_acc: 0.6305\n",
      "Epoch 447/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8564 - acc: 0.6435 - val_loss: 0.9883 - val_acc: 0.6319\n",
      "Epoch 448/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8559 - acc: 0.6437 - val_loss: 0.9851 - val_acc: 0.6308\n",
      "Epoch 449/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8552 - acc: 0.6448 - val_loss: 0.9813 - val_acc: 0.6334\n",
      "Epoch 450/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8554 - acc: 0.6441 - val_loss: 0.9826 - val_acc: 0.6300\n",
      "Epoch 451/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8551 - acc: 0.6443 - val_loss: 0.9851 - val_acc: 0.6313\n",
      "Epoch 452/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8545 - acc: 0.6450 - val_loss: 0.9874 - val_acc: 0.6309\n",
      "Epoch 453/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8544 - acc: 0.6446 - val_loss: 0.9883 - val_acc: 0.6314\n",
      "Epoch 454/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8538 - acc: 0.6451 - val_loss: 0.9824 - val_acc: 0.6334\n",
      "Epoch 455/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8528 - acc: 0.6453 - val_loss: 0.9811 - val_acc: 0.6335\n",
      "Epoch 456/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8547 - acc: 0.6443 - val_loss: 0.9858 - val_acc: 0.6319\n",
      "Epoch 457/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8572 - acc: 0.6441 - val_loss: 0.9783 - val_acc: 0.6328\n",
      "Epoch 458/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8539 - acc: 0.6446 - val_loss: 0.9925 - val_acc: 0.6307\n",
      "Epoch 459/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8538 - acc: 0.6463 - val_loss: 0.9793 - val_acc: 0.6331\n",
      "Epoch 460/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8540 - acc: 0.6454 - val_loss: 0.9807 - val_acc: 0.6349\n",
      "Epoch 461/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8540 - acc: 0.6446 - val_loss: 0.9829 - val_acc: 0.6324\n",
      "Epoch 462/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8506 - acc: 0.6456 - val_loss: 0.9850 - val_acc: 0.6328\n",
      "Epoch 463/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8532 - acc: 0.6454 - val_loss: 0.9834 - val_acc: 0.6336\n",
      "Epoch 464/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8510 - acc: 0.6461 - val_loss: 0.9907 - val_acc: 0.6326\n",
      "Epoch 465/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8519 - acc: 0.6462 - val_loss: 0.9842 - val_acc: 0.6326\n",
      "Epoch 466/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8525 - acc: 0.6456 - val_loss: 0.9811 - val_acc: 0.6329\n",
      "Epoch 467/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8530 - acc: 0.6453 - val_loss: 0.9766 - val_acc: 0.6348\n",
      "Epoch 468/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8517 - acc: 0.6466 - val_loss: 0.9802 - val_acc: 0.6335\n",
      "Epoch 469/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8514 - acc: 0.6468 - val_loss: 0.9865 - val_acc: 0.6344\n",
      "Epoch 470/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8513 - acc: 0.6473 - val_loss: 0.9844 - val_acc: 0.6319\n",
      "Epoch 471/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8523 - acc: 0.6457 - val_loss: 0.9802 - val_acc: 0.6331\n",
      "Epoch 472/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8505 - acc: 0.6473 - val_loss: 0.9817 - val_acc: 0.6307\n",
      "Epoch 473/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8512 - acc: 0.6468 - val_loss: 0.9852 - val_acc: 0.6319\n",
      "Epoch 474/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8524 - acc: 0.6458 - val_loss: 0.9857 - val_acc: 0.6330\n",
      "Epoch 475/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8476 - acc: 0.6482 - val_loss: 0.9847 - val_acc: 0.6331\n",
      "Epoch 476/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8513 - acc: 0.6467 - val_loss: 0.9829 - val_acc: 0.6334\n",
      "Epoch 477/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8518 - acc: 0.6466 - val_loss: 0.9820 - val_acc: 0.6348\n",
      "Epoch 478/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8493 - acc: 0.6473 - val_loss: 0.9751 - val_acc: 0.6349\n",
      "Epoch 479/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8497 - acc: 0.6462 - val_loss: 0.9830 - val_acc: 0.6327\n",
      "Epoch 480/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8488 - acc: 0.6470 - val_loss: 0.9812 - val_acc: 0.6319\n",
      "Epoch 481/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8520 - acc: 0.6468 - val_loss: 0.9795 - val_acc: 0.6329\n",
      "Epoch 482/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8498 - acc: 0.6475 - val_loss: 0.9806 - val_acc: 0.6358\n",
      "Epoch 483/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8497 - acc: 0.6460 - val_loss: 0.9808 - val_acc: 0.6379\n",
      "Epoch 484/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8490 - acc: 0.6474 - val_loss: 0.9762 - val_acc: 0.6356\n",
      "Epoch 485/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8505 - acc: 0.6471 - val_loss: 0.9835 - val_acc: 0.6349\n",
      "Epoch 486/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8485 - acc: 0.6484 - val_loss: 0.9822 - val_acc: 0.6339\n",
      "Epoch 487/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8497 - acc: 0.6476 - val_loss: 0.9816 - val_acc: 0.6344\n",
      "Epoch 488/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8496 - acc: 0.6472 - val_loss: 0.9811 - val_acc: 0.6358\n",
      "Epoch 489/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8470 - acc: 0.6484 - val_loss: 0.9829 - val_acc: 0.6338\n",
      "Epoch 490/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8488 - acc: 0.6479 - val_loss: 0.9833 - val_acc: 0.6362\n",
      "Epoch 491/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8464 - acc: 0.6485 - val_loss: 0.9836 - val_acc: 0.6346\n",
      "Epoch 492/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8475 - acc: 0.6491 - val_loss: 0.9874 - val_acc: 0.6343\n",
      "Epoch 493/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8472 - acc: 0.6485 - val_loss: 0.9855 - val_acc: 0.6360\n",
      "Epoch 494/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8462 - acc: 0.6486 - val_loss: 0.9784 - val_acc: 0.6359\n",
      "Epoch 495/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8467 - acc: 0.6493 - val_loss: 0.9832 - val_acc: 0.6360\n",
      "Epoch 496/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8472 - acc: 0.6481 - val_loss: 0.9816 - val_acc: 0.6343\n",
      "Epoch 497/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8459 - acc: 0.6492 - val_loss: 0.9803 - val_acc: 0.6363\n",
      "Epoch 498/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8458 - acc: 0.6494 - val_loss: 0.9835 - val_acc: 0.6359\n",
      "Epoch 499/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8493 - acc: 0.6473 - val_loss: 0.9792 - val_acc: 0.6353\n",
      "Epoch 500/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8472 - acc: 0.6493 - val_loss: 0.9803 - val_acc: 0.6377\n",
      "Epoch 501/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8465 - acc: 0.6492 - val_loss: 0.9814 - val_acc: 0.6354\n",
      "Epoch 502/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8455 - acc: 0.6493 - val_loss: 0.9864 - val_acc: 0.6372\n",
      "Epoch 503/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8471 - acc: 0.6483 - val_loss: 0.9851 - val_acc: 0.6342\n",
      "Epoch 504/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8457 - acc: 0.6490 - val_loss: 0.9884 - val_acc: 0.6341\n",
      "Epoch 505/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8477 - acc: 0.6483 - val_loss: 0.9854 - val_acc: 0.6340\n",
      "Epoch 506/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8471 - acc: 0.6488 - val_loss: 0.9769 - val_acc: 0.6354\n",
      "Epoch 507/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8462 - acc: 0.6486 - val_loss: 0.9822 - val_acc: 0.6358\n",
      "Epoch 508/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8474 - acc: 0.6480 - val_loss: 0.9791 - val_acc: 0.6354\n",
      "Epoch 509/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8465 - acc: 0.6490 - val_loss: 0.9844 - val_acc: 0.6357\n",
      "Epoch 510/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8469 - acc: 0.6491 - val_loss: 0.9838 - val_acc: 0.6374\n",
      "Epoch 511/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8446 - acc: 0.6491 - val_loss: 0.9819 - val_acc: 0.6356\n",
      "Epoch 512/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8439 - acc: 0.6494 - val_loss: 0.9819 - val_acc: 0.6357\n",
      "Epoch 513/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8470 - acc: 0.6494 - val_loss: 0.9836 - val_acc: 0.6309\n",
      "Epoch 514/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8459 - acc: 0.6492 - val_loss: 0.9781 - val_acc: 0.6342\n",
      "Epoch 515/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8429 - acc: 0.6501 - val_loss: 0.9831 - val_acc: 0.6338\n",
      "Epoch 516/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8467 - acc: 0.6490 - val_loss: 0.9804 - val_acc: 0.6371\n",
      "Epoch 517/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8436 - acc: 0.6508 - val_loss: 0.9865 - val_acc: 0.6363\n",
      "Epoch 518/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8434 - acc: 0.6504 - val_loss: 0.9781 - val_acc: 0.6364\n",
      "Epoch 519/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8454 - acc: 0.6499 - val_loss: 0.9799 - val_acc: 0.6344\n",
      "Epoch 520/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8432 - acc: 0.6509 - val_loss: 0.9813 - val_acc: 0.6374\n",
      "Epoch 521/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8428 - acc: 0.6505 - val_loss: 0.9739 - val_acc: 0.6372\n",
      "Epoch 522/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8417 - acc: 0.6508 - val_loss: 0.9782 - val_acc: 0.6352\n",
      "Epoch 523/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8429 - acc: 0.6508 - val_loss: 0.9833 - val_acc: 0.6381\n",
      "Epoch 524/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8418 - acc: 0.6509 - val_loss: 0.9867 - val_acc: 0.6363\n",
      "Epoch 525/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8424 - acc: 0.6514 - val_loss: 0.9808 - val_acc: 0.6360\n",
      "Epoch 526/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8406 - acc: 0.6509 - val_loss: 0.9853 - val_acc: 0.6351\n",
      "Epoch 527/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8422 - acc: 0.6517 - val_loss: 0.9840 - val_acc: 0.6351\n",
      "Epoch 528/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8447 - acc: 0.6512 - val_loss: 0.9757 - val_acc: 0.6378\n",
      "Epoch 529/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8421 - acc: 0.6516 - val_loss: 0.9764 - val_acc: 0.6372\n",
      "Epoch 530/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8402 - acc: 0.6516 - val_loss: 0.9810 - val_acc: 0.6373\n",
      "Epoch 531/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8409 - acc: 0.6516 - val_loss: 0.9720 - val_acc: 0.6367\n",
      "Epoch 532/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8431 - acc: 0.6502 - val_loss: 0.9740 - val_acc: 0.6390\n",
      "Epoch 533/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8424 - acc: 0.6504 - val_loss: 0.9779 - val_acc: 0.6364\n",
      "Epoch 534/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8405 - acc: 0.6516 - val_loss: 0.9764 - val_acc: 0.6355\n",
      "Epoch 535/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8422 - acc: 0.6508 - val_loss: 0.9795 - val_acc: 0.6375\n",
      "Epoch 536/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8419 - acc: 0.6516 - val_loss: 0.9726 - val_acc: 0.6393\n",
      "Epoch 537/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8410 - acc: 0.6521 - val_loss: 0.9778 - val_acc: 0.6391\n",
      "Epoch 538/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8401 - acc: 0.6521 - val_loss: 0.9751 - val_acc: 0.6371\n",
      "Epoch 539/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8403 - acc: 0.6516 - val_loss: 0.9797 - val_acc: 0.6386\n",
      "Epoch 540/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8405 - acc: 0.6511 - val_loss: 0.9776 - val_acc: 0.6368\n",
      "Epoch 541/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8427 - acc: 0.6512 - val_loss: 0.9783 - val_acc: 0.6369\n",
      "Epoch 542/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8399 - acc: 0.6520 - val_loss: 0.9725 - val_acc: 0.6386\n",
      "Epoch 543/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8432 - acc: 0.6517 - val_loss: 0.9740 - val_acc: 0.6381\n",
      "Epoch 544/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8411 - acc: 0.6524 - val_loss: 0.9802 - val_acc: 0.6360\n",
      "Epoch 545/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8396 - acc: 0.6522 - val_loss: 0.9771 - val_acc: 0.6399\n",
      "Epoch 546/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8402 - acc: 0.6514 - val_loss: 0.9875 - val_acc: 0.6399\n",
      "Epoch 547/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8415 - acc: 0.6508 - val_loss: 0.9751 - val_acc: 0.6405\n",
      "Epoch 548/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8386 - acc: 0.6527 - val_loss: 0.9827 - val_acc: 0.6394\n",
      "Epoch 549/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8399 - acc: 0.6527 - val_loss: 0.9782 - val_acc: 0.6412\n",
      "Epoch 550/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8367 - acc: 0.6532 - val_loss: 0.9776 - val_acc: 0.6391\n",
      "Epoch 551/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8372 - acc: 0.6535 - val_loss: 0.9787 - val_acc: 0.6385\n",
      "Epoch 552/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8369 - acc: 0.6538 - val_loss: 0.9690 - val_acc: 0.6395\n",
      "Epoch 553/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8400 - acc: 0.6525 - val_loss: 0.9839 - val_acc: 0.6380\n",
      "Epoch 554/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8365 - acc: 0.6532 - val_loss: 0.9743 - val_acc: 0.6390\n",
      "Epoch 555/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8388 - acc: 0.6528 - val_loss: 0.9721 - val_acc: 0.6387\n",
      "Epoch 556/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8391 - acc: 0.6528 - val_loss: 0.9771 - val_acc: 0.6375\n",
      "Epoch 557/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8413 - acc: 0.6522 - val_loss: 0.9747 - val_acc: 0.6394\n",
      "Epoch 558/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8388 - acc: 0.6526 - val_loss: 0.9721 - val_acc: 0.6398\n",
      "Epoch 559/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8410 - acc: 0.6526 - val_loss: 0.9740 - val_acc: 0.6378\n",
      "Epoch 560/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8382 - acc: 0.6526 - val_loss: 0.9675 - val_acc: 0.6399\n",
      "Epoch 561/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8360 - acc: 0.6540 - val_loss: 0.9731 - val_acc: 0.6401\n",
      "Epoch 562/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8343 - acc: 0.6540 - val_loss: 0.9782 - val_acc: 0.6396\n",
      "Epoch 563/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8360 - acc: 0.6548 - val_loss: 0.9742 - val_acc: 0.6400\n",
      "Epoch 564/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8397 - acc: 0.6534 - val_loss: 0.9705 - val_acc: 0.6409\n",
      "Epoch 565/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8379 - acc: 0.6538 - val_loss: 0.9713 - val_acc: 0.6392\n",
      "Epoch 566/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8386 - acc: 0.6532 - val_loss: 0.9755 - val_acc: 0.6393\n",
      "Epoch 567/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8361 - acc: 0.6540 - val_loss: 0.9781 - val_acc: 0.6373\n",
      "Epoch 568/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8372 - acc: 0.6552 - val_loss: 0.9745 - val_acc: 0.6403\n",
      "Epoch 569/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8365 - acc: 0.6541 - val_loss: 0.9811 - val_acc: 0.6413\n",
      "Epoch 570/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8352 - acc: 0.6540 - val_loss: 0.9808 - val_acc: 0.6386\n",
      "Epoch 571/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8355 - acc: 0.6543 - val_loss: 0.9801 - val_acc: 0.6388\n",
      "Epoch 572/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8342 - acc: 0.6554 - val_loss: 0.9744 - val_acc: 0.6396\n",
      "Epoch 573/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8361 - acc: 0.6540 - val_loss: 0.9773 - val_acc: 0.6410\n",
      "Epoch 574/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8352 - acc: 0.6541 - val_loss: 0.9800 - val_acc: 0.6391\n",
      "Epoch 575/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8340 - acc: 0.6546 - val_loss: 0.9763 - val_acc: 0.6393\n",
      "Epoch 576/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8365 - acc: 0.6539 - val_loss: 0.9791 - val_acc: 0.6389\n",
      "Epoch 577/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8334 - acc: 0.6559 - val_loss: 0.9777 - val_acc: 0.6398\n",
      "Epoch 578/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8376 - acc: 0.6538 - val_loss: 0.9751 - val_acc: 0.6407\n",
      "Epoch 579/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8350 - acc: 0.6551 - val_loss: 0.9807 - val_acc: 0.6388\n",
      "Epoch 580/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8346 - acc: 0.6550 - val_loss: 0.9734 - val_acc: 0.6408\n",
      "Epoch 581/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8348 - acc: 0.6552 - val_loss: 0.9776 - val_acc: 0.6417\n",
      "Epoch 582/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8320 - acc: 0.6564 - val_loss: 0.9779 - val_acc: 0.6390\n",
      "Epoch 583/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8334 - acc: 0.6559 - val_loss: 0.9742 - val_acc: 0.6408\n",
      "Epoch 584/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8341 - acc: 0.6551 - val_loss: 0.9713 - val_acc: 0.6415\n",
      "Epoch 585/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8338 - acc: 0.6554 - val_loss: 0.9667 - val_acc: 0.6410\n",
      "Epoch 586/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8364 - acc: 0.6549 - val_loss: 0.9720 - val_acc: 0.6426\n",
      "Epoch 587/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8330 - acc: 0.6554 - val_loss: 0.9851 - val_acc: 0.6404\n",
      "Epoch 588/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8310 - acc: 0.6574 - val_loss: 0.9870 - val_acc: 0.6404\n",
      "Epoch 589/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8332 - acc: 0.6561 - val_loss: 0.9764 - val_acc: 0.6397\n",
      "Epoch 590/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8345 - acc: 0.6552 - val_loss: 0.9795 - val_acc: 0.6398\n",
      "Epoch 591/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8332 - acc: 0.6558 - val_loss: 0.9768 - val_acc: 0.6405\n",
      "Epoch 592/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8319 - acc: 0.6556 - val_loss: 0.9781 - val_acc: 0.6405\n",
      "Epoch 593/1000\n",
      "214938/214938 [==============================] - 10s 46us/step - loss: 0.8346 - acc: 0.6553 - val_loss: 0.9750 - val_acc: 0.6401\n",
      "Epoch 594/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8362 - acc: 0.6549 - val_loss: 0.9740 - val_acc: 0.6402\n",
      "Epoch 595/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8335 - acc: 0.6558 - val_loss: 0.9712 - val_acc: 0.6411\n",
      "Epoch 596/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8317 - acc: 0.6570 - val_loss: 0.9757 - val_acc: 0.6409\n",
      "Epoch 597/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8319 - acc: 0.6563 - val_loss: 0.9768 - val_acc: 0.6416\n",
      "Epoch 598/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8344 - acc: 0.6546 - val_loss: 0.9691 - val_acc: 0.6408\n",
      "Epoch 599/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8337 - acc: 0.6561 - val_loss: 0.9749 - val_acc: 0.6413\n",
      "Epoch 600/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8327 - acc: 0.6562 - val_loss: 0.9767 - val_acc: 0.6435\n",
      "Epoch 601/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8303 - acc: 0.6569 - val_loss: 0.9770 - val_acc: 0.6408\n",
      "Epoch 602/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8311 - acc: 0.6565 - val_loss: 0.9754 - val_acc: 0.6433\n",
      "Epoch 603/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8331 - acc: 0.6567 - val_loss: 0.9664 - val_acc: 0.6414\n",
      "Epoch 604/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8330 - acc: 0.6560 - val_loss: 0.9735 - val_acc: 0.6433\n",
      "Epoch 605/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8297 - acc: 0.6580 - val_loss: 0.9690 - val_acc: 0.6424\n",
      "Epoch 606/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8321 - acc: 0.6572 - val_loss: 0.9732 - val_acc: 0.6402\n",
      "Epoch 607/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8322 - acc: 0.6567 - val_loss: 0.9683 - val_acc: 0.6415\n",
      "Epoch 608/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8334 - acc: 0.6558 - val_loss: 0.9693 - val_acc: 0.6409\n",
      "Epoch 609/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8333 - acc: 0.6561 - val_loss: 0.9734 - val_acc: 0.6407\n",
      "Epoch 610/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8324 - acc: 0.6566 - val_loss: 0.9709 - val_acc: 0.6407\n",
      "Epoch 611/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8280 - acc: 0.6568 - val_loss: 0.9757 - val_acc: 0.6412\n",
      "Epoch 612/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8275 - acc: 0.6583 - val_loss: 0.9743 - val_acc: 0.6432\n",
      "Epoch 613/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8308 - acc: 0.6570 - val_loss: 0.9685 - val_acc: 0.6431\n",
      "Epoch 614/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8305 - acc: 0.6571 - val_loss: 0.9712 - val_acc: 0.6411\n",
      "Epoch 615/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8302 - acc: 0.6564 - val_loss: 0.9702 - val_acc: 0.6417\n",
      "Epoch 616/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8283 - acc: 0.6575 - val_loss: 0.9692 - val_acc: 0.6423\n",
      "Epoch 617/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8304 - acc: 0.6572 - val_loss: 0.9740 - val_acc: 0.6406\n",
      "Epoch 618/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8303 - acc: 0.6571 - val_loss: 0.9718 - val_acc: 0.6424\n",
      "Epoch 619/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8286 - acc: 0.6578 - val_loss: 0.9755 - val_acc: 0.6415\n",
      "Epoch 620/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8312 - acc: 0.6568 - val_loss: 0.9723 - val_acc: 0.6420\n",
      "Epoch 621/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8280 - acc: 0.6581 - val_loss: 0.9729 - val_acc: 0.6430\n",
      "Epoch 622/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8280 - acc: 0.6576 - val_loss: 0.9744 - val_acc: 0.6415\n",
      "Epoch 623/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8299 - acc: 0.6577 - val_loss: 0.9713 - val_acc: 0.6421\n",
      "Epoch 624/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8289 - acc: 0.6580 - val_loss: 0.9701 - val_acc: 0.6430\n",
      "Epoch 625/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8298 - acc: 0.6577 - val_loss: 0.9712 - val_acc: 0.6418\n",
      "Epoch 626/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8279 - acc: 0.6581 - val_loss: 0.9688 - val_acc: 0.6421\n",
      "Epoch 627/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8295 - acc: 0.6576 - val_loss: 0.9616 - val_acc: 0.6424\n",
      "Epoch 628/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8274 - acc: 0.6584 - val_loss: 0.9787 - val_acc: 0.6424\n",
      "Epoch 629/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8299 - acc: 0.6584 - val_loss: 0.9639 - val_acc: 0.6427\n",
      "Epoch 630/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8267 - acc: 0.6595 - val_loss: 0.9769 - val_acc: 0.6418\n",
      "Epoch 631/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8282 - acc: 0.6578 - val_loss: 0.9791 - val_acc: 0.6413\n",
      "Epoch 632/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8284 - acc: 0.6578 - val_loss: 0.9677 - val_acc: 0.6434\n",
      "Epoch 633/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8283 - acc: 0.6585 - val_loss: 0.9699 - val_acc: 0.6419\n",
      "Epoch 634/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8290 - acc: 0.6575 - val_loss: 0.9733 - val_acc: 0.6439\n",
      "Epoch 635/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8251 - acc: 0.6587 - val_loss: 0.9728 - val_acc: 0.6418\n",
      "Epoch 636/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8297 - acc: 0.6567 - val_loss: 0.9719 - val_acc: 0.6423\n",
      "Epoch 637/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8270 - acc: 0.6594 - val_loss: 0.9706 - val_acc: 0.6427\n",
      "Epoch 638/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8277 - acc: 0.6589 - val_loss: 0.9745 - val_acc: 0.6433\n",
      "Epoch 639/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8281 - acc: 0.6589 - val_loss: 0.9763 - val_acc: 0.6430\n",
      "Epoch 640/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8280 - acc: 0.6574 - val_loss: 0.9662 - val_acc: 0.6426\n",
      "Epoch 641/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8280 - acc: 0.6584 - val_loss: 0.9677 - val_acc: 0.6421\n",
      "Epoch 642/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8289 - acc: 0.6582 - val_loss: 0.9664 - val_acc: 0.6424\n",
      "Epoch 643/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8280 - acc: 0.6590 - val_loss: 0.9688 - val_acc: 0.6452\n",
      "Epoch 644/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8263 - acc: 0.6595 - val_loss: 0.9694 - val_acc: 0.6430\n",
      "Epoch 645/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8282 - acc: 0.6589 - val_loss: 0.9678 - val_acc: 0.6451\n",
      "Epoch 646/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8266 - acc: 0.6593 - val_loss: 0.9691 - val_acc: 0.6414\n",
      "Epoch 647/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8272 - acc: 0.6590 - val_loss: 0.9708 - val_acc: 0.6444\n",
      "Epoch 648/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8275 - acc: 0.6587 - val_loss: 0.9709 - val_acc: 0.6430\n",
      "Epoch 649/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8277 - acc: 0.6582 - val_loss: 0.9712 - val_acc: 0.6408\n",
      "Epoch 650/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8281 - acc: 0.6583 - val_loss: 0.9721 - val_acc: 0.6443\n",
      "Epoch 651/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8278 - acc: 0.6592 - val_loss: 0.9855 - val_acc: 0.6404\n",
      "Epoch 652/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8255 - acc: 0.6595 - val_loss: 0.9682 - val_acc: 0.6444\n",
      "Epoch 653/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8258 - acc: 0.6595 - val_loss: 0.9721 - val_acc: 0.6436\n",
      "Epoch 654/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8271 - acc: 0.6587 - val_loss: 0.9716 - val_acc: 0.6416\n",
      "Epoch 655/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8272 - acc: 0.6598 - val_loss: 0.9693 - val_acc: 0.6458\n",
      "Epoch 656/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8270 - acc: 0.6592 - val_loss: 0.9646 - val_acc: 0.6436\n",
      "Epoch 657/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8277 - acc: 0.6587 - val_loss: 0.9708 - val_acc: 0.6450\n",
      "Epoch 658/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8236 - acc: 0.6590 - val_loss: 0.9678 - val_acc: 0.6443\n",
      "Epoch 659/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8260 - acc: 0.6588 - val_loss: 0.9640 - val_acc: 0.6442\n",
      "Epoch 660/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8259 - acc: 0.6590 - val_loss: 0.9678 - val_acc: 0.6437\n",
      "Epoch 661/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8278 - acc: 0.6588 - val_loss: 0.9711 - val_acc: 0.6438\n",
      "Epoch 662/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8244 - acc: 0.6596 - val_loss: 0.9678 - val_acc: 0.6459\n",
      "Epoch 663/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8220 - acc: 0.6610 - val_loss: 0.9650 - val_acc: 0.6436\n",
      "Epoch 664/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8258 - acc: 0.6584 - val_loss: 0.9657 - val_acc: 0.6450\n",
      "Epoch 665/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8228 - acc: 0.6598 - val_loss: 0.9693 - val_acc: 0.6446\n",
      "Epoch 666/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8241 - acc: 0.6605 - val_loss: 0.9614 - val_acc: 0.6456\n",
      "Epoch 667/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8232 - acc: 0.6603 - val_loss: 0.9656 - val_acc: 0.6438\n",
      "Epoch 668/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8257 - acc: 0.6600 - val_loss: 0.9713 - val_acc: 0.6447\n",
      "Epoch 669/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8260 - acc: 0.6601 - val_loss: 0.9661 - val_acc: 0.6461\n",
      "Epoch 670/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8232 - acc: 0.6613 - val_loss: 0.9668 - val_acc: 0.6448\n",
      "Epoch 671/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8298 - acc: 0.6584 - val_loss: 0.9701 - val_acc: 0.6446\n",
      "Epoch 672/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8261 - acc: 0.6601 - val_loss: 0.9725 - val_acc: 0.6443\n",
      "Epoch 673/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8217 - acc: 0.6615 - val_loss: 0.9730 - val_acc: 0.6443\n",
      "Epoch 674/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8240 - acc: 0.6603 - val_loss: 0.9659 - val_acc: 0.6433\n",
      "Epoch 675/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8238 - acc: 0.6600 - val_loss: 0.9644 - val_acc: 0.6458\n",
      "Epoch 676/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8218 - acc: 0.6607 - val_loss: 0.9737 - val_acc: 0.6434\n",
      "Epoch 677/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8229 - acc: 0.6611 - val_loss: 0.9711 - val_acc: 0.6442\n",
      "Epoch 678/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8214 - acc: 0.6609 - val_loss: 0.9758 - val_acc: 0.6443\n",
      "Epoch 679/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8228 - acc: 0.6605 - val_loss: 0.9643 - val_acc: 0.6463\n",
      "Epoch 680/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8234 - acc: 0.6615 - val_loss: 0.9670 - val_acc: 0.6442\n",
      "Epoch 681/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8214 - acc: 0.6610 - val_loss: 0.9637 - val_acc: 0.6454\n",
      "Epoch 682/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8229 - acc: 0.6615 - val_loss: 0.9707 - val_acc: 0.6444\n",
      "Epoch 683/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8209 - acc: 0.6606 - val_loss: 0.9748 - val_acc: 0.6441\n",
      "Epoch 684/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8221 - acc: 0.6614 - val_loss: 0.9801 - val_acc: 0.6437\n",
      "Epoch 685/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8236 - acc: 0.6604 - val_loss: 0.9773 - val_acc: 0.6427\n",
      "Epoch 686/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8216 - acc: 0.6619 - val_loss: 0.9728 - val_acc: 0.6461\n",
      "Epoch 687/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8240 - acc: 0.6615 - val_loss: 0.9680 - val_acc: 0.6442\n",
      "Epoch 688/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8211 - acc: 0.6611 - val_loss: 0.9817 - val_acc: 0.6436\n",
      "Epoch 689/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8223 - acc: 0.6617 - val_loss: 0.9697 - val_acc: 0.6436\n",
      "Epoch 690/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8211 - acc: 0.6620 - val_loss: 0.9737 - val_acc: 0.6444\n",
      "Epoch 691/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8216 - acc: 0.6615 - val_loss: 0.9668 - val_acc: 0.6449\n",
      "Epoch 692/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8217 - acc: 0.6615 - val_loss: 0.9668 - val_acc: 0.6446\n",
      "Epoch 693/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8215 - acc: 0.6618 - val_loss: 0.9640 - val_acc: 0.6450\n",
      "Epoch 694/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8226 - acc: 0.6608 - val_loss: 0.9673 - val_acc: 0.6472\n",
      "Epoch 695/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8211 - acc: 0.6622 - val_loss: 0.9648 - val_acc: 0.6463\n",
      "Epoch 696/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8236 - acc: 0.6614 - val_loss: 0.9685 - val_acc: 0.6447\n",
      "Epoch 697/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8229 - acc: 0.6614 - val_loss: 0.9613 - val_acc: 0.6449\n",
      "Epoch 698/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8196 - acc: 0.6634 - val_loss: 0.9650 - val_acc: 0.6453\n",
      "Epoch 699/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8221 - acc: 0.6613 - val_loss: 0.9663 - val_acc: 0.6475\n",
      "Epoch 700/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8225 - acc: 0.6611 - val_loss: 0.9549 - val_acc: 0.6476\n",
      "Epoch 701/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8221 - acc: 0.6618 - val_loss: 0.9649 - val_acc: 0.6459\n",
      "Epoch 702/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8248 - acc: 0.6605 - val_loss: 0.9662 - val_acc: 0.6453\n",
      "Epoch 703/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8203 - acc: 0.6616 - val_loss: 0.9705 - val_acc: 0.6471\n",
      "Epoch 704/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8190 - acc: 0.6632 - val_loss: 0.9742 - val_acc: 0.6464\n",
      "Epoch 705/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8205 - acc: 0.6617 - val_loss: 0.9707 - val_acc: 0.6467\n",
      "Epoch 706/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8197 - acc: 0.6624 - val_loss: 0.9640 - val_acc: 0.6472\n",
      "Epoch 707/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8184 - acc: 0.6630 - val_loss: 0.9667 - val_acc: 0.6476\n",
      "Epoch 708/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8223 - acc: 0.6615 - val_loss: 0.9733 - val_acc: 0.6436\n",
      "Epoch 709/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8206 - acc: 0.6624 - val_loss: 0.9625 - val_acc: 0.6471\n",
      "Epoch 710/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8194 - acc: 0.6630 - val_loss: 0.9709 - val_acc: 0.6460\n",
      "Epoch 711/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8215 - acc: 0.6615 - val_loss: 0.9674 - val_acc: 0.6446\n",
      "Epoch 712/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8203 - acc: 0.6622 - val_loss: 0.9572 - val_acc: 0.6456\n",
      "Epoch 713/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8180 - acc: 0.6635 - val_loss: 0.9702 - val_acc: 0.6471\n",
      "Epoch 714/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8202 - acc: 0.6616 - val_loss: 0.9616 - val_acc: 0.6482\n",
      "Epoch 715/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8197 - acc: 0.6626 - val_loss: 0.9683 - val_acc: 0.6448\n",
      "Epoch 716/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8209 - acc: 0.6620 - val_loss: 0.9605 - val_acc: 0.6474\n",
      "Epoch 717/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8187 - acc: 0.6625 - val_loss: 0.9604 - val_acc: 0.6480\n",
      "Epoch 718/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8170 - acc: 0.6625 - val_loss: 0.9665 - val_acc: 0.6474\n",
      "Epoch 719/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8175 - acc: 0.6634 - val_loss: 0.9685 - val_acc: 0.6462\n",
      "Epoch 720/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8167 - acc: 0.6643 - val_loss: 0.9651 - val_acc: 0.6471\n",
      "Epoch 721/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8179 - acc: 0.6629 - val_loss: 0.9626 - val_acc: 0.6479\n",
      "Epoch 722/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8161 - acc: 0.6640 - val_loss: 0.9708 - val_acc: 0.6464\n",
      "Epoch 723/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8158 - acc: 0.6640 - val_loss: 0.9658 - val_acc: 0.6467\n",
      "Epoch 724/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8157 - acc: 0.6648 - val_loss: 0.9637 - val_acc: 0.6487\n",
      "Epoch 725/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8183 - acc: 0.6633 - val_loss: 0.9582 - val_acc: 0.6480\n",
      "Epoch 726/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8164 - acc: 0.6636 - val_loss: 0.9623 - val_acc: 0.6474\n",
      "Epoch 727/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8194 - acc: 0.6631 - val_loss: 0.9618 - val_acc: 0.6475\n",
      "Epoch 728/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8165 - acc: 0.6643 - val_loss: 0.9698 - val_acc: 0.6459\n",
      "Epoch 729/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8193 - acc: 0.6629 - val_loss: 0.9612 - val_acc: 0.6481\n",
      "Epoch 730/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8173 - acc: 0.6636 - val_loss: 0.9680 - val_acc: 0.6477\n",
      "Epoch 731/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8187 - acc: 0.6634 - val_loss: 0.9629 - val_acc: 0.6476\n",
      "Epoch 732/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8191 - acc: 0.6631 - val_loss: 0.9701 - val_acc: 0.6478\n",
      "Epoch 733/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8157 - acc: 0.6643 - val_loss: 0.9603 - val_acc: 0.6499\n",
      "Epoch 734/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8194 - acc: 0.6624 - val_loss: 0.9598 - val_acc: 0.6476\n",
      "Epoch 735/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8181 - acc: 0.6632 - val_loss: 0.9623 - val_acc: 0.6479\n",
      "Epoch 736/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8214 - acc: 0.6625 - val_loss: 0.9612 - val_acc: 0.6468\n",
      "Epoch 737/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8177 - acc: 0.6638 - val_loss: 0.9665 - val_acc: 0.6501\n",
      "Epoch 738/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8152 - acc: 0.6652 - val_loss: 0.9675 - val_acc: 0.6470\n",
      "Epoch 739/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8172 - acc: 0.6648 - val_loss: 0.9639 - val_acc: 0.6484\n",
      "Epoch 740/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8209 - acc: 0.6631 - val_loss: 0.9606 - val_acc: 0.6475\n",
      "Epoch 741/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8175 - acc: 0.6629 - val_loss: 0.9619 - val_acc: 0.6492\n",
      "Epoch 742/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8172 - acc: 0.6630 - val_loss: 0.9650 - val_acc: 0.6466\n",
      "Epoch 743/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8173 - acc: 0.6627 - val_loss: 0.9690 - val_acc: 0.6472\n",
      "Epoch 744/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8151 - acc: 0.6639 - val_loss: 0.9656 - val_acc: 0.6484\n",
      "Epoch 745/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8157 - acc: 0.6647 - val_loss: 0.9775 - val_acc: 0.6486\n",
      "Epoch 746/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8167 - acc: 0.6636 - val_loss: 0.9636 - val_acc: 0.6469\n",
      "Epoch 747/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8160 - acc: 0.6649 - val_loss: 0.9638 - val_acc: 0.6487\n",
      "Epoch 748/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8152 - acc: 0.6652 - val_loss: 0.9713 - val_acc: 0.6461\n",
      "Epoch 749/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8149 - acc: 0.6647 - val_loss: 0.9627 - val_acc: 0.6491\n",
      "Epoch 750/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8179 - acc: 0.6639 - val_loss: 0.9629 - val_acc: 0.6487\n",
      "Epoch 751/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8202 - acc: 0.6631 - val_loss: 0.9572 - val_acc: 0.6476\n",
      "Epoch 752/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8139 - acc: 0.6647 - val_loss: 0.9731 - val_acc: 0.6457\n",
      "Epoch 753/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8166 - acc: 0.6632 - val_loss: 0.9707 - val_acc: 0.6458\n",
      "Epoch 754/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8140 - acc: 0.6654 - val_loss: 0.9734 - val_acc: 0.6471\n",
      "Epoch 755/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8128 - acc: 0.6667 - val_loss: 0.9676 - val_acc: 0.6475\n",
      "Epoch 756/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8136 - acc: 0.6651 - val_loss: 0.9728 - val_acc: 0.6464\n",
      "Epoch 757/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8133 - acc: 0.6649 - val_loss: 0.9653 - val_acc: 0.6489\n",
      "Epoch 758/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8180 - acc: 0.6639 - val_loss: 0.9661 - val_acc: 0.6460\n",
      "Epoch 759/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8164 - acc: 0.6645 - val_loss: 0.9601 - val_acc: 0.6484\n",
      "Epoch 760/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8161 - acc: 0.6639 - val_loss: 0.9717 - val_acc: 0.6471\n",
      "Epoch 761/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8148 - acc: 0.6640 - val_loss: 0.9637 - val_acc: 0.6468\n",
      "Epoch 762/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8139 - acc: 0.6653 - val_loss: 0.9672 - val_acc: 0.6479\n",
      "Epoch 763/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8148 - acc: 0.6647 - val_loss: 0.9725 - val_acc: 0.6484\n",
      "Epoch 764/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8161 - acc: 0.6641 - val_loss: 0.9627 - val_acc: 0.6498\n",
      "Epoch 765/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8138 - acc: 0.6654 - val_loss: 0.9585 - val_acc: 0.6489\n",
      "Epoch 766/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8141 - acc: 0.6652 - val_loss: 0.9734 - val_acc: 0.6480\n",
      "Epoch 767/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8111 - acc: 0.6665 - val_loss: 0.9672 - val_acc: 0.6494\n",
      "Epoch 768/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8141 - acc: 0.6650 - val_loss: 0.9711 - val_acc: 0.6481\n",
      "Epoch 769/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8119 - acc: 0.6662 - val_loss: 0.9620 - val_acc: 0.6488\n",
      "Epoch 770/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8154 - acc: 0.6647 - val_loss: 0.9733 - val_acc: 0.6480\n",
      "Epoch 771/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8128 - acc: 0.6655 - val_loss: 0.9735 - val_acc: 0.6457\n",
      "Epoch 772/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8151 - acc: 0.6646 - val_loss: 0.9645 - val_acc: 0.6507\n",
      "Epoch 773/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8128 - acc: 0.6651 - val_loss: 0.9628 - val_acc: 0.6482\n",
      "Epoch 774/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8138 - acc: 0.6657 - val_loss: 0.9626 - val_acc: 0.6485\n",
      "Epoch 775/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8114 - acc: 0.6662 - val_loss: 0.9563 - val_acc: 0.6500\n",
      "Epoch 776/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8129 - acc: 0.6662 - val_loss: 0.9682 - val_acc: 0.6486\n",
      "Epoch 777/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8140 - acc: 0.6647 - val_loss: 0.9617 - val_acc: 0.6483\n",
      "Epoch 778/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8143 - acc: 0.6652 - val_loss: 0.9663 - val_acc: 0.6460\n",
      "Epoch 779/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8144 - acc: 0.6658 - val_loss: 0.9642 - val_acc: 0.6509\n",
      "Epoch 780/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8108 - acc: 0.6665 - val_loss: 0.9715 - val_acc: 0.6492\n",
      "Epoch 781/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8127 - acc: 0.6663 - val_loss: 0.9692 - val_acc: 0.6479\n",
      "Epoch 782/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8142 - acc: 0.6661 - val_loss: 0.9685 - val_acc: 0.6469\n",
      "Epoch 783/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8123 - acc: 0.6667 - val_loss: 0.9662 - val_acc: 0.6484\n",
      "Epoch 784/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8127 - acc: 0.6655 - val_loss: 0.9597 - val_acc: 0.6485\n",
      "Epoch 785/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8153 - acc: 0.6646 - val_loss: 0.9639 - val_acc: 0.6498\n",
      "Epoch 786/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8133 - acc: 0.6659 - val_loss: 0.9626 - val_acc: 0.6501\n",
      "Epoch 787/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8118 - acc: 0.6663 - val_loss: 0.9657 - val_acc: 0.6493\n",
      "Epoch 788/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8119 - acc: 0.6662 - val_loss: 0.9728 - val_acc: 0.6483\n",
      "Epoch 789/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8138 - acc: 0.6662 - val_loss: 0.9613 - val_acc: 0.6500\n",
      "Epoch 790/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8147 - acc: 0.6655 - val_loss: 0.9661 - val_acc: 0.6488\n",
      "Epoch 791/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8146 - acc: 0.6655 - val_loss: 0.9613 - val_acc: 0.6485\n",
      "Epoch 792/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8113 - acc: 0.6673 - val_loss: 0.9744 - val_acc: 0.6485\n",
      "Epoch 793/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8126 - acc: 0.6657 - val_loss: 0.9754 - val_acc: 0.6469\n",
      "Epoch 794/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8130 - acc: 0.6664 - val_loss: 0.9629 - val_acc: 0.6511\n",
      "Epoch 795/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8104 - acc: 0.6661 - val_loss: 0.9716 - val_acc: 0.6477\n",
      "Epoch 796/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8091 - acc: 0.6679 - val_loss: 0.9665 - val_acc: 0.6505\n",
      "Epoch 797/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8128 - acc: 0.6667 - val_loss: 0.9665 - val_acc: 0.6499\n",
      "Epoch 798/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8119 - acc: 0.6666 - val_loss: 0.9643 - val_acc: 0.6502\n",
      "Epoch 799/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8116 - acc: 0.6665 - val_loss: 0.9701 - val_acc: 0.6508\n",
      "Epoch 800/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8115 - acc: 0.6666 - val_loss: 0.9660 - val_acc: 0.6519\n",
      "Epoch 801/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8105 - acc: 0.6672 - val_loss: 0.9619 - val_acc: 0.6494\n",
      "Epoch 802/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8103 - acc: 0.6678 - val_loss: 0.9574 - val_acc: 0.6531\n",
      "Epoch 803/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8113 - acc: 0.6661 - val_loss: 0.9614 - val_acc: 0.6518\n",
      "Epoch 804/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8110 - acc: 0.6677 - val_loss: 0.9584 - val_acc: 0.6492\n",
      "Epoch 805/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8083 - acc: 0.6684 - val_loss: 0.9726 - val_acc: 0.6502\n",
      "Epoch 806/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8115 - acc: 0.6669 - val_loss: 0.9704 - val_acc: 0.6499\n",
      "Epoch 807/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8120 - acc: 0.6670 - val_loss: 0.9578 - val_acc: 0.6485\n",
      "Epoch 808/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8104 - acc: 0.6672 - val_loss: 0.9623 - val_acc: 0.6507\n",
      "Epoch 809/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8109 - acc: 0.6667 - val_loss: 0.9691 - val_acc: 0.6507\n",
      "Epoch 810/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8101 - acc: 0.6678 - val_loss: 0.9652 - val_acc: 0.6491\n",
      "Epoch 811/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8090 - acc: 0.6677 - val_loss: 0.9607 - val_acc: 0.6519\n",
      "Epoch 812/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8093 - acc: 0.6676 - val_loss: 0.9611 - val_acc: 0.6492\n",
      "Epoch 813/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8105 - acc: 0.6673 - val_loss: 0.9675 - val_acc: 0.6508\n",
      "Epoch 814/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8082 - acc: 0.6688 - val_loss: 0.9606 - val_acc: 0.6503\n",
      "Epoch 815/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8110 - acc: 0.6665 - val_loss: 0.9617 - val_acc: 0.6498\n",
      "Epoch 816/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8116 - acc: 0.6666 - val_loss: 0.9644 - val_acc: 0.6480\n",
      "Epoch 817/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8110 - acc: 0.6673 - val_loss: 0.9704 - val_acc: 0.6477\n",
      "Epoch 818/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8095 - acc: 0.6674 - val_loss: 0.9574 - val_acc: 0.6498\n",
      "Epoch 819/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8125 - acc: 0.6675 - val_loss: 0.9595 - val_acc: 0.6494\n",
      "Epoch 820/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8080 - acc: 0.6689 - val_loss: 0.9631 - val_acc: 0.6520\n",
      "Epoch 821/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8094 - acc: 0.6674 - val_loss: 0.9645 - val_acc: 0.6500\n",
      "Epoch 822/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8089 - acc: 0.6676 - val_loss: 0.9596 - val_acc: 0.6508\n",
      "Epoch 823/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8131 - acc: 0.6660 - val_loss: 0.9637 - val_acc: 0.6533\n",
      "Epoch 824/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8099 - acc: 0.6677 - val_loss: 0.9629 - val_acc: 0.6500\n",
      "Epoch 825/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8083 - acc: 0.6677 - val_loss: 0.9712 - val_acc: 0.6517\n",
      "Epoch 826/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8085 - acc: 0.6679 - val_loss: 0.9644 - val_acc: 0.6522\n",
      "Epoch 827/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8108 - acc: 0.6673 - val_loss: 0.9594 - val_acc: 0.6499\n",
      "Epoch 828/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8120 - acc: 0.6668 - val_loss: 0.9621 - val_acc: 0.6496\n",
      "Epoch 829/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8100 - acc: 0.6673 - val_loss: 0.9620 - val_acc: 0.6517\n",
      "Epoch 830/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8102 - acc: 0.6678 - val_loss: 0.9597 - val_acc: 0.6512\n",
      "Epoch 831/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8090 - acc: 0.6680 - val_loss: 0.9599 - val_acc: 0.6531\n",
      "Epoch 832/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8141 - acc: 0.6670 - val_loss: 0.9610 - val_acc: 0.6520\n",
      "Epoch 833/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8125 - acc: 0.6669 - val_loss: 0.9563 - val_acc: 0.6515\n",
      "Epoch 834/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8069 - acc: 0.6685 - val_loss: 0.9625 - val_acc: 0.6537\n",
      "Epoch 835/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8087 - acc: 0.6675 - val_loss: 0.9641 - val_acc: 0.6519\n",
      "Epoch 836/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8054 - acc: 0.6689 - val_loss: 0.9621 - val_acc: 0.6504\n",
      "Epoch 837/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8107 - acc: 0.6683 - val_loss: 0.9628 - val_acc: 0.6486\n",
      "Epoch 838/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8070 - acc: 0.6689 - val_loss: 0.9697 - val_acc: 0.6521\n",
      "Epoch 839/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8077 - acc: 0.6679 - val_loss: 0.9634 - val_acc: 0.6527\n",
      "Epoch 840/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8085 - acc: 0.6685 - val_loss: 0.9636 - val_acc: 0.6498\n",
      "Epoch 841/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8096 - acc: 0.6674 - val_loss: 0.9721 - val_acc: 0.6517\n",
      "Epoch 842/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8103 - acc: 0.6682 - val_loss: 0.9702 - val_acc: 0.6450\n",
      "Epoch 843/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8152 - acc: 0.6655 - val_loss: 0.9511 - val_acc: 0.6511\n",
      "Epoch 844/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8103 - acc: 0.6679 - val_loss: 0.9541 - val_acc: 0.6508\n",
      "Epoch 845/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8113 - acc: 0.6680 - val_loss: 0.9562 - val_acc: 0.6515\n",
      "Epoch 846/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8074 - acc: 0.6684 - val_loss: 0.9580 - val_acc: 0.6518\n",
      "Epoch 847/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8044 - acc: 0.6701 - val_loss: 0.9515 - val_acc: 0.6521\n",
      "Epoch 848/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8074 - acc: 0.6690 - val_loss: 0.9528 - val_acc: 0.6511\n",
      "Epoch 849/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8069 - acc: 0.6692 - val_loss: 0.9630 - val_acc: 0.6498\n",
      "Epoch 850/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8077 - acc: 0.6684 - val_loss: 0.9596 - val_acc: 0.6527\n",
      "Epoch 851/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8060 - acc: 0.6699 - val_loss: 0.9630 - val_acc: 0.6513\n",
      "Epoch 852/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8087 - acc: 0.6688 - val_loss: 0.9704 - val_acc: 0.6505\n",
      "Epoch 853/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8096 - acc: 0.6676 - val_loss: 0.9677 - val_acc: 0.6522\n",
      "Epoch 854/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8090 - acc: 0.6683 - val_loss: 0.9596 - val_acc: 0.6497\n",
      "Epoch 855/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8071 - acc: 0.6674 - val_loss: 0.9639 - val_acc: 0.6534\n",
      "Epoch 856/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8063 - acc: 0.6683 - val_loss: 0.9608 - val_acc: 0.6509\n",
      "Epoch 857/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8081 - acc: 0.6683 - val_loss: 0.9601 - val_acc: 0.6497\n",
      "Epoch 858/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8080 - acc: 0.6677 - val_loss: 0.9617 - val_acc: 0.6488\n",
      "Epoch 859/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8063 - acc: 0.6697 - val_loss: 0.9550 - val_acc: 0.6525\n",
      "Epoch 860/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8069 - acc: 0.6685 - val_loss: 0.9637 - val_acc: 0.6503\n",
      "Epoch 861/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8065 - acc: 0.6698 - val_loss: 0.9591 - val_acc: 0.6511\n",
      "Epoch 862/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8052 - acc: 0.6703 - val_loss: 0.9611 - val_acc: 0.6527\n",
      "Epoch 863/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8109 - acc: 0.6672 - val_loss: 0.9559 - val_acc: 0.6537\n",
      "Epoch 864/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8043 - acc: 0.6697 - val_loss: 0.9628 - val_acc: 0.6535\n",
      "Epoch 865/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8086 - acc: 0.6688 - val_loss: 0.9653 - val_acc: 0.6520\n",
      "Epoch 866/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8080 - acc: 0.6684 - val_loss: 0.9613 - val_acc: 0.6529\n",
      "Epoch 867/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8077 - acc: 0.6687 - val_loss: 0.9675 - val_acc: 0.6541\n",
      "Epoch 868/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8057 - acc: 0.6700 - val_loss: 0.9559 - val_acc: 0.6480\n",
      "Epoch 869/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8059 - acc: 0.6691 - val_loss: 0.9537 - val_acc: 0.6538\n",
      "Epoch 870/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8069 - acc: 0.6695 - val_loss: 0.9604 - val_acc: 0.6518\n",
      "Epoch 871/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8042 - acc: 0.6699 - val_loss: 0.9640 - val_acc: 0.6525\n",
      "Epoch 872/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8076 - acc: 0.6693 - val_loss: 0.9746 - val_acc: 0.6484\n",
      "Epoch 873/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8083 - acc: 0.6686 - val_loss: 0.9612 - val_acc: 0.6524\n",
      "Epoch 874/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8057 - acc: 0.6694 - val_loss: 0.9686 - val_acc: 0.6537\n",
      "Epoch 875/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8065 - acc: 0.6694 - val_loss: 0.9583 - val_acc: 0.6521\n",
      "Epoch 876/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8067 - acc: 0.6694 - val_loss: 0.9708 - val_acc: 0.6518\n",
      "Epoch 877/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8051 - acc: 0.6697 - val_loss: 0.9608 - val_acc: 0.6526\n",
      "Epoch 878/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8045 - acc: 0.6696 - val_loss: 0.9636 - val_acc: 0.6524\n",
      "Epoch 879/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8050 - acc: 0.6695 - val_loss: 0.9604 - val_acc: 0.6523\n",
      "Epoch 880/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8065 - acc: 0.6694 - val_loss: 0.9643 - val_acc: 0.6520\n",
      "Epoch 881/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8032 - acc: 0.6701 - val_loss: 0.9589 - val_acc: 0.6534\n",
      "Epoch 882/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8028 - acc: 0.6700 - val_loss: 0.9659 - val_acc: 0.6537\n",
      "Epoch 883/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8035 - acc: 0.6697 - val_loss: 0.9537 - val_acc: 0.6522\n",
      "Epoch 884/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8028 - acc: 0.6706 - val_loss: 0.9685 - val_acc: 0.6531\n",
      "Epoch 885/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8038 - acc: 0.6710 - val_loss: 0.9683 - val_acc: 0.6524\n",
      "Epoch 886/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8024 - acc: 0.6700 - val_loss: 0.9621 - val_acc: 0.6511\n",
      "Epoch 887/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8038 - acc: 0.6711 - val_loss: 0.9656 - val_acc: 0.6539\n",
      "Epoch 888/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8022 - acc: 0.6719 - val_loss: 0.9710 - val_acc: 0.6519\n",
      "Epoch 889/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8029 - acc: 0.6707 - val_loss: 0.9755 - val_acc: 0.6526\n",
      "Epoch 890/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8073 - acc: 0.6690 - val_loss: 0.9665 - val_acc: 0.6520\n",
      "Epoch 891/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8064 - acc: 0.6694 - val_loss: 0.9628 - val_acc: 0.6521\n",
      "Epoch 892/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8052 - acc: 0.6695 - val_loss: 0.9639 - val_acc: 0.6520\n",
      "Epoch 893/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8049 - acc: 0.6695 - val_loss: 0.9547 - val_acc: 0.6526\n",
      "Epoch 894/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8021 - acc: 0.6704 - val_loss: 0.9652 - val_acc: 0.6536\n",
      "Epoch 895/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8038 - acc: 0.6708 - val_loss: 0.9548 - val_acc: 0.6526\n",
      "Epoch 896/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8024 - acc: 0.6711 - val_loss: 0.9546 - val_acc: 0.6539\n",
      "Epoch 897/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8034 - acc: 0.6699 - val_loss: 0.9613 - val_acc: 0.6540\n",
      "Epoch 898/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8052 - acc: 0.6704 - val_loss: 0.9639 - val_acc: 0.6519\n",
      "Epoch 899/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8034 - acc: 0.6713 - val_loss: 0.9655 - val_acc: 0.6535\n",
      "Epoch 900/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8015 - acc: 0.6712 - val_loss: 0.9654 - val_acc: 0.6537\n",
      "Epoch 901/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8014 - acc: 0.6719 - val_loss: 0.9665 - val_acc: 0.6548\n",
      "Epoch 902/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8046 - acc: 0.6696 - val_loss: 0.9564 - val_acc: 0.6549\n",
      "Epoch 903/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8018 - acc: 0.6716 - val_loss: 0.9572 - val_acc: 0.6537\n",
      "Epoch 904/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8008 - acc: 0.6722 - val_loss: 0.9660 - val_acc: 0.6522\n",
      "Epoch 905/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8013 - acc: 0.6719 - val_loss: 0.9582 - val_acc: 0.6523\n",
      "Epoch 906/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8063 - acc: 0.6701 - val_loss: 0.9635 - val_acc: 0.6516\n",
      "Epoch 907/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8055 - acc: 0.6690 - val_loss: 0.9674 - val_acc: 0.6509\n",
      "Epoch 908/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8028 - acc: 0.6712 - val_loss: 0.9622 - val_acc: 0.6510\n",
      "Epoch 909/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.7995 - acc: 0.6721 - val_loss: 0.9658 - val_acc: 0.6511\n",
      "Epoch 910/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8029 - acc: 0.6721 - val_loss: 0.9603 - val_acc: 0.6538\n",
      "Epoch 911/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8033 - acc: 0.6710 - val_loss: 0.9589 - val_acc: 0.6519\n",
      "Epoch 912/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8033 - acc: 0.6712 - val_loss: 0.9550 - val_acc: 0.6540\n",
      "Epoch 913/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8021 - acc: 0.6707 - val_loss: 0.9629 - val_acc: 0.6543\n",
      "Epoch 914/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8015 - acc: 0.6707 - val_loss: 0.9600 - val_acc: 0.6523\n",
      "Epoch 915/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8043 - acc: 0.6702 - val_loss: 0.9594 - val_acc: 0.6521\n",
      "Epoch 916/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8034 - acc: 0.6707 - val_loss: 0.9664 - val_acc: 0.6522\n",
      "Epoch 917/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8061 - acc: 0.6695 - val_loss: 0.9630 - val_acc: 0.6526\n",
      "Epoch 918/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8033 - acc: 0.6713 - val_loss: 0.9602 - val_acc: 0.6540\n",
      "Epoch 919/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7993 - acc: 0.6722 - val_loss: 0.9620 - val_acc: 0.6559\n",
      "Epoch 920/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8012 - acc: 0.6723 - val_loss: 0.9595 - val_acc: 0.6549\n",
      "Epoch 921/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8000 - acc: 0.6717 - val_loss: 0.9680 - val_acc: 0.6545\n",
      "Epoch 922/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8005 - acc: 0.6711 - val_loss: 0.9621 - val_acc: 0.6532\n",
      "Epoch 923/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8044 - acc: 0.6706 - val_loss: 0.9635 - val_acc: 0.6540\n",
      "Epoch 924/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8016 - acc: 0.6720 - val_loss: 0.9603 - val_acc: 0.6533\n",
      "Epoch 925/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8023 - acc: 0.6717 - val_loss: 0.9592 - val_acc: 0.6527\n",
      "Epoch 926/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8000 - acc: 0.6713 - val_loss: 0.9546 - val_acc: 0.6529\n",
      "Epoch 927/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.7996 - acc: 0.6713 - val_loss: 0.9587 - val_acc: 0.6533\n",
      "Epoch 928/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8002 - acc: 0.6728 - val_loss: 0.9673 - val_acc: 0.6529\n",
      "Epoch 929/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8010 - acc: 0.6716 - val_loss: 0.9645 - val_acc: 0.6539\n",
      "Epoch 930/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8098 - acc: 0.6711 - val_loss: 0.9626 - val_acc: 0.6542\n",
      "Epoch 931/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8007 - acc: 0.6718 - val_loss: 0.9596 - val_acc: 0.6556\n",
      "Epoch 932/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8005 - acc: 0.6723 - val_loss: 0.9596 - val_acc: 0.6518\n",
      "Epoch 933/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8008 - acc: 0.6721 - val_loss: 0.9574 - val_acc: 0.6536\n",
      "Epoch 934/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8006 - acc: 0.6719 - val_loss: 0.9611 - val_acc: 0.6515\n",
      "Epoch 935/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8044 - acc: 0.6705 - val_loss: 0.9579 - val_acc: 0.6544\n",
      "Epoch 936/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.7997 - acc: 0.6732 - val_loss: 0.9576 - val_acc: 0.6529\n",
      "Epoch 937/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.8020 - acc: 0.6709 - val_loss: 0.9530 - val_acc: 0.6515\n",
      "Epoch 938/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8051 - acc: 0.6706 - val_loss: 0.9586 - val_acc: 0.6552\n",
      "Epoch 939/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8048 - acc: 0.6714 - val_loss: 0.9510 - val_acc: 0.6533\n",
      "Epoch 940/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8024 - acc: 0.6717 - val_loss: 0.9611 - val_acc: 0.6537\n",
      "Epoch 941/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7996 - acc: 0.6725 - val_loss: 0.9528 - val_acc: 0.6548\n",
      "Epoch 942/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.7988 - acc: 0.6726 - val_loss: 0.9589 - val_acc: 0.6546\n",
      "Epoch 943/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8048 - acc: 0.6705 - val_loss: 0.9594 - val_acc: 0.6550\n",
      "Epoch 944/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7973 - acc: 0.6737 - val_loss: 0.9689 - val_acc: 0.6553\n",
      "Epoch 945/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7991 - acc: 0.6723 - val_loss: 0.9664 - val_acc: 0.6524\n",
      "Epoch 946/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8025 - acc: 0.6718 - val_loss: 0.9523 - val_acc: 0.6540\n",
      "Epoch 947/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8001 - acc: 0.6715 - val_loss: 0.9647 - val_acc: 0.6542\n",
      "Epoch 948/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.7987 - acc: 0.6724 - val_loss: 0.9609 - val_acc: 0.6553\n",
      "Epoch 949/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.8014 - acc: 0.6710 - val_loss: 0.9684 - val_acc: 0.6538\n",
      "Epoch 950/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8024 - acc: 0.6708 - val_loss: 0.9646 - val_acc: 0.6555\n",
      "Epoch 951/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8027 - acc: 0.6715 - val_loss: 0.9536 - val_acc: 0.6545\n",
      "Epoch 952/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.7998 - acc: 0.6723 - val_loss: 0.9666 - val_acc: 0.6529\n",
      "Epoch 953/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.7985 - acc: 0.6736 - val_loss: 0.9629 - val_acc: 0.6531\n",
      "Epoch 954/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7999 - acc: 0.6723 - val_loss: 0.9650 - val_acc: 0.6530\n",
      "Epoch 955/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.7979 - acc: 0.6737 - val_loss: 0.9669 - val_acc: 0.6530\n",
      "Epoch 956/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.8028 - acc: 0.6722 - val_loss: 0.9607 - val_acc: 0.6522\n",
      "Epoch 957/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8022 - acc: 0.6720 - val_loss: 0.9559 - val_acc: 0.6553\n",
      "Epoch 958/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.7986 - acc: 0.6724 - val_loss: 0.9594 - val_acc: 0.6549\n",
      "Epoch 959/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.7983 - acc: 0.6730 - val_loss: 0.9624 - val_acc: 0.6534\n",
      "Epoch 960/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8015 - acc: 0.6715 - val_loss: 0.9603 - val_acc: 0.6525\n",
      "Epoch 961/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7964 - acc: 0.6736 - val_loss: 0.9591 - val_acc: 0.6531\n",
      "Epoch 962/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7996 - acc: 0.6728 - val_loss: 0.9596 - val_acc: 0.6550\n",
      "Epoch 963/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.7990 - acc: 0.6731 - val_loss: 0.9663 - val_acc: 0.6520\n",
      "Epoch 964/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.7995 - acc: 0.6727 - val_loss: 0.9613 - val_acc: 0.6551\n",
      "Epoch 965/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.7983 - acc: 0.6726 - val_loss: 0.9677 - val_acc: 0.6534\n",
      "Epoch 966/1000\n",
      "214938/214938 [==============================] - 10s 44us/step - loss: 0.7985 - acc: 0.6743 - val_loss: 0.9643 - val_acc: 0.6536\n",
      "Epoch 967/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.7994 - acc: 0.6727 - val_loss: 0.9578 - val_acc: 0.6542\n",
      "Epoch 968/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7985 - acc: 0.6732 - val_loss: 0.9654 - val_acc: 0.6540\n",
      "Epoch 969/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8013 - acc: 0.6720 - val_loss: 0.9598 - val_acc: 0.6508\n",
      "Epoch 970/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8014 - acc: 0.6720 - val_loss: 0.9589 - val_acc: 0.6530\n",
      "Epoch 971/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8037 - acc: 0.6719 - val_loss: 0.9580 - val_acc: 0.6521\n",
      "Epoch 972/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.8037 - acc: 0.6711 - val_loss: 0.9574 - val_acc: 0.6567\n",
      "Epoch 973/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7978 - acc: 0.6733 - val_loss: 0.9576 - val_acc: 0.6536\n",
      "Epoch 974/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8020 - acc: 0.6730 - val_loss: 0.9626 - val_acc: 0.6548\n",
      "Epoch 975/1000\n",
      "214938/214938 [==============================] - 10s 45us/step - loss: 0.7987 - acc: 0.6730 - val_loss: 0.9561 - val_acc: 0.6555\n",
      "Epoch 976/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7977 - acc: 0.6736 - val_loss: 0.9686 - val_acc: 0.6549\n",
      "Epoch 977/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7972 - acc: 0.6727 - val_loss: 0.9562 - val_acc: 0.6549\n",
      "Epoch 978/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7958 - acc: 0.6737 - val_loss: 0.9566 - val_acc: 0.6550\n",
      "Epoch 979/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7961 - acc: 0.6744 - val_loss: 0.9666 - val_acc: 0.6536\n",
      "Epoch 980/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7992 - acc: 0.6733 - val_loss: 0.9596 - val_acc: 0.6568\n",
      "Epoch 981/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7980 - acc: 0.6734 - val_loss: 0.9566 - val_acc: 0.6533\n",
      "Epoch 982/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7996 - acc: 0.6733 - val_loss: 0.9529 - val_acc: 0.6544\n",
      "Epoch 983/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.7987 - acc: 0.6729 - val_loss: 0.9759 - val_acc: 0.6514\n",
      "Epoch 984/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7987 - acc: 0.6740 - val_loss: 0.9542 - val_acc: 0.6538\n",
      "Epoch 985/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8006 - acc: 0.6721 - val_loss: 0.9572 - val_acc: 0.6520\n",
      "Epoch 986/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7982 - acc: 0.6738 - val_loss: 0.9542 - val_acc: 0.6558\n",
      "Epoch 987/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7970 - acc: 0.6740 - val_loss: 0.9730 - val_acc: 0.6543\n",
      "Epoch 988/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7977 - acc: 0.6734 - val_loss: 0.9585 - val_acc: 0.6530\n",
      "Epoch 989/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8003 - acc: 0.6724 - val_loss: 0.9499 - val_acc: 0.6540\n",
      "Epoch 990/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7993 - acc: 0.6734 - val_loss: 0.9554 - val_acc: 0.6540\n",
      "Epoch 991/1000\n",
      "214938/214938 [==============================] - 9s 42us/step - loss: 0.7952 - acc: 0.6740 - val_loss: 0.9594 - val_acc: 0.6542\n",
      "Epoch 992/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.8002 - acc: 0.6733 - val_loss: 0.9578 - val_acc: 0.6535\n",
      "Epoch 993/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7956 - acc: 0.6735 - val_loss: 0.9693 - val_acc: 0.6529\n",
      "Epoch 994/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.7967 - acc: 0.6740 - val_loss: 0.9474 - val_acc: 0.6547\n",
      "Epoch 995/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.7945 - acc: 0.6742 - val_loss: 0.9583 - val_acc: 0.6535\n",
      "Epoch 996/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7963 - acc: 0.6748 - val_loss: 0.9576 - val_acc: 0.6538\n",
      "Epoch 997/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7949 - acc: 0.6749 - val_loss: 0.9587 - val_acc: 0.6563\n",
      "Epoch 998/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7967 - acc: 0.6740 - val_loss: 0.9633 - val_acc: 0.6524\n",
      "Epoch 999/1000\n",
      "214938/214938 [==============================] - 9s 44us/step - loss: 0.7987 - acc: 0.6730 - val_loss: 0.9637 - val_acc: 0.6547\n",
      "Epoch 1000/1000\n",
      "214938/214938 [==============================] - 9s 43us/step - loss: 0.7989 - acc: 0.6731 - val_loss: 0.9577 - val_acc: 0.6551\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l1\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "import ptetaphi_nn\n",
    "import tools\n",
    "with open(\"filepath.txt\", 'r') as f:\n",
    "    filename = f.read()\n",
    "\n",
    "s_table = tools.open_file(filename, sort_by=\"tag\")\n",
    "\n",
    "print('filtering from', len(s_table), 'events')\n",
    "\n",
    "# we don't know how many real b exist\n",
    "#nb4 = (s_table.nbjets == 3) | (s_table.nbjets == 4) # 3 or 4 b-jets exist\n",
    "\n",
    "# we have exactly 3 b tags\n",
    "nt3 = s_table.nbtags==3  # 3 b tags\n",
    "\n",
    "events = s_table[nt3]\n",
    "\n",
    "# and ensure that the 3 tags are actually correct\n",
    "# this results in very little event loss\n",
    "events = events[events.truth[:,0] == 1]\n",
    "events = events[events.truth[:,1] == 1]\n",
    "events = events[events.truth[:,2] == 1]\n",
    "print(len(events))\n",
    "\n",
    "cutoff = 10  # not many events have >10 jets\n",
    "# \"pad\" = ensure all events have same length, cut off ends if needed\n",
    "events = tools.pad(events, cutoff)\n",
    "\n",
    "# then ensure require pt >= 40 and |eta| <= 2.5\n",
    "pt_filter = events.resolved_lv.pt <= 40\n",
    "events.resolved_lv.pt[pt_filter] = 0\n",
    "events.resolved_lv.eta[pt_filter] = 0\n",
    "events.resolved_lv.phi[pt_filter] = 0\n",
    "\n",
    "eta_filter = (events.resolved_lv.eta >= -2.5) & (events.resolved_lv.eta >= 2.5)\n",
    "events.resolved_lv.pt[eta_filter] = 0\n",
    "events.resolved_lv.eta[eta_filter] = 0\n",
    "events.resolved_lv.phi[eta_filter] = 0\n",
    "\n",
    "print(len(events))\n",
    "\n",
    "nn = ptetaphi_nn.PtEtaPhiNN(events)\n",
    "# Feed forward NN\n",
    "\n",
    "# create network\n",
    "nn.model = Sequential([\n",
    "    Dense(3*(cutoff-3), input_dim=3*(cutoff-3), kernel_initializer='normal', activation='relu'),\n",
    "    Dense(700, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(500, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(300, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense( 50, activation='relu'),\n",
    "    Dense(8, kernel_initializer='normal', activation='softmax')])\n",
    "nn.model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=\"adam\", metrics=['acc'])\n",
    "nn.model.summary()\n",
    "nn.learn(epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using data given when this model was created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 61411/61411 [00:00<00:00, 101872.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.evaluate(savename=\"same_filters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the architecture as a json string\n",
    "arch = nn.model.to_json()\n",
    "# save the architecture string to a file somehow, the below will work\n",
    "with open('architecture_same_filters.json', 'w') as arch_file:\n",
    "    arch_file.write(arch)\n",
    "# now save the weights as an HDF5 file\n",
    "nn.model.save_weights('weights_same_filters.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
