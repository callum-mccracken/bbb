{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# How does the shape / size of our network affect its ability to learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting data by tag\n",
      "308955\n",
      "303925\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 700)               15400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 408       \n",
      "=================================================================\n",
      "Total params: 552,220\n",
      "Trainable params: 552,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 212747 samples, validate on 30393 samples\n",
      "Epoch 1/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.1240 - acc: 0.4861 - val_loss: 1.0687 - val_acc: 0.5108\n",
      "Epoch 2/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 1.0703 - acc: 0.5119 - val_loss: 1.0573 - val_acc: 0.5185\n",
      "Epoch 3/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 1.0615 - acc: 0.5160 - val_loss: 1.0530 - val_acc: 0.5180\n",
      "Epoch 4/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 1.0573 - acc: 0.5160 - val_loss: 1.0500 - val_acc: 0.5194\n",
      "Epoch 5/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 1.0543 - acc: 0.5180 - val_loss: 1.0479 - val_acc: 0.5208\n",
      "Epoch 6/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 1.0521 - acc: 0.5184 - val_loss: 1.0470 - val_acc: 0.5256\n",
      "Epoch 7/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 1.0501 - acc: 0.5197 - val_loss: 1.0446 - val_acc: 0.5228\n",
      "Epoch 8/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 1.0487 - acc: 0.5205 - val_loss: 1.0421 - val_acc: 0.5234\n",
      "Epoch 9/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 1.0474 - acc: 0.5205 - val_loss: 1.0445 - val_acc: 0.5247\n",
      "Epoch 10/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 1.0462 - acc: 0.5211 - val_loss: 1.0438 - val_acc: 0.5236\n",
      "Epoch 11/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 1.0452 - acc: 0.5208 - val_loss: 1.0407 - val_acc: 0.5249\n",
      "Epoch 12/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 1.0438 - acc: 0.5214 - val_loss: 1.0409 - val_acc: 0.5258\n",
      "Epoch 13/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 1.0429 - acc: 0.5229 - val_loss: 1.0388 - val_acc: 0.5248\n",
      "Epoch 14/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 1.0417 - acc: 0.5229 - val_loss: 1.0390 - val_acc: 0.5229\n",
      "Epoch 15/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 1.0415 - acc: 0.5234 - val_loss: 1.0395 - val_acc: 0.5263\n",
      "Epoch 16/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 1.0393 - acc: 0.5240 - val_loss: 1.0340 - val_acc: 0.5284\n",
      "Epoch 17/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 1.0383 - acc: 0.5235 - val_loss: 1.0370 - val_acc: 0.5255\n",
      "Epoch 18/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 1.0374 - acc: 0.5239 - val_loss: 1.0349 - val_acc: 0.5265\n",
      "Epoch 19/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 1.0359 - acc: 0.5248 - val_loss: 1.0331 - val_acc: 0.5272\n",
      "Epoch 20/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 1.0352 - acc: 0.5253 - val_loss: 1.0341 - val_acc: 0.5278\n",
      "Epoch 21/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 1.0337 - acc: 0.5258 - val_loss: 1.0359 - val_acc: 0.5246\n",
      "Epoch 22/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 1.0324 - acc: 0.5261 - val_loss: 1.0347 - val_acc: 0.5276\n",
      "Epoch 23/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 1.0320 - acc: 0.5270 - val_loss: 1.0339 - val_acc: 0.5300\n",
      "Epoch 24/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 1.0306 - acc: 0.5270 - val_loss: 1.0305 - val_acc: 0.5293\n",
      "Epoch 25/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 1.0292 - acc: 0.5273 - val_loss: 1.0298 - val_acc: 0.5262\n",
      "Epoch 26/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 1.0280 - acc: 0.5274 - val_loss: 1.0289 - val_acc: 0.5300\n",
      "Epoch 27/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 1.0263 - acc: 0.5291 - val_loss: 1.0273 - val_acc: 0.5282\n",
      "Epoch 28/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 1.0243 - acc: 0.5291 - val_loss: 1.0283 - val_acc: 0.5306\n",
      "Epoch 29/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 1.0228 - acc: 0.5308 - val_loss: 1.0281 - val_acc: 0.5309\n",
      "Epoch 30/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 1.0215 - acc: 0.5310 - val_loss: 1.0274 - val_acc: 0.5281\n",
      "Epoch 31/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 1.0210 - acc: 0.5314 - val_loss: 1.0244 - val_acc: 0.5306\n",
      "Epoch 32/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 1.0191 - acc: 0.5316 - val_loss: 1.0245 - val_acc: 0.5312\n",
      "Epoch 33/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 1.0169 - acc: 0.5322 - val_loss: 1.0241 - val_acc: 0.5319\n",
      "Epoch 34/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 1.0155 - acc: 0.5340 - val_loss: 1.0198 - val_acc: 0.5333\n",
      "Epoch 35/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 1.0137 - acc: 0.5340 - val_loss: 1.0197 - val_acc: 0.5324\n",
      "Epoch 36/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 1.0112 - acc: 0.5348 - val_loss: 1.0163 - val_acc: 0.5351\n",
      "Epoch 37/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 1.0094 - acc: 0.5361 - val_loss: 1.0180 - val_acc: 0.5334\n",
      "Epoch 38/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 1.0072 - acc: 0.5368 - val_loss: 1.0152 - val_acc: 0.5358\n",
      "Epoch 39/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 1.0056 - acc: 0.5379 - val_loss: 1.0136 - val_acc: 0.5379\n",
      "Epoch 40/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 1.0031 - acc: 0.5388 - val_loss: 1.0124 - val_acc: 0.5387\n",
      "Epoch 41/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 1.0011 - acc: 0.5398 - val_loss: 1.0142 - val_acc: 0.5382\n",
      "Epoch 42/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9992 - acc: 0.5400 - val_loss: 1.0112 - val_acc: 0.5407\n",
      "Epoch 43/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.9974 - acc: 0.5408 - val_loss: 1.0080 - val_acc: 0.5391\n",
      "Epoch 44/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.9956 - acc: 0.5418 - val_loss: 1.0048 - val_acc: 0.5420\n",
      "Epoch 45/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9928 - acc: 0.5434 - val_loss: 1.0086 - val_acc: 0.5415\n",
      "Epoch 46/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.9907 - acc: 0.5438 - val_loss: 1.0038 - val_acc: 0.5436\n",
      "Epoch 47/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.9880 - acc: 0.5453 - val_loss: 1.0037 - val_acc: 0.5413\n",
      "Epoch 48/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.9865 - acc: 0.5456 - val_loss: 1.0025 - val_acc: 0.5455\n",
      "Epoch 49/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.9847 - acc: 0.5458 - val_loss: 1.0027 - val_acc: 0.5443\n",
      "Epoch 50/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.9816 - acc: 0.5483 - val_loss: 0.9976 - val_acc: 0.5465\n",
      "Epoch 51/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.9797 - acc: 0.5485 - val_loss: 0.9992 - val_acc: 0.5441\n",
      "Epoch 52/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9766 - acc: 0.5501 - val_loss: 1.0001 - val_acc: 0.5449\n",
      "Epoch 53/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.9756 - acc: 0.5510 - val_loss: 0.9954 - val_acc: 0.5476\n",
      "Epoch 54/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.9727 - acc: 0.5524 - val_loss: 0.9947 - val_acc: 0.5493\n",
      "Epoch 55/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.9705 - acc: 0.5531 - val_loss: 0.9891 - val_acc: 0.5534\n",
      "Epoch 56/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9681 - acc: 0.5542 - val_loss: 0.9917 - val_acc: 0.5517\n",
      "Epoch 57/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.9649 - acc: 0.5557 - val_loss: 0.9919 - val_acc: 0.5528\n",
      "Epoch 58/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.9637 - acc: 0.5564 - val_loss: 0.9879 - val_acc: 0.5545\n",
      "Epoch 59/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9621 - acc: 0.5576 - val_loss: 0.9888 - val_acc: 0.5549\n",
      "Epoch 60/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.9587 - acc: 0.5592 - val_loss: 0.9918 - val_acc: 0.5540\n",
      "Epoch 61/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.9578 - acc: 0.5592 - val_loss: 0.9881 - val_acc: 0.5554\n",
      "Epoch 62/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.9550 - acc: 0.5601 - val_loss: 0.9846 - val_acc: 0.5558\n",
      "Epoch 63/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9522 - acc: 0.5608 - val_loss: 0.9859 - val_acc: 0.5551\n",
      "Epoch 64/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.9511 - acc: 0.5611 - val_loss: 0.9780 - val_acc: 0.5596\n",
      "Epoch 65/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.9472 - acc: 0.5632 - val_loss: 0.9799 - val_acc: 0.5604\n",
      "Epoch 66/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9473 - acc: 0.5640 - val_loss: 0.9792 - val_acc: 0.5615\n",
      "Epoch 67/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.9438 - acc: 0.5652 - val_loss: 0.9781 - val_acc: 0.5622\n",
      "Epoch 68/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.9430 - acc: 0.5659 - val_loss: 0.9762 - val_acc: 0.5637\n",
      "Epoch 69/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.9393 - acc: 0.5677 - val_loss: 0.9764 - val_acc: 0.5627\n",
      "Epoch 70/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9386 - acc: 0.5682 - val_loss: 0.9732 - val_acc: 0.5654\n",
      "Epoch 71/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.9360 - acc: 0.5689 - val_loss: 0.9711 - val_acc: 0.5679\n",
      "Epoch 72/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.9336 - acc: 0.5701 - val_loss: 0.9692 - val_acc: 0.5666\n",
      "Epoch 73/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9314 - acc: 0.5712 - val_loss: 0.9692 - val_acc: 0.5674\n",
      "Epoch 74/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9307 - acc: 0.5725 - val_loss: 0.9647 - val_acc: 0.5702\n",
      "Epoch 75/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.9280 - acc: 0.5727 - val_loss: 0.9624 - val_acc: 0.5712\n",
      "Epoch 76/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9251 - acc: 0.5756 - val_loss: 0.9638 - val_acc: 0.5728\n",
      "Epoch 77/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.9247 - acc: 0.5753 - val_loss: 0.9628 - val_acc: 0.5695\n",
      "Epoch 78/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9223 - acc: 0.5760 - val_loss: 0.9630 - val_acc: 0.5738\n",
      "Epoch 79/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.9191 - acc: 0.5769 - val_loss: 0.9660 - val_acc: 0.5748\n",
      "Epoch 80/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.9171 - acc: 0.5796 - val_loss: 0.9612 - val_acc: 0.5768\n",
      "Epoch 81/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.9158 - acc: 0.5784 - val_loss: 0.9626 - val_acc: 0.5729\n",
      "Epoch 82/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9142 - acc: 0.5798 - val_loss: 0.9568 - val_acc: 0.5750\n",
      "Epoch 83/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.9120 - acc: 0.5800 - val_loss: 0.9583 - val_acc: 0.5777\n",
      "Epoch 84/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.9102 - acc: 0.5823 - val_loss: 0.9566 - val_acc: 0.5799\n",
      "Epoch 85/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.9093 - acc: 0.5830 - val_loss: 0.9565 - val_acc: 0.5811\n",
      "Epoch 86/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.9082 - acc: 0.5826 - val_loss: 0.9525 - val_acc: 0.5821\n",
      "Epoch 87/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.9055 - acc: 0.5834 - val_loss: 0.9511 - val_acc: 0.5823\n",
      "Epoch 88/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.9033 - acc: 0.5851 - val_loss: 0.9527 - val_acc: 0.5824\n",
      "Epoch 89/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.9021 - acc: 0.5846 - val_loss: 0.9524 - val_acc: 0.5825\n",
      "Epoch 90/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.9007 - acc: 0.5852 - val_loss: 0.9528 - val_acc: 0.5852\n",
      "Epoch 91/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.8979 - acc: 0.5872 - val_loss: 0.9473 - val_acc: 0.5856\n",
      "Epoch 92/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.8968 - acc: 0.5884 - val_loss: 0.9532 - val_acc: 0.5845\n",
      "Epoch 93/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8956 - acc: 0.5882 - val_loss: 0.9472 - val_acc: 0.5871\n",
      "Epoch 94/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.8927 - acc: 0.5906 - val_loss: 0.9492 - val_acc: 0.5863\n",
      "Epoch 95/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.8927 - acc: 0.5907 - val_loss: 0.9436 - val_acc: 0.5908\n",
      "Epoch 96/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.8899 - acc: 0.5913 - val_loss: 0.9433 - val_acc: 0.5913\n",
      "Epoch 97/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.8878 - acc: 0.5918 - val_loss: 0.9404 - val_acc: 0.5907\n",
      "Epoch 98/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.8884 - acc: 0.5918 - val_loss: 0.9432 - val_acc: 0.5923\n",
      "Epoch 99/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8848 - acc: 0.5937 - val_loss: 0.9345 - val_acc: 0.5944\n",
      "Epoch 100/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.8840 - acc: 0.5945 - val_loss: 0.9374 - val_acc: 0.5925\n",
      "Epoch 101/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8823 - acc: 0.5958 - val_loss: 0.9387 - val_acc: 0.5915\n",
      "Epoch 102/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8824 - acc: 0.5955 - val_loss: 0.9347 - val_acc: 0.5945\n",
      "Epoch 103/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8788 - acc: 0.5970 - val_loss: 0.9389 - val_acc: 0.5938\n",
      "Epoch 104/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8783 - acc: 0.5971 - val_loss: 0.9389 - val_acc: 0.5952\n",
      "Epoch 105/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8760 - acc: 0.5985 - val_loss: 0.9320 - val_acc: 0.5991\n",
      "Epoch 106/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8764 - acc: 0.5986 - val_loss: 0.9341 - val_acc: 0.5956\n",
      "Epoch 107/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8732 - acc: 0.6006 - val_loss: 0.9325 - val_acc: 0.5970\n",
      "Epoch 108/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8725 - acc: 0.6012 - val_loss: 0.9331 - val_acc: 0.5951\n",
      "Epoch 109/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8714 - acc: 0.6003 - val_loss: 0.9338 - val_acc: 0.5980\n",
      "Epoch 110/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8671 - acc: 0.6022 - val_loss: 0.9335 - val_acc: 0.5983\n",
      "Epoch 111/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8669 - acc: 0.6035 - val_loss: 0.9299 - val_acc: 0.5992\n",
      "Epoch 112/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8665 - acc: 0.6033 - val_loss: 0.9348 - val_acc: 0.5984\n",
      "Epoch 113/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.8640 - acc: 0.6031 - val_loss: 0.9303 - val_acc: 0.6018\n",
      "Epoch 114/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8633 - acc: 0.6050 - val_loss: 0.9280 - val_acc: 0.6021\n",
      "Epoch 115/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8614 - acc: 0.6058 - val_loss: 0.9272 - val_acc: 0.6038\n",
      "Epoch 116/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8610 - acc: 0.6058 - val_loss: 0.9262 - val_acc: 0.6041\n",
      "Epoch 117/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.8590 - acc: 0.6079 - val_loss: 0.9281 - val_acc: 0.6037\n",
      "Epoch 118/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.8579 - acc: 0.6066 - val_loss: 0.9249 - val_acc: 0.6052\n",
      "Epoch 119/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.8558 - acc: 0.6092 - val_loss: 0.9245 - val_acc: 0.6085\n",
      "Epoch 120/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.8561 - acc: 0.6084 - val_loss: 0.9254 - val_acc: 0.6039\n",
      "Epoch 121/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8551 - acc: 0.6098 - val_loss: 0.9222 - val_acc: 0.6055\n",
      "Epoch 122/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.8535 - acc: 0.6098 - val_loss: 0.9223 - val_acc: 0.6069\n",
      "Epoch 123/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8525 - acc: 0.6102 - val_loss: 0.9216 - val_acc: 0.6094\n",
      "Epoch 124/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8504 - acc: 0.6115 - val_loss: 0.9197 - val_acc: 0.6091\n",
      "Epoch 125/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8503 - acc: 0.6125 - val_loss: 0.9228 - val_acc: 0.6082\n",
      "Epoch 126/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8473 - acc: 0.6132 - val_loss: 0.9217 - val_acc: 0.6088\n",
      "Epoch 127/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8467 - acc: 0.6133 - val_loss: 0.9159 - val_acc: 0.6125\n",
      "Epoch 128/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8449 - acc: 0.6146 - val_loss: 0.9189 - val_acc: 0.6126\n",
      "Epoch 129/1000\n",
      "212747/212747 [==============================] - 9s 40us/step - loss: 0.8456 - acc: 0.6149 - val_loss: 0.9150 - val_acc: 0.6129\n",
      "Epoch 130/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8449 - acc: 0.6144 - val_loss: 0.9115 - val_acc: 0.6148\n",
      "Epoch 131/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8413 - acc: 0.6159 - val_loss: 0.9198 - val_acc: 0.6125\n",
      "Epoch 132/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8419 - acc: 0.6155 - val_loss: 0.9141 - val_acc: 0.6147\n",
      "Epoch 133/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8391 - acc: 0.6180 - val_loss: 0.9148 - val_acc: 0.6137\n",
      "Epoch 134/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8395 - acc: 0.6178 - val_loss: 0.9155 - val_acc: 0.6133\n",
      "Epoch 135/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8384 - acc: 0.6175 - val_loss: 0.9094 - val_acc: 0.6155\n",
      "Epoch 136/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8338 - acc: 0.6195 - val_loss: 0.9105 - val_acc: 0.6183\n",
      "Epoch 137/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8334 - acc: 0.6211 - val_loss: 0.9113 - val_acc: 0.6168\n",
      "Epoch 138/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8363 - acc: 0.6205 - val_loss: 0.9111 - val_acc: 0.6170\n",
      "Epoch 139/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8338 - acc: 0.6194 - val_loss: 0.9090 - val_acc: 0.6165\n",
      "Epoch 140/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.8324 - acc: 0.6210 - val_loss: 0.9071 - val_acc: 0.6183\n",
      "Epoch 141/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.8298 - acc: 0.6220 - val_loss: 0.9125 - val_acc: 0.6191\n",
      "Epoch 142/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.8291 - acc: 0.6215 - val_loss: 0.9138 - val_acc: 0.6199\n",
      "Epoch 143/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.8289 - acc: 0.6227 - val_loss: 0.9086 - val_acc: 0.6216\n",
      "Epoch 144/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.8289 - acc: 0.6232 - val_loss: 0.9097 - val_acc: 0.6200\n",
      "Epoch 145/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.8270 - acc: 0.6241 - val_loss: 0.9026 - val_acc: 0.6240\n",
      "Epoch 146/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.8257 - acc: 0.6240 - val_loss: 0.9100 - val_acc: 0.6211\n",
      "Epoch 147/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8220 - acc: 0.6253 - val_loss: 0.9037 - val_acc: 0.6221\n",
      "Epoch 148/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8223 - acc: 0.6262 - val_loss: 0.9047 - val_acc: 0.6236\n",
      "Epoch 149/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8233 - acc: 0.6256 - val_loss: 0.8996 - val_acc: 0.6264\n",
      "Epoch 150/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8211 - acc: 0.6262 - val_loss: 0.9006 - val_acc: 0.6255\n",
      "Epoch 151/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8200 - acc: 0.6267 - val_loss: 0.9044 - val_acc: 0.6223\n",
      "Epoch 152/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8197 - acc: 0.6275 - val_loss: 0.9008 - val_acc: 0.6247\n",
      "Epoch 153/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8182 - acc: 0.6286 - val_loss: 0.9023 - val_acc: 0.6267\n",
      "Epoch 154/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8191 - acc: 0.6279 - val_loss: 0.8973 - val_acc: 0.6249\n",
      "Epoch 155/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8151 - acc: 0.6295 - val_loss: 0.8980 - val_acc: 0.6261\n",
      "Epoch 156/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8158 - acc: 0.6299 - val_loss: 0.8993 - val_acc: 0.6270\n",
      "Epoch 157/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8139 - acc: 0.6303 - val_loss: 0.9025 - val_acc: 0.6254\n",
      "Epoch 158/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8125 - acc: 0.6310 - val_loss: 0.9003 - val_acc: 0.6256\n",
      "Epoch 159/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8132 - acc: 0.6297 - val_loss: 0.8998 - val_acc: 0.6285\n",
      "Epoch 160/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8107 - acc: 0.6309 - val_loss: 0.9032 - val_acc: 0.6251\n",
      "Epoch 161/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8125 - acc: 0.6310 - val_loss: 0.8934 - val_acc: 0.6303\n",
      "Epoch 162/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8096 - acc: 0.6318 - val_loss: 0.8956 - val_acc: 0.6307\n",
      "Epoch 163/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8073 - acc: 0.6337 - val_loss: 0.9025 - val_acc: 0.6307\n",
      "Epoch 164/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8080 - acc: 0.6321 - val_loss: 0.9041 - val_acc: 0.6296\n",
      "Epoch 165/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.8095 - acc: 0.6331 - val_loss: 0.8952 - val_acc: 0.6298\n",
      "Epoch 166/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.8067 - acc: 0.6328 - val_loss: 0.8925 - val_acc: 0.6313\n",
      "Epoch 167/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.8054 - acc: 0.6342 - val_loss: 0.8920 - val_acc: 0.6297\n",
      "Epoch 168/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8055 - acc: 0.6354 - val_loss: 0.8937 - val_acc: 0.6323\n",
      "Epoch 169/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.8044 - acc: 0.6350 - val_loss: 0.8950 - val_acc: 0.6307\n",
      "Epoch 170/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.8033 - acc: 0.6352 - val_loss: 0.8941 - val_acc: 0.6321\n",
      "Epoch 171/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.8035 - acc: 0.6363 - val_loss: 0.8933 - val_acc: 0.6343\n",
      "Epoch 172/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8025 - acc: 0.6359 - val_loss: 0.8894 - val_acc: 0.6342\n",
      "Epoch 173/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8009 - acc: 0.6373 - val_loss: 0.8907 - val_acc: 0.6345\n",
      "Epoch 174/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.8003 - acc: 0.6369 - val_loss: 0.8904 - val_acc: 0.6336\n",
      "Epoch 175/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8015 - acc: 0.6361 - val_loss: 0.8910 - val_acc: 0.6345\n",
      "Epoch 176/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7972 - acc: 0.6389 - val_loss: 0.8947 - val_acc: 0.6349\n",
      "Epoch 177/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7967 - acc: 0.6375 - val_loss: 0.8915 - val_acc: 0.6353\n",
      "Epoch 178/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7948 - acc: 0.6403 - val_loss: 0.8917 - val_acc: 0.6369\n",
      "Epoch 179/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7953 - acc: 0.6403 - val_loss: 0.8915 - val_acc: 0.6349\n",
      "Epoch 180/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7947 - acc: 0.6392 - val_loss: 0.8880 - val_acc: 0.6348\n",
      "Epoch 181/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7949 - acc: 0.6398 - val_loss: 0.8879 - val_acc: 0.6371\n",
      "Epoch 182/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7934 - acc: 0.6409 - val_loss: 0.8850 - val_acc: 0.6378\n",
      "Epoch 183/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7916 - acc: 0.6416 - val_loss: 0.8855 - val_acc: 0.6423\n",
      "Epoch 184/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7916 - acc: 0.6415 - val_loss: 0.8831 - val_acc: 0.6395\n",
      "Epoch 185/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7901 - acc: 0.6422 - val_loss: 0.8808 - val_acc: 0.6402\n",
      "Epoch 186/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7900 - acc: 0.6418 - val_loss: 0.8862 - val_acc: 0.6401\n",
      "Epoch 187/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7910 - acc: 0.6419 - val_loss: 0.8826 - val_acc: 0.6385\n",
      "Epoch 188/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7875 - acc: 0.6436 - val_loss: 0.8865 - val_acc: 0.6395\n",
      "Epoch 189/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7879 - acc: 0.6440 - val_loss: 0.8812 - val_acc: 0.6414\n",
      "Epoch 190/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7847 - acc: 0.6444 - val_loss: 0.8845 - val_acc: 0.6419\n",
      "Epoch 191/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.7864 - acc: 0.6447 - val_loss: 0.8860 - val_acc: 0.6373\n",
      "Epoch 192/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7856 - acc: 0.6452 - val_loss: 0.8825 - val_acc: 0.6394\n",
      "Epoch 193/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7856 - acc: 0.6457 - val_loss: 0.8783 - val_acc: 0.6421\n",
      "Epoch 194/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7836 - acc: 0.6452 - val_loss: 0.8775 - val_acc: 0.6418\n",
      "Epoch 195/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7847 - acc: 0.6453 - val_loss: 0.8772 - val_acc: 0.6429\n",
      "Epoch 196/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7814 - acc: 0.6464 - val_loss: 0.8787 - val_acc: 0.6426\n",
      "Epoch 197/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7819 - acc: 0.6465 - val_loss: 0.8822 - val_acc: 0.6417\n",
      "Epoch 198/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7802 - acc: 0.6468 - val_loss: 0.8784 - val_acc: 0.6433\n",
      "Epoch 199/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7795 - acc: 0.6486 - val_loss: 0.8788 - val_acc: 0.6431\n",
      "Epoch 200/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7807 - acc: 0.6485 - val_loss: 0.8786 - val_acc: 0.6425\n",
      "Epoch 201/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7792 - acc: 0.6484 - val_loss: 0.8764 - val_acc: 0.6437\n",
      "Epoch 202/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7793 - acc: 0.6466 - val_loss: 0.8782 - val_acc: 0.6454\n",
      "Epoch 203/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7778 - acc: 0.6492 - val_loss: 0.8787 - val_acc: 0.6443\n",
      "Epoch 204/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7775 - acc: 0.6487 - val_loss: 0.8767 - val_acc: 0.6446\n",
      "Epoch 205/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7771 - acc: 0.6485 - val_loss: 0.8797 - val_acc: 0.6431\n",
      "Epoch 206/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7763 - acc: 0.6494 - val_loss: 0.8753 - val_acc: 0.6470\n",
      "Epoch 207/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7746 - acc: 0.6503 - val_loss: 0.8816 - val_acc: 0.6434\n",
      "Epoch 208/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7758 - acc: 0.6491 - val_loss: 0.8755 - val_acc: 0.6480\n",
      "Epoch 209/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.7758 - acc: 0.6507 - val_loss: 0.8794 - val_acc: 0.6476\n",
      "Epoch 210/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7740 - acc: 0.6501 - val_loss: 0.8783 - val_acc: 0.6488\n",
      "Epoch 211/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7731 - acc: 0.6506 - val_loss: 0.8726 - val_acc: 0.6458\n",
      "Epoch 212/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7721 - acc: 0.6513 - val_loss: 0.8746 - val_acc: 0.6453\n",
      "Epoch 213/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7722 - acc: 0.6508 - val_loss: 0.8725 - val_acc: 0.6491\n",
      "Epoch 214/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7707 - acc: 0.6511 - val_loss: 0.8734 - val_acc: 0.6467\n",
      "Epoch 215/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.7695 - acc: 0.6523 - val_loss: 0.8703 - val_acc: 0.6473\n",
      "Epoch 216/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7688 - acc: 0.6530 - val_loss: 0.8722 - val_acc: 0.6479\n",
      "Epoch 217/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7695 - acc: 0.6538 - val_loss: 0.8717 - val_acc: 0.6491\n",
      "Epoch 218/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7698 - acc: 0.6534 - val_loss: 0.8670 - val_acc: 0.6489\n",
      "Epoch 219/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7667 - acc: 0.6551 - val_loss: 0.8755 - val_acc: 0.6478\n",
      "Epoch 220/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7660 - acc: 0.6538 - val_loss: 0.8740 - val_acc: 0.6500\n",
      "Epoch 221/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7687 - acc: 0.6538 - val_loss: 0.8796 - val_acc: 0.6468\n",
      "Epoch 222/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7640 - acc: 0.6554 - val_loss: 0.8795 - val_acc: 0.6494\n",
      "Epoch 223/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7651 - acc: 0.6544 - val_loss: 0.8725 - val_acc: 0.6514\n",
      "Epoch 224/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7670 - acc: 0.6537 - val_loss: 0.8710 - val_acc: 0.6506\n",
      "Epoch 225/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7646 - acc: 0.6569 - val_loss: 0.8703 - val_acc: 0.6531\n",
      "Epoch 226/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7648 - acc: 0.6551 - val_loss: 0.8694 - val_acc: 0.6514\n",
      "Epoch 227/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7630 - acc: 0.6564 - val_loss: 0.8702 - val_acc: 0.6510\n",
      "Epoch 228/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7617 - acc: 0.6565 - val_loss: 0.8711 - val_acc: 0.6536\n",
      "Epoch 229/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.7606 - acc: 0.6576 - val_loss: 0.8665 - val_acc: 0.6530\n",
      "Epoch 230/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7623 - acc: 0.6560 - val_loss: 0.8712 - val_acc: 0.6506\n",
      "Epoch 231/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7594 - acc: 0.6582 - val_loss: 0.8695 - val_acc: 0.6540\n",
      "Epoch 232/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7600 - acc: 0.6575 - val_loss: 0.8712 - val_acc: 0.6505\n",
      "Epoch 233/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7582 - acc: 0.6575 - val_loss: 0.8711 - val_acc: 0.6541\n",
      "Epoch 234/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7573 - acc: 0.6596 - val_loss: 0.8714 - val_acc: 0.6538\n",
      "Epoch 235/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7592 - acc: 0.6577 - val_loss: 0.8732 - val_acc: 0.6526\n",
      "Epoch 236/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7587 - acc: 0.6581 - val_loss: 0.8672 - val_acc: 0.6545\n",
      "Epoch 237/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7572 - acc: 0.6594 - val_loss: 0.8657 - val_acc: 0.6523\n",
      "Epoch 238/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7543 - acc: 0.6597 - val_loss: 0.8685 - val_acc: 0.6571\n",
      "Epoch 239/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7545 - acc: 0.6604 - val_loss: 0.8682 - val_acc: 0.6538\n",
      "Epoch 240/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7554 - acc: 0.6590 - val_loss: 0.8641 - val_acc: 0.6577\n",
      "Epoch 241/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7533 - acc: 0.6609 - val_loss: 0.8633 - val_acc: 0.6552\n",
      "Epoch 242/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7560 - acc: 0.6598 - val_loss: 0.8628 - val_acc: 0.6567\n",
      "Epoch 243/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7550 - acc: 0.6600 - val_loss: 0.8648 - val_acc: 0.6545\n",
      "Epoch 244/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7555 - acc: 0.6602 - val_loss: 0.8681 - val_acc: 0.6529\n",
      "Epoch 245/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7549 - acc: 0.6597 - val_loss: 0.8634 - val_acc: 0.6575\n",
      "Epoch 246/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7547 - acc: 0.6604 - val_loss: 0.8607 - val_acc: 0.6552\n",
      "Epoch 247/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.7522 - acc: 0.6617 - val_loss: 0.8615 - val_acc: 0.6573\n",
      "Epoch 248/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7513 - acc: 0.6621 - val_loss: 0.8638 - val_acc: 0.6578\n",
      "Epoch 249/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7522 - acc: 0.6618 - val_loss: 0.8586 - val_acc: 0.6576\n",
      "Epoch 250/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7507 - acc: 0.6622 - val_loss: 0.8589 - val_acc: 0.6583\n",
      "Epoch 251/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7490 - acc: 0.6630 - val_loss: 0.8645 - val_acc: 0.6575\n",
      "Epoch 252/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7518 - acc: 0.6620 - val_loss: 0.8595 - val_acc: 0.6580\n",
      "Epoch 253/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7497 - acc: 0.6630 - val_loss: 0.8615 - val_acc: 0.6600\n",
      "Epoch 254/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7476 - acc: 0.6640 - val_loss: 0.8713 - val_acc: 0.6527\n",
      "Epoch 255/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7482 - acc: 0.6629 - val_loss: 0.8650 - val_acc: 0.6604\n",
      "Epoch 256/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7491 - acc: 0.6626 - val_loss: 0.8655 - val_acc: 0.6568\n",
      "Epoch 257/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7470 - acc: 0.6642 - val_loss: 0.8580 - val_acc: 0.6589\n",
      "Epoch 258/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7448 - acc: 0.6655 - val_loss: 0.8608 - val_acc: 0.6569\n",
      "Epoch 259/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7489 - acc: 0.6630 - val_loss: 0.8650 - val_acc: 0.6564\n",
      "Epoch 260/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7448 - acc: 0.6646 - val_loss: 0.8606 - val_acc: 0.6564\n",
      "Epoch 261/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.7465 - acc: 0.6647 - val_loss: 0.8537 - val_acc: 0.6566\n",
      "Epoch 262/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.7453 - acc: 0.6658 - val_loss: 0.8657 - val_acc: 0.6544\n",
      "Epoch 263/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7440 - acc: 0.6663 - val_loss: 0.8636 - val_acc: 0.6593\n",
      "Epoch 264/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7446 - acc: 0.6648 - val_loss: 0.8607 - val_acc: 0.6591\n",
      "Epoch 265/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7445 - acc: 0.6655 - val_loss: 0.8546 - val_acc: 0.6607\n",
      "Epoch 266/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7439 - acc: 0.6663 - val_loss: 0.8561 - val_acc: 0.6622\n",
      "Epoch 267/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7419 - acc: 0.6660 - val_loss: 0.8564 - val_acc: 0.6634\n",
      "Epoch 268/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7408 - acc: 0.6671 - val_loss: 0.8570 - val_acc: 0.6633\n",
      "Epoch 269/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7429 - acc: 0.6662 - val_loss: 0.8542 - val_acc: 0.6626\n",
      "Epoch 270/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7416 - acc: 0.6676 - val_loss: 0.8610 - val_acc: 0.6611\n",
      "Epoch 271/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7400 - acc: 0.6675 - val_loss: 0.8553 - val_acc: 0.6621\n",
      "Epoch 272/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7414 - acc: 0.6670 - val_loss: 0.8570 - val_acc: 0.6603\n",
      "Epoch 273/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7402 - acc: 0.6672 - val_loss: 0.8534 - val_acc: 0.6638\n",
      "Epoch 274/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7388 - acc: 0.6679 - val_loss: 0.8560 - val_acc: 0.6607\n",
      "Epoch 275/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7382 - acc: 0.6695 - val_loss: 0.8515 - val_acc: 0.6623\n",
      "Epoch 276/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7379 - acc: 0.6680 - val_loss: 0.8512 - val_acc: 0.6628\n",
      "Epoch 277/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7382 - acc: 0.6684 - val_loss: 0.8586 - val_acc: 0.6637\n",
      "Epoch 278/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.7366 - acc: 0.6689 - val_loss: 0.8510 - val_acc: 0.6627\n",
      "Epoch 279/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7370 - acc: 0.6694 - val_loss: 0.8544 - val_acc: 0.6637\n",
      "Epoch 280/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7372 - acc: 0.6695 - val_loss: 0.8493 - val_acc: 0.6637\n",
      "Epoch 281/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.7366 - acc: 0.6690 - val_loss: 0.8586 - val_acc: 0.6634\n",
      "Epoch 282/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7345 - acc: 0.6702 - val_loss: 0.8558 - val_acc: 0.6637\n",
      "Epoch 283/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7339 - acc: 0.6705 - val_loss: 0.8542 - val_acc: 0.6657\n",
      "Epoch 284/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7335 - acc: 0.6718 - val_loss: 0.8518 - val_acc: 0.6639\n",
      "Epoch 285/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7346 - acc: 0.6710 - val_loss: 0.8487 - val_acc: 0.6662\n",
      "Epoch 286/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7316 - acc: 0.6725 - val_loss: 0.8524 - val_acc: 0.6641\n",
      "Epoch 287/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7322 - acc: 0.6717 - val_loss: 0.8516 - val_acc: 0.6654\n",
      "Epoch 288/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7317 - acc: 0.6719 - val_loss: 0.8528 - val_acc: 0.6662\n",
      "Epoch 289/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7331 - acc: 0.6719 - val_loss: 0.8501 - val_acc: 0.6653\n",
      "Epoch 290/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.7317 - acc: 0.6734 - val_loss: 0.8531 - val_acc: 0.6668\n",
      "Epoch 291/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7306 - acc: 0.6729 - val_loss: 0.8484 - val_acc: 0.6671\n",
      "Epoch 292/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7353 - acc: 0.6699 - val_loss: 0.8510 - val_acc: 0.6631\n",
      "Epoch 293/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7299 - acc: 0.6729 - val_loss: 0.8544 - val_acc: 0.6644\n",
      "Epoch 294/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7306 - acc: 0.6721 - val_loss: 0.8519 - val_acc: 0.6654\n",
      "Epoch 295/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7332 - acc: 0.6714 - val_loss: 0.8500 - val_acc: 0.6675\n",
      "Epoch 296/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7280 - acc: 0.6726 - val_loss: 0.8491 - val_acc: 0.6655\n",
      "Epoch 297/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7306 - acc: 0.6731 - val_loss: 0.8443 - val_acc: 0.6655\n",
      "Epoch 298/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7279 - acc: 0.6739 - val_loss: 0.8528 - val_acc: 0.6651\n",
      "Epoch 299/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7306 - acc: 0.6736 - val_loss: 0.8507 - val_acc: 0.6669\n",
      "Epoch 300/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7281 - acc: 0.6740 - val_loss: 0.8489 - val_acc: 0.6680\n",
      "Epoch 301/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.7249 - acc: 0.6760 - val_loss: 0.8518 - val_acc: 0.6659\n",
      "Epoch 302/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7259 - acc: 0.6737 - val_loss: 0.8532 - val_acc: 0.6686\n",
      "Epoch 303/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7275 - acc: 0.6742 - val_loss: 0.8448 - val_acc: 0.6689\n",
      "Epoch 304/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7274 - acc: 0.6740 - val_loss: 0.8465 - val_acc: 0.6654\n",
      "Epoch 305/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7298 - acc: 0.6737 - val_loss: 0.8448 - val_acc: 0.6697\n",
      "Epoch 306/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7243 - acc: 0.6752 - val_loss: 0.8521 - val_acc: 0.6673\n",
      "Epoch 307/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7207 - acc: 0.6767 - val_loss: 0.8522 - val_acc: 0.6676\n",
      "Epoch 308/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.7274 - acc: 0.6743 - val_loss: 0.8589 - val_acc: 0.6676\n",
      "Epoch 309/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7249 - acc: 0.6754 - val_loss: 0.8451 - val_acc: 0.6701\n",
      "Epoch 310/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7253 - acc: 0.6760 - val_loss: 0.8484 - val_acc: 0.6672\n",
      "Epoch 311/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7242 - acc: 0.6765 - val_loss: 0.8466 - val_acc: 0.6681\n",
      "Epoch 312/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7207 - acc: 0.6775 - val_loss: 0.8467 - val_acc: 0.6695\n",
      "Epoch 313/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7212 - acc: 0.6767 - val_loss: 0.8474 - val_acc: 0.6678\n",
      "Epoch 314/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7209 - acc: 0.6773 - val_loss: 0.8437 - val_acc: 0.6693\n",
      "Epoch 315/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7221 - acc: 0.6770 - val_loss: 0.8496 - val_acc: 0.6699\n",
      "Epoch 316/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7225 - acc: 0.6774 - val_loss: 0.8476 - val_acc: 0.6708\n",
      "Epoch 317/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7227 - acc: 0.6772 - val_loss: 0.8447 - val_acc: 0.6720\n",
      "Epoch 318/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7196 - acc: 0.6771 - val_loss: 0.8484 - val_acc: 0.6692\n",
      "Epoch 319/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7204 - acc: 0.6783 - val_loss: 0.8413 - val_acc: 0.6709\n",
      "Epoch 320/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7234 - acc: 0.6770 - val_loss: 0.8471 - val_acc: 0.6684\n",
      "Epoch 321/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7199 - acc: 0.6775 - val_loss: 0.8445 - val_acc: 0.6719\n",
      "Epoch 322/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7200 - acc: 0.6782 - val_loss: 0.8509 - val_acc: 0.6701\n",
      "Epoch 323/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7204 - acc: 0.6783 - val_loss: 0.8439 - val_acc: 0.6700\n",
      "Epoch 324/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7182 - acc: 0.6784 - val_loss: 0.8383 - val_acc: 0.6723\n",
      "Epoch 325/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7186 - acc: 0.6782 - val_loss: 0.8525 - val_acc: 0.6699\n",
      "Epoch 326/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.7198 - acc: 0.6782 - val_loss: 0.8458 - val_acc: 0.6697\n",
      "Epoch 327/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7176 - acc: 0.6785 - val_loss: 0.8453 - val_acc: 0.6699\n",
      "Epoch 328/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7164 - acc: 0.6790 - val_loss: 0.8488 - val_acc: 0.6683\n",
      "Epoch 329/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7158 - acc: 0.6802 - val_loss: 0.8459 - val_acc: 0.6710\n",
      "Epoch 330/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7180 - acc: 0.6801 - val_loss: 0.8376 - val_acc: 0.6715\n",
      "Epoch 331/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7163 - acc: 0.6795 - val_loss: 0.8472 - val_acc: 0.6721\n",
      "Epoch 332/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.7170 - acc: 0.6794 - val_loss: 0.8414 - val_acc: 0.6723\n",
      "Epoch 333/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7149 - acc: 0.6797 - val_loss: 0.8527 - val_acc: 0.6726\n",
      "Epoch 334/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7163 - acc: 0.6798 - val_loss: 0.8413 - val_acc: 0.6722\n",
      "Epoch 335/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.7161 - acc: 0.6807 - val_loss: 0.8428 - val_acc: 0.6699\n",
      "Epoch 336/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7123 - acc: 0.6804 - val_loss: 0.8421 - val_acc: 0.6715\n",
      "Epoch 337/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7147 - acc: 0.6808 - val_loss: 0.8442 - val_acc: 0.6722\n",
      "Epoch 338/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7144 - acc: 0.6806 - val_loss: 0.8380 - val_acc: 0.6733\n",
      "Epoch 339/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7149 - acc: 0.6799 - val_loss: 0.8433 - val_acc: 0.6705\n",
      "Epoch 340/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7133 - acc: 0.6810 - val_loss: 0.8440 - val_acc: 0.6705\n",
      "Epoch 341/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7141 - acc: 0.6819 - val_loss: 0.8409 - val_acc: 0.6731\n",
      "Epoch 342/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.7117 - acc: 0.6819 - val_loss: 0.8444 - val_acc: 0.6700\n",
      "Epoch 343/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7110 - acc: 0.6812 - val_loss: 0.8405 - val_acc: 0.6718\n",
      "Epoch 344/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7128 - acc: 0.6817 - val_loss: 0.8375 - val_acc: 0.6732\n",
      "Epoch 345/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7122 - acc: 0.6806 - val_loss: 0.8397 - val_acc: 0.6714\n",
      "Epoch 346/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7110 - acc: 0.6823 - val_loss: 0.8368 - val_acc: 0.6754\n",
      "Epoch 347/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7123 - acc: 0.6808 - val_loss: 0.8424 - val_acc: 0.6727\n",
      "Epoch 348/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7103 - acc: 0.6833 - val_loss: 0.8395 - val_acc: 0.6747\n",
      "Epoch 349/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7104 - acc: 0.6833 - val_loss: 0.8334 - val_acc: 0.6772\n",
      "Epoch 350/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7091 - acc: 0.6831 - val_loss: 0.8363 - val_acc: 0.6759\n",
      "Epoch 351/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7090 - acc: 0.6836 - val_loss: 0.8392 - val_acc: 0.6736\n",
      "Epoch 352/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7088 - acc: 0.6838 - val_loss: 0.8445 - val_acc: 0.6736\n",
      "Epoch 353/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7088 - acc: 0.6841 - val_loss: 0.8382 - val_acc: 0.6735\n",
      "Epoch 354/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7103 - acc: 0.6827 - val_loss: 0.8406 - val_acc: 0.6759\n",
      "Epoch 355/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7099 - acc: 0.6836 - val_loss: 0.8431 - val_acc: 0.6766\n",
      "Epoch 356/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7073 - acc: 0.6835 - val_loss: 0.8370 - val_acc: 0.6744\n",
      "Epoch 357/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.7071 - acc: 0.6840 - val_loss: 0.8373 - val_acc: 0.6758\n",
      "Epoch 358/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7077 - acc: 0.6832 - val_loss: 0.8351 - val_acc: 0.6754\n",
      "Epoch 359/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7061 - acc: 0.6841 - val_loss: 0.8389 - val_acc: 0.6736\n",
      "Epoch 360/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7118 - acc: 0.6827 - val_loss: 0.8402 - val_acc: 0.6734\n",
      "Epoch 361/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7055 - acc: 0.6850 - val_loss: 0.8426 - val_acc: 0.6751\n",
      "Epoch 362/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7075 - acc: 0.6851 - val_loss: 0.8335 - val_acc: 0.6778\n",
      "Epoch 363/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7046 - acc: 0.6856 - val_loss: 0.8362 - val_acc: 0.6772\n",
      "Epoch 364/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7033 - acc: 0.6865 - val_loss: 0.8413 - val_acc: 0.6757\n",
      "Epoch 365/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7071 - acc: 0.6847 - val_loss: 0.8392 - val_acc: 0.6772\n",
      "Epoch 366/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.7040 - acc: 0.6855 - val_loss: 0.8420 - val_acc: 0.6775\n",
      "Epoch 367/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7056 - acc: 0.6852 - val_loss: 0.8385 - val_acc: 0.6758\n",
      "Epoch 368/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7031 - acc: 0.6864 - val_loss: 0.8387 - val_acc: 0.6757\n",
      "Epoch 369/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7020 - acc: 0.6871 - val_loss: 0.8373 - val_acc: 0.6774\n",
      "Epoch 370/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7041 - acc: 0.6849 - val_loss: 0.8396 - val_acc: 0.6740\n",
      "Epoch 371/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7015 - acc: 0.6864 - val_loss: 0.8461 - val_acc: 0.6757\n",
      "Epoch 372/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7050 - acc: 0.6848 - val_loss: 0.8376 - val_acc: 0.6768\n",
      "Epoch 373/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7021 - acc: 0.6865 - val_loss: 0.8419 - val_acc: 0.6757\n",
      "Epoch 374/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7028 - acc: 0.6866 - val_loss: 0.8363 - val_acc: 0.6802\n",
      "Epoch 375/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7043 - acc: 0.6857 - val_loss: 0.8351 - val_acc: 0.6787\n",
      "Epoch 376/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7024 - acc: 0.6865 - val_loss: 0.8414 - val_acc: 0.6749\n",
      "Epoch 377/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7008 - acc: 0.6877 - val_loss: 0.8418 - val_acc: 0.6774\n",
      "Epoch 378/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.7017 - acc: 0.6869 - val_loss: 0.8358 - val_acc: 0.6771\n",
      "Epoch 379/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7005 - acc: 0.6879 - val_loss: 0.8418 - val_acc: 0.6750\n",
      "Epoch 380/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.7010 - acc: 0.6876 - val_loss: 0.8400 - val_acc: 0.6781\n",
      "Epoch 381/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6996 - acc: 0.6889 - val_loss: 0.8442 - val_acc: 0.6800\n",
      "Epoch 382/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6974 - acc: 0.6890 - val_loss: 0.8397 - val_acc: 0.6787\n",
      "Epoch 383/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7009 - acc: 0.6874 - val_loss: 0.8403 - val_acc: 0.6776\n",
      "Epoch 384/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6967 - acc: 0.6895 - val_loss: 0.8386 - val_acc: 0.6761\n",
      "Epoch 385/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6998 - acc: 0.6879 - val_loss: 0.8452 - val_acc: 0.6792\n",
      "Epoch 386/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7009 - acc: 0.6881 - val_loss: 0.8383 - val_acc: 0.6764\n",
      "Epoch 387/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.6965 - acc: 0.6897 - val_loss: 0.8420 - val_acc: 0.6783\n",
      "Epoch 388/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6978 - acc: 0.6882 - val_loss: 0.8367 - val_acc: 0.6784\n",
      "Epoch 389/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6975 - acc: 0.6883 - val_loss: 0.8415 - val_acc: 0.6799\n",
      "Epoch 390/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6964 - acc: 0.6896 - val_loss: 0.8433 - val_acc: 0.6762\n",
      "Epoch 391/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6973 - acc: 0.6893 - val_loss: 0.8368 - val_acc: 0.6774\n",
      "Epoch 392/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6989 - acc: 0.6894 - val_loss: 0.8391 - val_acc: 0.6751\n",
      "Epoch 393/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.6964 - acc: 0.6894 - val_loss: 0.8373 - val_acc: 0.6782\n",
      "Epoch 394/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6947 - acc: 0.6902 - val_loss: 0.8444 - val_acc: 0.6780\n",
      "Epoch 395/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6937 - acc: 0.6912 - val_loss: 0.8324 - val_acc: 0.6776\n",
      "Epoch 396/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6959 - acc: 0.6902 - val_loss: 0.8314 - val_acc: 0.6809\n",
      "Epoch 397/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6925 - acc: 0.6917 - val_loss: 0.8297 - val_acc: 0.6779\n",
      "Epoch 398/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6989 - acc: 0.6890 - val_loss: 0.8329 - val_acc: 0.6781\n",
      "Epoch 399/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6930 - acc: 0.6905 - val_loss: 0.8431 - val_acc: 0.6776\n",
      "Epoch 400/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6938 - acc: 0.6905 - val_loss: 0.8376 - val_acc: 0.6781\n",
      "Epoch 401/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6928 - acc: 0.6915 - val_loss: 0.8388 - val_acc: 0.6763\n",
      "Epoch 402/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6951 - acc: 0.6909 - val_loss: 0.8346 - val_acc: 0.6803\n",
      "Epoch 403/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6957 - acc: 0.6904 - val_loss: 0.8315 - val_acc: 0.6777\n",
      "Epoch 404/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6916 - acc: 0.6925 - val_loss: 0.8339 - val_acc: 0.6770\n",
      "Epoch 405/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6932 - acc: 0.6914 - val_loss: 0.8346 - val_acc: 0.6800\n",
      "Epoch 406/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6920 - acc: 0.6921 - val_loss: 0.8339 - val_acc: 0.6779\n",
      "Epoch 407/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6955 - acc: 0.6898 - val_loss: 0.8319 - val_acc: 0.6809\n",
      "Epoch 408/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6915 - acc: 0.6926 - val_loss: 0.8296 - val_acc: 0.6795\n",
      "Epoch 409/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6943 - acc: 0.6913 - val_loss: 0.8366 - val_acc: 0.6789\n",
      "Epoch 410/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6893 - acc: 0.6927 - val_loss: 0.8398 - val_acc: 0.6795\n",
      "Epoch 411/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6938 - acc: 0.6916 - val_loss: 0.8317 - val_acc: 0.6787\n",
      "Epoch 412/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6916 - acc: 0.6911 - val_loss: 0.8399 - val_acc: 0.6781\n",
      "Epoch 413/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.6909 - acc: 0.6925 - val_loss: 0.8374 - val_acc: 0.6792\n",
      "Epoch 414/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6897 - acc: 0.6932 - val_loss: 0.8305 - val_acc: 0.6804\n",
      "Epoch 415/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6890 - acc: 0.6928 - val_loss: 0.8371 - val_acc: 0.6822\n",
      "Epoch 416/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6898 - acc: 0.6932 - val_loss: 0.8377 - val_acc: 0.6818\n",
      "Epoch 417/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6889 - acc: 0.6937 - val_loss: 0.8394 - val_acc: 0.6809\n",
      "Epoch 418/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6908 - acc: 0.6932 - val_loss: 0.8401 - val_acc: 0.6781\n",
      "Epoch 419/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6902 - acc: 0.6930 - val_loss: 0.8418 - val_acc: 0.6821\n",
      "Epoch 420/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6927 - acc: 0.6924 - val_loss: 0.8288 - val_acc: 0.6817\n",
      "Epoch 421/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6900 - acc: 0.6926 - val_loss: 0.8282 - val_acc: 0.6829\n",
      "Epoch 422/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6895 - acc: 0.6933 - val_loss: 0.8334 - val_acc: 0.6817\n",
      "Epoch 423/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6889 - acc: 0.6929 - val_loss: 0.8419 - val_acc: 0.6792\n",
      "Epoch 424/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6862 - acc: 0.6945 - val_loss: 0.8321 - val_acc: 0.6776\n",
      "Epoch 425/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6891 - acc: 0.6932 - val_loss: 0.8335 - val_acc: 0.6834\n",
      "Epoch 426/1000\n",
      "212747/212747 [==============================] - 7s 33us/step - loss: 0.6875 - acc: 0.6939 - val_loss: 0.8357 - val_acc: 0.6801\n",
      "Epoch 427/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6853 - acc: 0.6949 - val_loss: 0.8353 - val_acc: 0.6813\n",
      "Epoch 428/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6876 - acc: 0.6940 - val_loss: 0.8366 - val_acc: 0.6846\n",
      "Epoch 429/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6927 - acc: 0.6912 - val_loss: 0.8293 - val_acc: 0.6824\n",
      "Epoch 430/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6871 - acc: 0.6955 - val_loss: 0.8342 - val_acc: 0.6813\n",
      "Epoch 431/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6863 - acc: 0.6951 - val_loss: 0.8387 - val_acc: 0.6826\n",
      "Epoch 432/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6881 - acc: 0.6930 - val_loss: 0.8383 - val_acc: 0.6809\n",
      "Epoch 433/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6870 - acc: 0.6959 - val_loss: 0.8398 - val_acc: 0.6816\n",
      "Epoch 434/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6863 - acc: 0.6946 - val_loss: 0.8257 - val_acc: 0.6833\n",
      "Epoch 435/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6865 - acc: 0.6953 - val_loss: 0.8329 - val_acc: 0.6825\n",
      "Epoch 436/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6853 - acc: 0.6951 - val_loss: 0.8428 - val_acc: 0.6831\n",
      "Epoch 437/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6845 - acc: 0.6961 - val_loss: 0.8311 - val_acc: 0.6823\n",
      "Epoch 438/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6853 - acc: 0.6960 - val_loss: 0.8280 - val_acc: 0.6823\n",
      "Epoch 439/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6878 - acc: 0.6950 - val_loss: 0.8333 - val_acc: 0.6812\n",
      "Epoch 440/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6840 - acc: 0.6957 - val_loss: 0.8278 - val_acc: 0.6827\n",
      "Epoch 441/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6837 - acc: 0.6948 - val_loss: 0.8355 - val_acc: 0.6811\n",
      "Epoch 442/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6857 - acc: 0.6952 - val_loss: 0.8321 - val_acc: 0.6783\n",
      "Epoch 443/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6829 - acc: 0.6962 - val_loss: 0.8293 - val_acc: 0.6848\n",
      "Epoch 444/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6863 - acc: 0.6956 - val_loss: 0.8295 - val_acc: 0.6823\n",
      "Epoch 445/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6819 - acc: 0.6967 - val_loss: 0.8275 - val_acc: 0.6824\n",
      "Epoch 446/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6800 - acc: 0.6976 - val_loss: 0.8225 - val_acc: 0.6839\n",
      "Epoch 447/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6808 - acc: 0.6977 - val_loss: 0.8361 - val_acc: 0.6817\n",
      "Epoch 448/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6810 - acc: 0.6973 - val_loss: 0.8285 - val_acc: 0.6843\n",
      "Epoch 449/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6828 - acc: 0.6959 - val_loss: 0.8347 - val_acc: 0.6852\n",
      "Epoch 450/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6811 - acc: 0.6969 - val_loss: 0.8346 - val_acc: 0.6844\n",
      "Epoch 451/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6817 - acc: 0.6963 - val_loss: 0.8319 - val_acc: 0.6842\n",
      "Epoch 452/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6813 - acc: 0.6979 - val_loss: 0.8332 - val_acc: 0.6820\n",
      "Epoch 453/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6819 - acc: 0.6962 - val_loss: 0.8350 - val_acc: 0.6815\n",
      "Epoch 454/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6823 - acc: 0.6967 - val_loss: 0.8260 - val_acc: 0.6855\n",
      "Epoch 455/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6815 - acc: 0.6974 - val_loss: 0.8253 - val_acc: 0.6845\n",
      "Epoch 456/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6805 - acc: 0.6977 - val_loss: 0.8329 - val_acc: 0.6818\n",
      "Epoch 457/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6822 - acc: 0.6970 - val_loss: 0.8234 - val_acc: 0.6859\n",
      "Epoch 458/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6829 - acc: 0.6968 - val_loss: 0.8330 - val_acc: 0.6837\n",
      "Epoch 459/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6785 - acc: 0.6992 - val_loss: 0.8375 - val_acc: 0.6837\n",
      "Epoch 460/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6805 - acc: 0.6977 - val_loss: 0.8257 - val_acc: 0.6842\n",
      "Epoch 461/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6795 - acc: 0.6978 - val_loss: 0.8314 - val_acc: 0.6864\n",
      "Epoch 462/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6794 - acc: 0.6982 - val_loss: 0.8247 - val_acc: 0.6859\n",
      "Epoch 463/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6764 - acc: 0.6995 - val_loss: 0.8290 - val_acc: 0.6858\n",
      "Epoch 464/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6802 - acc: 0.6976 - val_loss: 0.8300 - val_acc: 0.6838\n",
      "Epoch 465/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6772 - acc: 0.6986 - val_loss: 0.8330 - val_acc: 0.6830\n",
      "Epoch 466/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6805 - acc: 0.6981 - val_loss: 0.8283 - val_acc: 0.6849\n",
      "Epoch 467/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6763 - acc: 0.6997 - val_loss: 0.8274 - val_acc: 0.6861\n",
      "Epoch 468/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6792 - acc: 0.6984 - val_loss: 0.8282 - val_acc: 0.6837\n",
      "Epoch 469/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6773 - acc: 0.6984 - val_loss: 0.8293 - val_acc: 0.6855\n",
      "Epoch 470/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6796 - acc: 0.6983 - val_loss: 0.8344 - val_acc: 0.6835\n",
      "Epoch 471/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6783 - acc: 0.6989 - val_loss: 0.8294 - val_acc: 0.6844\n",
      "Epoch 472/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6798 - acc: 0.6992 - val_loss: 0.8230 - val_acc: 0.6858\n",
      "Epoch 473/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6787 - acc: 0.6992 - val_loss: 0.8257 - val_acc: 0.6862\n",
      "Epoch 474/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6796 - acc: 0.6991 - val_loss: 0.8178 - val_acc: 0.6855\n",
      "Epoch 475/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6760 - acc: 0.6994 - val_loss: 0.8293 - val_acc: 0.6869\n",
      "Epoch 476/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6762 - acc: 0.7003 - val_loss: 0.8386 - val_acc: 0.6856\n",
      "Epoch 477/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6794 - acc: 0.6981 - val_loss: 0.8295 - val_acc: 0.6861\n",
      "Epoch 478/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6774 - acc: 0.6996 - val_loss: 0.8270 - val_acc: 0.6876\n",
      "Epoch 479/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6763 - acc: 0.7002 - val_loss: 0.8348 - val_acc: 0.6866\n",
      "Epoch 480/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6716 - acc: 0.7022 - val_loss: 0.8259 - val_acc: 0.6849\n",
      "Epoch 481/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6746 - acc: 0.7004 - val_loss: 0.8232 - val_acc: 0.6858\n",
      "Epoch 482/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6759 - acc: 0.7004 - val_loss: 0.8215 - val_acc: 0.6870\n",
      "Epoch 483/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6748 - acc: 0.7012 - val_loss: 0.8256 - val_acc: 0.6883\n",
      "Epoch 484/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6800 - acc: 0.6985 - val_loss: 0.8239 - val_acc: 0.6862\n",
      "Epoch 485/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6737 - acc: 0.7018 - val_loss: 0.8269 - val_acc: 0.6920\n",
      "Epoch 486/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6704 - acc: 0.7015 - val_loss: 0.8293 - val_acc: 0.6892\n",
      "Epoch 487/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6717 - acc: 0.7022 - val_loss: 0.8256 - val_acc: 0.6895\n",
      "Epoch 488/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6759 - acc: 0.7000 - val_loss: 0.8200 - val_acc: 0.6901\n",
      "Epoch 489/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6753 - acc: 0.7010 - val_loss: 0.8260 - val_acc: 0.6884\n",
      "Epoch 490/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6784 - acc: 0.6999 - val_loss: 0.8230 - val_acc: 0.6880\n",
      "Epoch 491/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6749 - acc: 0.7009 - val_loss: 0.8258 - val_acc: 0.6875\n",
      "Epoch 492/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6745 - acc: 0.7021 - val_loss: 0.8275 - val_acc: 0.6877\n",
      "Epoch 493/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6741 - acc: 0.7006 - val_loss: 0.8330 - val_acc: 0.6839\n",
      "Epoch 494/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6734 - acc: 0.7010 - val_loss: 0.8263 - val_acc: 0.6867\n",
      "Epoch 495/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6729 - acc: 0.7015 - val_loss: 0.8255 - val_acc: 0.6888\n",
      "Epoch 496/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6725 - acc: 0.7018 - val_loss: 0.8260 - val_acc: 0.6882\n",
      "Epoch 497/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6734 - acc: 0.7019 - val_loss: 0.8245 - val_acc: 0.6892\n",
      "Epoch 498/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6735 - acc: 0.7010 - val_loss: 0.8238 - val_acc: 0.6872\n",
      "Epoch 499/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6715 - acc: 0.7016 - val_loss: 0.8275 - val_acc: 0.6894\n",
      "Epoch 500/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6720 - acc: 0.7015 - val_loss: 0.8292 - val_acc: 0.6873\n",
      "Epoch 501/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6718 - acc: 0.7013 - val_loss: 0.8275 - val_acc: 0.6855\n",
      "Epoch 502/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6722 - acc: 0.7021 - val_loss: 0.8199 - val_acc: 0.6878\n",
      "Epoch 503/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6702 - acc: 0.7022 - val_loss: 0.8344 - val_acc: 0.6870\n",
      "Epoch 504/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6705 - acc: 0.7027 - val_loss: 0.8305 - val_acc: 0.6858\n",
      "Epoch 505/1000\n",
      "212747/212747 [==============================] - 9s 40us/step - loss: 0.6682 - acc: 0.7038 - val_loss: 0.8222 - val_acc: 0.6877\n",
      "Epoch 506/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6701 - acc: 0.7028 - val_loss: 0.8337 - val_acc: 0.6886\n",
      "Epoch 507/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6695 - acc: 0.7033 - val_loss: 0.8277 - val_acc: 0.6884\n",
      "Epoch 508/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6694 - acc: 0.7028 - val_loss: 0.8233 - val_acc: 0.6879\n",
      "Epoch 509/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6689 - acc: 0.7029 - val_loss: 0.8291 - val_acc: 0.6875\n",
      "Epoch 510/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6714 - acc: 0.7026 - val_loss: 0.8273 - val_acc: 0.6872\n",
      "Epoch 511/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6686 - acc: 0.7043 - val_loss: 0.8333 - val_acc: 0.6883\n",
      "Epoch 512/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6689 - acc: 0.7042 - val_loss: 0.8228 - val_acc: 0.6873\n",
      "Epoch 513/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6734 - acc: 0.7012 - val_loss: 0.8240 - val_acc: 0.6874\n",
      "Epoch 514/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6703 - acc: 0.7035 - val_loss: 0.8220 - val_acc: 0.6883\n",
      "Epoch 515/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6692 - acc: 0.7024 - val_loss: 0.8229 - val_acc: 0.6871\n",
      "Epoch 516/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6657 - acc: 0.7038 - val_loss: 0.8271 - val_acc: 0.6911\n",
      "Epoch 517/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6672 - acc: 0.7044 - val_loss: 0.8253 - val_acc: 0.6905\n",
      "Epoch 518/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6695 - acc: 0.7036 - val_loss: 0.8280 - val_acc: 0.6895\n",
      "Epoch 519/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6676 - acc: 0.7041 - val_loss: 0.8249 - val_acc: 0.6887\n",
      "Epoch 520/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6718 - acc: 0.7037 - val_loss: 0.8227 - val_acc: 0.6877\n",
      "Epoch 521/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6703 - acc: 0.7024 - val_loss: 0.8278 - val_acc: 0.6862\n",
      "Epoch 522/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6668 - acc: 0.7057 - val_loss: 0.8201 - val_acc: 0.6894\n",
      "Epoch 523/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6682 - acc: 0.7042 - val_loss: 0.8224 - val_acc: 0.6895\n",
      "Epoch 524/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6700 - acc: 0.7038 - val_loss: 0.8241 - val_acc: 0.6903\n",
      "Epoch 525/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6678 - acc: 0.7034 - val_loss: 0.8227 - val_acc: 0.6886\n",
      "Epoch 526/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6671 - acc: 0.7042 - val_loss: 0.8296 - val_acc: 0.6899\n",
      "Epoch 527/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6697 - acc: 0.7036 - val_loss: 0.8195 - val_acc: 0.6894\n",
      "Epoch 528/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6705 - acc: 0.7034 - val_loss: 0.8238 - val_acc: 0.6885\n",
      "Epoch 529/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6687 - acc: 0.7032 - val_loss: 0.8290 - val_acc: 0.6863\n",
      "Epoch 530/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6664 - acc: 0.7040 - val_loss: 0.8255 - val_acc: 0.6918\n",
      "Epoch 531/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6709 - acc: 0.7033 - val_loss: 0.8175 - val_acc: 0.6912\n",
      "Epoch 532/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6690 - acc: 0.7034 - val_loss: 0.8181 - val_acc: 0.6912\n",
      "Epoch 533/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6660 - acc: 0.7042 - val_loss: 0.8214 - val_acc: 0.6891\n",
      "Epoch 534/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6653 - acc: 0.7050 - val_loss: 0.8221 - val_acc: 0.6901\n",
      "Epoch 535/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6659 - acc: 0.7052 - val_loss: 0.8177 - val_acc: 0.6885\n",
      "Epoch 536/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6677 - acc: 0.7030 - val_loss: 0.8228 - val_acc: 0.6904\n",
      "Epoch 537/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6632 - acc: 0.7063 - val_loss: 0.8231 - val_acc: 0.6914\n",
      "Epoch 538/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6663 - acc: 0.7063 - val_loss: 0.8265 - val_acc: 0.6905\n",
      "Epoch 539/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6644 - acc: 0.7069 - val_loss: 0.8239 - val_acc: 0.6907\n",
      "Epoch 540/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6640 - acc: 0.7053 - val_loss: 0.8194 - val_acc: 0.6905\n",
      "Epoch 541/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6679 - acc: 0.7037 - val_loss: 0.8196 - val_acc: 0.6897\n",
      "Epoch 542/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6628 - acc: 0.7062 - val_loss: 0.8123 - val_acc: 0.6909\n",
      "Epoch 543/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6671 - acc: 0.7047 - val_loss: 0.8232 - val_acc: 0.6907\n",
      "Epoch 544/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6640 - acc: 0.7059 - val_loss: 0.8198 - val_acc: 0.6906\n",
      "Epoch 545/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6637 - acc: 0.7077 - val_loss: 0.8206 - val_acc: 0.6948\n",
      "Epoch 546/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6665 - acc: 0.7047 - val_loss: 0.8164 - val_acc: 0.6929\n",
      "Epoch 547/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6636 - acc: 0.7061 - val_loss: 0.8179 - val_acc: 0.6889\n",
      "Epoch 548/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6623 - acc: 0.7076 - val_loss: 0.8210 - val_acc: 0.6894\n",
      "Epoch 549/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6639 - acc: 0.7070 - val_loss: 0.8223 - val_acc: 0.6918\n",
      "Epoch 550/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6643 - acc: 0.7069 - val_loss: 0.8158 - val_acc: 0.6889\n",
      "Epoch 551/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6649 - acc: 0.7061 - val_loss: 0.8198 - val_acc: 0.6917\n",
      "Epoch 552/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6611 - acc: 0.7063 - val_loss: 0.8258 - val_acc: 0.6916\n",
      "Epoch 553/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6617 - acc: 0.7079 - val_loss: 0.8240 - val_acc: 0.6935\n",
      "Epoch 554/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6632 - acc: 0.7071 - val_loss: 0.8202 - val_acc: 0.6916\n",
      "Epoch 555/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6679 - acc: 0.7056 - val_loss: 0.8164 - val_acc: 0.6881\n",
      "Epoch 556/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6610 - acc: 0.7077 - val_loss: 0.8226 - val_acc: 0.6921\n",
      "Epoch 557/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6600 - acc: 0.7077 - val_loss: 0.8207 - val_acc: 0.6895\n",
      "Epoch 558/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6637 - acc: 0.7063 - val_loss: 0.8283 - val_acc: 0.6902\n",
      "Epoch 559/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6637 - acc: 0.7068 - val_loss: 0.8224 - val_acc: 0.6904\n",
      "Epoch 560/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6661 - acc: 0.7069 - val_loss: 0.8194 - val_acc: 0.6923\n",
      "Epoch 561/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6624 - acc: 0.7057 - val_loss: 0.8299 - val_acc: 0.6929\n",
      "Epoch 562/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6623 - acc: 0.7066 - val_loss: 0.8203 - val_acc: 0.6948\n",
      "Epoch 563/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6615 - acc: 0.7072 - val_loss: 0.8221 - val_acc: 0.6948\n",
      "Epoch 564/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6595 - acc: 0.7078 - val_loss: 0.8146 - val_acc: 0.6938\n",
      "Epoch 565/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6630 - acc: 0.7073 - val_loss: 0.8201 - val_acc: 0.6925\n",
      "Epoch 566/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6606 - acc: 0.7087 - val_loss: 0.8156 - val_acc: 0.6945\n",
      "Epoch 567/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6609 - acc: 0.7084 - val_loss: 0.8113 - val_acc: 0.6929\n",
      "Epoch 568/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6600 - acc: 0.7079 - val_loss: 0.8187 - val_acc: 0.6940\n",
      "Epoch 569/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6643 - acc: 0.7073 - val_loss: 0.8229 - val_acc: 0.6941\n",
      "Epoch 570/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6598 - acc: 0.7073 - val_loss: 0.8215 - val_acc: 0.6941\n",
      "Epoch 571/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6621 - acc: 0.7076 - val_loss: 0.8182 - val_acc: 0.6947\n",
      "Epoch 572/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6611 - acc: 0.7084 - val_loss: 0.8201 - val_acc: 0.6941\n",
      "Epoch 573/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6593 - acc: 0.7075 - val_loss: 0.8147 - val_acc: 0.6943\n",
      "Epoch 574/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6593 - acc: 0.7086 - val_loss: 0.8148 - val_acc: 0.6912\n",
      "Epoch 575/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6611 - acc: 0.7089 - val_loss: 0.8131 - val_acc: 0.6947\n",
      "Epoch 576/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6588 - acc: 0.7088 - val_loss: 0.8156 - val_acc: 0.6934\n",
      "Epoch 577/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6587 - acc: 0.7084 - val_loss: 0.8205 - val_acc: 0.6948\n",
      "Epoch 578/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6622 - acc: 0.7075 - val_loss: 0.8262 - val_acc: 0.6913\n",
      "Epoch 579/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6583 - acc: 0.7089 - val_loss: 0.8112 - val_acc: 0.6931\n",
      "Epoch 580/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6604 - acc: 0.7086 - val_loss: 0.8175 - val_acc: 0.6921\n",
      "Epoch 581/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6568 - acc: 0.7104 - val_loss: 0.8219 - val_acc: 0.6925\n",
      "Epoch 582/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6568 - acc: 0.7095 - val_loss: 0.8348 - val_acc: 0.6941\n",
      "Epoch 583/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6594 - acc: 0.7094 - val_loss: 0.8207 - val_acc: 0.6922\n",
      "Epoch 584/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6605 - acc: 0.7082 - val_loss: 0.8213 - val_acc: 0.6933\n",
      "Epoch 585/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6569 - acc: 0.7092 - val_loss: 0.8179 - val_acc: 0.6945\n",
      "Epoch 586/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6592 - acc: 0.7093 - val_loss: 0.8106 - val_acc: 0.6936\n",
      "Epoch 587/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6566 - acc: 0.7097 - val_loss: 0.8255 - val_acc: 0.6935\n",
      "Epoch 588/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6600 - acc: 0.7079 - val_loss: 0.8174 - val_acc: 0.6936\n",
      "Epoch 589/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6570 - acc: 0.7093 - val_loss: 0.8208 - val_acc: 0.6968\n",
      "Epoch 590/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6588 - acc: 0.7081 - val_loss: 0.8201 - val_acc: 0.6938\n",
      "Epoch 591/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6586 - acc: 0.7095 - val_loss: 0.8194 - val_acc: 0.6914\n",
      "Epoch 592/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6583 - acc: 0.7092 - val_loss: 0.8171 - val_acc: 0.6918\n",
      "Epoch 593/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6578 - acc: 0.7095 - val_loss: 0.8138 - val_acc: 0.6937\n",
      "Epoch 594/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6560 - acc: 0.7098 - val_loss: 0.8174 - val_acc: 0.6938\n",
      "Epoch 595/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6573 - acc: 0.7081 - val_loss: 0.8172 - val_acc: 0.6942\n",
      "Epoch 596/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6573 - acc: 0.7101 - val_loss: 0.8178 - val_acc: 0.6928\n",
      "Epoch 597/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6576 - acc: 0.7102 - val_loss: 0.8201 - val_acc: 0.6935\n",
      "Epoch 598/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6590 - acc: 0.7090 - val_loss: 0.8198 - val_acc: 0.6947\n",
      "Epoch 599/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6559 - acc: 0.7104 - val_loss: 0.8161 - val_acc: 0.6932\n",
      "Epoch 600/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6581 - acc: 0.7095 - val_loss: 0.8193 - val_acc: 0.6927\n",
      "Epoch 601/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6545 - acc: 0.7100 - val_loss: 0.8218 - val_acc: 0.6922\n",
      "Epoch 602/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6572 - acc: 0.7087 - val_loss: 0.8175 - val_acc: 0.6960\n",
      "Epoch 603/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6557 - acc: 0.7102 - val_loss: 0.8130 - val_acc: 0.6916\n",
      "Epoch 604/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6557 - acc: 0.7094 - val_loss: 0.8143 - val_acc: 0.6952\n",
      "Epoch 605/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6561 - acc: 0.7109 - val_loss: 0.8157 - val_acc: 0.6930\n",
      "Epoch 606/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6570 - acc: 0.7102 - val_loss: 0.8174 - val_acc: 0.6946\n",
      "Epoch 607/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6555 - acc: 0.7116 - val_loss: 0.8167 - val_acc: 0.6951\n",
      "Epoch 608/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6550 - acc: 0.7112 - val_loss: 0.8143 - val_acc: 0.6965\n",
      "Epoch 609/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6558 - acc: 0.7106 - val_loss: 0.8104 - val_acc: 0.6957\n",
      "Epoch 610/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6527 - acc: 0.7118 - val_loss: 0.8151 - val_acc: 0.6948\n",
      "Epoch 611/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6538 - acc: 0.7120 - val_loss: 0.8130 - val_acc: 0.6933\n",
      "Epoch 612/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6554 - acc: 0.7102 - val_loss: 0.8180 - val_acc: 0.6951\n",
      "Epoch 613/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6546 - acc: 0.7102 - val_loss: 0.8153 - val_acc: 0.6918\n",
      "Epoch 614/1000\n",
      "212747/212747 [==============================] - 9s 40us/step - loss: 0.6555 - acc: 0.7105 - val_loss: 0.8158 - val_acc: 0.6929\n",
      "Epoch 615/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6539 - acc: 0.7103 - val_loss: 0.8166 - val_acc: 0.6912\n",
      "Epoch 616/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6521 - acc: 0.7120 - val_loss: 0.8173 - val_acc: 0.6960\n",
      "Epoch 617/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6542 - acc: 0.7103 - val_loss: 0.8095 - val_acc: 0.6947\n",
      "Epoch 618/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6542 - acc: 0.7103 - val_loss: 0.8194 - val_acc: 0.6974\n",
      "Epoch 619/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6517 - acc: 0.7109 - val_loss: 0.8171 - val_acc: 0.6967\n",
      "Epoch 620/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6513 - acc: 0.7120 - val_loss: 0.8256 - val_acc: 0.6968\n",
      "Epoch 621/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6506 - acc: 0.7123 - val_loss: 0.8140 - val_acc: 0.6953\n",
      "Epoch 622/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6521 - acc: 0.7113 - val_loss: 0.8137 - val_acc: 0.6919\n",
      "Epoch 623/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6541 - acc: 0.7103 - val_loss: 0.8174 - val_acc: 0.6945\n",
      "Epoch 624/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6516 - acc: 0.7117 - val_loss: 0.8173 - val_acc: 0.6976\n",
      "Epoch 625/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6577 - acc: 0.7097 - val_loss: 0.8168 - val_acc: 0.6941\n",
      "Epoch 626/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6519 - acc: 0.7122 - val_loss: 0.8170 - val_acc: 0.6925\n",
      "Epoch 627/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6551 - acc: 0.7110 - val_loss: 0.8148 - val_acc: 0.6946\n",
      "Epoch 628/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6523 - acc: 0.7119 - val_loss: 0.8213 - val_acc: 0.6962\n",
      "Epoch 629/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6550 - acc: 0.7119 - val_loss: 0.8126 - val_acc: 0.6960\n",
      "Epoch 630/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6540 - acc: 0.7122 - val_loss: 0.8135 - val_acc: 0.6934\n",
      "Epoch 631/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6526 - acc: 0.7122 - val_loss: 0.8143 - val_acc: 0.6984\n",
      "Epoch 632/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6545 - acc: 0.7113 - val_loss: 0.8134 - val_acc: 0.6943\n",
      "Epoch 633/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6524 - acc: 0.7118 - val_loss: 0.8073 - val_acc: 0.6939\n",
      "Epoch 634/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6557 - acc: 0.7124 - val_loss: 0.8167 - val_acc: 0.6979\n",
      "Epoch 635/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6516 - acc: 0.7126 - val_loss: 0.8070 - val_acc: 0.6973\n",
      "Epoch 636/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6521 - acc: 0.7120 - val_loss: 0.8128 - val_acc: 0.6983\n",
      "Epoch 637/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6511 - acc: 0.7132 - val_loss: 0.8100 - val_acc: 0.6957\n",
      "Epoch 638/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6524 - acc: 0.7127 - val_loss: 0.8169 - val_acc: 0.6952\n",
      "Epoch 639/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6515 - acc: 0.7122 - val_loss: 0.8189 - val_acc: 0.6969\n",
      "Epoch 640/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6526 - acc: 0.7115 - val_loss: 0.8149 - val_acc: 0.6944\n",
      "Epoch 641/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6512 - acc: 0.7114 - val_loss: 0.8237 - val_acc: 0.6964\n",
      "Epoch 642/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6530 - acc: 0.7122 - val_loss: 0.8150 - val_acc: 0.6951\n",
      "Epoch 643/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6535 - acc: 0.7118 - val_loss: 0.8139 - val_acc: 0.6953\n",
      "Epoch 644/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6490 - acc: 0.7128 - val_loss: 0.8180 - val_acc: 0.6956\n",
      "Epoch 645/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6509 - acc: 0.7130 - val_loss: 0.8110 - val_acc: 0.6952\n",
      "Epoch 646/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6494 - acc: 0.7132 - val_loss: 0.8167 - val_acc: 0.6961\n",
      "Epoch 647/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6518 - acc: 0.7119 - val_loss: 0.8140 - val_acc: 0.6971\n",
      "Epoch 648/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6506 - acc: 0.7135 - val_loss: 0.8142 - val_acc: 0.6957\n",
      "Epoch 649/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6491 - acc: 0.7136 - val_loss: 0.8166 - val_acc: 0.6965\n",
      "Epoch 650/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6470 - acc: 0.7137 - val_loss: 0.8199 - val_acc: 0.6972\n",
      "Epoch 651/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6511 - acc: 0.7124 - val_loss: 0.8175 - val_acc: 0.6965\n",
      "Epoch 652/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6485 - acc: 0.7139 - val_loss: 0.8052 - val_acc: 0.6988\n",
      "Epoch 653/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6531 - acc: 0.7121 - val_loss: 0.8086 - val_acc: 0.6947\n",
      "Epoch 654/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6473 - acc: 0.7139 - val_loss: 0.8149 - val_acc: 0.6967\n",
      "Epoch 655/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6460 - acc: 0.7157 - val_loss: 0.8099 - val_acc: 0.6954\n",
      "Epoch 656/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6494 - acc: 0.7138 - val_loss: 0.8110 - val_acc: 0.6966\n",
      "Epoch 657/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6501 - acc: 0.7137 - val_loss: 0.8191 - val_acc: 0.6988\n",
      "Epoch 658/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6502 - acc: 0.7124 - val_loss: 0.8101 - val_acc: 0.6950\n",
      "Epoch 659/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6503 - acc: 0.7129 - val_loss: 0.8086 - val_acc: 0.6975\n",
      "Epoch 660/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6498 - acc: 0.7140 - val_loss: 0.8103 - val_acc: 0.6947\n",
      "Epoch 661/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6487 - acc: 0.7136 - val_loss: 0.8095 - val_acc: 0.6969\n",
      "Epoch 662/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6484 - acc: 0.7154 - val_loss: 0.8184 - val_acc: 0.6958\n",
      "Epoch 663/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6452 - acc: 0.7147 - val_loss: 0.8055 - val_acc: 0.6988\n",
      "Epoch 664/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6477 - acc: 0.7143 - val_loss: 0.8142 - val_acc: 0.6959\n",
      "Epoch 665/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6485 - acc: 0.7145 - val_loss: 0.8114 - val_acc: 0.6971\n",
      "Epoch 666/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6484 - acc: 0.7137 - val_loss: 0.8162 - val_acc: 0.6997\n",
      "Epoch 667/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6429 - acc: 0.7164 - val_loss: 0.8147 - val_acc: 0.6994\n",
      "Epoch 668/1000\n",
      "212747/212747 [==============================] - 7s 33us/step - loss: 0.6513 - acc: 0.7136 - val_loss: 0.8117 - val_acc: 0.6991\n",
      "Epoch 669/1000\n",
      "212747/212747 [==============================] - 7s 33us/step - loss: 0.6549 - acc: 0.7117 - val_loss: 0.8179 - val_acc: 0.6984\n",
      "Epoch 670/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6505 - acc: 0.7134 - val_loss: 0.8080 - val_acc: 0.6956\n",
      "Epoch 671/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6481 - acc: 0.7141 - val_loss: 0.8078 - val_acc: 0.6986\n",
      "Epoch 672/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6453 - acc: 0.7159 - val_loss: 0.8149 - val_acc: 0.6975\n",
      "Epoch 673/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6459 - acc: 0.7150 - val_loss: 0.8188 - val_acc: 0.6980\n",
      "Epoch 674/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6526 - acc: 0.7120 - val_loss: 0.8128 - val_acc: 0.6949\n",
      "Epoch 675/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6496 - acc: 0.7136 - val_loss: 0.8094 - val_acc: 0.6966\n",
      "Epoch 676/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6439 - acc: 0.7163 - val_loss: 0.8059 - val_acc: 0.6981\n",
      "Epoch 677/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6452 - acc: 0.7158 - val_loss: 0.8165 - val_acc: 0.6963\n",
      "Epoch 678/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6470 - acc: 0.7136 - val_loss: 0.8088 - val_acc: 0.6966\n",
      "Epoch 679/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6457 - acc: 0.7149 - val_loss: 0.8159 - val_acc: 0.6974\n",
      "Epoch 680/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6490 - acc: 0.7128 - val_loss: 0.8088 - val_acc: 0.6981\n",
      "Epoch 681/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.6427 - acc: 0.7160 - val_loss: 0.8093 - val_acc: 0.6988\n",
      "Epoch 682/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6468 - acc: 0.7145 - val_loss: 0.8116 - val_acc: 0.6939\n",
      "Epoch 683/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6457 - acc: 0.7148 - val_loss: 0.8093 - val_acc: 0.6974\n",
      "Epoch 684/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6482 - acc: 0.7138 - val_loss: 0.8011 - val_acc: 0.6959\n",
      "Epoch 685/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6453 - acc: 0.7149 - val_loss: 0.8122 - val_acc: 0.7000\n",
      "Epoch 686/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6462 - acc: 0.7150 - val_loss: 0.8147 - val_acc: 0.6933\n",
      "Epoch 687/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6483 - acc: 0.7146 - val_loss: 0.8173 - val_acc: 0.6971\n",
      "Epoch 688/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6468 - acc: 0.7145 - val_loss: 0.8156 - val_acc: 0.6984\n",
      "Epoch 689/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6443 - acc: 0.7163 - val_loss: 0.8066 - val_acc: 0.6998\n",
      "Epoch 690/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6490 - acc: 0.7140 - val_loss: 0.8113 - val_acc: 0.6986\n",
      "Epoch 691/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6435 - acc: 0.7161 - val_loss: 0.8047 - val_acc: 0.6999\n",
      "Epoch 692/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6436 - acc: 0.7160 - val_loss: 0.8081 - val_acc: 0.6995\n",
      "Epoch 693/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6441 - acc: 0.7157 - val_loss: 0.8091 - val_acc: 0.6992\n",
      "Epoch 694/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6436 - acc: 0.7165 - val_loss: 0.8180 - val_acc: 0.6986\n",
      "Epoch 695/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6439 - acc: 0.7154 - val_loss: 0.8127 - val_acc: 0.6992\n",
      "Epoch 696/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6450 - acc: 0.7163 - val_loss: 0.8056 - val_acc: 0.6974\n",
      "Epoch 697/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6457 - acc: 0.7151 - val_loss: 0.8048 - val_acc: 0.7015\n",
      "Epoch 698/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6442 - acc: 0.7158 - val_loss: 0.8055 - val_acc: 0.6980\n",
      "Epoch 699/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6452 - acc: 0.7164 - val_loss: 0.8016 - val_acc: 0.6998\n",
      "Epoch 700/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6418 - acc: 0.7167 - val_loss: 0.8106 - val_acc: 0.6983\n",
      "Epoch 701/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6484 - acc: 0.7153 - val_loss: 0.8062 - val_acc: 0.6985\n",
      "Epoch 702/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6456 - acc: 0.7161 - val_loss: 0.8092 - val_acc: 0.6993\n",
      "Epoch 703/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6441 - acc: 0.7154 - val_loss: 0.8144 - val_acc: 0.6982\n",
      "Epoch 704/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.6461 - acc: 0.7158 - val_loss: 0.8120 - val_acc: 0.6981\n",
      "Epoch 705/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6446 - acc: 0.7160 - val_loss: 0.8031 - val_acc: 0.6995\n",
      "Epoch 706/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6431 - acc: 0.7160 - val_loss: 0.8112 - val_acc: 0.6992\n",
      "Epoch 707/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6401 - acc: 0.7187 - val_loss: 0.8048 - val_acc: 0.6993\n",
      "Epoch 708/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6433 - acc: 0.7167 - val_loss: 0.8108 - val_acc: 0.7002\n",
      "Epoch 709/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6440 - acc: 0.7164 - val_loss: 0.8081 - val_acc: 0.6978\n",
      "Epoch 710/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6478 - acc: 0.7144 - val_loss: 0.8098 - val_acc: 0.6998\n",
      "Epoch 711/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6441 - acc: 0.7160 - val_loss: 0.8075 - val_acc: 0.6994\n",
      "Epoch 712/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6448 - acc: 0.7159 - val_loss: 0.8130 - val_acc: 0.7008\n",
      "Epoch 713/1000\n",
      "212747/212747 [==============================] - 7s 33us/step - loss: 0.6421 - acc: 0.7184 - val_loss: 0.8090 - val_acc: 0.7008\n",
      "Epoch 714/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6423 - acc: 0.7162 - val_loss: 0.8159 - val_acc: 0.6975\n",
      "Epoch 715/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6421 - acc: 0.7165 - val_loss: 0.8056 - val_acc: 0.6993\n",
      "Epoch 716/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6466 - acc: 0.7151 - val_loss: 0.8140 - val_acc: 0.6980\n",
      "Epoch 717/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6578 - acc: 0.7117 - val_loss: 0.8148 - val_acc: 0.6954\n",
      "Epoch 718/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6497 - acc: 0.7140 - val_loss: 0.8065 - val_acc: 0.6973\n",
      "Epoch 719/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6411 - acc: 0.7165 - val_loss: 0.8065 - val_acc: 0.6986\n",
      "Epoch 720/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6395 - acc: 0.7179 - val_loss: 0.8129 - val_acc: 0.7027\n",
      "Epoch 721/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6407 - acc: 0.7170 - val_loss: 0.8094 - val_acc: 0.6996\n",
      "Epoch 722/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6423 - acc: 0.7165 - val_loss: 0.8049 - val_acc: 0.7020\n",
      "Epoch 723/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6397 - acc: 0.7177 - val_loss: 0.8053 - val_acc: 0.7019\n",
      "Epoch 724/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6391 - acc: 0.7172 - val_loss: 0.8051 - val_acc: 0.7001\n",
      "Epoch 725/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6404 - acc: 0.7184 - val_loss: 0.8191 - val_acc: 0.6978\n",
      "Epoch 726/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6410 - acc: 0.7173 - val_loss: 0.8050 - val_acc: 0.6997\n",
      "Epoch 727/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6413 - acc: 0.7175 - val_loss: 0.8069 - val_acc: 0.6989\n",
      "Epoch 728/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6421 - acc: 0.7174 - val_loss: 0.8103 - val_acc: 0.6999\n",
      "Epoch 729/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6423 - acc: 0.7176 - val_loss: 0.8144 - val_acc: 0.6927\n",
      "Epoch 730/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6467 - acc: 0.7155 - val_loss: 0.8013 - val_acc: 0.6991\n",
      "Epoch 731/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6392 - acc: 0.7176 - val_loss: 0.8158 - val_acc: 0.6976\n",
      "Epoch 732/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6400 - acc: 0.7180 - val_loss: 0.8123 - val_acc: 0.7017\n",
      "Epoch 733/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6394 - acc: 0.7181 - val_loss: 0.8106 - val_acc: 0.7024\n",
      "Epoch 734/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6424 - acc: 0.7166 - val_loss: 0.8142 - val_acc: 0.7009\n",
      "Epoch 735/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6419 - acc: 0.7174 - val_loss: 0.8049 - val_acc: 0.6997\n",
      "Epoch 736/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6410 - acc: 0.7168 - val_loss: 0.7965 - val_acc: 0.7008\n",
      "Epoch 737/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6418 - acc: 0.7177 - val_loss: 0.8078 - val_acc: 0.7011\n",
      "Epoch 738/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6397 - acc: 0.7177 - val_loss: 0.8045 - val_acc: 0.7011\n",
      "Epoch 739/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6409 - acc: 0.7177 - val_loss: 0.8096 - val_acc: 0.7006\n",
      "Epoch 740/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6388 - acc: 0.7176 - val_loss: 0.8122 - val_acc: 0.7016\n",
      "Epoch 741/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6398 - acc: 0.7184 - val_loss: 0.8011 - val_acc: 0.7009\n",
      "Epoch 742/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6393 - acc: 0.7188 - val_loss: 0.7994 - val_acc: 0.6995\n",
      "Epoch 743/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6440 - acc: 0.7167 - val_loss: 0.8114 - val_acc: 0.7005\n",
      "Epoch 744/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6408 - acc: 0.7176 - val_loss: 0.8140 - val_acc: 0.7015\n",
      "Epoch 745/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6401 - acc: 0.7184 - val_loss: 0.8109 - val_acc: 0.6996\n",
      "Epoch 746/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6414 - acc: 0.7175 - val_loss: 0.8037 - val_acc: 0.6998\n",
      "Epoch 747/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6413 - acc: 0.7171 - val_loss: 0.8039 - val_acc: 0.7002\n",
      "Epoch 748/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6407 - acc: 0.7172 - val_loss: 0.8116 - val_acc: 0.7018\n",
      "Epoch 749/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6369 - acc: 0.7192 - val_loss: 0.8048 - val_acc: 0.6982\n",
      "Epoch 750/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6404 - acc: 0.7186 - val_loss: 0.8027 - val_acc: 0.7023\n",
      "Epoch 751/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6378 - acc: 0.7189 - val_loss: 0.8150 - val_acc: 0.6990\n",
      "Epoch 752/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6387 - acc: 0.7186 - val_loss: 0.8120 - val_acc: 0.7013\n",
      "Epoch 753/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6385 - acc: 0.7191 - val_loss: 0.8053 - val_acc: 0.6995\n",
      "Epoch 754/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6364 - acc: 0.7203 - val_loss: 0.8078 - val_acc: 0.6997\n",
      "Epoch 755/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6395 - acc: 0.7190 - val_loss: 0.8090 - val_acc: 0.7017\n",
      "Epoch 756/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6370 - acc: 0.7185 - val_loss: 0.8032 - val_acc: 0.7010\n",
      "Epoch 757/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6403 - acc: 0.7177 - val_loss: 0.8178 - val_acc: 0.7008\n",
      "Epoch 758/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6370 - acc: 0.7191 - val_loss: 0.8070 - val_acc: 0.7020\n",
      "Epoch 759/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6381 - acc: 0.7188 - val_loss: 0.8121 - val_acc: 0.7005\n",
      "Epoch 760/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6396 - acc: 0.7181 - val_loss: 0.8090 - val_acc: 0.7031\n",
      "Epoch 761/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6375 - acc: 0.7199 - val_loss: 0.7945 - val_acc: 0.7041\n",
      "Epoch 762/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6361 - acc: 0.7205 - val_loss: 0.8050 - val_acc: 0.7036\n",
      "Epoch 763/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6376 - acc: 0.7190 - val_loss: 0.8078 - val_acc: 0.7026\n",
      "Epoch 764/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6401 - acc: 0.7181 - val_loss: 0.8076 - val_acc: 0.6991\n",
      "Epoch 765/1000\n",
      "212747/212747 [==============================] - 7s 33us/step - loss: 0.6363 - acc: 0.7199 - val_loss: 0.8127 - val_acc: 0.7022\n",
      "Epoch 766/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6388 - acc: 0.7194 - val_loss: 0.8081 - val_acc: 0.7027\n",
      "Epoch 767/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6380 - acc: 0.7194 - val_loss: 0.8134 - val_acc: 0.6972\n",
      "Epoch 768/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6370 - acc: 0.7199 - val_loss: 0.8061 - val_acc: 0.7005\n",
      "Epoch 769/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6361 - acc: 0.7195 - val_loss: 0.8104 - val_acc: 0.7008\n",
      "Epoch 770/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6357 - acc: 0.7202 - val_loss: 0.8036 - val_acc: 0.7013\n",
      "Epoch 771/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6375 - acc: 0.7197 - val_loss: 0.8067 - val_acc: 0.7019\n",
      "Epoch 772/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6373 - acc: 0.7194 - val_loss: 0.8025 - val_acc: 0.7046\n",
      "Epoch 773/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6361 - acc: 0.7199 - val_loss: 0.8067 - val_acc: 0.7006\n",
      "Epoch 774/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6379 - acc: 0.7189 - val_loss: 0.8098 - val_acc: 0.7030\n",
      "Epoch 775/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6369 - acc: 0.7197 - val_loss: 0.8082 - val_acc: 0.7023\n",
      "Epoch 776/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6394 - acc: 0.7193 - val_loss: 0.8050 - val_acc: 0.7032\n",
      "Epoch 777/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6382 - acc: 0.7193 - val_loss: 0.8094 - val_acc: 0.7034\n",
      "Epoch 778/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6325 - acc: 0.7206 - val_loss: 0.8109 - val_acc: 0.7032\n",
      "Epoch 779/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6381 - acc: 0.7191 - val_loss: 0.8008 - val_acc: 0.7010\n",
      "Epoch 780/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6353 - acc: 0.7198 - val_loss: 0.8077 - val_acc: 0.7020\n",
      "Epoch 781/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6340 - acc: 0.7207 - val_loss: 0.8107 - val_acc: 0.7035\n",
      "Epoch 782/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6377 - acc: 0.7197 - val_loss: 0.8037 - val_acc: 0.7019\n",
      "Epoch 783/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6367 - acc: 0.7199 - val_loss: 0.8076 - val_acc: 0.7021\n",
      "Epoch 784/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6352 - acc: 0.7214 - val_loss: 0.8069 - val_acc: 0.6991\n",
      "Epoch 785/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6389 - acc: 0.7202 - val_loss: 0.8031 - val_acc: 0.7036\n",
      "Epoch 786/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6362 - acc: 0.7197 - val_loss: 0.8072 - val_acc: 0.7018\n",
      "Epoch 787/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6376 - acc: 0.7198 - val_loss: 0.8037 - val_acc: 0.7020\n",
      "Epoch 788/1000\n",
      "212747/212747 [==============================] - 7s 33us/step - loss: 0.6361 - acc: 0.7207 - val_loss: 0.8115 - val_acc: 0.7040\n",
      "Epoch 789/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6365 - acc: 0.7196 - val_loss: 0.8099 - val_acc: 0.7032\n",
      "Epoch 790/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6375 - acc: 0.7199 - val_loss: 0.8060 - val_acc: 0.7038\n",
      "Epoch 791/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6403 - acc: 0.7193 - val_loss: 0.8090 - val_acc: 0.7037\n",
      "Epoch 792/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6328 - acc: 0.7202 - val_loss: 0.8049 - val_acc: 0.7041\n",
      "Epoch 793/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6326 - acc: 0.7207 - val_loss: 0.8181 - val_acc: 0.7002\n",
      "Epoch 794/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6383 - acc: 0.7197 - val_loss: 0.8085 - val_acc: 0.7015\n",
      "Epoch 795/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6336 - acc: 0.7211 - val_loss: 0.7980 - val_acc: 0.7013\n",
      "Epoch 796/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6394 - acc: 0.7200 - val_loss: 0.7999 - val_acc: 0.7018\n",
      "Epoch 797/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6362 - acc: 0.7203 - val_loss: 0.8078 - val_acc: 0.7024\n",
      "Epoch 798/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6351 - acc: 0.7214 - val_loss: 0.8105 - val_acc: 0.7030\n",
      "Epoch 799/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6358 - acc: 0.7211 - val_loss: 0.8098 - val_acc: 0.7059\n",
      "Epoch 800/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6401 - acc: 0.7191 - val_loss: 0.7972 - val_acc: 0.7044\n",
      "Epoch 801/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6339 - acc: 0.7213 - val_loss: 0.8042 - val_acc: 0.7024\n",
      "Epoch 802/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6360 - acc: 0.7196 - val_loss: 0.7985 - val_acc: 0.7022\n",
      "Epoch 803/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6332 - acc: 0.7212 - val_loss: 0.8102 - val_acc: 0.7014\n",
      "Epoch 804/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6330 - acc: 0.7215 - val_loss: 0.8152 - val_acc: 0.7034\n",
      "Epoch 805/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6387 - acc: 0.7202 - val_loss: 0.8086 - val_acc: 0.7027\n",
      "Epoch 806/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6331 - acc: 0.7207 - val_loss: 0.8036 - val_acc: 0.7030\n",
      "Epoch 807/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6335 - acc: 0.7211 - val_loss: 0.8057 - val_acc: 0.7032\n",
      "Epoch 808/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6330 - acc: 0.7213 - val_loss: 0.7982 - val_acc: 0.7027\n",
      "Epoch 809/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6325 - acc: 0.7218 - val_loss: 0.8111 - val_acc: 0.7033\n",
      "Epoch 810/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6323 - acc: 0.7229 - val_loss: 0.8088 - val_acc: 0.6997\n",
      "Epoch 811/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6356 - acc: 0.7202 - val_loss: 0.8069 - val_acc: 0.7039\n",
      "Epoch 812/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6419 - acc: 0.7186 - val_loss: 0.8047 - val_acc: 0.7019\n",
      "Epoch 813/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6330 - acc: 0.7211 - val_loss: 0.8125 - val_acc: 0.7040\n",
      "Epoch 814/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6318 - acc: 0.7220 - val_loss: 0.8021 - val_acc: 0.7058\n",
      "Epoch 815/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6268 - acc: 0.7235 - val_loss: 0.8081 - val_acc: 0.7029\n",
      "Epoch 816/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6325 - acc: 0.7222 - val_loss: 0.8116 - val_acc: 0.7020\n",
      "Epoch 817/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6338 - acc: 0.7216 - val_loss: 0.8095 - val_acc: 0.7025\n",
      "Epoch 818/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6364 - acc: 0.7205 - val_loss: 0.8095 - val_acc: 0.7016\n",
      "Epoch 819/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6303 - acc: 0.7221 - val_loss: 0.8170 - val_acc: 0.7009\n",
      "Epoch 820/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6310 - acc: 0.7230 - val_loss: 0.8187 - val_acc: 0.7031\n",
      "Epoch 821/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6310 - acc: 0.7233 - val_loss: 0.8085 - val_acc: 0.7060\n",
      "Epoch 822/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6344 - acc: 0.7217 - val_loss: 0.8144 - val_acc: 0.6966\n",
      "Epoch 823/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6441 - acc: 0.7183 - val_loss: 0.8020 - val_acc: 0.7023\n",
      "Epoch 824/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6349 - acc: 0.7206 - val_loss: 0.8042 - val_acc: 0.7043\n",
      "Epoch 825/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6331 - acc: 0.7226 - val_loss: 0.8018 - val_acc: 0.7050\n",
      "Epoch 826/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6290 - acc: 0.7228 - val_loss: 0.8120 - val_acc: 0.7035\n",
      "Epoch 827/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6291 - acc: 0.7231 - val_loss: 0.8126 - val_acc: 0.7041\n",
      "Epoch 828/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6280 - acc: 0.7228 - val_loss: 0.8065 - val_acc: 0.7035\n",
      "Epoch 829/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6299 - acc: 0.7218 - val_loss: 0.8037 - val_acc: 0.7038\n",
      "Epoch 830/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6334 - acc: 0.7208 - val_loss: 0.8011 - val_acc: 0.7035\n",
      "Epoch 831/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6334 - acc: 0.7218 - val_loss: 0.8077 - val_acc: 0.7039\n",
      "Epoch 832/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6461 - acc: 0.7185 - val_loss: 0.8005 - val_acc: 0.7008\n",
      "Epoch 833/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6354 - acc: 0.7218 - val_loss: 0.8126 - val_acc: 0.7036\n",
      "Epoch 834/1000\n",
      "212747/212747 [==============================] - 7s 33us/step - loss: 0.6345 - acc: 0.7215 - val_loss: 0.8049 - val_acc: 0.7038\n",
      "Epoch 835/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6360 - acc: 0.7222 - val_loss: 0.8126 - val_acc: 0.7017\n",
      "Epoch 836/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6336 - acc: 0.7213 - val_loss: 0.8064 - val_acc: 0.7040\n",
      "Epoch 837/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6302 - acc: 0.7227 - val_loss: 0.8011 - val_acc: 0.7024\n",
      "Epoch 838/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6277 - acc: 0.7242 - val_loss: 0.8015 - val_acc: 0.7022\n",
      "Epoch 839/1000\n",
      "212747/212747 [==============================] - 7s 33us/step - loss: 0.6333 - acc: 0.7225 - val_loss: 0.8084 - val_acc: 0.7037\n",
      "Epoch 840/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6327 - acc: 0.7221 - val_loss: 0.8044 - val_acc: 0.7032\n",
      "Epoch 841/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6297 - acc: 0.7228 - val_loss: 0.8138 - val_acc: 0.7035\n",
      "Epoch 842/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6281 - acc: 0.7242 - val_loss: 0.8049 - val_acc: 0.7031\n",
      "Epoch 843/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6326 - acc: 0.7230 - val_loss: 0.8130 - val_acc: 0.7021\n",
      "Epoch 844/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6320 - acc: 0.7238 - val_loss: 0.8032 - val_acc: 0.7043\n",
      "Epoch 845/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6289 - acc: 0.7230 - val_loss: 0.8058 - val_acc: 0.7024\n",
      "Epoch 846/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6297 - acc: 0.7223 - val_loss: 0.8051 - val_acc: 0.7033\n",
      "Epoch 847/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6308 - acc: 0.7217 - val_loss: 0.8140 - val_acc: 0.7035\n",
      "Epoch 848/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6289 - acc: 0.7228 - val_loss: 0.8015 - val_acc: 0.7032\n",
      "Epoch 849/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6275 - acc: 0.7239 - val_loss: 0.8105 - val_acc: 0.7021\n",
      "Epoch 850/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6329 - acc: 0.7219 - val_loss: 0.8023 - val_acc: 0.7031\n",
      "Epoch 851/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6292 - acc: 0.7235 - val_loss: 0.8099 - val_acc: 0.7037\n",
      "Epoch 852/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6282 - acc: 0.7241 - val_loss: 0.8036 - val_acc: 0.7033\n",
      "Epoch 853/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6292 - acc: 0.7243 - val_loss: 0.8127 - val_acc: 0.7036\n",
      "Epoch 854/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6286 - acc: 0.7234 - val_loss: 0.8026 - val_acc: 0.7045\n",
      "Epoch 855/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6295 - acc: 0.7239 - val_loss: 0.8032 - val_acc: 0.7050\n",
      "Epoch 856/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6285 - acc: 0.7241 - val_loss: 0.8089 - val_acc: 0.7030\n",
      "Epoch 857/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6336 - acc: 0.7225 - val_loss: 0.8090 - val_acc: 0.7047\n",
      "Epoch 858/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6278 - acc: 0.7244 - val_loss: 0.8168 - val_acc: 0.7042\n",
      "Epoch 859/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6285 - acc: 0.7242 - val_loss: 0.8044 - val_acc: 0.7035\n",
      "Epoch 860/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6324 - acc: 0.7220 - val_loss: 0.8156 - val_acc: 0.7028\n",
      "Epoch 861/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6281 - acc: 0.7233 - val_loss: 0.8026 - val_acc: 0.7063\n",
      "Epoch 862/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6350 - acc: 0.7219 - val_loss: 0.8060 - val_acc: 0.7060\n",
      "Epoch 863/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6304 - acc: 0.7235 - val_loss: 0.7998 - val_acc: 0.7026\n",
      "Epoch 864/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6338 - acc: 0.7222 - val_loss: 0.8065 - val_acc: 0.7029\n",
      "Epoch 865/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6266 - acc: 0.7249 - val_loss: 0.8010 - val_acc: 0.7043\n",
      "Epoch 866/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6284 - acc: 0.7247 - val_loss: 0.7997 - val_acc: 0.7052\n",
      "Epoch 867/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6296 - acc: 0.7226 - val_loss: 0.8138 - val_acc: 0.7013\n",
      "Epoch 868/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6282 - acc: 0.7242 - val_loss: 0.8125 - val_acc: 0.7017\n",
      "Epoch 869/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6349 - acc: 0.7213 - val_loss: 0.8064 - val_acc: 0.7034\n",
      "Epoch 870/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6283 - acc: 0.7236 - val_loss: 0.8044 - val_acc: 0.7042\n",
      "Epoch 871/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6260 - acc: 0.7245 - val_loss: 0.8062 - val_acc: 0.7056\n",
      "Epoch 872/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6270 - acc: 0.7252 - val_loss: 0.8057 - val_acc: 0.7041\n",
      "Epoch 873/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6260 - acc: 0.7257 - val_loss: 0.8027 - val_acc: 0.7078\n",
      "Epoch 874/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6275 - acc: 0.7248 - val_loss: 0.7926 - val_acc: 0.7051\n",
      "Epoch 875/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6251 - acc: 0.7256 - val_loss: 0.8056 - val_acc: 0.7052\n",
      "Epoch 876/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6314 - acc: 0.7229 - val_loss: 0.8003 - val_acc: 0.7051\n",
      "Epoch 877/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6352 - acc: 0.7214 - val_loss: 0.8117 - val_acc: 0.7016\n",
      "Epoch 878/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6305 - acc: 0.7227 - val_loss: 0.8008 - val_acc: 0.7053\n",
      "Epoch 879/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6296 - acc: 0.7236 - val_loss: 0.8083 - val_acc: 0.7051\n",
      "Epoch 880/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6267 - acc: 0.7252 - val_loss: 0.8065 - val_acc: 0.7046\n",
      "Epoch 881/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6261 - acc: 0.7230 - val_loss: 0.8019 - val_acc: 0.7061\n",
      "Epoch 882/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6305 - acc: 0.7232 - val_loss: 0.8141 - val_acc: 0.7053\n",
      "Epoch 883/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6342 - acc: 0.7226 - val_loss: 0.7996 - val_acc: 0.7064\n",
      "Epoch 884/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6240 - acc: 0.7264 - val_loss: 0.8018 - val_acc: 0.7046\n",
      "Epoch 885/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6230 - acc: 0.7268 - val_loss: 0.8028 - val_acc: 0.7055\n",
      "Epoch 886/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6238 - acc: 0.7257 - val_loss: 0.8077 - val_acc: 0.7046\n",
      "Epoch 887/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6235 - acc: 0.7261 - val_loss: 0.8104 - val_acc: 0.7049\n",
      "Epoch 888/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6260 - acc: 0.7260 - val_loss: 0.8058 - val_acc: 0.7036\n",
      "Epoch 889/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6291 - acc: 0.7252 - val_loss: 0.8032 - val_acc: 0.7046\n",
      "Epoch 890/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6252 - acc: 0.7256 - val_loss: 0.8016 - val_acc: 0.7036\n",
      "Epoch 891/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6273 - acc: 0.7236 - val_loss: 0.8059 - val_acc: 0.7070\n",
      "Epoch 892/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6247 - acc: 0.7260 - val_loss: 0.7972 - val_acc: 0.7055\n",
      "Epoch 893/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6244 - acc: 0.7253 - val_loss: 0.8131 - val_acc: 0.7018\n",
      "Epoch 894/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6335 - acc: 0.7218 - val_loss: 0.8142 - val_acc: 0.7035\n",
      "Epoch 895/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6259 - acc: 0.7239 - val_loss: 0.8108 - val_acc: 0.7077\n",
      "Epoch 896/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6283 - acc: 0.7240 - val_loss: 0.8023 - val_acc: 0.7043\n",
      "Epoch 897/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6298 - acc: 0.7247 - val_loss: 0.7993 - val_acc: 0.7059\n",
      "Epoch 898/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6274 - acc: 0.7236 - val_loss: 0.8108 - val_acc: 0.7037\n",
      "Epoch 899/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6227 - acc: 0.7258 - val_loss: 0.8078 - val_acc: 0.7081\n",
      "Epoch 900/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6259 - acc: 0.7252 - val_loss: 0.7986 - val_acc: 0.7061\n",
      "Epoch 901/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6247 - acc: 0.7258 - val_loss: 0.8056 - val_acc: 0.7085\n",
      "Epoch 902/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6231 - acc: 0.7270 - val_loss: 0.8078 - val_acc: 0.7054\n",
      "Epoch 903/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6229 - acc: 0.7265 - val_loss: 0.8039 - val_acc: 0.7054\n",
      "Epoch 904/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6264 - acc: 0.7241 - val_loss: 0.8034 - val_acc: 0.7038\n",
      "Epoch 905/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6261 - acc: 0.7258 - val_loss: 0.8057 - val_acc: 0.7061\n",
      "Epoch 906/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6235 - acc: 0.7260 - val_loss: 0.8148 - val_acc: 0.7071\n",
      "Epoch 907/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6293 - acc: 0.7237 - val_loss: 0.7994 - val_acc: 0.7085\n",
      "Epoch 908/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6243 - acc: 0.7259 - val_loss: 0.8004 - val_acc: 0.7079\n",
      "Epoch 909/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6242 - acc: 0.7269 - val_loss: 0.8010 - val_acc: 0.7050\n",
      "Epoch 910/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6279 - acc: 0.7256 - val_loss: 0.7997 - val_acc: 0.7102\n",
      "Epoch 911/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6272 - acc: 0.7252 - val_loss: 0.7980 - val_acc: 0.7060\n",
      "Epoch 912/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6234 - acc: 0.7257 - val_loss: 0.7984 - val_acc: 0.7070\n",
      "Epoch 913/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6237 - acc: 0.7252 - val_loss: 0.8009 - val_acc: 0.7073\n",
      "Epoch 914/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6257 - acc: 0.7252 - val_loss: 0.7885 - val_acc: 0.7069\n",
      "Epoch 915/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6224 - acc: 0.7269 - val_loss: 0.8040 - val_acc: 0.7049\n",
      "Epoch 916/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6275 - acc: 0.7246 - val_loss: 0.7989 - val_acc: 0.7073\n",
      "Epoch 917/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6262 - acc: 0.7256 - val_loss: 0.8008 - val_acc: 0.7052\n",
      "Epoch 918/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6257 - acc: 0.7254 - val_loss: 0.8040 - val_acc: 0.7057\n",
      "Epoch 919/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6258 - acc: 0.7252 - val_loss: 0.7961 - val_acc: 0.7075\n",
      "Epoch 920/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6248 - acc: 0.7257 - val_loss: 0.7980 - val_acc: 0.7069\n",
      "Epoch 921/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6237 - acc: 0.7271 - val_loss: 0.8027 - val_acc: 0.7056\n",
      "Epoch 922/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6240 - acc: 0.7267 - val_loss: 0.7933 - val_acc: 0.7065\n",
      "Epoch 923/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6225 - acc: 0.7275 - val_loss: 0.8059 - val_acc: 0.7053\n",
      "Epoch 924/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6228 - acc: 0.7271 - val_loss: 0.8047 - val_acc: 0.7054\n",
      "Epoch 925/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6287 - acc: 0.7250 - val_loss: 0.8034 - val_acc: 0.7049\n",
      "Epoch 926/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6255 - acc: 0.7263 - val_loss: 0.8064 - val_acc: 0.7072\n",
      "Epoch 927/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6219 - acc: 0.7270 - val_loss: 0.7924 - val_acc: 0.7062\n",
      "Epoch 928/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6252 - acc: 0.7263 - val_loss: 0.7915 - val_acc: 0.7065\n",
      "Epoch 929/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6215 - acc: 0.7269 - val_loss: 0.8015 - val_acc: 0.7044\n",
      "Epoch 930/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6215 - acc: 0.7278 - val_loss: 0.8050 - val_acc: 0.7066\n",
      "Epoch 931/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6218 - acc: 0.7268 - val_loss: 0.8005 - val_acc: 0.7067\n",
      "Epoch 932/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6245 - acc: 0.7258 - val_loss: 0.8006 - val_acc: 0.7049\n",
      "Epoch 933/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6226 - acc: 0.7266 - val_loss: 0.8084 - val_acc: 0.7076\n",
      "Epoch 934/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6244 - acc: 0.7263 - val_loss: 0.8023 - val_acc: 0.7045\n",
      "Epoch 935/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6256 - acc: 0.7261 - val_loss: 0.8082 - val_acc: 0.7058\n",
      "Epoch 936/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6230 - acc: 0.7269 - val_loss: 0.8147 - val_acc: 0.7051\n",
      "Epoch 937/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6247 - acc: 0.7265 - val_loss: 0.7961 - val_acc: 0.7065\n",
      "Epoch 938/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6214 - acc: 0.7265 - val_loss: 0.7955 - val_acc: 0.7060\n",
      "Epoch 939/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6221 - acc: 0.7271 - val_loss: 0.8037 - val_acc: 0.7050\n",
      "Epoch 940/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6263 - acc: 0.7244 - val_loss: 0.8078 - val_acc: 0.7047\n",
      "Epoch 941/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6209 - acc: 0.7277 - val_loss: 0.8046 - val_acc: 0.7069\n",
      "Epoch 942/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6236 - acc: 0.7263 - val_loss: 0.8025 - val_acc: 0.7066\n",
      "Epoch 943/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6242 - acc: 0.7263 - val_loss: 0.7984 - val_acc: 0.7078\n",
      "Epoch 944/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6215 - acc: 0.7265 - val_loss: 0.7933 - val_acc: 0.7085\n",
      "Epoch 945/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6234 - acc: 0.7271 - val_loss: 0.7973 - val_acc: 0.7085\n",
      "Epoch 946/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6180 - acc: 0.7272 - val_loss: 0.8103 - val_acc: 0.7079\n",
      "Epoch 947/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6269 - acc: 0.7252 - val_loss: 0.8021 - val_acc: 0.7066\n",
      "Epoch 948/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6214 - acc: 0.7266 - val_loss: 0.7978 - val_acc: 0.7070\n",
      "Epoch 949/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6207 - acc: 0.7278 - val_loss: 0.8032 - val_acc: 0.7070\n",
      "Epoch 950/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6187 - acc: 0.7275 - val_loss: 0.7984 - val_acc: 0.7080\n",
      "Epoch 951/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6225 - acc: 0.7267 - val_loss: 0.7977 - val_acc: 0.7069\n",
      "Epoch 952/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6204 - acc: 0.7283 - val_loss: 0.7993 - val_acc: 0.7098\n",
      "Epoch 953/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6237 - acc: 0.7275 - val_loss: 0.7994 - val_acc: 0.7077\n",
      "Epoch 954/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6210 - acc: 0.7280 - val_loss: 0.7990 - val_acc: 0.7070\n",
      "Epoch 955/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6203 - acc: 0.7281 - val_loss: 0.8060 - val_acc: 0.7047\n",
      "Epoch 956/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6210 - acc: 0.7275 - val_loss: 0.8151 - val_acc: 0.7076\n",
      "Epoch 957/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6232 - acc: 0.7273 - val_loss: 0.7988 - val_acc: 0.7059\n",
      "Epoch 958/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6323 - acc: 0.7233 - val_loss: 0.8066 - val_acc: 0.7084\n",
      "Epoch 959/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6193 - acc: 0.7288 - val_loss: 0.7994 - val_acc: 0.7093\n",
      "Epoch 960/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6196 - acc: 0.7277 - val_loss: 0.7983 - val_acc: 0.7089\n",
      "Epoch 961/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6206 - acc: 0.7271 - val_loss: 0.8017 - val_acc: 0.7072\n",
      "Epoch 962/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6226 - acc: 0.7278 - val_loss: 0.7890 - val_acc: 0.7084\n",
      "Epoch 963/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6216 - acc: 0.7282 - val_loss: 0.8002 - val_acc: 0.7093\n",
      "Epoch 964/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.6203 - acc: 0.7284 - val_loss: 0.7959 - val_acc: 0.7094\n",
      "Epoch 965/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6241 - acc: 0.7275 - val_loss: 0.7995 - val_acc: 0.7060\n",
      "Epoch 966/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6227 - acc: 0.7269 - val_loss: 0.8009 - val_acc: 0.7059\n",
      "Epoch 967/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6203 - acc: 0.7278 - val_loss: 0.8005 - val_acc: 0.7088\n",
      "Epoch 968/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6189 - acc: 0.7278 - val_loss: 0.8035 - val_acc: 0.7086\n",
      "Epoch 969/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6187 - acc: 0.7281 - val_loss: 0.7940 - val_acc: 0.7080\n",
      "Epoch 970/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6200 - acc: 0.7285 - val_loss: 0.8009 - val_acc: 0.7091\n",
      "Epoch 971/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6282 - acc: 0.7261 - val_loss: 0.8086 - val_acc: 0.7082\n",
      "Epoch 972/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6210 - acc: 0.7270 - val_loss: 0.8011 - val_acc: 0.7081\n",
      "Epoch 973/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6210 - acc: 0.7278 - val_loss: 0.8087 - val_acc: 0.7068\n",
      "Epoch 974/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6214 - acc: 0.7286 - val_loss: 0.7940 - val_acc: 0.7069\n",
      "Epoch 975/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6190 - acc: 0.7289 - val_loss: 0.8107 - val_acc: 0.7027\n",
      "Epoch 976/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6193 - acc: 0.7283 - val_loss: 0.8035 - val_acc: 0.7072\n",
      "Epoch 977/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6182 - acc: 0.7285 - val_loss: 0.7983 - val_acc: 0.7102\n",
      "Epoch 978/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6220 - acc: 0.7273 - val_loss: 0.8018 - val_acc: 0.7098\n",
      "Epoch 979/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6192 - acc: 0.7278 - val_loss: 0.7940 - val_acc: 0.7092\n",
      "Epoch 980/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.6180 - acc: 0.7287 - val_loss: 0.7907 - val_acc: 0.7088\n",
      "Epoch 981/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6168 - acc: 0.7284 - val_loss: 0.7970 - val_acc: 0.7089\n",
      "Epoch 982/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6197 - acc: 0.7285 - val_loss: 0.8024 - val_acc: 0.7067\n",
      "Epoch 983/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6159 - acc: 0.7299 - val_loss: 0.8007 - val_acc: 0.7073\n",
      "Epoch 984/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6211 - acc: 0.7282 - val_loss: 0.7916 - val_acc: 0.7062\n",
      "Epoch 985/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6332 - acc: 0.7240 - val_loss: 0.8033 - val_acc: 0.7087\n",
      "Epoch 986/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6195 - acc: 0.7277 - val_loss: 0.8056 - val_acc: 0.7104\n",
      "Epoch 987/1000\n",
      "212747/212747 [==============================] - 8s 35us/step - loss: 0.6172 - acc: 0.7292 - val_loss: 0.8006 - val_acc: 0.7098\n",
      "Epoch 988/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6212 - acc: 0.7278 - val_loss: 0.7990 - val_acc: 0.7093\n",
      "Epoch 989/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6200 - acc: 0.7283 - val_loss: 0.7948 - val_acc: 0.7097\n",
      "Epoch 990/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6159 - acc: 0.7297 - val_loss: 0.7996 - val_acc: 0.7088\n",
      "Epoch 991/1000\n",
      "212747/212747 [==============================] - 7s 34us/step - loss: 0.6195 - acc: 0.7287 - val_loss: 0.8016 - val_acc: 0.7070\n",
      "Epoch 992/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6158 - acc: 0.7293 - val_loss: 0.7995 - val_acc: 0.7079\n",
      "Epoch 993/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6136 - acc: 0.7311 - val_loss: 0.7960 - val_acc: 0.7105\n",
      "Epoch 994/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6137 - acc: 0.7292 - val_loss: 0.7999 - val_acc: 0.7098\n",
      "Epoch 995/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.6180 - acc: 0.7292 - val_loss: 0.7930 - val_acc: 0.7081\n",
      "Epoch 996/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6170 - acc: 0.7294 - val_loss: 0.7981 - val_acc: 0.7110\n",
      "Epoch 997/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6218 - acc: 0.7285 - val_loss: 0.7929 - val_acc: 0.7081\n",
      "Epoch 998/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.6197 - acc: 0.7284 - val_loss: 0.8015 - val_acc: 0.7098\n",
      "Epoch 999/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6168 - acc: 0.7293 - val_loss: 0.7983 - val_acc: 0.7098\n",
      "Epoch 1000/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.6172 - acc: 0.7295 - val_loss: 0.7973 - val_acc: 0.7084\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l1\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "import ptetaphi_nn\n",
    "import tools\n",
    "with open(\"filepath.txt\", 'r') as f:\n",
    "    filename = f.read()\n",
    "    \n",
    "s_table = tools.open_file(filename, sort_by=\"tag\")\n",
    "# filter by realistic situation where we have 3 tags and 3 or 4 jets.\n",
    "# ignore the case where there may be >4 since those are pretty rare\n",
    "nb4 = (s_table.nbjets == 3) | (s_table.nbjets == 4) # 3 or 4 b-jets exist\n",
    "nt3 = s_table.nbtags==3  # 3 b tags\n",
    "nb4nt3 = nb4 & nt3\n",
    "events = s_table[nb4nt3]\n",
    "print(len(events))\n",
    "\n",
    "# and ensure that the 3 tags are actually correct\n",
    "# this results in very little event loss\n",
    "events = events[events.truth[:,0] == 1]\n",
    "events = events[events.truth[:,1] == 1]\n",
    "events = events[events.truth[:,2] == 1]\n",
    "print(len(events))\n",
    "\n",
    "cutoff = 10  # not many events have >10 jets\n",
    "# \"pad\" = ensure all events have same length, cut off ends if needed\n",
    "events = tools.pad(events, cutoff)\n",
    "\n",
    "nn = ptetaphi_nn.PtEtaPhiNN(events)\n",
    "# Feed forward NN\n",
    "\n",
    "# create network\n",
    "nn.model = Sequential([\n",
    "    Dense(3*(cutoff-3), input_dim=3*(cutoff-3), kernel_initializer='normal', activation='relu'),\n",
    "    Dense(700, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(500, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(300, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense( 50, activation='relu'),\n",
    "    Dense(8, kernel_initializer='normal', activation='softmax')])\n",
    "nn.model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=\"adam\", metrics=['acc'])\n",
    "nn.model.summary()\n",
    "nn.learn(epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using data given when this model was created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60785/60785 [00:00<00:00, 95425.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.evaluate(savename=\"2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the architecture as a json string\n",
    "arch = nn.model.to_json()\n",
    "# save the architecture string to a file somehow, the below will work\n",
    "with open('architecture_2b.json', 'w') as arch_file:\n",
    "    arch_file.write(arch)\n",
    "# now save the weights as an HDF5 file\n",
    "nn.model.save_weights('weights_2b.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
