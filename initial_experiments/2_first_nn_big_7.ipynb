{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# How does the shape / size of our network affect its ability to learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting data by tag\n",
      "308955\n",
      "303925\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 700)               9100      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 545,461\n",
      "Trainable params: 545,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 212747 samples, validate on 30393 samples\n",
      "Epoch 1/1000\n",
      "212747/212747 [==============================] - 11s 53us/step - loss: 1.0889 - acc: 0.4990 - val_loss: 1.0494 - val_acc: 0.5177\n",
      "Epoch 2/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0494 - acc: 0.5170 - val_loss: 1.0369 - val_acc: 0.5214\n",
      "Epoch 3/1000\n",
      "212747/212747 [==============================] - 10s 45us/step - loss: 1.0415 - acc: 0.5199 - val_loss: 1.0296 - val_acc: 0.5242\n",
      "Epoch 4/1000\n",
      "212747/212747 [==============================] - 10s 45us/step - loss: 1.0365 - acc: 0.5217 - val_loss: 1.0274 - val_acc: 0.5251\n",
      "Epoch 5/1000\n",
      "212747/212747 [==============================] - 10s 45us/step - loss: 1.0331 - acc: 0.5228 - val_loss: 1.0268 - val_acc: 0.5229\n",
      "Epoch 6/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0316 - acc: 0.5228 - val_loss: 1.0255 - val_acc: 0.5243\n",
      "Epoch 7/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0302 - acc: 0.5237 - val_loss: 1.0282 - val_acc: 0.5260\n",
      "Epoch 8/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0288 - acc: 0.5242 - val_loss: 1.0253 - val_acc: 0.5238\n",
      "Epoch 9/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0275 - acc: 0.5248 - val_loss: 1.0237 - val_acc: 0.5214\n",
      "Epoch 10/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0266 - acc: 0.5244 - val_loss: 1.0217 - val_acc: 0.5265\n",
      "Epoch 11/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0252 - acc: 0.5250 - val_loss: 1.0206 - val_acc: 0.5271\n",
      "Epoch 12/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0237 - acc: 0.5255 - val_loss: 1.0199 - val_acc: 0.5270\n",
      "Epoch 13/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0235 - acc: 0.5253 - val_loss: 1.0194 - val_acc: 0.5276\n",
      "Epoch 14/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0227 - acc: 0.5250 - val_loss: 1.0168 - val_acc: 0.5283\n",
      "Epoch 15/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0212 - acc: 0.5267 - val_loss: 1.0182 - val_acc: 0.5265\n",
      "Epoch 16/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0215 - acc: 0.5271 - val_loss: 1.0181 - val_acc: 0.5288\n",
      "Epoch 17/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0199 - acc: 0.5266 - val_loss: 1.0158 - val_acc: 0.5298\n",
      "Epoch 18/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0194 - acc: 0.5266 - val_loss: 1.0158 - val_acc: 0.5305\n",
      "Epoch 19/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0187 - acc: 0.5278 - val_loss: 1.0138 - val_acc: 0.5291\n",
      "Epoch 20/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0185 - acc: 0.5273 - val_loss: 1.0123 - val_acc: 0.5307\n",
      "Epoch 21/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0170 - acc: 0.5271 - val_loss: 1.0143 - val_acc: 0.5301\n",
      "Epoch 22/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 1.0166 - acc: 0.5280 - val_loss: 1.0143 - val_acc: 0.5292\n",
      "Epoch 23/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0161 - acc: 0.5285 - val_loss: 1.0123 - val_acc: 0.5306\n",
      "Epoch 24/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0154 - acc: 0.5290 - val_loss: 1.0136 - val_acc: 0.5316\n",
      "Epoch 25/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0151 - acc: 0.5287 - val_loss: 1.0144 - val_acc: 0.5292\n",
      "Epoch 26/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0139 - acc: 0.5305 - val_loss: 1.0104 - val_acc: 0.5318\n",
      "Epoch 27/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0137 - acc: 0.5293 - val_loss: 1.0126 - val_acc: 0.5285\n",
      "Epoch 28/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0132 - acc: 0.5295 - val_loss: 1.0099 - val_acc: 0.5332\n",
      "Epoch 29/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0127 - acc: 0.5305 - val_loss: 1.0098 - val_acc: 0.5320\n",
      "Epoch 30/1000\n",
      "212747/212747 [==============================] - 9s 45us/step - loss: 1.0115 - acc: 0.5313 - val_loss: 1.0087 - val_acc: 0.5320\n",
      "Epoch 31/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0111 - acc: 0.5306 - val_loss: 1.0122 - val_acc: 0.5323\n",
      "Epoch 32/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0105 - acc: 0.5314 - val_loss: 1.0092 - val_acc: 0.5316\n",
      "Epoch 33/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0097 - acc: 0.5307 - val_loss: 1.0082 - val_acc: 0.5344\n",
      "Epoch 34/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0092 - acc: 0.5309 - val_loss: 1.0078 - val_acc: 0.5332\n",
      "Epoch 35/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0081 - acc: 0.5319 - val_loss: 1.0066 - val_acc: 0.5322\n",
      "Epoch 36/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0085 - acc: 0.5311 - val_loss: 1.0049 - val_acc: 0.5356\n",
      "Epoch 37/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0074 - acc: 0.5319 - val_loss: 1.0077 - val_acc: 0.5305\n",
      "Epoch 38/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0068 - acc: 0.5320 - val_loss: 1.0068 - val_acc: 0.5324\n",
      "Epoch 39/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0057 - acc: 0.5320 - val_loss: 1.0067 - val_acc: 0.5318\n",
      "Epoch 40/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0051 - acc: 0.5330 - val_loss: 1.0039 - val_acc: 0.5339\n",
      "Epoch 41/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0039 - acc: 0.5327 - val_loss: 1.0044 - val_acc: 0.5312\n",
      "Epoch 42/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0046 - acc: 0.5332 - val_loss: 1.0038 - val_acc: 0.5345\n",
      "Epoch 43/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 1.0033 - acc: 0.5333 - val_loss: 1.0038 - val_acc: 0.5352\n",
      "Epoch 44/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0019 - acc: 0.5340 - val_loss: 1.0024 - val_acc: 0.5363\n",
      "Epoch 45/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0018 - acc: 0.5347 - val_loss: 1.0019 - val_acc: 0.5318\n",
      "Epoch 46/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 1.0014 - acc: 0.5349 - val_loss: 1.0012 - val_acc: 0.5357\n",
      "Epoch 47/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9999 - acc: 0.5348 - val_loss: 1.0023 - val_acc: 0.5369\n",
      "Epoch 48/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9993 - acc: 0.5352 - val_loss: 0.9987 - val_acc: 0.5377\n",
      "Epoch 49/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9986 - acc: 0.5354 - val_loss: 0.9991 - val_acc: 0.5365\n",
      "Epoch 50/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9980 - acc: 0.5357 - val_loss: 0.9993 - val_acc: 0.5351\n",
      "Epoch 51/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9970 - acc: 0.5366 - val_loss: 0.9995 - val_acc: 0.5375\n",
      "Epoch 52/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9967 - acc: 0.5360 - val_loss: 0.9993 - val_acc: 0.5401\n",
      "Epoch 53/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9953 - acc: 0.5377 - val_loss: 0.9963 - val_acc: 0.5386\n",
      "Epoch 54/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9946 - acc: 0.5381 - val_loss: 0.9991 - val_acc: 0.5346\n",
      "Epoch 55/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9941 - acc: 0.5378 - val_loss: 0.9986 - val_acc: 0.5382\n",
      "Epoch 56/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9929 - acc: 0.5386 - val_loss: 0.9946 - val_acc: 0.5400\n",
      "Epoch 57/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9924 - acc: 0.5384 - val_loss: 0.9943 - val_acc: 0.5396\n",
      "Epoch 58/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9912 - acc: 0.5384 - val_loss: 0.9968 - val_acc: 0.5364\n",
      "Epoch 59/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9902 - acc: 0.5385 - val_loss: 0.9939 - val_acc: 0.5410\n",
      "Epoch 60/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9900 - acc: 0.5395 - val_loss: 0.9934 - val_acc: 0.5400\n",
      "Epoch 61/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9887 - acc: 0.5405 - val_loss: 0.9917 - val_acc: 0.5410\n",
      "Epoch 62/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9891 - acc: 0.5405 - val_loss: 0.9915 - val_acc: 0.5399\n",
      "Epoch 63/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9877 - acc: 0.5402 - val_loss: 0.9932 - val_acc: 0.5407\n",
      "Epoch 64/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9868 - acc: 0.5407 - val_loss: 0.9991 - val_acc: 0.5396\n",
      "Epoch 65/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9867 - acc: 0.5411 - val_loss: 0.9932 - val_acc: 0.5398\n",
      "Epoch 66/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9859 - acc: 0.5409 - val_loss: 0.9910 - val_acc: 0.5411\n",
      "Epoch 67/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9847 - acc: 0.5419 - val_loss: 0.9893 - val_acc: 0.5442\n",
      "Epoch 68/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9836 - acc: 0.5422 - val_loss: 0.9879 - val_acc: 0.5432\n",
      "Epoch 69/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9825 - acc: 0.5428 - val_loss: 0.9882 - val_acc: 0.5418\n",
      "Epoch 70/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9823 - acc: 0.5431 - val_loss: 0.9866 - val_acc: 0.5426\n",
      "Epoch 71/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9809 - acc: 0.5442 - val_loss: 0.9893 - val_acc: 0.5437\n",
      "Epoch 72/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9811 - acc: 0.5437 - val_loss: 0.9834 - val_acc: 0.5436\n",
      "Epoch 73/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9792 - acc: 0.5442 - val_loss: 0.9851 - val_acc: 0.5461\n",
      "Epoch 74/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9794 - acc: 0.5450 - val_loss: 0.9845 - val_acc: 0.5430\n",
      "Epoch 75/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9779 - acc: 0.5447 - val_loss: 0.9853 - val_acc: 0.5438\n",
      "Epoch 76/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9774 - acc: 0.5443 - val_loss: 0.9848 - val_acc: 0.5455\n",
      "Epoch 77/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9762 - acc: 0.5460 - val_loss: 0.9831 - val_acc: 0.5465\n",
      "Epoch 78/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9757 - acc: 0.5458 - val_loss: 0.9845 - val_acc: 0.5444\n",
      "Epoch 79/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9742 - acc: 0.5473 - val_loss: 0.9823 - val_acc: 0.5446\n",
      "Epoch 80/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9744 - acc: 0.5472 - val_loss: 0.9823 - val_acc: 0.5449\n",
      "Epoch 81/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9741 - acc: 0.5470 - val_loss: 0.9812 - val_acc: 0.5436\n",
      "Epoch 82/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9720 - acc: 0.5478 - val_loss: 0.9799 - val_acc: 0.5480\n",
      "Epoch 83/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9710 - acc: 0.5477 - val_loss: 0.9796 - val_acc: 0.5462\n",
      "Epoch 84/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9715 - acc: 0.5479 - val_loss: 0.9765 - val_acc: 0.5483\n",
      "Epoch 85/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9703 - acc: 0.5490 - val_loss: 0.9781 - val_acc: 0.5459\n",
      "Epoch 86/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9689 - acc: 0.5480 - val_loss: 0.9778 - val_acc: 0.5497\n",
      "Epoch 87/1000\n",
      "212747/212747 [==============================] - 9s 45us/step - loss: 0.9687 - acc: 0.5494 - val_loss: 0.9770 - val_acc: 0.5498\n",
      "Epoch 88/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9684 - acc: 0.5484 - val_loss: 0.9760 - val_acc: 0.5477\n",
      "Epoch 89/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9671 - acc: 0.5493 - val_loss: 0.9756 - val_acc: 0.5463\n",
      "Epoch 90/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9661 - acc: 0.5495 - val_loss: 0.9751 - val_acc: 0.5488\n",
      "Epoch 91/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9659 - acc: 0.5509 - val_loss: 0.9748 - val_acc: 0.5475\n",
      "Epoch 92/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9643 - acc: 0.5510 - val_loss: 0.9738 - val_acc: 0.5489\n",
      "Epoch 93/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9649 - acc: 0.5502 - val_loss: 0.9725 - val_acc: 0.5510\n",
      "Epoch 94/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9638 - acc: 0.5513 - val_loss: 0.9718 - val_acc: 0.5507\n",
      "Epoch 95/1000\n",
      "212747/212747 [==============================] - 9s 40us/step - loss: 0.9617 - acc: 0.5523 - val_loss: 0.9696 - val_acc: 0.5519\n",
      "Epoch 96/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.9613 - acc: 0.5523 - val_loss: 0.9718 - val_acc: 0.5517\n",
      "Epoch 97/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.9604 - acc: 0.5517 - val_loss: 0.9714 - val_acc: 0.5538\n",
      "Epoch 98/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.9598 - acc: 0.5529 - val_loss: 0.9720 - val_acc: 0.5509\n",
      "Epoch 99/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.9588 - acc: 0.5530 - val_loss: 0.9696 - val_acc: 0.5506\n",
      "Epoch 100/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.9586 - acc: 0.5534 - val_loss: 0.9675 - val_acc: 0.5518\n",
      "Epoch 101/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.9586 - acc: 0.5538 - val_loss: 0.9675 - val_acc: 0.5525\n",
      "Epoch 102/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.9563 - acc: 0.5552 - val_loss: 0.9673 - val_acc: 0.5540\n",
      "Epoch 103/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9558 - acc: 0.5544 - val_loss: 0.9671 - val_acc: 0.5519\n",
      "Epoch 104/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9558 - acc: 0.5550 - val_loss: 0.9682 - val_acc: 0.5523\n",
      "Epoch 105/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9549 - acc: 0.5555 - val_loss: 0.9674 - val_acc: 0.5527\n",
      "Epoch 106/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9536 - acc: 0.5554 - val_loss: 0.9659 - val_acc: 0.5529\n",
      "Epoch 107/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9537 - acc: 0.5562 - val_loss: 0.9633 - val_acc: 0.5530\n",
      "Epoch 108/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9518 - acc: 0.5569 - val_loss: 0.9644 - val_acc: 0.5545\n",
      "Epoch 109/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9517 - acc: 0.5562 - val_loss: 0.9644 - val_acc: 0.5550\n",
      "Epoch 110/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9511 - acc: 0.5573 - val_loss: 0.9617 - val_acc: 0.5569\n",
      "Epoch 111/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9500 - acc: 0.5567 - val_loss: 0.9625 - val_acc: 0.5568\n",
      "Epoch 112/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9491 - acc: 0.5573 - val_loss: 0.9653 - val_acc: 0.5560\n",
      "Epoch 113/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9493 - acc: 0.5590 - val_loss: 0.9634 - val_acc: 0.5562\n",
      "Epoch 114/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9486 - acc: 0.5576 - val_loss: 0.9620 - val_acc: 0.5577\n",
      "Epoch 115/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9484 - acc: 0.5586 - val_loss: 0.9604 - val_acc: 0.5571\n",
      "Epoch 116/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9465 - acc: 0.5597 - val_loss: 0.9628 - val_acc: 0.5557\n",
      "Epoch 117/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9451 - acc: 0.5602 - val_loss: 0.9584 - val_acc: 0.5585\n",
      "Epoch 118/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9447 - acc: 0.5607 - val_loss: 0.9611 - val_acc: 0.5572\n",
      "Epoch 119/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9449 - acc: 0.5601 - val_loss: 0.9592 - val_acc: 0.5590\n",
      "Epoch 120/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9437 - acc: 0.5617 - val_loss: 0.9567 - val_acc: 0.5612\n",
      "Epoch 121/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9425 - acc: 0.5617 - val_loss: 0.9569 - val_acc: 0.5629\n",
      "Epoch 122/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9428 - acc: 0.5617 - val_loss: 0.9566 - val_acc: 0.5606\n",
      "Epoch 123/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9416 - acc: 0.5627 - val_loss: 0.9579 - val_acc: 0.5617\n",
      "Epoch 124/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9411 - acc: 0.5625 - val_loss: 0.9556 - val_acc: 0.5626\n",
      "Epoch 125/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9414 - acc: 0.5621 - val_loss: 0.9574 - val_acc: 0.5630\n",
      "Epoch 126/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9394 - acc: 0.5629 - val_loss: 0.9549 - val_acc: 0.5622\n",
      "Epoch 127/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9378 - acc: 0.5637 - val_loss: 0.9538 - val_acc: 0.5604\n",
      "Epoch 128/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9384 - acc: 0.5637 - val_loss: 0.9551 - val_acc: 0.5644\n",
      "Epoch 129/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9367 - acc: 0.5636 - val_loss: 0.9538 - val_acc: 0.5642\n",
      "Epoch 130/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9358 - acc: 0.5641 - val_loss: 0.9536 - val_acc: 0.5631\n",
      "Epoch 131/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9347 - acc: 0.5648 - val_loss: 0.9529 - val_acc: 0.5648\n",
      "Epoch 132/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9346 - acc: 0.5643 - val_loss: 0.9516 - val_acc: 0.5658\n",
      "Epoch 133/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9331 - acc: 0.5657 - val_loss: 0.9509 - val_acc: 0.5664\n",
      "Epoch 134/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9340 - acc: 0.5649 - val_loss: 0.9532 - val_acc: 0.5640\n",
      "Epoch 135/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9330 - acc: 0.5660 - val_loss: 0.9536 - val_acc: 0.5640\n",
      "Epoch 136/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9316 - acc: 0.5662 - val_loss: 0.9526 - val_acc: 0.5645\n",
      "Epoch 137/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9331 - acc: 0.5670 - val_loss: 0.9503 - val_acc: 0.5639\n",
      "Epoch 138/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9311 - acc: 0.5665 - val_loss: 0.9522 - val_acc: 0.5645\n",
      "Epoch 139/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9312 - acc: 0.5677 - val_loss: 0.9496 - val_acc: 0.5645\n",
      "Epoch 140/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9309 - acc: 0.5672 - val_loss: 0.9511 - val_acc: 0.5679\n",
      "Epoch 141/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9287 - acc: 0.5688 - val_loss: 0.9502 - val_acc: 0.5667\n",
      "Epoch 142/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9291 - acc: 0.5684 - val_loss: 0.9465 - val_acc: 0.5681\n",
      "Epoch 143/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9286 - acc: 0.5694 - val_loss: 0.9458 - val_acc: 0.5710\n",
      "Epoch 144/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9264 - acc: 0.5694 - val_loss: 0.9504 - val_acc: 0.5659\n",
      "Epoch 145/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9264 - acc: 0.5699 - val_loss: 0.9462 - val_acc: 0.5689\n",
      "Epoch 146/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9250 - acc: 0.5701 - val_loss: 0.9473 - val_acc: 0.5691\n",
      "Epoch 147/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9250 - acc: 0.5706 - val_loss: 0.9443 - val_acc: 0.5712\n",
      "Epoch 148/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9245 - acc: 0.5702 - val_loss: 0.9456 - val_acc: 0.5716\n",
      "Epoch 149/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9239 - acc: 0.5697 - val_loss: 0.9440 - val_acc: 0.5707\n",
      "Epoch 150/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9240 - acc: 0.5714 - val_loss: 0.9427 - val_acc: 0.5709\n",
      "Epoch 151/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9223 - acc: 0.5719 - val_loss: 0.9431 - val_acc: 0.5718\n",
      "Epoch 152/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.9219 - acc: 0.5718 - val_loss: 0.9423 - val_acc: 0.5716\n",
      "Epoch 153/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9215 - acc: 0.5726 - val_loss: 0.9415 - val_acc: 0.5722\n",
      "Epoch 154/1000\n",
      "212747/212747 [==============================] - 10s 45us/step - loss: 0.9217 - acc: 0.5719 - val_loss: 0.9394 - val_acc: 0.5745\n",
      "Epoch 155/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9194 - acc: 0.5739 - val_loss: 0.9395 - val_acc: 0.5730\n",
      "Epoch 156/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9201 - acc: 0.5730 - val_loss: 0.9406 - val_acc: 0.5708\n",
      "Epoch 157/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9173 - acc: 0.5742 - val_loss: 0.9402 - val_acc: 0.5734\n",
      "Epoch 158/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9190 - acc: 0.5741 - val_loss: 0.9414 - val_acc: 0.5712\n",
      "Epoch 159/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9171 - acc: 0.5739 - val_loss: 0.9419 - val_acc: 0.5717\n",
      "Epoch 160/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9164 - acc: 0.5746 - val_loss: 0.9396 - val_acc: 0.5758\n",
      "Epoch 161/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9151 - acc: 0.5754 - val_loss: 0.9393 - val_acc: 0.5756\n",
      "Epoch 162/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9152 - acc: 0.5759 - val_loss: 0.9376 - val_acc: 0.5770\n",
      "Epoch 163/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9146 - acc: 0.5758 - val_loss: 0.9382 - val_acc: 0.5752\n",
      "Epoch 164/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9153 - acc: 0.5753 - val_loss: 0.9387 - val_acc: 0.5772\n",
      "Epoch 165/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9133 - acc: 0.5762 - val_loss: 0.9358 - val_acc: 0.5778\n",
      "Epoch 166/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9146 - acc: 0.5752 - val_loss: 0.9350 - val_acc: 0.5786\n",
      "Epoch 167/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9136 - acc: 0.5765 - val_loss: 0.9369 - val_acc: 0.5758\n",
      "Epoch 168/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9117 - acc: 0.5768 - val_loss: 0.9374 - val_acc: 0.5753\n",
      "Epoch 169/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9119 - acc: 0.5777 - val_loss: 0.9357 - val_acc: 0.5788\n",
      "Epoch 170/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9114 - acc: 0.5782 - val_loss: 0.9357 - val_acc: 0.5769\n",
      "Epoch 171/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9110 - acc: 0.5783 - val_loss: 0.9328 - val_acc: 0.5780\n",
      "Epoch 172/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9104 - acc: 0.5784 - val_loss: 0.9329 - val_acc: 0.5808\n",
      "Epoch 173/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9090 - acc: 0.5784 - val_loss: 0.9368 - val_acc: 0.5775\n",
      "Epoch 174/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9088 - acc: 0.5780 - val_loss: 0.9344 - val_acc: 0.5789\n",
      "Epoch 175/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9081 - acc: 0.5780 - val_loss: 0.9351 - val_acc: 0.5777\n",
      "Epoch 176/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9081 - acc: 0.5786 - val_loss: 0.9359 - val_acc: 0.5760\n",
      "Epoch 177/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9079 - acc: 0.5789 - val_loss: 0.9333 - val_acc: 0.5773\n",
      "Epoch 178/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9070 - acc: 0.5784 - val_loss: 0.9309 - val_acc: 0.5804\n",
      "Epoch 179/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9062 - acc: 0.5797 - val_loss: 0.9319 - val_acc: 0.5805\n",
      "Epoch 180/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9059 - acc: 0.5792 - val_loss: 0.9340 - val_acc: 0.5815\n",
      "Epoch 181/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9067 - acc: 0.5802 - val_loss: 0.9326 - val_acc: 0.5812\n",
      "Epoch 182/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9041 - acc: 0.5812 - val_loss: 0.9299 - val_acc: 0.5807\n",
      "Epoch 183/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9026 - acc: 0.5818 - val_loss: 0.9297 - val_acc: 0.5799\n",
      "Epoch 184/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9040 - acc: 0.5808 - val_loss: 0.9329 - val_acc: 0.5817\n",
      "Epoch 185/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9029 - acc: 0.5819 - val_loss: 0.9302 - val_acc: 0.5821\n",
      "Epoch 186/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.9020 - acc: 0.5817 - val_loss: 0.9281 - val_acc: 0.5851\n",
      "Epoch 187/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9023 - acc: 0.5816 - val_loss: 0.9281 - val_acc: 0.5819\n",
      "Epoch 188/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9019 - acc: 0.5818 - val_loss: 0.9317 - val_acc: 0.5811\n",
      "Epoch 189/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.9008 - acc: 0.5825 - val_loss: 0.9271 - val_acc: 0.5819\n",
      "Epoch 190/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8994 - acc: 0.5831 - val_loss: 0.9301 - val_acc: 0.5839\n",
      "Epoch 191/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8986 - acc: 0.5840 - val_loss: 0.9287 - val_acc: 0.5840\n",
      "Epoch 192/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.9002 - acc: 0.5837 - val_loss: 0.9268 - val_acc: 0.5853\n",
      "Epoch 193/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8999 - acc: 0.5833 - val_loss: 0.9305 - val_acc: 0.5829\n",
      "Epoch 194/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8986 - acc: 0.5841 - val_loss: 0.9271 - val_acc: 0.5836\n",
      "Epoch 195/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8984 - acc: 0.5852 - val_loss: 0.9291 - val_acc: 0.5839\n",
      "Epoch 196/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8972 - acc: 0.5853 - val_loss: 0.9255 - val_acc: 0.5866\n",
      "Epoch 197/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8974 - acc: 0.5849 - val_loss: 0.9239 - val_acc: 0.5855\n",
      "Epoch 198/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8973 - acc: 0.5851 - val_loss: 0.9269 - val_acc: 0.5844\n",
      "Epoch 199/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8959 - acc: 0.5844 - val_loss: 0.9269 - val_acc: 0.5837\n",
      "Epoch 200/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8954 - acc: 0.5864 - val_loss: 0.9249 - val_acc: 0.5865\n",
      "Epoch 201/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8953 - acc: 0.5857 - val_loss: 0.9225 - val_acc: 0.5863\n",
      "Epoch 202/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8946 - acc: 0.5863 - val_loss: 0.9192 - val_acc: 0.5896\n",
      "Epoch 203/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8928 - acc: 0.5876 - val_loss: 0.9229 - val_acc: 0.5866\n",
      "Epoch 204/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8920 - acc: 0.5870 - val_loss: 0.9246 - val_acc: 0.5856\n",
      "Epoch 205/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8917 - acc: 0.5873 - val_loss: 0.9194 - val_acc: 0.5887\n",
      "Epoch 206/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.8928 - acc: 0.5871 - val_loss: 0.9230 - val_acc: 0.5898\n",
      "Epoch 207/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8923 - acc: 0.5879 - val_loss: 0.9233 - val_acc: 0.5861\n",
      "Epoch 208/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8905 - acc: 0.5877 - val_loss: 0.9214 - val_acc: 0.5883\n",
      "Epoch 209/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8912 - acc: 0.5874 - val_loss: 0.9229 - val_acc: 0.5877\n",
      "Epoch 210/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8910 - acc: 0.5884 - val_loss: 0.9163 - val_acc: 0.5924\n",
      "Epoch 211/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8907 - acc: 0.5883 - val_loss: 0.9173 - val_acc: 0.5912\n",
      "Epoch 212/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8894 - acc: 0.5893 - val_loss: 0.9206 - val_acc: 0.5912\n",
      "Epoch 213/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8890 - acc: 0.5888 - val_loss: 0.9190 - val_acc: 0.5917\n",
      "Epoch 214/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8887 - acc: 0.5887 - val_loss: 0.9208 - val_acc: 0.5922\n",
      "Epoch 215/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8881 - acc: 0.5896 - val_loss: 0.9191 - val_acc: 0.5935\n",
      "Epoch 216/1000\n",
      "212747/212747 [==============================] - 9s 45us/step - loss: 0.8874 - acc: 0.5900 - val_loss: 0.9176 - val_acc: 0.5903\n",
      "Epoch 217/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8873 - acc: 0.5896 - val_loss: 0.9178 - val_acc: 0.5917\n",
      "Epoch 218/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8872 - acc: 0.5911 - val_loss: 0.9184 - val_acc: 0.5917\n",
      "Epoch 219/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8863 - acc: 0.5915 - val_loss: 0.9184 - val_acc: 0.5931\n",
      "Epoch 220/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8853 - acc: 0.5903 - val_loss: 0.9151 - val_acc: 0.5939\n",
      "Epoch 221/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8845 - acc: 0.5920 - val_loss: 0.9163 - val_acc: 0.5932\n",
      "Epoch 222/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8859 - acc: 0.5903 - val_loss: 0.9152 - val_acc: 0.5925\n",
      "Epoch 223/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8850 - acc: 0.5906 - val_loss: 0.9187 - val_acc: 0.5920\n",
      "Epoch 224/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8830 - acc: 0.5919 - val_loss: 0.9179 - val_acc: 0.5905\n",
      "Epoch 225/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8847 - acc: 0.5921 - val_loss: 0.9169 - val_acc: 0.5937\n",
      "Epoch 226/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8847 - acc: 0.5913 - val_loss: 0.9148 - val_acc: 0.5909\n",
      "Epoch 227/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8837 - acc: 0.5918 - val_loss: 0.9152 - val_acc: 0.5915\n",
      "Epoch 228/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8822 - acc: 0.5925 - val_loss: 0.9143 - val_acc: 0.5933\n",
      "Epoch 229/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8827 - acc: 0.5931 - val_loss: 0.9122 - val_acc: 0.5963\n",
      "Epoch 230/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8812 - acc: 0.5932 - val_loss: 0.9159 - val_acc: 0.5945\n",
      "Epoch 231/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8823 - acc: 0.5929 - val_loss: 0.9150 - val_acc: 0.5957\n",
      "Epoch 232/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8791 - acc: 0.5942 - val_loss: 0.9138 - val_acc: 0.5943\n",
      "Epoch 233/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8815 - acc: 0.5936 - val_loss: 0.9112 - val_acc: 0.5941\n",
      "Epoch 234/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8803 - acc: 0.5933 - val_loss: 0.9160 - val_acc: 0.5949\n",
      "Epoch 235/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8800 - acc: 0.5934 - val_loss: 0.9128 - val_acc: 0.5952\n",
      "Epoch 236/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8803 - acc: 0.5938 - val_loss: 0.9137 - val_acc: 0.5953\n",
      "Epoch 237/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8797 - acc: 0.5937 - val_loss: 0.9128 - val_acc: 0.5976\n",
      "Epoch 238/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8776 - acc: 0.5942 - val_loss: 0.9132 - val_acc: 0.5959\n",
      "Epoch 239/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8774 - acc: 0.5955 - val_loss: 0.9101 - val_acc: 0.5987\n",
      "Epoch 240/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8772 - acc: 0.5956 - val_loss: 0.9101 - val_acc: 0.5994\n",
      "Epoch 241/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8757 - acc: 0.5959 - val_loss: 0.9117 - val_acc: 0.5973\n",
      "Epoch 242/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8745 - acc: 0.5960 - val_loss: 0.9144 - val_acc: 0.5938\n",
      "Epoch 243/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8753 - acc: 0.5963 - val_loss: 0.9098 - val_acc: 0.5986\n",
      "Epoch 244/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8757 - acc: 0.5950 - val_loss: 0.9109 - val_acc: 0.6007\n",
      "Epoch 245/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8750 - acc: 0.5969 - val_loss: 0.9133 - val_acc: 0.5972\n",
      "Epoch 246/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8761 - acc: 0.5963 - val_loss: 0.9089 - val_acc: 0.5952\n",
      "Epoch 247/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8752 - acc: 0.5963 - val_loss: 0.9087 - val_acc: 0.5976\n",
      "Epoch 248/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8735 - acc: 0.5968 - val_loss: 0.9119 - val_acc: 0.5967\n",
      "Epoch 249/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8749 - acc: 0.5982 - val_loss: 0.9069 - val_acc: 0.5988\n",
      "Epoch 250/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8741 - acc: 0.5973 - val_loss: 0.9061 - val_acc: 0.5966\n",
      "Epoch 251/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8727 - acc: 0.5984 - val_loss: 0.9066 - val_acc: 0.5998\n",
      "Epoch 252/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8708 - acc: 0.5987 - val_loss: 0.9099 - val_acc: 0.5954\n",
      "Epoch 253/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8713 - acc: 0.5979 - val_loss: 0.9066 - val_acc: 0.6001\n",
      "Epoch 254/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8731 - acc: 0.5973 - val_loss: 0.9065 - val_acc: 0.5992\n",
      "Epoch 255/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8703 - acc: 0.5992 - val_loss: 0.9083 - val_acc: 0.5991\n",
      "Epoch 256/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8720 - acc: 0.5983 - val_loss: 0.9055 - val_acc: 0.6018\n",
      "Epoch 257/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8700 - acc: 0.5982 - val_loss: 0.9075 - val_acc: 0.5961\n",
      "Epoch 258/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8705 - acc: 0.5985 - val_loss: 0.9034 - val_acc: 0.6033\n",
      "Epoch 259/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8692 - acc: 0.5999 - val_loss: 0.9049 - val_acc: 0.6012\n",
      "Epoch 260/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8679 - acc: 0.6000 - val_loss: 0.9076 - val_acc: 0.5992\n",
      "Epoch 261/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8687 - acc: 0.6011 - val_loss: 0.9004 - val_acc: 0.6037\n",
      "Epoch 262/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8687 - acc: 0.5994 - val_loss: 0.9019 - val_acc: 0.6016\n",
      "Epoch 263/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8677 - acc: 0.6000 - val_loss: 0.9028 - val_acc: 0.6035\n",
      "Epoch 264/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8673 - acc: 0.6015 - val_loss: 0.9042 - val_acc: 0.6030\n",
      "Epoch 265/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8657 - acc: 0.6019 - val_loss: 0.9049 - val_acc: 0.6004\n",
      "Epoch 266/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8666 - acc: 0.6004 - val_loss: 0.9030 - val_acc: 0.6035\n",
      "Epoch 267/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8670 - acc: 0.6009 - val_loss: 0.9036 - val_acc: 0.6043\n",
      "Epoch 268/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8646 - acc: 0.6010 - val_loss: 0.9003 - val_acc: 0.6047\n",
      "Epoch 269/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8639 - acc: 0.6019 - val_loss: 0.9039 - val_acc: 0.6036\n",
      "Epoch 270/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8663 - acc: 0.6014 - val_loss: 0.9032 - val_acc: 0.6042\n",
      "Epoch 271/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8655 - acc: 0.6026 - val_loss: 0.8993 - val_acc: 0.6048\n",
      "Epoch 272/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8638 - acc: 0.6031 - val_loss: 0.9009 - val_acc: 0.6055\n",
      "Epoch 273/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8628 - acc: 0.6036 - val_loss: 0.9015 - val_acc: 0.6057\n",
      "Epoch 274/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8631 - acc: 0.6034 - val_loss: 0.8989 - val_acc: 0.6055\n",
      "Epoch 275/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8645 - acc: 0.6027 - val_loss: 0.9017 - val_acc: 0.6047\n",
      "Epoch 276/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8631 - acc: 0.6023 - val_loss: 0.8998 - val_acc: 0.6038\n",
      "Epoch 277/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8637 - acc: 0.6030 - val_loss: 0.9057 - val_acc: 0.6035\n",
      "Epoch 278/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8629 - acc: 0.6036 - val_loss: 0.9015 - val_acc: 0.6037\n",
      "Epoch 279/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8613 - acc: 0.6037 - val_loss: 0.9033 - val_acc: 0.6051\n",
      "Epoch 280/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8605 - acc: 0.6034 - val_loss: 0.9004 - val_acc: 0.6058\n",
      "Epoch 281/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8628 - acc: 0.6032 - val_loss: 0.8984 - val_acc: 0.6065\n",
      "Epoch 282/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8596 - acc: 0.6051 - val_loss: 0.9023 - val_acc: 0.6053\n",
      "Epoch 283/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8600 - acc: 0.6046 - val_loss: 0.9010 - val_acc: 0.6059\n",
      "Epoch 284/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8612 - acc: 0.6042 - val_loss: 0.9008 - val_acc: 0.6069\n",
      "Epoch 285/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8604 - acc: 0.6041 - val_loss: 0.9001 - val_acc: 0.6070\n",
      "Epoch 286/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8594 - acc: 0.6054 - val_loss: 0.8975 - val_acc: 0.6085\n",
      "Epoch 287/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8592 - acc: 0.6045 - val_loss: 0.8991 - val_acc: 0.6073\n",
      "Epoch 288/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8587 - acc: 0.6068 - val_loss: 0.9003 - val_acc: 0.6056\n",
      "Epoch 289/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8585 - acc: 0.6071 - val_loss: 0.8992 - val_acc: 0.6095\n",
      "Epoch 290/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8588 - acc: 0.6063 - val_loss: 0.8972 - val_acc: 0.6086\n",
      "Epoch 291/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8576 - acc: 0.6053 - val_loss: 0.8964 - val_acc: 0.6078\n",
      "Epoch 292/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8574 - acc: 0.6061 - val_loss: 0.8982 - val_acc: 0.6076\n",
      "Epoch 293/1000\n",
      "212747/212747 [==============================] - 9s 45us/step - loss: 0.8572 - acc: 0.6057 - val_loss: 0.8979 - val_acc: 0.6095\n",
      "Epoch 294/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8592 - acc: 0.6057 - val_loss: 0.8929 - val_acc: 0.6086\n",
      "Epoch 295/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8580 - acc: 0.6057 - val_loss: 0.8952 - val_acc: 0.6093\n",
      "Epoch 296/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8556 - acc: 0.6071 - val_loss: 0.8948 - val_acc: 0.6100\n",
      "Epoch 297/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8541 - acc: 0.6071 - val_loss: 0.8959 - val_acc: 0.6106\n",
      "Epoch 298/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8553 - acc: 0.6068 - val_loss: 0.8950 - val_acc: 0.6110\n",
      "Epoch 299/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8539 - acc: 0.6086 - val_loss: 0.8969 - val_acc: 0.6107\n",
      "Epoch 300/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8548 - acc: 0.6086 - val_loss: 0.8969 - val_acc: 0.6084\n",
      "Epoch 301/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8549 - acc: 0.6073 - val_loss: 0.8934 - val_acc: 0.6128\n",
      "Epoch 302/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8557 - acc: 0.6066 - val_loss: 0.8933 - val_acc: 0.6104\n",
      "Epoch 303/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8544 - acc: 0.6085 - val_loss: 0.8957 - val_acc: 0.6091\n",
      "Epoch 304/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8521 - acc: 0.6093 - val_loss: 0.8922 - val_acc: 0.6130\n",
      "Epoch 305/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8529 - acc: 0.6079 - val_loss: 0.8933 - val_acc: 0.6095\n",
      "Epoch 306/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8515 - acc: 0.6095 - val_loss: 0.8942 - val_acc: 0.6095\n",
      "Epoch 307/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8538 - acc: 0.6089 - val_loss: 0.8944 - val_acc: 0.6087\n",
      "Epoch 308/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8531 - acc: 0.6087 - val_loss: 0.8932 - val_acc: 0.6114\n",
      "Epoch 309/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8551 - acc: 0.6076 - val_loss: 0.8947 - val_acc: 0.6104\n",
      "Epoch 310/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8534 - acc: 0.6078 - val_loss: 0.8916 - val_acc: 0.6129\n",
      "Epoch 311/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8498 - acc: 0.6097 - val_loss: 0.8910 - val_acc: 0.6141\n",
      "Epoch 312/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8513 - acc: 0.6093 - val_loss: 0.8908 - val_acc: 0.6137\n",
      "Epoch 313/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8491 - acc: 0.6105 - val_loss: 0.8914 - val_acc: 0.6117\n",
      "Epoch 314/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8493 - acc: 0.6114 - val_loss: 0.8928 - val_acc: 0.6140\n",
      "Epoch 315/1000\n",
      "212747/212747 [==============================] - 9s 45us/step - loss: 0.8501 - acc: 0.6106 - val_loss: 0.8898 - val_acc: 0.6138\n",
      "Epoch 316/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8487 - acc: 0.6105 - val_loss: 0.8945 - val_acc: 0.6104\n",
      "Epoch 317/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8495 - acc: 0.6109 - val_loss: 0.8921 - val_acc: 0.6127\n",
      "Epoch 318/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8493 - acc: 0.6106 - val_loss: 0.8906 - val_acc: 0.6139\n",
      "Epoch 319/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8477 - acc: 0.6109 - val_loss: 0.8891 - val_acc: 0.6160\n",
      "Epoch 320/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8480 - acc: 0.6110 - val_loss: 0.8907 - val_acc: 0.6148\n",
      "Epoch 321/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8466 - acc: 0.6131 - val_loss: 0.8937 - val_acc: 0.6161\n",
      "Epoch 322/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8479 - acc: 0.6107 - val_loss: 0.8904 - val_acc: 0.6161\n",
      "Epoch 323/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8467 - acc: 0.6123 - val_loss: 0.8929 - val_acc: 0.6136\n",
      "Epoch 324/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8470 - acc: 0.6114 - val_loss: 0.8894 - val_acc: 0.6169\n",
      "Epoch 325/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8472 - acc: 0.6124 - val_loss: 0.8877 - val_acc: 0.6140\n",
      "Epoch 326/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8457 - acc: 0.6126 - val_loss: 0.8881 - val_acc: 0.6154\n",
      "Epoch 327/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8463 - acc: 0.6113 - val_loss: 0.8879 - val_acc: 0.6155\n",
      "Epoch 328/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8444 - acc: 0.6125 - val_loss: 0.8912 - val_acc: 0.6158\n",
      "Epoch 329/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8453 - acc: 0.6124 - val_loss: 0.8860 - val_acc: 0.6170\n",
      "Epoch 330/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8456 - acc: 0.6121 - val_loss: 0.8909 - val_acc: 0.6150\n",
      "Epoch 331/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8443 - acc: 0.6132 - val_loss: 0.8873 - val_acc: 0.6170\n",
      "Epoch 332/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8448 - acc: 0.6131 - val_loss: 0.8898 - val_acc: 0.6172\n",
      "Epoch 333/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8442 - acc: 0.6130 - val_loss: 0.8903 - val_acc: 0.6136\n",
      "Epoch 334/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8442 - acc: 0.6126 - val_loss: 0.8858 - val_acc: 0.6176\n",
      "Epoch 335/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8451 - acc: 0.6127 - val_loss: 0.8865 - val_acc: 0.6166\n",
      "Epoch 336/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8442 - acc: 0.6144 - val_loss: 0.8859 - val_acc: 0.6207\n",
      "Epoch 337/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8438 - acc: 0.6132 - val_loss: 0.8869 - val_acc: 0.6183\n",
      "Epoch 338/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8434 - acc: 0.6135 - val_loss: 0.8857 - val_acc: 0.6182\n",
      "Epoch 339/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8407 - acc: 0.6153 - val_loss: 0.8885 - val_acc: 0.6185\n",
      "Epoch 340/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8438 - acc: 0.6129 - val_loss: 0.8857 - val_acc: 0.6187\n",
      "Epoch 341/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8442 - acc: 0.6130 - val_loss: 0.8862 - val_acc: 0.6174\n",
      "Epoch 342/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8407 - acc: 0.6159 - val_loss: 0.8867 - val_acc: 0.6180\n",
      "Epoch 343/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8393 - acc: 0.6154 - val_loss: 0.8852 - val_acc: 0.6165\n",
      "Epoch 344/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8414 - acc: 0.6147 - val_loss: 0.8874 - val_acc: 0.6191\n",
      "Epoch 345/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8422 - acc: 0.6152 - val_loss: 0.8921 - val_acc: 0.6156\n",
      "Epoch 346/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8390 - acc: 0.6172 - val_loss: 0.8837 - val_acc: 0.6200\n",
      "Epoch 347/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8404 - acc: 0.6147 - val_loss: 0.8854 - val_acc: 0.6201\n",
      "Epoch 348/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8393 - acc: 0.6150 - val_loss: 0.8830 - val_acc: 0.6220\n",
      "Epoch 349/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8400 - acc: 0.6159 - val_loss: 0.8850 - val_acc: 0.6221\n",
      "Epoch 350/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8391 - acc: 0.6158 - val_loss: 0.8850 - val_acc: 0.6192\n",
      "Epoch 351/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8375 - acc: 0.6178 - val_loss: 0.8868 - val_acc: 0.6215\n",
      "Epoch 352/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8400 - acc: 0.6159 - val_loss: 0.8846 - val_acc: 0.6213\n",
      "Epoch 353/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8370 - acc: 0.6170 - val_loss: 0.8852 - val_acc: 0.6219\n",
      "Epoch 354/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8393 - acc: 0.6164 - val_loss: 0.8821 - val_acc: 0.6227\n",
      "Epoch 355/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.8365 - acc: 0.6171 - val_loss: 0.8830 - val_acc: 0.6214\n",
      "Epoch 356/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8370 - acc: 0.6171 - val_loss: 0.8841 - val_acc: 0.6193\n",
      "Epoch 357/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8376 - acc: 0.6155 - val_loss: 0.8832 - val_acc: 0.6216\n",
      "Epoch 358/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8367 - acc: 0.6166 - val_loss: 0.8839 - val_acc: 0.6221\n",
      "Epoch 359/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8368 - acc: 0.6173 - val_loss: 0.8819 - val_acc: 0.6218\n",
      "Epoch 360/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8367 - acc: 0.6170 - val_loss: 0.8825 - val_acc: 0.6192\n",
      "Epoch 361/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8370 - acc: 0.6169 - val_loss: 0.8805 - val_acc: 0.6215\n",
      "Epoch 362/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8368 - acc: 0.6174 - val_loss: 0.8804 - val_acc: 0.6247\n",
      "Epoch 363/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8352 - acc: 0.6173 - val_loss: 0.8835 - val_acc: 0.6234\n",
      "Epoch 364/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8367 - acc: 0.6180 - val_loss: 0.8818 - val_acc: 0.6231\n",
      "Epoch 365/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8350 - acc: 0.6171 - val_loss: 0.8811 - val_acc: 0.6226\n",
      "Epoch 366/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8349 - acc: 0.6190 - val_loss: 0.8816 - val_acc: 0.6217\n",
      "Epoch 367/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8355 - acc: 0.6186 - val_loss: 0.8806 - val_acc: 0.6214\n",
      "Epoch 368/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8339 - acc: 0.6191 - val_loss: 0.8823 - val_acc: 0.6211\n",
      "Epoch 369/1000\n",
      "212747/212747 [==============================] - 10s 45us/step - loss: 0.8336 - acc: 0.6193 - val_loss: 0.8848 - val_acc: 0.6206\n",
      "Epoch 370/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8322 - acc: 0.6190 - val_loss: 0.8825 - val_acc: 0.6224\n",
      "Epoch 371/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8326 - acc: 0.6198 - val_loss: 0.8810 - val_acc: 0.6225\n",
      "Epoch 372/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8323 - acc: 0.6190 - val_loss: 0.8788 - val_acc: 0.6242\n",
      "Epoch 373/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8330 - acc: 0.6209 - val_loss: 0.8794 - val_acc: 0.6230\n",
      "Epoch 374/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8327 - acc: 0.6190 - val_loss: 0.8829 - val_acc: 0.6228\n",
      "Epoch 375/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8337 - acc: 0.6189 - val_loss: 0.8807 - val_acc: 0.6210\n",
      "Epoch 376/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8320 - acc: 0.6198 - val_loss: 0.8841 - val_acc: 0.6209\n",
      "Epoch 377/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8314 - acc: 0.6205 - val_loss: 0.8787 - val_acc: 0.6270\n",
      "Epoch 378/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8315 - acc: 0.6198 - val_loss: 0.8762 - val_acc: 0.6254\n",
      "Epoch 379/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.8309 - acc: 0.6209 - val_loss: 0.8798 - val_acc: 0.6233\n",
      "Epoch 380/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8306 - acc: 0.6214 - val_loss: 0.8820 - val_acc: 0.6236\n",
      "Epoch 381/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8305 - acc: 0.6210 - val_loss: 0.8764 - val_acc: 0.6280\n",
      "Epoch 382/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8301 - acc: 0.6216 - val_loss: 0.8754 - val_acc: 0.6282\n",
      "Epoch 383/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8305 - acc: 0.6212 - val_loss: 0.8773 - val_acc: 0.6267\n",
      "Epoch 384/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8295 - acc: 0.6225 - val_loss: 0.8765 - val_acc: 0.6259\n",
      "Epoch 385/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8295 - acc: 0.6222 - val_loss: 0.8724 - val_acc: 0.6296\n",
      "Epoch 386/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8294 - acc: 0.6221 - val_loss: 0.8717 - val_acc: 0.6294\n",
      "Epoch 387/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8292 - acc: 0.6211 - val_loss: 0.8732 - val_acc: 0.6256\n",
      "Epoch 388/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8292 - acc: 0.6216 - val_loss: 0.8786 - val_acc: 0.6248\n",
      "Epoch 389/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8278 - acc: 0.6217 - val_loss: 0.8786 - val_acc: 0.6267\n",
      "Epoch 390/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8278 - acc: 0.6222 - val_loss: 0.8760 - val_acc: 0.6300\n",
      "Epoch 391/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8274 - acc: 0.6224 - val_loss: 0.8746 - val_acc: 0.6283\n",
      "Epoch 392/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8274 - acc: 0.6214 - val_loss: 0.8743 - val_acc: 0.6288\n",
      "Epoch 393/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8274 - acc: 0.6217 - val_loss: 0.8803 - val_acc: 0.6253\n",
      "Epoch 394/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8281 - acc: 0.6211 - val_loss: 0.8766 - val_acc: 0.6245\n",
      "Epoch 395/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8255 - acc: 0.6228 - val_loss: 0.8772 - val_acc: 0.6278\n",
      "Epoch 396/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8260 - acc: 0.6233 - val_loss: 0.8736 - val_acc: 0.6300\n",
      "Epoch 397/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8261 - acc: 0.6231 - val_loss: 0.8748 - val_acc: 0.6298\n",
      "Epoch 398/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8249 - acc: 0.6244 - val_loss: 0.8769 - val_acc: 0.6258\n",
      "Epoch 399/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8257 - acc: 0.6236 - val_loss: 0.8761 - val_acc: 0.6291\n",
      "Epoch 400/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8246 - acc: 0.6241 - val_loss: 0.8732 - val_acc: 0.6320\n",
      "Epoch 401/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8252 - acc: 0.6225 - val_loss: 0.8768 - val_acc: 0.6294\n",
      "Epoch 402/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8232 - acc: 0.6245 - val_loss: 0.8759 - val_acc: 0.6276\n",
      "Epoch 403/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8242 - acc: 0.6236 - val_loss: 0.8764 - val_acc: 0.6268\n",
      "Epoch 404/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8256 - acc: 0.6232 - val_loss: 0.8764 - val_acc: 0.6276\n",
      "Epoch 405/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8227 - acc: 0.6234 - val_loss: 0.8784 - val_acc: 0.6288\n",
      "Epoch 406/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.8239 - acc: 0.6245 - val_loss: 0.8748 - val_acc: 0.6287\n",
      "Epoch 407/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8253 - acc: 0.6225 - val_loss: 0.8768 - val_acc: 0.6272\n",
      "Epoch 408/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8245 - acc: 0.6240 - val_loss: 0.8740 - val_acc: 0.6304\n",
      "Epoch 409/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8235 - acc: 0.6248 - val_loss: 0.8726 - val_acc: 0.6291\n",
      "Epoch 410/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8227 - acc: 0.6247 - val_loss: 0.8769 - val_acc: 0.6295\n",
      "Epoch 411/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8229 - acc: 0.6251 - val_loss: 0.8752 - val_acc: 0.6271\n",
      "Epoch 412/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8237 - acc: 0.6248 - val_loss: 0.8714 - val_acc: 0.6302\n",
      "Epoch 413/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8213 - acc: 0.6259 - val_loss: 0.8742 - val_acc: 0.6307\n",
      "Epoch 414/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8217 - acc: 0.6257 - val_loss: 0.8752 - val_acc: 0.6290\n",
      "Epoch 415/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8220 - acc: 0.6256 - val_loss: 0.8724 - val_acc: 0.6306\n",
      "Epoch 416/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8221 - acc: 0.6254 - val_loss: 0.8726 - val_acc: 0.6276\n",
      "Epoch 417/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8226 - acc: 0.6243 - val_loss: 0.8697 - val_acc: 0.6294\n",
      "Epoch 418/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8232 - acc: 0.6242 - val_loss: 0.8757 - val_acc: 0.6290\n",
      "Epoch 419/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8223 - acc: 0.6255 - val_loss: 0.8734 - val_acc: 0.6281\n",
      "Epoch 420/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8197 - acc: 0.6257 - val_loss: 0.8748 - val_acc: 0.6286\n",
      "Epoch 421/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8215 - acc: 0.6251 - val_loss: 0.8743 - val_acc: 0.6293\n",
      "Epoch 422/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8182 - acc: 0.6275 - val_loss: 0.8800 - val_acc: 0.6298\n",
      "Epoch 423/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8193 - acc: 0.6266 - val_loss: 0.8747 - val_acc: 0.6319\n",
      "Epoch 424/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8191 - acc: 0.6272 - val_loss: 0.8728 - val_acc: 0.6295\n",
      "Epoch 425/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8201 - acc: 0.6263 - val_loss: 0.8756 - val_acc: 0.6295\n",
      "Epoch 426/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8198 - acc: 0.6267 - val_loss: 0.8748 - val_acc: 0.6301\n",
      "Epoch 427/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8192 - acc: 0.6267 - val_loss: 0.8696 - val_acc: 0.6323\n",
      "Epoch 428/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8200 - acc: 0.6266 - val_loss: 0.8754 - val_acc: 0.6264\n",
      "Epoch 429/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8189 - acc: 0.6268 - val_loss: 0.8734 - val_acc: 0.6312\n",
      "Epoch 430/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8185 - acc: 0.6275 - val_loss: 0.8700 - val_acc: 0.6322\n",
      "Epoch 431/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.8187 - acc: 0.6276 - val_loss: 0.8764 - val_acc: 0.6291\n",
      "Epoch 432/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8177 - acc: 0.6267 - val_loss: 0.8713 - val_acc: 0.6318\n",
      "Epoch 433/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8184 - acc: 0.6279 - val_loss: 0.8729 - val_acc: 0.6312\n",
      "Epoch 434/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8177 - acc: 0.6276 - val_loss: 0.8704 - val_acc: 0.6331\n",
      "Epoch 435/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8185 - acc: 0.6281 - val_loss: 0.8669 - val_acc: 0.6323\n",
      "Epoch 436/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8162 - acc: 0.6280 - val_loss: 0.8723 - val_acc: 0.6319\n",
      "Epoch 437/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8172 - acc: 0.6281 - val_loss: 0.8690 - val_acc: 0.6348\n",
      "Epoch 438/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8178 - acc: 0.6274 - val_loss: 0.8692 - val_acc: 0.6329\n",
      "Epoch 439/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8157 - acc: 0.6291 - val_loss: 0.8728 - val_acc: 0.6342\n",
      "Epoch 440/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8172 - acc: 0.6283 - val_loss: 0.8731 - val_acc: 0.6316\n",
      "Epoch 441/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8160 - acc: 0.6281 - val_loss: 0.8705 - val_acc: 0.6321\n",
      "Epoch 442/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8170 - acc: 0.6278 - val_loss: 0.8723 - val_acc: 0.6325\n",
      "Epoch 443/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8159 - acc: 0.6285 - val_loss: 0.8687 - val_acc: 0.6321\n",
      "Epoch 444/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8179 - acc: 0.6277 - val_loss: 0.8729 - val_acc: 0.6309\n",
      "Epoch 445/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8130 - acc: 0.6306 - val_loss: 0.8733 - val_acc: 0.6316\n",
      "Epoch 446/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8152 - acc: 0.6287 - val_loss: 0.8716 - val_acc: 0.6327\n",
      "Epoch 447/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8140 - acc: 0.6285 - val_loss: 0.8747 - val_acc: 0.6305\n",
      "Epoch 448/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8147 - acc: 0.6291 - val_loss: 0.8695 - val_acc: 0.6322\n",
      "Epoch 449/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8140 - acc: 0.6296 - val_loss: 0.8712 - val_acc: 0.6307\n",
      "Epoch 450/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8142 - acc: 0.6292 - val_loss: 0.8673 - val_acc: 0.6345\n",
      "Epoch 451/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.8129 - acc: 0.6301 - val_loss: 0.8710 - val_acc: 0.6311\n",
      "Epoch 452/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8127 - acc: 0.6299 - val_loss: 0.8668 - val_acc: 0.6372\n",
      "Epoch 453/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8139 - acc: 0.6302 - val_loss: 0.8675 - val_acc: 0.6344\n",
      "Epoch 454/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8128 - acc: 0.6297 - val_loss: 0.8678 - val_acc: 0.6351\n",
      "Epoch 455/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8123 - acc: 0.6299 - val_loss: 0.8678 - val_acc: 0.6369\n",
      "Epoch 456/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8129 - acc: 0.6308 - val_loss: 0.8685 - val_acc: 0.6328\n",
      "Epoch 457/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8125 - acc: 0.6314 - val_loss: 0.8664 - val_acc: 0.6343\n",
      "Epoch 458/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8096 - acc: 0.6312 - val_loss: 0.8661 - val_acc: 0.6354\n",
      "Epoch 459/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8126 - acc: 0.6311 - val_loss: 0.8664 - val_acc: 0.6326\n",
      "Epoch 460/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8103 - acc: 0.6310 - val_loss: 0.8683 - val_acc: 0.6348\n",
      "Epoch 461/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8105 - acc: 0.6319 - val_loss: 0.8677 - val_acc: 0.6328\n",
      "Epoch 462/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8092 - acc: 0.6324 - val_loss: 0.8658 - val_acc: 0.6354\n",
      "Epoch 463/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8114 - acc: 0.6311 - val_loss: 0.8664 - val_acc: 0.6342\n",
      "Epoch 464/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8125 - acc: 0.6302 - val_loss: 0.8649 - val_acc: 0.6328\n",
      "Epoch 465/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8108 - acc: 0.6309 - val_loss: 0.8620 - val_acc: 0.6383\n",
      "Epoch 466/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8086 - acc: 0.6319 - val_loss: 0.8624 - val_acc: 0.6381\n",
      "Epoch 467/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.8125 - acc: 0.6307 - val_loss: 0.8656 - val_acc: 0.6337\n",
      "Epoch 468/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8107 - acc: 0.6314 - val_loss: 0.8654 - val_acc: 0.6337\n",
      "Epoch 469/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8105 - acc: 0.6319 - val_loss: 0.8647 - val_acc: 0.6348\n",
      "Epoch 470/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8087 - acc: 0.6328 - val_loss: 0.8655 - val_acc: 0.6333\n",
      "Epoch 471/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8083 - acc: 0.6320 - val_loss: 0.8697 - val_acc: 0.6351\n",
      "Epoch 472/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8084 - acc: 0.6313 - val_loss: 0.8648 - val_acc: 0.6362\n",
      "Epoch 473/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8088 - acc: 0.6328 - val_loss: 0.8639 - val_acc: 0.6395\n",
      "Epoch 474/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8072 - acc: 0.6333 - val_loss: 0.8625 - val_acc: 0.6373\n",
      "Epoch 475/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8087 - acc: 0.6321 - val_loss: 0.8605 - val_acc: 0.6397\n",
      "Epoch 476/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8073 - acc: 0.6332 - val_loss: 0.8647 - val_acc: 0.6354\n",
      "Epoch 477/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8080 - acc: 0.6319 - val_loss: 0.8613 - val_acc: 0.6387\n",
      "Epoch 478/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8084 - acc: 0.6327 - val_loss: 0.8655 - val_acc: 0.6365\n",
      "Epoch 479/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8072 - acc: 0.6337 - val_loss: 0.8614 - val_acc: 0.6398\n",
      "Epoch 480/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8094 - acc: 0.6331 - val_loss: 0.8620 - val_acc: 0.6375\n",
      "Epoch 481/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8083 - acc: 0.6328 - val_loss: 0.8682 - val_acc: 0.6339\n",
      "Epoch 482/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8076 - acc: 0.6324 - val_loss: 0.8653 - val_acc: 0.6383\n",
      "Epoch 483/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8051 - acc: 0.6337 - val_loss: 0.8631 - val_acc: 0.6397\n",
      "Epoch 484/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8068 - acc: 0.6337 - val_loss: 0.8629 - val_acc: 0.6410\n",
      "Epoch 485/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8076 - acc: 0.6330 - val_loss: 0.8628 - val_acc: 0.6389\n",
      "Epoch 486/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8063 - acc: 0.6331 - val_loss: 0.8624 - val_acc: 0.6404\n",
      "Epoch 487/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8071 - acc: 0.6343 - val_loss: 0.8629 - val_acc: 0.6397\n",
      "Epoch 488/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8056 - acc: 0.6331 - val_loss: 0.8630 - val_acc: 0.6392\n",
      "Epoch 489/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8061 - acc: 0.6339 - val_loss: 0.8649 - val_acc: 0.6383\n",
      "Epoch 490/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8041 - acc: 0.6342 - val_loss: 0.8637 - val_acc: 0.6391\n",
      "Epoch 491/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8064 - acc: 0.6336 - val_loss: 0.8615 - val_acc: 0.6382\n",
      "Epoch 492/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8047 - acc: 0.6350 - val_loss: 0.8606 - val_acc: 0.6408\n",
      "Epoch 493/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8041 - acc: 0.6352 - val_loss: 0.8620 - val_acc: 0.6395\n",
      "Epoch 494/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8041 - acc: 0.6357 - val_loss: 0.8618 - val_acc: 0.6397\n",
      "Epoch 495/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8040 - acc: 0.6354 - val_loss: 0.8608 - val_acc: 0.6403\n",
      "Epoch 496/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8034 - acc: 0.6337 - val_loss: 0.8643 - val_acc: 0.6333\n",
      "Epoch 497/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8046 - acc: 0.6353 - val_loss: 0.8604 - val_acc: 0.6394\n",
      "Epoch 498/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.8024 - acc: 0.6356 - val_loss: 0.8589 - val_acc: 0.6385\n",
      "Epoch 499/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.8050 - acc: 0.6340 - val_loss: 0.8579 - val_acc: 0.6428\n",
      "Epoch 500/1000\n",
      "212747/212747 [==============================] - 9s 40us/step - loss: 0.8031 - acc: 0.6353 - val_loss: 0.8645 - val_acc: 0.6391\n",
      "Epoch 501/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8018 - acc: 0.6366 - val_loss: 0.8600 - val_acc: 0.6422\n",
      "Epoch 502/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8032 - acc: 0.6367 - val_loss: 0.8616 - val_acc: 0.6429\n",
      "Epoch 503/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8025 - acc: 0.6351 - val_loss: 0.8603 - val_acc: 0.6410\n",
      "Epoch 504/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8044 - acc: 0.6357 - val_loss: 0.8624 - val_acc: 0.6436\n",
      "Epoch 505/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8021 - acc: 0.6356 - val_loss: 0.8594 - val_acc: 0.6400\n",
      "Epoch 506/1000\n",
      "212747/212747 [==============================] - 10s 45us/step - loss: 0.8018 - acc: 0.6357 - val_loss: 0.8610 - val_acc: 0.6400\n",
      "Epoch 507/1000\n",
      "212747/212747 [==============================] - 10s 45us/step - loss: 0.8026 - acc: 0.6364 - val_loss: 0.8613 - val_acc: 0.6397\n",
      "Epoch 508/1000\n",
      "212747/212747 [==============================] - 10s 45us/step - loss: 0.8027 - acc: 0.6348 - val_loss: 0.8628 - val_acc: 0.6382\n",
      "Epoch 509/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7986 - acc: 0.6369 - val_loss: 0.8594 - val_acc: 0.6421\n",
      "Epoch 510/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8013 - acc: 0.6358 - val_loss: 0.8603 - val_acc: 0.6416\n",
      "Epoch 511/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8008 - acc: 0.6364 - val_loss: 0.8589 - val_acc: 0.6434\n",
      "Epoch 512/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8022 - acc: 0.6366 - val_loss: 0.8606 - val_acc: 0.6422\n",
      "Epoch 513/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.8026 - acc: 0.6348 - val_loss: 0.8575 - val_acc: 0.6434\n",
      "Epoch 514/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8013 - acc: 0.6369 - val_loss: 0.8564 - val_acc: 0.6432\n",
      "Epoch 515/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.8004 - acc: 0.6372 - val_loss: 0.8613 - val_acc: 0.6434\n",
      "Epoch 516/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8006 - acc: 0.6370 - val_loss: 0.8571 - val_acc: 0.6421\n",
      "Epoch 517/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8007 - acc: 0.6369 - val_loss: 0.8617 - val_acc: 0.6420\n",
      "Epoch 518/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7979 - acc: 0.6381 - val_loss: 0.8578 - val_acc: 0.6415\n",
      "Epoch 519/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.8003 - acc: 0.6364 - val_loss: 0.8587 - val_acc: 0.6428\n",
      "Epoch 520/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.7988 - acc: 0.6372 - val_loss: 0.8607 - val_acc: 0.6404\n",
      "Epoch 521/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7988 - acc: 0.6368 - val_loss: 0.8591 - val_acc: 0.6391\n",
      "Epoch 522/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.8001 - acc: 0.6371 - val_loss: 0.8529 - val_acc: 0.6432\n",
      "Epoch 523/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.7990 - acc: 0.6363 - val_loss: 0.8587 - val_acc: 0.6412\n",
      "Epoch 524/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7994 - acc: 0.6379 - val_loss: 0.8571 - val_acc: 0.6440\n",
      "Epoch 525/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7984 - acc: 0.6383 - val_loss: 0.8539 - val_acc: 0.6441\n",
      "Epoch 526/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7974 - acc: 0.6391 - val_loss: 0.8598 - val_acc: 0.6427\n",
      "Epoch 527/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7972 - acc: 0.6380 - val_loss: 0.8554 - val_acc: 0.6435\n",
      "Epoch 528/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7986 - acc: 0.6389 - val_loss: 0.8571 - val_acc: 0.6421\n",
      "Epoch 529/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7970 - acc: 0.6387 - val_loss: 0.8657 - val_acc: 0.6371\n",
      "Epoch 530/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7992 - acc: 0.6380 - val_loss: 0.8602 - val_acc: 0.6420\n",
      "Epoch 531/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7986 - acc: 0.6380 - val_loss: 0.8580 - val_acc: 0.6420\n",
      "Epoch 532/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7963 - acc: 0.6389 - val_loss: 0.8588 - val_acc: 0.6442\n",
      "Epoch 533/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7980 - acc: 0.6382 - val_loss: 0.8562 - val_acc: 0.6426\n",
      "Epoch 534/1000\n",
      "212747/212747 [==============================] - 9s 45us/step - loss: 0.7973 - acc: 0.6392 - val_loss: 0.8561 - val_acc: 0.6438\n",
      "Epoch 535/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7969 - acc: 0.6389 - val_loss: 0.8584 - val_acc: 0.6425\n",
      "Epoch 536/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7965 - acc: 0.6395 - val_loss: 0.8555 - val_acc: 0.6430\n",
      "Epoch 537/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7983 - acc: 0.6388 - val_loss: 0.8672 - val_acc: 0.6402\n",
      "Epoch 538/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7964 - acc: 0.6385 - val_loss: 0.8582 - val_acc: 0.6444\n",
      "Epoch 539/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7944 - acc: 0.6393 - val_loss: 0.8589 - val_acc: 0.6449\n",
      "Epoch 540/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7955 - acc: 0.6398 - val_loss: 0.8523 - val_acc: 0.6448\n",
      "Epoch 541/1000\n",
      "212747/212747 [==============================] - 10s 45us/step - loss: 0.7967 - acc: 0.6379 - val_loss: 0.8587 - val_acc: 0.6454\n",
      "Epoch 542/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7957 - acc: 0.6385 - val_loss: 0.8571 - val_acc: 0.6442\n",
      "Epoch 543/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7973 - acc: 0.6383 - val_loss: 0.8559 - val_acc: 0.6453\n",
      "Epoch 544/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7958 - acc: 0.6382 - val_loss: 0.8549 - val_acc: 0.6441\n",
      "Epoch 545/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7958 - acc: 0.6390 - val_loss: 0.8535 - val_acc: 0.6422\n",
      "Epoch 546/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7942 - acc: 0.6395 - val_loss: 0.8555 - val_acc: 0.6451\n",
      "Epoch 547/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7944 - acc: 0.6389 - val_loss: 0.8548 - val_acc: 0.6444\n",
      "Epoch 548/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7942 - acc: 0.6387 - val_loss: 0.8546 - val_acc: 0.6434\n",
      "Epoch 549/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7944 - acc: 0.6408 - val_loss: 0.8538 - val_acc: 0.6438\n",
      "Epoch 550/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7939 - acc: 0.6405 - val_loss: 0.8546 - val_acc: 0.6471\n",
      "Epoch 551/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7946 - acc: 0.6392 - val_loss: 0.8534 - val_acc: 0.6464\n",
      "Epoch 552/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7946 - acc: 0.6395 - val_loss: 0.8569 - val_acc: 0.6441\n",
      "Epoch 553/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7953 - acc: 0.6406 - val_loss: 0.8547 - val_acc: 0.6445\n",
      "Epoch 554/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7932 - acc: 0.6402 - val_loss: 0.8564 - val_acc: 0.6455\n",
      "Epoch 555/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7933 - acc: 0.6407 - val_loss: 0.8509 - val_acc: 0.6425\n",
      "Epoch 556/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7949 - acc: 0.6399 - val_loss: 0.8522 - val_acc: 0.6456\n",
      "Epoch 557/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7925 - acc: 0.6411 - val_loss: 0.8512 - val_acc: 0.6469\n",
      "Epoch 558/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7943 - acc: 0.6405 - val_loss: 0.8536 - val_acc: 0.6464\n",
      "Epoch 559/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7926 - acc: 0.6406 - val_loss: 0.8520 - val_acc: 0.6456\n",
      "Epoch 560/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7928 - acc: 0.6404 - val_loss: 0.8512 - val_acc: 0.6476\n",
      "Epoch 561/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7916 - acc: 0.6410 - val_loss: 0.8553 - val_acc: 0.6446\n",
      "Epoch 562/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7919 - acc: 0.6407 - val_loss: 0.8521 - val_acc: 0.6504\n",
      "Epoch 563/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7925 - acc: 0.6413 - val_loss: 0.8532 - val_acc: 0.6437\n",
      "Epoch 564/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7920 - acc: 0.6410 - val_loss: 0.8556 - val_acc: 0.6452\n",
      "Epoch 565/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7901 - acc: 0.6423 - val_loss: 0.8510 - val_acc: 0.6457\n",
      "Epoch 566/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7924 - acc: 0.6409 - val_loss: 0.8521 - val_acc: 0.6464\n",
      "Epoch 567/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7927 - acc: 0.6403 - val_loss: 0.8533 - val_acc: 0.6474\n",
      "Epoch 568/1000\n",
      "212747/212747 [==============================] - 10s 45us/step - loss: 0.7906 - acc: 0.6431 - val_loss: 0.8508 - val_acc: 0.6500\n",
      "Epoch 569/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7917 - acc: 0.6412 - val_loss: 0.8532 - val_acc: 0.6502\n",
      "Epoch 570/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7904 - acc: 0.6435 - val_loss: 0.8548 - val_acc: 0.6478\n",
      "Epoch 571/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7895 - acc: 0.6425 - val_loss: 0.8525 - val_acc: 0.6475\n",
      "Epoch 572/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7920 - acc: 0.6411 - val_loss: 0.8535 - val_acc: 0.6468\n",
      "Epoch 573/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7939 - acc: 0.6411 - val_loss: 0.8485 - val_acc: 0.6481\n",
      "Epoch 574/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7909 - acc: 0.6431 - val_loss: 0.8503 - val_acc: 0.6463\n",
      "Epoch 575/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7906 - acc: 0.6430 - val_loss: 0.8504 - val_acc: 0.6460\n",
      "Epoch 576/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7900 - acc: 0.6416 - val_loss: 0.8509 - val_acc: 0.6469\n",
      "Epoch 577/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7886 - acc: 0.6436 - val_loss: 0.8461 - val_acc: 0.6478\n",
      "Epoch 578/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7883 - acc: 0.6434 - val_loss: 0.8499 - val_acc: 0.6479\n",
      "Epoch 579/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7902 - acc: 0.6416 - val_loss: 0.8527 - val_acc: 0.6488\n",
      "Epoch 580/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7913 - acc: 0.6421 - val_loss: 0.8516 - val_acc: 0.6485\n",
      "Epoch 581/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7885 - acc: 0.6435 - val_loss: 0.8523 - val_acc: 0.6485\n",
      "Epoch 582/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7896 - acc: 0.6432 - val_loss: 0.8517 - val_acc: 0.6484\n",
      "Epoch 583/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7898 - acc: 0.6428 - val_loss: 0.8498 - val_acc: 0.6484\n",
      "Epoch 584/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7873 - acc: 0.6439 - val_loss: 0.8543 - val_acc: 0.6501\n",
      "Epoch 585/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7901 - acc: 0.6431 - val_loss: 0.8508 - val_acc: 0.6495\n",
      "Epoch 586/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7901 - acc: 0.6421 - val_loss: 0.8526 - val_acc: 0.6488\n",
      "Epoch 587/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7874 - acc: 0.6434 - val_loss: 0.8485 - val_acc: 0.6489\n",
      "Epoch 588/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7879 - acc: 0.6434 - val_loss: 0.8505 - val_acc: 0.6500\n",
      "Epoch 589/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7887 - acc: 0.6431 - val_loss: 0.8542 - val_acc: 0.6463\n",
      "Epoch 590/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7887 - acc: 0.6418 - val_loss: 0.8502 - val_acc: 0.6496\n",
      "Epoch 591/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7865 - acc: 0.6431 - val_loss: 0.8574 - val_acc: 0.6467\n",
      "Epoch 592/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7873 - acc: 0.6430 - val_loss: 0.8497 - val_acc: 0.6498\n",
      "Epoch 593/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7885 - acc: 0.6437 - val_loss: 0.8507 - val_acc: 0.6484\n",
      "Epoch 594/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7867 - acc: 0.6447 - val_loss: 0.8469 - val_acc: 0.6501\n",
      "Epoch 595/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7856 - acc: 0.6435 - val_loss: 0.8502 - val_acc: 0.6504\n",
      "Epoch 596/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7890 - acc: 0.6431 - val_loss: 0.8517 - val_acc: 0.6486\n",
      "Epoch 597/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7869 - acc: 0.6450 - val_loss: 0.8514 - val_acc: 0.6494\n",
      "Epoch 598/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7861 - acc: 0.6446 - val_loss: 0.8414 - val_acc: 0.6524\n",
      "Epoch 599/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7855 - acc: 0.6446 - val_loss: 0.8477 - val_acc: 0.6535\n",
      "Epoch 600/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7846 - acc: 0.6458 - val_loss: 0.8512 - val_acc: 0.6482\n",
      "Epoch 601/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7861 - acc: 0.6446 - val_loss: 0.8483 - val_acc: 0.6490\n",
      "Epoch 602/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7869 - acc: 0.6439 - val_loss: 0.8448 - val_acc: 0.6521\n",
      "Epoch 603/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7857 - acc: 0.6449 - val_loss: 0.8450 - val_acc: 0.6493\n",
      "Epoch 604/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7848 - acc: 0.6456 - val_loss: 0.8480 - val_acc: 0.6513\n",
      "Epoch 605/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7887 - acc: 0.6442 - val_loss: 0.8499 - val_acc: 0.6495\n",
      "Epoch 606/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7852 - acc: 0.6444 - val_loss: 0.8479 - val_acc: 0.6502\n",
      "Epoch 607/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7846 - acc: 0.6450 - val_loss: 0.8474 - val_acc: 0.6530\n",
      "Epoch 608/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7862 - acc: 0.6442 - val_loss: 0.8496 - val_acc: 0.6521\n",
      "Epoch 609/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7856 - acc: 0.6446 - val_loss: 0.8491 - val_acc: 0.6519\n",
      "Epoch 610/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7838 - acc: 0.6452 - val_loss: 0.8501 - val_acc: 0.6495\n",
      "Epoch 611/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7860 - acc: 0.6451 - val_loss: 0.8507 - val_acc: 0.6511\n",
      "Epoch 612/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7859 - acc: 0.6440 - val_loss: 0.8503 - val_acc: 0.6490\n",
      "Epoch 613/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7855 - acc: 0.6451 - val_loss: 0.8469 - val_acc: 0.6536\n",
      "Epoch 614/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7848 - acc: 0.6454 - val_loss: 0.8505 - val_acc: 0.6490\n",
      "Epoch 615/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7840 - acc: 0.6455 - val_loss: 0.8477 - val_acc: 0.6540\n",
      "Epoch 616/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7834 - acc: 0.6454 - val_loss: 0.8506 - val_acc: 0.6512\n",
      "Epoch 617/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7823 - acc: 0.6461 - val_loss: 0.8463 - val_acc: 0.6535\n",
      "Epoch 618/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7828 - acc: 0.6471 - val_loss: 0.8489 - val_acc: 0.6509\n",
      "Epoch 619/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7830 - acc: 0.6456 - val_loss: 0.8471 - val_acc: 0.6496\n",
      "Epoch 620/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7849 - acc: 0.6449 - val_loss: 0.8465 - val_acc: 0.6515\n",
      "Epoch 621/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7829 - acc: 0.6469 - val_loss: 0.8457 - val_acc: 0.6531\n",
      "Epoch 622/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7832 - acc: 0.6465 - val_loss: 0.8449 - val_acc: 0.6524\n",
      "Epoch 623/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7816 - acc: 0.6471 - val_loss: 0.8479 - val_acc: 0.6515\n",
      "Epoch 624/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7812 - acc: 0.6468 - val_loss: 0.8470 - val_acc: 0.6510\n",
      "Epoch 625/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7855 - acc: 0.6464 - val_loss: 0.8438 - val_acc: 0.6520\n",
      "Epoch 626/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7826 - acc: 0.6465 - val_loss: 0.8420 - val_acc: 0.6530\n",
      "Epoch 627/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7815 - acc: 0.6474 - val_loss: 0.8463 - val_acc: 0.6535\n",
      "Epoch 628/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7813 - acc: 0.6472 - val_loss: 0.8459 - val_acc: 0.6528\n",
      "Epoch 629/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7823 - acc: 0.6464 - val_loss: 0.8472 - val_acc: 0.6529\n",
      "Epoch 630/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7813 - acc: 0.6458 - val_loss: 0.8412 - val_acc: 0.6528\n",
      "Epoch 631/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7811 - acc: 0.6472 - val_loss: 0.8464 - val_acc: 0.6519\n",
      "Epoch 632/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7817 - acc: 0.6470 - val_loss: 0.8444 - val_acc: 0.6517\n",
      "Epoch 633/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7824 - acc: 0.6474 - val_loss: 0.8406 - val_acc: 0.6529\n",
      "Epoch 634/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7812 - acc: 0.6472 - val_loss: 0.8446 - val_acc: 0.6507\n",
      "Epoch 635/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7809 - acc: 0.6472 - val_loss: 0.8431 - val_acc: 0.6518\n",
      "Epoch 636/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7810 - acc: 0.6470 - val_loss: 0.8449 - val_acc: 0.6515\n",
      "Epoch 637/1000\n",
      "212747/212747 [==============================] - 9s 45us/step - loss: 0.7800 - acc: 0.6478 - val_loss: 0.8419 - val_acc: 0.6550\n",
      "Epoch 638/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7790 - acc: 0.6473 - val_loss: 0.8469 - val_acc: 0.6519\n",
      "Epoch 639/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7789 - acc: 0.6483 - val_loss: 0.8476 - val_acc: 0.6537\n",
      "Epoch 640/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7795 - acc: 0.6487 - val_loss: 0.8424 - val_acc: 0.6548\n",
      "Epoch 641/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7787 - acc: 0.6482 - val_loss: 0.8492 - val_acc: 0.6518\n",
      "Epoch 642/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7785 - acc: 0.6492 - val_loss: 0.8444 - val_acc: 0.6554\n",
      "Epoch 643/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7816 - acc: 0.6471 - val_loss: 0.8399 - val_acc: 0.6563\n",
      "Epoch 644/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7797 - acc: 0.6480 - val_loss: 0.8450 - val_acc: 0.6550\n",
      "Epoch 645/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7816 - acc: 0.6480 - val_loss: 0.8405 - val_acc: 0.6545\n",
      "Epoch 646/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7783 - acc: 0.6479 - val_loss: 0.8450 - val_acc: 0.6564\n",
      "Epoch 647/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7793 - acc: 0.6486 - val_loss: 0.8435 - val_acc: 0.6549\n",
      "Epoch 648/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7790 - acc: 0.6466 - val_loss: 0.8446 - val_acc: 0.6505\n",
      "Epoch 649/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7763 - acc: 0.6492 - val_loss: 0.8429 - val_acc: 0.6542\n",
      "Epoch 650/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7772 - acc: 0.6485 - val_loss: 0.8433 - val_acc: 0.6544\n",
      "Epoch 651/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7786 - acc: 0.6482 - val_loss: 0.8396 - val_acc: 0.6554\n",
      "Epoch 652/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7786 - acc: 0.6486 - val_loss: 0.8388 - val_acc: 0.6566\n",
      "Epoch 653/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7784 - acc: 0.6478 - val_loss: 0.8444 - val_acc: 0.6518\n",
      "Epoch 654/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7770 - acc: 0.6495 - val_loss: 0.8384 - val_acc: 0.6572\n",
      "Epoch 655/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7773 - acc: 0.6494 - val_loss: 0.8415 - val_acc: 0.6557\n",
      "Epoch 656/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7782 - acc: 0.6494 - val_loss: 0.8372 - val_acc: 0.6581\n",
      "Epoch 657/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7759 - acc: 0.6500 - val_loss: 0.8420 - val_acc: 0.6546\n",
      "Epoch 658/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7766 - acc: 0.6492 - val_loss: 0.8429 - val_acc: 0.6560\n",
      "Epoch 659/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7781 - acc: 0.6483 - val_loss: 0.8448 - val_acc: 0.6579\n",
      "Epoch 660/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7745 - acc: 0.6503 - val_loss: 0.8416 - val_acc: 0.6560\n",
      "Epoch 661/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7786 - acc: 0.6483 - val_loss: 0.8394 - val_acc: 0.6549\n",
      "Epoch 662/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7778 - acc: 0.6495 - val_loss: 0.8387 - val_acc: 0.6565\n",
      "Epoch 663/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7774 - acc: 0.6496 - val_loss: 0.8452 - val_acc: 0.6553\n",
      "Epoch 664/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7758 - acc: 0.6489 - val_loss: 0.8426 - val_acc: 0.6548\n",
      "Epoch 665/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7756 - acc: 0.6492 - val_loss: 0.8439 - val_acc: 0.6576\n",
      "Epoch 666/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7781 - acc: 0.6494 - val_loss: 0.8393 - val_acc: 0.6574\n",
      "Epoch 667/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7758 - acc: 0.6498 - val_loss: 0.8427 - val_acc: 0.6562\n",
      "Epoch 668/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7756 - acc: 0.6499 - val_loss: 0.8379 - val_acc: 0.6580\n",
      "Epoch 669/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7752 - acc: 0.6503 - val_loss: 0.8416 - val_acc: 0.6565\n",
      "Epoch 670/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.7772 - acc: 0.6501 - val_loss: 0.8411 - val_acc: 0.6541\n",
      "Epoch 671/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7755 - acc: 0.6504 - val_loss: 0.8381 - val_acc: 0.6558\n",
      "Epoch 672/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7769 - acc: 0.6495 - val_loss: 0.8463 - val_acc: 0.6556\n",
      "Epoch 673/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7750 - acc: 0.6504 - val_loss: 0.8398 - val_acc: 0.6577\n",
      "Epoch 674/1000\n",
      "212747/212747 [==============================] - 9s 40us/step - loss: 0.7777 - acc: 0.6485 - val_loss: 0.8368 - val_acc: 0.6586\n",
      "Epoch 675/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7748 - acc: 0.6513 - val_loss: 0.8431 - val_acc: 0.6566\n",
      "Epoch 676/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7756 - acc: 0.6495 - val_loss: 0.8422 - val_acc: 0.6545\n",
      "Epoch 677/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7763 - acc: 0.6502 - val_loss: 0.8402 - val_acc: 0.6583\n",
      "Epoch 678/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7740 - acc: 0.6507 - val_loss: 0.8402 - val_acc: 0.6565\n",
      "Epoch 679/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7744 - acc: 0.6509 - val_loss: 0.8440 - val_acc: 0.6568\n",
      "Epoch 680/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7744 - acc: 0.6515 - val_loss: 0.8405 - val_acc: 0.6574\n",
      "Epoch 681/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7735 - acc: 0.6504 - val_loss: 0.8389 - val_acc: 0.6588\n",
      "Epoch 682/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7760 - acc: 0.6498 - val_loss: 0.8388 - val_acc: 0.6594\n",
      "Epoch 683/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7757 - acc: 0.6511 - val_loss: 0.8430 - val_acc: 0.6558\n",
      "Epoch 684/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7760 - acc: 0.6510 - val_loss: 0.8372 - val_acc: 0.6580\n",
      "Epoch 685/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7755 - acc: 0.6491 - val_loss: 0.8358 - val_acc: 0.6610\n",
      "Epoch 686/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7747 - acc: 0.6511 - val_loss: 0.8376 - val_acc: 0.6578\n",
      "Epoch 687/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7765 - acc: 0.6501 - val_loss: 0.8384 - val_acc: 0.6569\n",
      "Epoch 688/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7727 - acc: 0.6523 - val_loss: 0.8411 - val_acc: 0.6579\n",
      "Epoch 689/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7724 - acc: 0.6525 - val_loss: 0.8390 - val_acc: 0.6597\n",
      "Epoch 690/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7725 - acc: 0.6514 - val_loss: 0.8392 - val_acc: 0.6583\n",
      "Epoch 691/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7732 - acc: 0.6504 - val_loss: 0.8492 - val_acc: 0.6578\n",
      "Epoch 692/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7729 - acc: 0.6513 - val_loss: 0.8390 - val_acc: 0.6561\n",
      "Epoch 693/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7728 - acc: 0.6516 - val_loss: 0.8463 - val_acc: 0.6588\n",
      "Epoch 694/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7728 - acc: 0.6516 - val_loss: 0.8424 - val_acc: 0.6571\n",
      "Epoch 695/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.7735 - acc: 0.6509 - val_loss: 0.8372 - val_acc: 0.6585\n",
      "Epoch 696/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7734 - acc: 0.6512 - val_loss: 0.8402 - val_acc: 0.6555\n",
      "Epoch 697/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.7718 - acc: 0.6523 - val_loss: 0.8400 - val_acc: 0.6576\n",
      "Epoch 698/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.7725 - acc: 0.6518 - val_loss: 0.8420 - val_acc: 0.6582\n",
      "Epoch 699/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7697 - acc: 0.6538 - val_loss: 0.8422 - val_acc: 0.6560\n",
      "Epoch 700/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7712 - acc: 0.6537 - val_loss: 0.8393 - val_acc: 0.6585\n",
      "Epoch 701/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7717 - acc: 0.6520 - val_loss: 0.8365 - val_acc: 0.6580\n",
      "Epoch 702/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7724 - acc: 0.6521 - val_loss: 0.8364 - val_acc: 0.6579\n",
      "Epoch 703/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7707 - acc: 0.6515 - val_loss: 0.8389 - val_acc: 0.6603\n",
      "Epoch 704/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7715 - acc: 0.6524 - val_loss: 0.8401 - val_acc: 0.6619\n",
      "Epoch 705/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7722 - acc: 0.6520 - val_loss: 0.8368 - val_acc: 0.6593\n",
      "Epoch 706/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7709 - acc: 0.6536 - val_loss: 0.8397 - val_acc: 0.6577\n",
      "Epoch 707/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7714 - acc: 0.6533 - val_loss: 0.8372 - val_acc: 0.6615\n",
      "Epoch 708/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7720 - acc: 0.6522 - val_loss: 0.8381 - val_acc: 0.6581\n",
      "Epoch 709/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7718 - acc: 0.6525 - val_loss: 0.8389 - val_acc: 0.6601\n",
      "Epoch 710/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7704 - acc: 0.6530 - val_loss: 0.8418 - val_acc: 0.6590\n",
      "Epoch 711/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7691 - acc: 0.6519 - val_loss: 0.8378 - val_acc: 0.6613\n",
      "Epoch 712/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7722 - acc: 0.6515 - val_loss: 0.8381 - val_acc: 0.6605\n",
      "Epoch 713/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7690 - acc: 0.6542 - val_loss: 0.8360 - val_acc: 0.6593\n",
      "Epoch 714/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7693 - acc: 0.6536 - val_loss: 0.8393 - val_acc: 0.6573\n",
      "Epoch 715/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7727 - acc: 0.6513 - val_loss: 0.8401 - val_acc: 0.6602\n",
      "Epoch 716/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7696 - acc: 0.6538 - val_loss: 0.8363 - val_acc: 0.6591\n",
      "Epoch 717/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7720 - acc: 0.6525 - val_loss: 0.8399 - val_acc: 0.6611\n",
      "Epoch 718/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7704 - acc: 0.6541 - val_loss: 0.8359 - val_acc: 0.6604\n",
      "Epoch 719/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7692 - acc: 0.6531 - val_loss: 0.8374 - val_acc: 0.6592\n",
      "Epoch 720/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7685 - acc: 0.6538 - val_loss: 0.8391 - val_acc: 0.6596\n",
      "Epoch 721/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7709 - acc: 0.6531 - val_loss: 0.8349 - val_acc: 0.6605\n",
      "Epoch 722/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7698 - acc: 0.6523 - val_loss: 0.8353 - val_acc: 0.6598\n",
      "Epoch 723/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7697 - acc: 0.6535 - val_loss: 0.8408 - val_acc: 0.6569\n",
      "Epoch 724/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7683 - acc: 0.6544 - val_loss: 0.8364 - val_acc: 0.6616\n",
      "Epoch 725/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7699 - acc: 0.6536 - val_loss: 0.8360 - val_acc: 0.6600\n",
      "Epoch 726/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7679 - acc: 0.6544 - val_loss: 0.8354 - val_acc: 0.6578\n",
      "Epoch 727/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7686 - acc: 0.6532 - val_loss: 0.8387 - val_acc: 0.6585\n",
      "Epoch 728/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7679 - acc: 0.6535 - val_loss: 0.8402 - val_acc: 0.6608\n",
      "Epoch 729/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7677 - acc: 0.6543 - val_loss: 0.8372 - val_acc: 0.6594\n",
      "Epoch 730/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7692 - acc: 0.6531 - val_loss: 0.8344 - val_acc: 0.6597\n",
      "Epoch 731/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7681 - acc: 0.6549 - val_loss: 0.8297 - val_acc: 0.6618\n",
      "Epoch 732/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7669 - acc: 0.6553 - val_loss: 0.8309 - val_acc: 0.6624\n",
      "Epoch 733/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7683 - acc: 0.6535 - val_loss: 0.8361 - val_acc: 0.6608\n",
      "Epoch 734/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.7681 - acc: 0.6551 - val_loss: 0.8346 - val_acc: 0.6614\n",
      "Epoch 735/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7663 - acc: 0.6550 - val_loss: 0.8340 - val_acc: 0.6641\n",
      "Epoch 736/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7707 - acc: 0.6531 - val_loss: 0.8345 - val_acc: 0.6588\n",
      "Epoch 737/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7693 - acc: 0.6539 - val_loss: 0.8297 - val_acc: 0.6600\n",
      "Epoch 738/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7665 - acc: 0.6556 - val_loss: 0.8298 - val_acc: 0.6602\n",
      "Epoch 739/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7665 - acc: 0.6550 - val_loss: 0.8311 - val_acc: 0.6609\n",
      "Epoch 740/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7668 - acc: 0.6542 - val_loss: 0.8362 - val_acc: 0.6620\n",
      "Epoch 741/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7661 - acc: 0.6559 - val_loss: 0.8380 - val_acc: 0.6614\n",
      "Epoch 742/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7663 - acc: 0.6549 - val_loss: 0.8334 - val_acc: 0.6571\n",
      "Epoch 743/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7665 - acc: 0.6551 - val_loss: 0.8328 - val_acc: 0.6621\n",
      "Epoch 744/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7667 - acc: 0.6545 - val_loss: 0.8370 - val_acc: 0.6593\n",
      "Epoch 745/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7670 - acc: 0.6551 - val_loss: 0.8343 - val_acc: 0.6602\n",
      "Epoch 746/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7666 - acc: 0.6553 - val_loss: 0.8349 - val_acc: 0.6608\n",
      "Epoch 747/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7665 - acc: 0.6550 - val_loss: 0.8368 - val_acc: 0.6624\n",
      "Epoch 748/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7647 - acc: 0.6560 - val_loss: 0.8312 - val_acc: 0.6620\n",
      "Epoch 749/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7667 - acc: 0.6556 - val_loss: 0.8313 - val_acc: 0.6595\n",
      "Epoch 750/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7690 - acc: 0.6546 - val_loss: 0.8333 - val_acc: 0.6606\n",
      "Epoch 751/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7669 - acc: 0.6545 - val_loss: 0.8372 - val_acc: 0.6603\n",
      "Epoch 752/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7644 - acc: 0.6554 - val_loss: 0.8330 - val_acc: 0.6618\n",
      "Epoch 753/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7658 - acc: 0.6554 - val_loss: 0.8323 - val_acc: 0.6627\n",
      "Epoch 754/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7665 - acc: 0.6556 - val_loss: 0.8375 - val_acc: 0.6608\n",
      "Epoch 755/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7661 - acc: 0.6560 - val_loss: 0.8363 - val_acc: 0.6610\n",
      "Epoch 756/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7645 - acc: 0.6555 - val_loss: 0.8361 - val_acc: 0.6614\n",
      "Epoch 757/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7646 - acc: 0.6559 - val_loss: 0.8345 - val_acc: 0.6607\n",
      "Epoch 758/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7667 - acc: 0.6548 - val_loss: 0.8372 - val_acc: 0.6613\n",
      "Epoch 759/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7625 - acc: 0.6563 - val_loss: 0.8362 - val_acc: 0.6617\n",
      "Epoch 760/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7640 - acc: 0.6569 - val_loss: 0.8322 - val_acc: 0.6649\n",
      "Epoch 761/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7631 - acc: 0.6575 - val_loss: 0.8325 - val_acc: 0.6639\n",
      "Epoch 762/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7632 - acc: 0.6556 - val_loss: 0.8368 - val_acc: 0.6607\n",
      "Epoch 763/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7639 - acc: 0.6567 - val_loss: 0.8330 - val_acc: 0.6624\n",
      "Epoch 764/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7644 - acc: 0.6567 - val_loss: 0.8349 - val_acc: 0.6612\n",
      "Epoch 765/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7641 - acc: 0.6565 - val_loss: 0.8287 - val_acc: 0.6625\n",
      "Epoch 766/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7638 - acc: 0.6564 - val_loss: 0.8315 - val_acc: 0.6628\n",
      "Epoch 767/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7646 - acc: 0.6560 - val_loss: 0.8301 - val_acc: 0.6624\n",
      "Epoch 768/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7630 - acc: 0.6560 - val_loss: 0.8356 - val_acc: 0.6631\n",
      "Epoch 769/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7629 - acc: 0.6569 - val_loss: 0.8314 - val_acc: 0.6630\n",
      "Epoch 770/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7644 - acc: 0.6565 - val_loss: 0.8331 - val_acc: 0.6614\n",
      "Epoch 771/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7643 - acc: 0.6560 - val_loss: 0.8288 - val_acc: 0.6657\n",
      "Epoch 772/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7616 - acc: 0.6566 - val_loss: 0.8332 - val_acc: 0.6640\n",
      "Epoch 773/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7627 - acc: 0.6567 - val_loss: 0.8360 - val_acc: 0.6639\n",
      "Epoch 774/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7644 - acc: 0.6566 - val_loss: 0.8345 - val_acc: 0.6628\n",
      "Epoch 775/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7637 - acc: 0.6573 - val_loss: 0.8316 - val_acc: 0.6613\n",
      "Epoch 776/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7645 - acc: 0.6556 - val_loss: 0.8307 - val_acc: 0.6625\n",
      "Epoch 777/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7621 - acc: 0.6579 - val_loss: 0.8270 - val_acc: 0.6655\n",
      "Epoch 778/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7613 - acc: 0.6586 - val_loss: 0.8325 - val_acc: 0.6638\n",
      "Epoch 779/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7605 - acc: 0.6586 - val_loss: 0.8254 - val_acc: 0.6630\n",
      "Epoch 780/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7621 - acc: 0.6576 - val_loss: 0.8318 - val_acc: 0.6591\n",
      "Epoch 781/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7605 - acc: 0.6586 - val_loss: 0.8253 - val_acc: 0.6646\n",
      "Epoch 782/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7632 - acc: 0.6574 - val_loss: 0.8306 - val_acc: 0.6629\n",
      "Epoch 783/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7625 - acc: 0.6576 - val_loss: 0.8324 - val_acc: 0.6626\n",
      "Epoch 784/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7624 - acc: 0.6577 - val_loss: 0.8303 - val_acc: 0.6637\n",
      "Epoch 785/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7612 - acc: 0.6570 - val_loss: 0.8267 - val_acc: 0.6643\n",
      "Epoch 786/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7616 - acc: 0.6574 - val_loss: 0.8285 - val_acc: 0.6625\n",
      "Epoch 787/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7631 - acc: 0.6572 - val_loss: 0.8252 - val_acc: 0.6639\n",
      "Epoch 788/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7626 - acc: 0.6586 - val_loss: 0.8286 - val_acc: 0.6620\n",
      "Epoch 789/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7592 - acc: 0.6588 - val_loss: 0.8290 - val_acc: 0.6665\n",
      "Epoch 790/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7610 - acc: 0.6572 - val_loss: 0.8325 - val_acc: 0.6624\n",
      "Epoch 791/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7602 - acc: 0.6585 - val_loss: 0.8297 - val_acc: 0.6646\n",
      "Epoch 792/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7613 - acc: 0.6574 - val_loss: 0.8355 - val_acc: 0.6629\n",
      "Epoch 793/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7607 - acc: 0.6578 - val_loss: 0.8251 - val_acc: 0.6669\n",
      "Epoch 794/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7601 - acc: 0.6583 - val_loss: 0.8255 - val_acc: 0.6649\n",
      "Epoch 795/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7605 - acc: 0.6574 - val_loss: 0.8361 - val_acc: 0.6617\n",
      "Epoch 796/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7626 - acc: 0.6568 - val_loss: 0.8267 - val_acc: 0.6639\n",
      "Epoch 797/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7599 - acc: 0.6580 - val_loss: 0.8276 - val_acc: 0.6650\n",
      "Epoch 798/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7614 - acc: 0.6577 - val_loss: 0.8287 - val_acc: 0.6641\n",
      "Epoch 799/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7626 - acc: 0.6580 - val_loss: 0.8242 - val_acc: 0.6646\n",
      "Epoch 800/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7591 - acc: 0.6592 - val_loss: 0.8330 - val_acc: 0.6676\n",
      "Epoch 801/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7623 - acc: 0.6571 - val_loss: 0.8316 - val_acc: 0.6650\n",
      "Epoch 802/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7593 - acc: 0.6596 - val_loss: 0.8298 - val_acc: 0.6636\n",
      "Epoch 803/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7610 - acc: 0.6584 - val_loss: 0.8347 - val_acc: 0.6638\n",
      "Epoch 804/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7613 - acc: 0.6582 - val_loss: 0.8307 - val_acc: 0.6669\n",
      "Epoch 805/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7598 - acc: 0.6584 - val_loss: 0.8307 - val_acc: 0.6639\n",
      "Epoch 806/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7598 - acc: 0.6586 - val_loss: 0.8282 - val_acc: 0.6649\n",
      "Epoch 807/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7605 - acc: 0.6577 - val_loss: 0.8288 - val_acc: 0.6634\n",
      "Epoch 808/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7606 - acc: 0.6588 - val_loss: 0.8315 - val_acc: 0.6639\n",
      "Epoch 809/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7579 - acc: 0.6602 - val_loss: 0.8285 - val_acc: 0.6658\n",
      "Epoch 810/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7603 - acc: 0.6590 - val_loss: 0.8253 - val_acc: 0.6671\n",
      "Epoch 811/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7618 - acc: 0.6569 - val_loss: 0.8297 - val_acc: 0.6652\n",
      "Epoch 812/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7579 - acc: 0.6598 - val_loss: 0.8283 - val_acc: 0.6667\n",
      "Epoch 813/1000\n",
      "212747/212747 [==============================] - 7s 35us/step - loss: 0.7578 - acc: 0.6598 - val_loss: 0.8258 - val_acc: 0.6653\n",
      "Epoch 814/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7600 - acc: 0.6591 - val_loss: 0.8327 - val_acc: 0.6632\n",
      "Epoch 815/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7584 - acc: 0.6578 - val_loss: 0.8326 - val_acc: 0.6626\n",
      "Epoch 816/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7566 - acc: 0.6587 - val_loss: 0.8302 - val_acc: 0.6664\n",
      "Epoch 817/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7569 - acc: 0.6599 - val_loss: 0.8346 - val_acc: 0.6648\n",
      "Epoch 818/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7587 - acc: 0.6600 - val_loss: 0.8292 - val_acc: 0.6655\n",
      "Epoch 819/1000\n",
      "212747/212747 [==============================] - 8s 36us/step - loss: 0.7575 - acc: 0.6592 - val_loss: 0.8298 - val_acc: 0.6656\n",
      "Epoch 820/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7583 - acc: 0.6601 - val_loss: 0.8312 - val_acc: 0.6642\n",
      "Epoch 821/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7597 - acc: 0.6584 - val_loss: 0.8262 - val_acc: 0.6658\n",
      "Epoch 822/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7583 - acc: 0.6601 - val_loss: 0.8328 - val_acc: 0.6621\n",
      "Epoch 823/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7590 - acc: 0.6586 - val_loss: 0.8309 - val_acc: 0.6661\n",
      "Epoch 824/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7576 - acc: 0.6597 - val_loss: 0.8216 - val_acc: 0.6692\n",
      "Epoch 825/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7580 - acc: 0.6602 - val_loss: 0.8290 - val_acc: 0.6669\n",
      "Epoch 826/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7603 - acc: 0.6583 - val_loss: 0.8262 - val_acc: 0.6688\n",
      "Epoch 827/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7589 - acc: 0.6600 - val_loss: 0.8267 - val_acc: 0.6648\n",
      "Epoch 828/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7609 - acc: 0.6589 - val_loss: 0.8328 - val_acc: 0.6622\n",
      "Epoch 829/1000\n",
      "212747/212747 [==============================] - 8s 40us/step - loss: 0.7569 - acc: 0.6607 - val_loss: 0.8272 - val_acc: 0.6642\n",
      "Epoch 830/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7555 - acc: 0.6606 - val_loss: 0.8288 - val_acc: 0.6681\n",
      "Epoch 831/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7573 - acc: 0.6598 - val_loss: 0.8288 - val_acc: 0.6668\n",
      "Epoch 832/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7567 - acc: 0.6599 - val_loss: 0.8278 - val_acc: 0.6654\n",
      "Epoch 833/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7558 - acc: 0.6606 - val_loss: 0.8245 - val_acc: 0.6668\n",
      "Epoch 834/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7566 - acc: 0.6602 - val_loss: 0.8342 - val_acc: 0.6667\n",
      "Epoch 835/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7564 - acc: 0.6612 - val_loss: 0.8287 - val_acc: 0.6653\n",
      "Epoch 836/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7558 - acc: 0.6610 - val_loss: 0.8279 - val_acc: 0.6654\n",
      "Epoch 837/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7546 - acc: 0.6620 - val_loss: 0.8317 - val_acc: 0.6692\n",
      "Epoch 838/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7562 - acc: 0.6602 - val_loss: 0.8302 - val_acc: 0.6663\n",
      "Epoch 839/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7566 - acc: 0.6618 - val_loss: 0.8247 - val_acc: 0.6678\n",
      "Epoch 840/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7541 - acc: 0.6614 - val_loss: 0.8307 - val_acc: 0.6662\n",
      "Epoch 841/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7565 - acc: 0.6604 - val_loss: 0.8290 - val_acc: 0.6666\n",
      "Epoch 842/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7559 - acc: 0.6611 - val_loss: 0.8296 - val_acc: 0.6667\n",
      "Epoch 843/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7578 - acc: 0.6612 - val_loss: 0.8285 - val_acc: 0.6693\n",
      "Epoch 844/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7566 - acc: 0.6598 - val_loss: 0.8269 - val_acc: 0.6684\n",
      "Epoch 845/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7545 - acc: 0.6618 - val_loss: 0.8296 - val_acc: 0.6667\n",
      "Epoch 846/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7575 - acc: 0.6603 - val_loss: 0.8263 - val_acc: 0.6692\n",
      "Epoch 847/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7533 - acc: 0.6620 - val_loss: 0.8278 - val_acc: 0.6683\n",
      "Epoch 848/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7565 - acc: 0.6613 - val_loss: 0.8269 - val_acc: 0.6688\n",
      "Epoch 849/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7564 - acc: 0.6603 - val_loss: 0.8301 - val_acc: 0.6624\n",
      "Epoch 850/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7553 - acc: 0.6614 - val_loss: 0.8294 - val_acc: 0.6642\n",
      "Epoch 851/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7542 - acc: 0.6604 - val_loss: 0.8257 - val_acc: 0.6679\n",
      "Epoch 852/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7555 - acc: 0.6601 - val_loss: 0.8228 - val_acc: 0.6674\n",
      "Epoch 853/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7556 - acc: 0.6608 - val_loss: 0.8241 - val_acc: 0.6679\n",
      "Epoch 854/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7527 - acc: 0.6615 - val_loss: 0.8253 - val_acc: 0.6662\n",
      "Epoch 855/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7537 - acc: 0.6610 - val_loss: 0.8266 - val_acc: 0.6683\n",
      "Epoch 856/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7539 - acc: 0.6614 - val_loss: 0.8257 - val_acc: 0.6678\n",
      "Epoch 857/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7555 - acc: 0.6619 - val_loss: 0.8267 - val_acc: 0.6639\n",
      "Epoch 858/1000\n",
      "212747/212747 [==============================] - 8s 37us/step - loss: 0.7550 - acc: 0.6617 - val_loss: 0.8285 - val_acc: 0.6680\n",
      "Epoch 859/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7540 - acc: 0.6607 - val_loss: 0.8228 - val_acc: 0.6689\n",
      "Epoch 860/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7560 - acc: 0.6615 - val_loss: 0.8245 - val_acc: 0.6670\n",
      "Epoch 861/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7535 - acc: 0.6619 - val_loss: 0.8268 - val_acc: 0.6685\n",
      "Epoch 862/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.7530 - acc: 0.6612 - val_loss: 0.8262 - val_acc: 0.6672\n",
      "Epoch 863/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7497 - acc: 0.6633 - val_loss: 0.8293 - val_acc: 0.6676\n",
      "Epoch 864/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7539 - acc: 0.6605 - val_loss: 0.8267 - val_acc: 0.6672\n",
      "Epoch 865/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7523 - acc: 0.6635 - val_loss: 0.8310 - val_acc: 0.6661\n",
      "Epoch 866/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7529 - acc: 0.6619 - val_loss: 0.8301 - val_acc: 0.6682\n",
      "Epoch 867/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7523 - acc: 0.6628 - val_loss: 0.8264 - val_acc: 0.6683\n",
      "Epoch 868/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7557 - acc: 0.6605 - val_loss: 0.8235 - val_acc: 0.6675\n",
      "Epoch 869/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7525 - acc: 0.6626 - val_loss: 0.8255 - val_acc: 0.6665\n",
      "Epoch 870/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7537 - acc: 0.6614 - val_loss: 0.8251 - val_acc: 0.6673\n",
      "Epoch 871/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7519 - acc: 0.6624 - val_loss: 0.8268 - val_acc: 0.6667\n",
      "Epoch 872/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7526 - acc: 0.6618 - val_loss: 0.8256 - val_acc: 0.6704\n",
      "Epoch 873/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7542 - acc: 0.6619 - val_loss: 0.8295 - val_acc: 0.6660\n",
      "Epoch 874/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7505 - acc: 0.6638 - val_loss: 0.8220 - val_acc: 0.6672\n",
      "Epoch 875/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7532 - acc: 0.6623 - val_loss: 0.8271 - val_acc: 0.6669\n",
      "Epoch 876/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7515 - acc: 0.6620 - val_loss: 0.8276 - val_acc: 0.6660\n",
      "Epoch 877/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7504 - acc: 0.6621 - val_loss: 0.8273 - val_acc: 0.6650\n",
      "Epoch 878/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7516 - acc: 0.6631 - val_loss: 0.8230 - val_acc: 0.6697\n",
      "Epoch 879/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7511 - acc: 0.6635 - val_loss: 0.8245 - val_acc: 0.6704\n",
      "Epoch 880/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7517 - acc: 0.6630 - val_loss: 0.8305 - val_acc: 0.6636\n",
      "Epoch 881/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7517 - acc: 0.6632 - val_loss: 0.8216 - val_acc: 0.6687\n",
      "Epoch 882/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7521 - acc: 0.6618 - val_loss: 0.8284 - val_acc: 0.6679\n",
      "Epoch 883/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7543 - acc: 0.6623 - val_loss: 0.8256 - val_acc: 0.6682\n",
      "Epoch 884/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7520 - acc: 0.6633 - val_loss: 0.8267 - val_acc: 0.6689\n",
      "Epoch 885/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7530 - acc: 0.6626 - val_loss: 0.8245 - val_acc: 0.6711\n",
      "Epoch 886/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7521 - acc: 0.6621 - val_loss: 0.8247 - val_acc: 0.6702\n",
      "Epoch 887/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7508 - acc: 0.6629 - val_loss: 0.8231 - val_acc: 0.6674\n",
      "Epoch 888/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7507 - acc: 0.6641 - val_loss: 0.8243 - val_acc: 0.6678\n",
      "Epoch 889/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7512 - acc: 0.6642 - val_loss: 0.8235 - val_acc: 0.6698\n",
      "Epoch 890/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7510 - acc: 0.6625 - val_loss: 0.8217 - val_acc: 0.6700\n",
      "Epoch 891/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7515 - acc: 0.6633 - val_loss: 0.8231 - val_acc: 0.6677\n",
      "Epoch 892/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7510 - acc: 0.6627 - val_loss: 0.8306 - val_acc: 0.6655\n",
      "Epoch 893/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7503 - acc: 0.6630 - val_loss: 0.8242 - val_acc: 0.6695\n",
      "Epoch 894/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7509 - acc: 0.6640 - val_loss: 0.8253 - val_acc: 0.6706\n",
      "Epoch 895/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7502 - acc: 0.6638 - val_loss: 0.8213 - val_acc: 0.6707\n",
      "Epoch 896/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7492 - acc: 0.6645 - val_loss: 0.8240 - val_acc: 0.6688\n",
      "Epoch 897/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7504 - acc: 0.6629 - val_loss: 0.8262 - val_acc: 0.6704\n",
      "Epoch 898/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7499 - acc: 0.6641 - val_loss: 0.8278 - val_acc: 0.6682\n",
      "Epoch 899/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7479 - acc: 0.6647 - val_loss: 0.8251 - val_acc: 0.6701\n",
      "Epoch 900/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7504 - acc: 0.6640 - val_loss: 0.8219 - val_acc: 0.6697\n",
      "Epoch 901/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7512 - acc: 0.6634 - val_loss: 0.8213 - val_acc: 0.6713\n",
      "Epoch 902/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7482 - acc: 0.6655 - val_loss: 0.8223 - val_acc: 0.6717\n",
      "Epoch 903/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7487 - acc: 0.6649 - val_loss: 0.8246 - val_acc: 0.6721\n",
      "Epoch 904/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7484 - acc: 0.6654 - val_loss: 0.8268 - val_acc: 0.6691\n",
      "Epoch 905/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7478 - acc: 0.6648 - val_loss: 0.8255 - val_acc: 0.6709\n",
      "Epoch 906/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7494 - acc: 0.6648 - val_loss: 0.8284 - val_acc: 0.6693\n",
      "Epoch 907/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7484 - acc: 0.6656 - val_loss: 0.8232 - val_acc: 0.6666\n",
      "Epoch 908/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7479 - acc: 0.6653 - val_loss: 0.8218 - val_acc: 0.6684\n",
      "Epoch 909/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7471 - acc: 0.6639 - val_loss: 0.8269 - val_acc: 0.6649\n",
      "Epoch 910/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7494 - acc: 0.6648 - val_loss: 0.8185 - val_acc: 0.6707\n",
      "Epoch 911/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7477 - acc: 0.6640 - val_loss: 0.8262 - val_acc: 0.6668\n",
      "Epoch 912/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7474 - acc: 0.6651 - val_loss: 0.8194 - val_acc: 0.6712\n",
      "Epoch 913/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7492 - acc: 0.6645 - val_loss: 0.8218 - val_acc: 0.6716\n",
      "Epoch 914/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7501 - acc: 0.6640 - val_loss: 0.8240 - val_acc: 0.6704\n",
      "Epoch 915/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7478 - acc: 0.6646 - val_loss: 0.8235 - val_acc: 0.6706\n",
      "Epoch 916/1000\n",
      "212747/212747 [==============================] - 10s 45us/step - loss: 0.7501 - acc: 0.6640 - val_loss: 0.8238 - val_acc: 0.6693\n",
      "Epoch 917/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7495 - acc: 0.6639 - val_loss: 0.8236 - val_acc: 0.6673\n",
      "Epoch 918/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7505 - acc: 0.6634 - val_loss: 0.8254 - val_acc: 0.6696\n",
      "Epoch 919/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7482 - acc: 0.6651 - val_loss: 0.8210 - val_acc: 0.6706\n",
      "Epoch 920/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7481 - acc: 0.6653 - val_loss: 0.8240 - val_acc: 0.6706\n",
      "Epoch 921/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7482 - acc: 0.6642 - val_loss: 0.8243 - val_acc: 0.6672\n",
      "Epoch 922/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.7451 - acc: 0.6675 - val_loss: 0.8269 - val_acc: 0.6693\n",
      "Epoch 923/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7482 - acc: 0.6654 - val_loss: 0.8198 - val_acc: 0.6704\n",
      "Epoch 924/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7481 - acc: 0.6646 - val_loss: 0.8238 - val_acc: 0.6695\n",
      "Epoch 925/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7455 - acc: 0.6661 - val_loss: 0.8186 - val_acc: 0.6704\n",
      "Epoch 926/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7455 - acc: 0.6650 - val_loss: 0.8292 - val_acc: 0.6700\n",
      "Epoch 927/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7487 - acc: 0.6640 - val_loss: 0.8254 - val_acc: 0.6723\n",
      "Epoch 928/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7486 - acc: 0.6653 - val_loss: 0.8186 - val_acc: 0.6727\n",
      "Epoch 929/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7486 - acc: 0.6652 - val_loss: 0.8250 - val_acc: 0.6683\n",
      "Epoch 930/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7462 - acc: 0.6660 - val_loss: 0.8215 - val_acc: 0.6731\n",
      "Epoch 931/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7452 - acc: 0.6662 - val_loss: 0.8195 - val_acc: 0.6723\n",
      "Epoch 932/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.7482 - acc: 0.6646 - val_loss: 0.8236 - val_acc: 0.6691\n",
      "Epoch 933/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7469 - acc: 0.6645 - val_loss: 0.8215 - val_acc: 0.6715\n",
      "Epoch 934/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7468 - acc: 0.6653 - val_loss: 0.8189 - val_acc: 0.6710\n",
      "Epoch 935/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7473 - acc: 0.6656 - val_loss: 0.8168 - val_acc: 0.6713\n",
      "Epoch 936/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7473 - acc: 0.6658 - val_loss: 0.8216 - val_acc: 0.6690\n",
      "Epoch 937/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7474 - acc: 0.6656 - val_loss: 0.8194 - val_acc: 0.6735\n",
      "Epoch 938/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7470 - acc: 0.6657 - val_loss: 0.8248 - val_acc: 0.6705\n",
      "Epoch 939/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7473 - acc: 0.6651 - val_loss: 0.8252 - val_acc: 0.6681\n",
      "Epoch 940/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7458 - acc: 0.6650 - val_loss: 0.8234 - val_acc: 0.6699\n",
      "Epoch 941/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7456 - acc: 0.6666 - val_loss: 0.8205 - val_acc: 0.6699\n",
      "Epoch 942/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7471 - acc: 0.6648 - val_loss: 0.8222 - val_acc: 0.6713\n",
      "Epoch 943/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7477 - acc: 0.6646 - val_loss: 0.8228 - val_acc: 0.6708\n",
      "Epoch 944/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7463 - acc: 0.6661 - val_loss: 0.8269 - val_acc: 0.6724\n",
      "Epoch 945/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7463 - acc: 0.6651 - val_loss: 0.8193 - val_acc: 0.6721\n",
      "Epoch 946/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7454 - acc: 0.6666 - val_loss: 0.8233 - val_acc: 0.6715\n",
      "Epoch 947/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7435 - acc: 0.6668 - val_loss: 0.8268 - val_acc: 0.6708\n",
      "Epoch 948/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7440 - acc: 0.6670 - val_loss: 0.8225 - val_acc: 0.6705\n",
      "Epoch 949/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7464 - acc: 0.6661 - val_loss: 0.8199 - val_acc: 0.6689\n",
      "Epoch 950/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7460 - acc: 0.6657 - val_loss: 0.8208 - val_acc: 0.6706\n",
      "Epoch 951/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7489 - acc: 0.6660 - val_loss: 0.8222 - val_acc: 0.6729\n",
      "Epoch 952/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7445 - acc: 0.6663 - val_loss: 0.8217 - val_acc: 0.6709\n",
      "Epoch 953/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7457 - acc: 0.6657 - val_loss: 0.8250 - val_acc: 0.6722\n",
      "Epoch 954/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7451 - acc: 0.6664 - val_loss: 0.8234 - val_acc: 0.6719\n",
      "Epoch 955/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7452 - acc: 0.6664 - val_loss: 0.8241 - val_acc: 0.6712\n",
      "Epoch 956/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7439 - acc: 0.6674 - val_loss: 0.8196 - val_acc: 0.6706\n",
      "Epoch 957/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7454 - acc: 0.6669 - val_loss: 0.8232 - val_acc: 0.6727\n",
      "Epoch 958/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7472 - acc: 0.6657 - val_loss: 0.8211 - val_acc: 0.6708\n",
      "Epoch 959/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7443 - acc: 0.6675 - val_loss: 0.8178 - val_acc: 0.6730\n",
      "Epoch 960/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7442 - acc: 0.6649 - val_loss: 0.8150 - val_acc: 0.6764\n",
      "Epoch 961/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7463 - acc: 0.6661 - val_loss: 0.8205 - val_acc: 0.6720\n",
      "Epoch 962/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7447 - acc: 0.6670 - val_loss: 0.8203 - val_acc: 0.6690\n",
      "Epoch 963/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7461 - acc: 0.6670 - val_loss: 0.8242 - val_acc: 0.6708\n",
      "Epoch 964/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7441 - acc: 0.6679 - val_loss: 0.8267 - val_acc: 0.6729\n",
      "Epoch 965/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7438 - acc: 0.6669 - val_loss: 0.8224 - val_acc: 0.6713\n",
      "Epoch 966/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7423 - acc: 0.6690 - val_loss: 0.8224 - val_acc: 0.6725\n",
      "Epoch 967/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7444 - acc: 0.6671 - val_loss: 0.8191 - val_acc: 0.6730\n",
      "Epoch 968/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7456 - acc: 0.6664 - val_loss: 0.8189 - val_acc: 0.6704\n",
      "Epoch 969/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7429 - acc: 0.6684 - val_loss: 0.8180 - val_acc: 0.6747\n",
      "Epoch 970/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7435 - acc: 0.6668 - val_loss: 0.8175 - val_acc: 0.6718\n",
      "Epoch 971/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7440 - acc: 0.6681 - val_loss: 0.8202 - val_acc: 0.6739\n",
      "Epoch 972/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7433 - acc: 0.6671 - val_loss: 0.8196 - val_acc: 0.6722\n",
      "Epoch 973/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7449 - acc: 0.6664 - val_loss: 0.8189 - val_acc: 0.6749\n",
      "Epoch 974/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7403 - acc: 0.6702 - val_loss: 0.8184 - val_acc: 0.6722\n",
      "Epoch 975/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7448 - acc: 0.6670 - val_loss: 0.8167 - val_acc: 0.6743\n",
      "Epoch 976/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7428 - acc: 0.6681 - val_loss: 0.8181 - val_acc: 0.6709\n",
      "Epoch 977/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7439 - acc: 0.6676 - val_loss: 0.8186 - val_acc: 0.6725\n",
      "Epoch 978/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7453 - acc: 0.6665 - val_loss: 0.8213 - val_acc: 0.6726\n",
      "Epoch 979/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7417 - acc: 0.6690 - val_loss: 0.8211 - val_acc: 0.6742\n",
      "Epoch 980/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7441 - acc: 0.6679 - val_loss: 0.8172 - val_acc: 0.6740\n",
      "Epoch 981/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7416 - acc: 0.6692 - val_loss: 0.8182 - val_acc: 0.6747\n",
      "Epoch 982/1000\n",
      "212747/212747 [==============================] - 9s 44us/step - loss: 0.7429 - acc: 0.6682 - val_loss: 0.8222 - val_acc: 0.6734\n",
      "Epoch 983/1000\n",
      "212747/212747 [==============================] - 9s 41us/step - loss: 0.7439 - acc: 0.6669 - val_loss: 0.8123 - val_acc: 0.6739\n",
      "Epoch 984/1000\n",
      "212747/212747 [==============================] - 9s 43us/step - loss: 0.7421 - acc: 0.6688 - val_loss: 0.8215 - val_acc: 0.6733\n",
      "Epoch 985/1000\n",
      "212747/212747 [==============================] - 9s 42us/step - loss: 0.7402 - acc: 0.6684 - val_loss: 0.8151 - val_acc: 0.6740\n",
      "Epoch 986/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7430 - acc: 0.6681 - val_loss: 0.8179 - val_acc: 0.6723\n",
      "Epoch 987/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7417 - acc: 0.6698 - val_loss: 0.8189 - val_acc: 0.6726\n",
      "Epoch 988/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7408 - acc: 0.6697 - val_loss: 0.8150 - val_acc: 0.6752\n",
      "Epoch 989/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7417 - acc: 0.6676 - val_loss: 0.8203 - val_acc: 0.6730\n",
      "Epoch 990/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7413 - acc: 0.6687 - val_loss: 0.8204 - val_acc: 0.6721\n",
      "Epoch 991/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7420 - acc: 0.6690 - val_loss: 0.8198 - val_acc: 0.6727\n",
      "Epoch 992/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7424 - acc: 0.6686 - val_loss: 0.8162 - val_acc: 0.6738\n",
      "Epoch 993/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7420 - acc: 0.6687 - val_loss: 0.8235 - val_acc: 0.6729\n",
      "Epoch 994/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7409 - acc: 0.6686 - val_loss: 0.8210 - val_acc: 0.6736\n",
      "Epoch 995/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7418 - acc: 0.6685 - val_loss: 0.8241 - val_acc: 0.6699\n",
      "Epoch 996/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7405 - acc: 0.6688 - val_loss: 0.8279 - val_acc: 0.6673\n",
      "Epoch 997/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7415 - acc: 0.6689 - val_loss: 0.8183 - val_acc: 0.6739\n",
      "Epoch 998/1000\n",
      "212747/212747 [==============================] - 8s 38us/step - loss: 0.7410 - acc: 0.6682 - val_loss: 0.8192 - val_acc: 0.6718\n",
      "Epoch 999/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7396 - acc: 0.6689 - val_loss: 0.8135 - val_acc: 0.6755\n",
      "Epoch 1000/1000\n",
      "212747/212747 [==============================] - 8s 39us/step - loss: 0.7405 - acc: 0.6685 - val_loss: 0.8176 - val_acc: 0.6733\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l1\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "import ptetaphi_nn\n",
    "import tools\n",
    "with open(\"filepath.txt\", 'r') as f:\n",
    "    filename = f.read()\n",
    "    \n",
    "s_table = tools.open_file(filename, sort_by=\"tag\")\n",
    "# filter by realistic situation where we have 3 tags and 3 or 4 jets.\n",
    "# ignore the case where there may be >4 since those are pretty rare\n",
    "nb4 = (s_table.nbjets == 3) | (s_table.nbjets == 4) # 3 or 4 b-jets exist\n",
    "nt3 = s_table.nbtags==3  # 3 b tags\n",
    "nb4nt3 = nb4 & nt3\n",
    "events = s_table[nb4nt3]\n",
    "print(len(events))\n",
    "\n",
    "# and ensure that the 3 tags are actually correct\n",
    "# this results in very little event loss\n",
    "events = events[events.truth[:,0] == 1]\n",
    "events = events[events.truth[:,1] == 1]\n",
    "events = events[events.truth[:,2] == 1]\n",
    "print(len(events))\n",
    "\n",
    "cutoff = 7  # not many events have >10 jets\n",
    "# \"pad\" = ensure all events have same length, cut off ends if needed\n",
    "events = tools.pad(events, cutoff)\n",
    "\n",
    "nn = ptetaphi_nn.PtEtaPhiNN(events)\n",
    "# Feed forward NN\n",
    "\n",
    "# create network\n",
    "nn.model = Sequential([\n",
    "    Dense(3*(cutoff-3), input_dim=3*(cutoff-3), kernel_initializer='normal', activation='relu'),\n",
    "    Dense(700, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(500, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(300, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense( 50, activation='relu'),\n",
    "    Dense(cutoff-3+1, kernel_initializer='normal', activation='softmax')])\n",
    "nn.model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=\"adam\", metrics=['acc'])\n",
    "nn.model.summary()\n",
    "nn.learn(epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using data given when this model was created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 60785/60785 [00:00<00:00, 118648.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.evaluate(savename=\"7jets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the architecture as a json string\n",
    "arch = nn.model.to_json()\n",
    "# save the architecture string to a file somehow, the below will work\n",
    "with open('architecture_7jets.json', 'w') as arch_file:\n",
    "    arch_file.write(arch)\n",
    "# now save the weights as an HDF5 file\n",
    "nn.model.save_weights('weights_7jets.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
