{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening file\n",
      "sorting data by tag\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import uproot as ur\n",
    "import uproot_methods as urm\n",
    "import numpy as np\n",
    "import awkward\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tools\n",
    "from four_jet_network import FourJetNetwork\n",
    "\n",
    "filename = '/fast_scratch/atlas_bbbb/MAR20p0/user.jagrundy.20736236._000001.MiniNTuple.root'\n",
    "\n",
    "print(\"opening file\")\n",
    "s_table = tools.open_file(filename, sort_by=\"tag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1, pt classifier\n",
    "\n",
    "- if 4th jet found, keep selection based on this method\n",
    "- if not, proceed to stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"filtering from\", len(s_table), \"total events\")\n",
    "\n",
    "# filter so we get events with 3 or 4 b-jets, and 3 tags\n",
    "nb34 = (s_table.nbjets == 3) | (s_table.nbjets == 4) # 3 or 4 b-jets\n",
    "nj4 = s_table.njets >= 4 # at least 4 jets\n",
    "nt3 = s_table.nbtags==3  # 3 b-tags\n",
    "events = s_table[nb34 & nt3 & nj4]\n",
    "\n",
    "# and ensure that the 3 tags are actually correct\n",
    "# this results in very little event loss\n",
    "events = events[events.truth[:,0] == 1]\n",
    "events = events[events.truth[:,1] == 1]\n",
    "events = events[events.truth[:,2] == 1]\n",
    "\n",
    "n_events = len(events)\n",
    "print(n_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 10  # np.max(events.njets)\n",
    "padding_val = 0\n",
    "\n",
    "# pad events out to 'cutoff' events\n",
    "events = tools.pad(events, cutoff)\n",
    "# boost/rotate\n",
    "events = tools.boost_and_rotate(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pt_selector\n",
    "selections = pt_selector.select(events)\n",
    "# compare to tag_u, truth_u\n",
    "tools.evaluate_model(events.truth, events.tag, selections, savename='after_stage_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: The 4-jet NN Gauntlet\n",
    "\n",
    "- make 4-jet nn\n",
    "- split events into 4-jet groups\n",
    "- take best-fit jet in terms of 4-jet nn results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To make the 4-jet nn, just copy the 4b notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "# filter so we get events with 4 jets, 3 or 4 b-jets, and 3 tags\n",
    "j4 = (s_table.njets == 4) # 4 jets\n",
    "b34 = (s_table.nbjets == 3) | (s_table.nbjets == 4) # 3 or 4 b-jets\n",
    "nt3 = s_table.nbtags==3  # 3 b-tags\n",
    "events_4j = s_table[j4 & b34 & nt3]\n",
    "events_4j = events_4j[events_4j.truth[:,0] == 1]\n",
    "events_4j = events_4j[events_4j.truth[:,1] == 1]\n",
    "events_4j = events_4j[events_4j.truth[:,2] == 1]\n",
    "# pad, boost, rotate\n",
    "events_4j = tools.pad(events_4j, length=4)\n",
    "events_4j = tools.boost_and_rotate(events_4j)\n",
    "# create network\n",
    "nn = FourJetNetwork(events_4j)\n",
    "nn.model = Seuquential(\n",
    "    Dense(700, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(500, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(300, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense( 50, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    ")\n",
    "optimizer = Adam(lr=5e-5)\n",
    "nn.model.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "nn.model.summary()\n",
    "nn.learn(epochs=400)\n",
    "#nn.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the network score for some events is given by\n",
    "def score(nn, evs):\n",
    "    \"\"\"Note: this expects evs to be events of 4 jets\"\"\"\n",
    "    nn_input = tools.scale_nn_input(evs)\n",
    "    nn_score = nn.model.predict(nn_input)\n",
    "    return nn_score.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros((len(events), cutoff), dtype=float)\n",
    "\n",
    "# each group has this size\n",
    "group_len = len(events.truth[picked_no_4th])\n",
    "\n",
    "group_events = awkward.Table()\n",
    "group_events.truth = np.concatenate([events.truth[picked_no_4th][:,[0,1,2,i]] for i in range(3, cutoff)])\n",
    "group_events.tag = np.concatenate([events.tag[picked_no_4th][:,[0,1,2,i]] for i in range(3, cutoff)])\n",
    "pt = np.concatenate([events.resolved_lv.pt[picked_no_4th][:,[0,1,2,i]] for i in range(3, cutoff)])\n",
    "eta = np.concatenate([events.resolved_lv.eta[picked_no_4th][:,[0,1,2,i]] for i in range(3, cutoff)])\n",
    "phi = np.concatenate([events.resolved_lv.phi[picked_no_4th][:,[0,1,2,i]] for i in range(3, cutoff)])\n",
    "E = np.concatenate([events.resolved_lv.E[picked_no_4th][:,[0,1,2,i]] for i in range(3, cutoff)])\n",
    "group_events.resolved_lv = urm.TLorentzVectorArray.from_ptetaphie(\n",
    "    pt, eta, phi, E)\n",
    "print(len(group_events.truth))\n",
    "group_nn = FourJetNetwork(group_events)\n",
    "group_nn.learn(epochs=300)\n",
    "#group_nn.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_scores = score(group_nn, group_events)\n",
    "print(group_scores.shape)\n",
    "group_scores = group_scores.reshape((group_len, cutoff-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxes = np.max(group_scores, axis=1)\n",
    "select = np.argmax(group_scores,axis=1)\n",
    "select[maxes < 0.5] = cutoff\n",
    "nn_selections = np.zeros((len(select), cutoff+1), dtype=int)\n",
    "for i, s in enumerate(select):\n",
    "    nn_selections[i][s] = 1\n",
    "\n",
    "# chop off the last \"no selection\" jet\n",
    "nn_selections = nn_selections[:,:-1]\n",
    "\n",
    "# and actually evaluate\n",
    "#tools.evaluate_model(events.truth[picked_no_4th], events.tag[picked_no_4th], nn_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit the selections from earlier\n",
    "selections[picked_no_4th] = nn_selections\n",
    "tools.evaluate_model(events.truth, events.tag, selections, savename=\"after_stage_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
