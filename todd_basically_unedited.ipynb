{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Todd's Model, Basically Unedited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# Load the Keras NN from the h5 and json config files\n",
    "# Open the file with uproot\n",
    "import os,sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "import uproot\n",
    "import csv\n",
    "\n",
    "architecture_filepath = \"models/architecture_same_filters.json\"\n",
    "weights_filepath = \"models/weights_same_filters.h5\"\n",
    "scale_filepath = \"models/scaling_parameters_same_filters_3tags_only.csv\"\n",
    "data_filepath = \"user.jagrundy.20736236._000001.MiniNTuple.root\" \n",
    "\n",
    "# First, read the csv to get the offsets and scales for each input\n",
    "offset = {\"pt\":[],\"eta\":[],\"phi\":[]}\n",
    "scale  = {\"pt\":[],\"eta\":[],\"phi\":[]}\n",
    "with open(scale_filepath) as csvfile:\n",
    "    scale_reader = csv.reader(csvfile,delimiter=\",\")\n",
    "    row_count=0\n",
    "    for row in scale_reader:\n",
    "        if row_count < 4:\n",
    "            row_count+=1\n",
    "            continue\n",
    "        offset[\"pt\"].append(-float(row[0])) \n",
    "        offset[\"eta\"].append(-float(row[2])) \n",
    "        offset[\"phi\"].append(-float(row[4])) \n",
    "        scale[\"pt\"].append(1/np.sqrt(float(row[1])))\n",
    "        scale[\"eta\"].append(1/np.sqrt(float(row[3])))\n",
    "        scale[\"phi\"].append(1/np.sqrt(float(row[5])))\n",
    "\n",
    "# Horribly inefficient, but whatever, it's meant to be a quick check\n",
    "events = uproot.open(data_filepath)[\"XhhMiniNtuple\"]\n",
    "nn_inputs = []\n",
    "event_count=0\n",
    "for pts,etas,phis,tags in zip(events.array(\"resolvedJets_pt\"),  \\\n",
    "                              events.array(\"resolvedJets_eta\"), \\\n",
    "                              events.array(\"resolvedJets_phi\"), \\\n",
    "                              events.array(\"resolvedJets_is_DL1r_FixedCutBEff_77\")):\n",
    "    # Only consider 3-tag events\n",
    "    if sum(tags) != 3:\n",
    "        continue\n",
    "    # Loop over all the untagged jets in the event, up to 7, and save the scaled pt,eta,phi\n",
    "    event_pts,event_etas,event_phis = [],[],[]\n",
    "    notag_i = 0\n",
    "    for i in range(len(tags)):\n",
    "        if not tags[i]:\n",
    "            event_pts.append(  (pts[i] +offset[\"pt\"][notag_i]) *scale[\"pt\"][notag_i] )\n",
    "            event_etas.append( (etas[i]+offset[\"eta\"][notag_i])*scale[\"eta\"][notag_i] )\n",
    "            event_phis.append( (phis[i]+offset[\"phi\"][notag_i])*scale[\"phi\"][notag_i] )\n",
    "            notag_i += 1\n",
    "        if notag_i == 7: \n",
    "            break\n",
    "    # If we ended up with less than 7 jets, do zero-padding\n",
    "    while notag_i < 7:\n",
    "        event_pts.append(offset[\"pt\"][notag_i]*scale[\"pt\"][notag_i])\n",
    "        event_etas.append(offset[\"eta\"][notag_i]*scale[\"eta\"][notag_i])\n",
    "        event_phis.append(offset[\"phi\"][notag_i]*scale[\"phi\"][notag_i])\n",
    "        notag_i += 1\n",
    "    nn_inputs.append(np.array(event_pts+event_etas+event_phis))\n",
    "    # Only do the first few events for testing\n",
    "    #if event_count == 3:\n",
    "    #    break\n",
    "    event_count+=1\n",
    "nn_inputs = np.array(nn_inputs) # Has to be numpy array, not list\n",
    "\n",
    "# Load and run the model\n",
    "model = model_from_json(open(architecture_filepath,'r').read())\n",
    "model.load_weights(weights_filepath)\n",
    "scores = model.predict(nn_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Event 294\nInputs [-7.59174837e-01 -8.99359723e-01 -7.34556975e-01 -5.16809158e-01\n -3.29360190e-01 -1.94781994e-01 -1.10037601e-01  1.24973802e+00\n -2.88245004e-03 -3.81533066e-03 -3.43483027e-03 -2.05967334e-03\n  1.09038799e-03 -2.64976020e-03  1.31033194e+00  2.21391855e-04\n -1.63751978e-03  2.04173183e-04 -4.05969021e-03  1.08107861e-03\n  2.81306474e-03]\nOutputs\n   0 0.3591\n   1 0.0742\n   2 0.0214\n   3 0.0046\n   4 0.0007\n   5 1e-04\n   6 0.0\n   7 0.54\n\n"
    }
   ],
   "source": [
    "i_to_compare = 294\n",
    "print(\"Event\",i_to_compare)\n",
    "print(\"Inputs\",nn_inputs[i_to_compare])\n",
    "print(\"Outputs\")\n",
    "for j in range(len(scores[i_to_compare])):\n",
    "    print(\"  \",j,round(scores[i_to_compare][j],4))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}