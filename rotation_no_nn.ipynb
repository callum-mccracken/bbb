{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boost and Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import uproot as ur\n",
    "import uproot_methods as urm\n",
    "import numpy as np\n",
    "import awkward\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import tools\n",
    "\n",
    "filename = 'user.jagrundy.20736236._000001.MiniNTuple.root'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ntuple, get the data we need from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sorting data by tag\n"
    }
   ],
   "source": [
    "s_table = tools.open_file(filename, sort_by=\"tag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by realistic situation where we have 3 tags and 3 or 4 jets.\n",
    "# ignore the case where there may be >4 since those are pretty rare\n",
    "nb4 = (s_table.nbjets == 3) | (s_table.nbjets == 4) # 3 or 4 b-jets exist\n",
    "nt3 = s_table.nbtags==3  # 3 b tags\n",
    "nb4nt3 = nb4 & nt3\n",
    "events = s_table[nb4nt3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get jet locations, tag, truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "pt = events[\"resolved_lv\"].pt\n",
    "eta = events[\"resolved_lv\"].eta\n",
    "phi = events[\"resolved_lv\"].phi\n",
    "E = events[\"resolved_lv\"].E\n",
    "tag = events[\"tag\"] # tag[index] = [1, 1, 1, 0, 0, ...] (len >= 4)\n",
    "truth = events[\"truth\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 10\n",
    "padding_val = 0\n",
    "\n",
    "# cut off and pad\n",
    "padded_true = pad_sequences(truth,padding='post')[:,:cutoff]\n",
    "padded_tag = pad_sequences(tag, padding='post')[:,:cutoff]\n",
    "padded_pt = pad_sequences(pt, padding='post', dtype='float32', value = padding_val)[:,:cutoff]\n",
    "padded_eta = pad_sequences(eta, padding='post', dtype='float32', value = padding_val)[:,:cutoff]\n",
    "padded_phi = pad_sequences(phi, padding='post', dtype='float32', value = padding_val)[:,:cutoff]\n",
    "padded_E = pad_sequences(E, padding='post', dtype='float32', value = padding_val)[:,:cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter a bit more for events where we have 3 b-jets correctly tagged (plus maybe one more untagged b-jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1 1 0 0 0 0 0 0 0 0]\n[1 1 1 0 0 0 0 0 0 0]\n"
    }
   ],
   "source": [
    "# 1 = should have been tagged but wasn't. 0 = correctly tagged (or not tagged)\n",
    "untagged = np.logical_xor(padded_true, padded_tag).astype(int)\n",
    "\n",
    "# n_untagged[i] = number of untagged real jets in i-th event\n",
    "n_untagged = np.count_nonzero(untagged, axis=1)\n",
    "\n",
    "# consider the case where there are <=4 real b jets\n",
    "# use \"u\" for untagged<=1\n",
    "untagged_u = untagged[n_untagged <= 1]\n",
    "pt_u = padded_pt[n_untagged <= 1]\n",
    "eta_u = padded_eta[n_untagged <= 1]\n",
    "phi_u = padded_phi[n_untagged <= 1]\n",
    "E_u = padded_E[n_untagged <= 1]\n",
    "truth_u = padded_true[n_untagged <= 1]\n",
    "tag_u = padded_tag[n_untagged <= 1]\n",
    "\n",
    "# there's one weird event, which we'll remove\n",
    "non_weird_indices = list(range(len(truth_u)))\n",
    "for i, t in enumerate(truth_u):\n",
    "    if not all(t[:3] == np.array([1,1,1])):\n",
    "        print(t)\n",
    "        print(tag_u[i])\n",
    "        non_weird_indices.pop(i)\n",
    "non_weird_indices = np.array(non_weird_indices)\n",
    "\n",
    "\n",
    "untagged_u = untagged_u[non_weird_indices]\n",
    "pt_u = pt_u[non_weird_indices]\n",
    "eta_u = eta_u[non_weird_indices]\n",
    "phi_u = phi_u[non_weird_indices]\n",
    "E_u = E_u[non_weird_indices]\n",
    "truth_u = truth_u[non_weird_indices]\n",
    "tag_u = tag_u[non_weird_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotation time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make vectors\n",
    "vectors = urm.TLorentzVectorArray.from_ptetaphie(pt_u, eta_u, phi_u, E_u)\n",
    "\n",
    "# get sum vectors\n",
    "x_sum = np.repeat(np.sum(vectors.x, axis=1).reshape(-1, 1), cutoff, axis=1)\n",
    "y_sum = np.repeat(np.sum(vectors.y, axis=1).reshape(-1, 1), cutoff, axis=1)\n",
    "z_sum = np.repeat(np.sum(vectors.z, axis=1).reshape(-1, 1), cutoff, axis=1)\n",
    "t_sum = np.repeat(np.sum(vectors.t, axis=1).reshape(-1, 1), cutoff, axis=1)\n",
    "v_sum = urm.TLorentzVectorArray(x_sum, y_sum, z_sum, t_sum)\n",
    "\n",
    "# b for boosted\n",
    "vectors_b = vectors.boost(-v_sum.boostp3)\n",
    "v_sum_b = v_sum.boost(-v_sum.boostp3)\n",
    "# for filler data where eta = 0, we'll have NaN for eta, so replace that\n",
    "eta = np.nan_to_num(vectors_b.eta, nan=0.0)\n",
    "vectors_b = urm.TLorentzVectorArray.from_ptetaphie(\n",
    "    vectors_b.pt, eta, vectors_b.phi, vectors_b.E)\n",
    "\n",
    "# now rotate the system based on the first 3 jets\n",
    "# get sum of the first 3, similarly to before\n",
    "x_sum3 = np.repeat(np.sum(vectors_b.x[:,:3], axis=1).reshape(-1, 1), cutoff, axis=1)\n",
    "y_sum3 = np.repeat(np.sum(vectors_b.y[:,:3], axis=1).reshape(-1, 1), cutoff, axis=1)\n",
    "z_sum3 = np.repeat(np.sum(vectors_b.z[:,:3], axis=1).reshape(-1, 1), cutoff, axis=1)\n",
    "t_sum3 = np.repeat(np.sum(vectors_b.t[:,:3], axis=1).reshape(-1, 1), cutoff, axis=1)\n",
    "v_sum3 = urm.TLorentzVectorArray(x_sum3, y_sum3, z_sum3, t_sum3)\n",
    "\n",
    "# rotate about z so that phi=0 for v_sum3\n",
    "vectors_r = vectors_b.rotatez(-v_sum3.phi)\n",
    "v_sum3 = v_sum3.rotatez(-v_sum3.phi)\n",
    "\n",
    "# and again replace filler etas with 0\n",
    "eta = np.nan_to_num(vectors_r.eta, nan=0.0)\n",
    "vectors_final = urm.TLorentzVectorArray.from_ptetaphie(\n",
    "    vectors_r.pt, eta, vectors_r.phi, vectors_r.E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snip off the 3 first jets since they're already tagged correctly\n",
    "# (given our filtering procedure above)\n",
    "untagged_3, untagged_rest = untagged_u[:, :3], untagged_u[:, 3:]\n",
    "pt_3, pt_rest = vectors_final.pt[:, :3], vectors_final.pt[:, 3:]\n",
    "eta_3, eta_rest = vectors_final.eta[:, :3], vectors_final.eta[:, 3:]\n",
    "phi_3, phi_rest = vectors_final.phi[:, :3], vectors_final.phi[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 303925/303925 [00:02<00:00, 140628.73it/s]\n\n    Total number of events: 303925\n    Minus events ignored: 0, (0.00%)\n\n    4th b-jet really exists:\n        Correct 4th jet picked:         4.23%, 7234\n        Incorrect 4th jet picked:       6.92%, 11819\n        Event incorrectly ignored:      88.85%, 151818\n\n    No 4th b-jet really exists:\n        Correctly ignored event:        91.19%, 121333\n        Incorrectly picked a 4th jet:   8.81%, 11721\n\n    Or formatted in table form:\n                    ____________________\n                   |Truth-Matching      |\n                   |____________________|\n                   |4th exists  |No 4th |\n     ______________|____________|_______|\n    |4th |4th found|corr. 004.2%| 008.8%|\n    |Jet |         |inco. 006.9%|       |\n    |Reco|_________|____________|_______|\n    |    |no 4th   |      088.8%| 091.2%|\n    |____|_________|____________|_______|\n\n    (columns add to 100% each)\n    \n\n"
    }
   ],
   "source": [
    "# find the best jet from _rest that fits with _3, in terms of eta normalization\n",
    "eta_3_sums = np.repeat(np.sum(eta_3, axis=1).reshape(-1, 1), cutoff-3, axis=1)\n",
    "eta_sums = np.abs(eta_rest + eta_3_sums)\n",
    "lowest_vals = np.min(eta_sums, axis=1)\n",
    "lowest_indices = np.argmin(eta_sums, axis=1)\n",
    "\n",
    "# lowest values are typically less than 1, lower=more certainty\n",
    "# let's set an arbitrary threshold,\n",
    "# and say if lowest_val > thresh, pick no jet\n",
    "thresh = 0.05\n",
    "lowest_indices[lowest_vals>thresh] = 7\n",
    "#print(lowest_vals[:5])\n",
    "#print(lowest_indices[:5])  \n",
    "\n",
    "# put this in a better format\n",
    "selection_index = lowest_indices + 3\n",
    "selections = np.zeros((len(truth_u), cutoff+1), dtype=int)\n",
    "for i, s in enumerate(selection_index):\n",
    "    selections[i][s] = 1\n",
    "# chop off last index so selection = [0,...,0] for no selection\n",
    "selections = selections[:, :-1]\n",
    "\n",
    "# compare to tag_u, truth_u\n",
    "tools.evaluate_model(truth_u, tag_u, selections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit1bc87f48281d409ab7479945988ac1ab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}