{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The Best Model As Of July 6 2020\n",
    "\n",
    "10 jets, #nofilter, PtEtaPhi network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting data by tag\n",
      "313660\n",
      "creating default model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 700)               21700     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 408       \n",
      "=================================================================\n",
      "Total params: 558,988\n",
      "Trainable params: 558,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 219561 samples, validate on 31367 samples\n",
      "Epoch 1/800\n",
      "219561/219561 [==============================] - 12s 56us/step - loss: 1.2922 - acc: 0.4629 - val_loss: 1.1364 - val_acc: 0.5184\n",
      "Epoch 2/800\n",
      "219561/219561 [==============================] - 12s 55us/step - loss: 1.1181 - acc: 0.5266 - val_loss: 1.0862 - val_acc: 0.5439\n",
      "Epoch 3/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 1.0811 - acc: 0.5442 - val_loss: 1.0593 - val_acc: 0.5573\n",
      "Epoch 4/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 1.0573 - acc: 0.5554 - val_loss: 1.0384 - val_acc: 0.5679\n",
      "Epoch 5/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 1.0380 - acc: 0.5642 - val_loss: 1.0216 - val_acc: 0.5747\n",
      "Epoch 6/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 1.0218 - acc: 0.5709 - val_loss: 1.0073 - val_acc: 0.5787\n",
      "Epoch 7/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 1.0095 - acc: 0.5760 - val_loss: 0.9964 - val_acc: 0.5835\n",
      "Epoch 8/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9983 - acc: 0.5803 - val_loss: 0.9862 - val_acc: 0.5879\n",
      "Epoch 9/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9890 - acc: 0.5843 - val_loss: 0.9806 - val_acc: 0.5891\n",
      "Epoch 10/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9808 - acc: 0.5863 - val_loss: 0.9703 - val_acc: 0.5933\n",
      "Epoch 11/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9732 - acc: 0.5891 - val_loss: 0.9642 - val_acc: 0.5960\n",
      "Epoch 12/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.9668 - acc: 0.5923 - val_loss: 0.9556 - val_acc: 0.6000\n",
      "Epoch 13/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9607 - acc: 0.5946 - val_loss: 0.9519 - val_acc: 0.6003\n",
      "Epoch 14/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9551 - acc: 0.5968 - val_loss: 0.9449 - val_acc: 0.6040\n",
      "Epoch 15/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.9496 - acc: 0.5985 - val_loss: 0.9391 - val_acc: 0.6079\n",
      "Epoch 16/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9448 - acc: 0.6014 - val_loss: 0.9345 - val_acc: 0.6095\n",
      "Epoch 17/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9393 - acc: 0.6030 - val_loss: 0.9290 - val_acc: 0.6111\n",
      "Epoch 18/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.9345 - acc: 0.6059 - val_loss: 0.9246 - val_acc: 0.6149\n",
      "Epoch 19/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9300 - acc: 0.6080 - val_loss: 0.9195 - val_acc: 0.6165\n",
      "Epoch 20/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9262 - acc: 0.6096 - val_loss: 0.9151 - val_acc: 0.6193\n",
      "Epoch 21/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9215 - acc: 0.6122 - val_loss: 0.9110 - val_acc: 0.6211\n",
      "Epoch 22/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9170 - acc: 0.6140 - val_loss: 0.9057 - val_acc: 0.6230\n",
      "Epoch 23/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9136 - acc: 0.6161 - val_loss: 0.9020 - val_acc: 0.6244\n",
      "Epoch 24/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9095 - acc: 0.6181 - val_loss: 0.8979 - val_acc: 0.6263\n",
      "Epoch 25/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9065 - acc: 0.6197 - val_loss: 0.8952 - val_acc: 0.6282\n",
      "Epoch 26/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.9022 - acc: 0.6212 - val_loss: 0.8922 - val_acc: 0.6306\n",
      "Epoch 27/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8990 - acc: 0.6233 - val_loss: 0.8892 - val_acc: 0.6307\n",
      "Epoch 28/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8958 - acc: 0.6242 - val_loss: 0.8862 - val_acc: 0.6329\n",
      "Epoch 29/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8929 - acc: 0.6257 - val_loss: 0.8825 - val_acc: 0.6336\n",
      "Epoch 30/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8902 - acc: 0.6270 - val_loss: 0.8795 - val_acc: 0.6354\n",
      "Epoch 31/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8869 - acc: 0.6282 - val_loss: 0.8768 - val_acc: 0.6375\n",
      "Epoch 32/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8846 - acc: 0.6298 - val_loss: 0.8740 - val_acc: 0.6383\n",
      "Epoch 33/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8816 - acc: 0.6307 - val_loss: 0.8712 - val_acc: 0.6397\n",
      "Epoch 34/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8792 - acc: 0.6327 - val_loss: 0.8685 - val_acc: 0.6411\n",
      "Epoch 35/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8768 - acc: 0.6342 - val_loss: 0.8683 - val_acc: 0.6415\n",
      "Epoch 36/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8747 - acc: 0.6344 - val_loss: 0.8645 - val_acc: 0.6433\n",
      "Epoch 37/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8714 - acc: 0.6362 - val_loss: 0.8623 - val_acc: 0.6446\n",
      "Epoch 38/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8684 - acc: 0.6363 - val_loss: 0.8578 - val_acc: 0.6457\n",
      "Epoch 39/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8667 - acc: 0.6381 - val_loss: 0.8558 - val_acc: 0.6472\n",
      "Epoch 40/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8642 - acc: 0.6387 - val_loss: 0.8529 - val_acc: 0.6480\n",
      "Epoch 41/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8617 - acc: 0.6407 - val_loss: 0.8518 - val_acc: 0.6492\n",
      "Epoch 42/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.8601 - acc: 0.6414 - val_loss: 0.8492 - val_acc: 0.6495\n",
      "Epoch 43/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8572 - acc: 0.6418 - val_loss: 0.8475 - val_acc: 0.6513\n",
      "Epoch 44/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8556 - acc: 0.6429 - val_loss: 0.8478 - val_acc: 0.6513\n",
      "Epoch 45/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8526 - acc: 0.6440 - val_loss: 0.8418 - val_acc: 0.6540\n",
      "Epoch 46/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8506 - acc: 0.6459 - val_loss: 0.8418 - val_acc: 0.6529\n",
      "Epoch 47/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8483 - acc: 0.6457 - val_loss: 0.8392 - val_acc: 0.6546\n",
      "Epoch 48/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8468 - acc: 0.6474 - val_loss: 0.8382 - val_acc: 0.6547\n",
      "Epoch 49/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8444 - acc: 0.6479 - val_loss: 0.8332 - val_acc: 0.6566\n",
      "Epoch 50/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8411 - acc: 0.6492 - val_loss: 0.8324 - val_acc: 0.6569\n",
      "Epoch 51/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8394 - acc: 0.6501 - val_loss: 0.8306 - val_acc: 0.6579\n",
      "Epoch 52/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8379 - acc: 0.6499 - val_loss: 0.8291 - val_acc: 0.6590\n",
      "Epoch 53/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8357 - acc: 0.6518 - val_loss: 0.8266 - val_acc: 0.6600\n",
      "Epoch 54/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8338 - acc: 0.6529 - val_loss: 0.8253 - val_acc: 0.6598\n",
      "Epoch 55/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8325 - acc: 0.6534 - val_loss: 0.8216 - val_acc: 0.6610\n",
      "Epoch 56/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8303 - acc: 0.6542 - val_loss: 0.8203 - val_acc: 0.6611\n",
      "Epoch 57/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8284 - acc: 0.6557 - val_loss: 0.8197 - val_acc: 0.6609\n",
      "Epoch 58/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8262 - acc: 0.6560 - val_loss: 0.8158 - val_acc: 0.6639\n",
      "Epoch 59/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.8243 - acc: 0.6574 - val_loss: 0.8152 - val_acc: 0.6631\n",
      "Epoch 60/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8228 - acc: 0.6576 - val_loss: 0.8138 - val_acc: 0.6640\n",
      "Epoch 61/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8211 - acc: 0.6588 - val_loss: 0.8119 - val_acc: 0.6639\n",
      "Epoch 62/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8186 - acc: 0.6597 - val_loss: 0.8096 - val_acc: 0.6659\n",
      "Epoch 63/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8167 - acc: 0.6596 - val_loss: 0.8078 - val_acc: 0.6662\n",
      "Epoch 64/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8147 - acc: 0.6606 - val_loss: 0.8074 - val_acc: 0.6671\n",
      "Epoch 65/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8134 - acc: 0.6613 - val_loss: 0.8048 - val_acc: 0.6667\n",
      "Epoch 66/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8113 - acc: 0.6633 - val_loss: 0.8026 - val_acc: 0.6689\n",
      "Epoch 67/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8099 - acc: 0.6640 - val_loss: 0.8009 - val_acc: 0.6700\n",
      "Epoch 68/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8072 - acc: 0.6646 - val_loss: 0.7986 - val_acc: 0.6712\n",
      "Epoch 69/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8059 - acc: 0.6648 - val_loss: 0.7978 - val_acc: 0.6713\n",
      "Epoch 70/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8025 - acc: 0.6665 - val_loss: 0.7970 - val_acc: 0.6715\n",
      "Epoch 71/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8023 - acc: 0.6662 - val_loss: 0.7940 - val_acc: 0.6731\n",
      "Epoch 72/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.8007 - acc: 0.6674 - val_loss: 0.7921 - val_acc: 0.6738\n",
      "Epoch 73/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7990 - acc: 0.6683 - val_loss: 0.7916 - val_acc: 0.6743\n",
      "Epoch 74/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7971 - acc: 0.6690 - val_loss: 0.7893 - val_acc: 0.6751\n",
      "Epoch 75/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7953 - acc: 0.6698 - val_loss: 0.7875 - val_acc: 0.6764\n",
      "Epoch 76/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7936 - acc: 0.6709 - val_loss: 0.7861 - val_acc: 0.6781\n",
      "Epoch 77/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7918 - acc: 0.6716 - val_loss: 0.7838 - val_acc: 0.6784\n",
      "Epoch 78/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7903 - acc: 0.6728 - val_loss: 0.7829 - val_acc: 0.6766\n",
      "Epoch 79/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7877 - acc: 0.6741 - val_loss: 0.7805 - val_acc: 0.6787\n",
      "Epoch 80/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7861 - acc: 0.6739 - val_loss: 0.7810 - val_acc: 0.6787\n",
      "Epoch 81/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7853 - acc: 0.6744 - val_loss: 0.7780 - val_acc: 0.6803\n",
      "Epoch 82/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7828 - acc: 0.6753 - val_loss: 0.7763 - val_acc: 0.6817\n",
      "Epoch 83/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7811 - acc: 0.6760 - val_loss: 0.7775 - val_acc: 0.6787\n",
      "Epoch 84/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7792 - acc: 0.6780 - val_loss: 0.7736 - val_acc: 0.6820\n",
      "Epoch 85/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7777 - acc: 0.6780 - val_loss: 0.7722 - val_acc: 0.6829\n",
      "Epoch 86/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7764 - acc: 0.6787 - val_loss: 0.7704 - val_acc: 0.6852\n",
      "Epoch 87/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7743 - acc: 0.6801 - val_loss: 0.7703 - val_acc: 0.6832\n",
      "Epoch 88/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7721 - acc: 0.6804 - val_loss: 0.7676 - val_acc: 0.6853\n",
      "Epoch 89/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7708 - acc: 0.6817 - val_loss: 0.7665 - val_acc: 0.6838\n",
      "Epoch 90/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7697 - acc: 0.6815 - val_loss: 0.7646 - val_acc: 0.6853\n",
      "Epoch 91/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7678 - acc: 0.6825 - val_loss: 0.7623 - val_acc: 0.6862\n",
      "Epoch 92/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7662 - acc: 0.6837 - val_loss: 0.7607 - val_acc: 0.6878\n",
      "Epoch 93/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7653 - acc: 0.6842 - val_loss: 0.7596 - val_acc: 0.6891\n",
      "Epoch 94/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7627 - acc: 0.6850 - val_loss: 0.7589 - val_acc: 0.6877\n",
      "Epoch 95/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7608 - acc: 0.6860 - val_loss: 0.7581 - val_acc: 0.6893\n",
      "Epoch 96/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7590 - acc: 0.6869 - val_loss: 0.7557 - val_acc: 0.6908\n",
      "Epoch 97/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7577 - acc: 0.6872 - val_loss: 0.7557 - val_acc: 0.6896\n",
      "Epoch 98/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7569 - acc: 0.6880 - val_loss: 0.7526 - val_acc: 0.6914\n",
      "Epoch 99/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7550 - acc: 0.6892 - val_loss: 0.7512 - val_acc: 0.6908\n",
      "Epoch 100/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7527 - acc: 0.6891 - val_loss: 0.7500 - val_acc: 0.6939\n",
      "Epoch 101/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.7518 - acc: 0.6897 - val_loss: 0.7483 - val_acc: 0.6955\n",
      "Epoch 102/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7496 - acc: 0.6915 - val_loss: 0.7468 - val_acc: 0.6939\n",
      "Epoch 103/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7488 - acc: 0.6917 - val_loss: 0.7462 - val_acc: 0.6942\n",
      "Epoch 104/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7473 - acc: 0.6927 - val_loss: 0.7429 - val_acc: 0.6973\n",
      "Epoch 105/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7459 - acc: 0.6930 - val_loss: 0.7432 - val_acc: 0.6960\n",
      "Epoch 106/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7433 - acc: 0.6935 - val_loss: 0.7413 - val_acc: 0.6982\n",
      "Epoch 107/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7422 - acc: 0.6946 - val_loss: 0.7389 - val_acc: 0.6987\n",
      "Epoch 108/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7403 - acc: 0.6944 - val_loss: 0.7386 - val_acc: 0.6974\n",
      "Epoch 109/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7393 - acc: 0.6962 - val_loss: 0.7369 - val_acc: 0.7008\n",
      "Epoch 110/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7385 - acc: 0.6957 - val_loss: 0.7353 - val_acc: 0.7012\n",
      "Epoch 111/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7360 - acc: 0.6969 - val_loss: 0.7352 - val_acc: 0.7001\n",
      "Epoch 112/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7339 - acc: 0.6984 - val_loss: 0.7326 - val_acc: 0.7031\n",
      "Epoch 113/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7329 - acc: 0.6991 - val_loss: 0.7323 - val_acc: 0.7017\n",
      "Epoch 114/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7313 - acc: 0.6998 - val_loss: 0.7304 - val_acc: 0.7036\n",
      "Epoch 115/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7300 - acc: 0.7000 - val_loss: 0.7305 - val_acc: 0.7024\n",
      "Epoch 116/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7284 - acc: 0.7001 - val_loss: 0.7282 - val_acc: 0.7038\n",
      "Epoch 117/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7263 - acc: 0.7017 - val_loss: 0.7261 - val_acc: 0.7057\n",
      "Epoch 118/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7256 - acc: 0.7021 - val_loss: 0.7263 - val_acc: 0.7048\n",
      "Epoch 119/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7245 - acc: 0.7017 - val_loss: 0.7242 - val_acc: 0.7072\n",
      "Epoch 120/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.7238 - acc: 0.7031 - val_loss: 0.7241 - val_acc: 0.7053\n",
      "Epoch 121/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.7219 - acc: 0.7034 - val_loss: 0.7215 - val_acc: 0.7068\n",
      "Epoch 122/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7194 - acc: 0.7049 - val_loss: 0.7198 - val_acc: 0.7094\n",
      "Epoch 123/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7180 - acc: 0.7047 - val_loss: 0.7186 - val_acc: 0.7089\n",
      "Epoch 124/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7159 - acc: 0.7067 - val_loss: 0.7175 - val_acc: 0.7100\n",
      "Epoch 125/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7145 - acc: 0.7067 - val_loss: 0.7161 - val_acc: 0.7101\n",
      "Epoch 126/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7133 - acc: 0.7071 - val_loss: 0.7159 - val_acc: 0.7106\n",
      "Epoch 127/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7123 - acc: 0.7075 - val_loss: 0.7124 - val_acc: 0.7105\n",
      "Epoch 128/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7107 - acc: 0.7089 - val_loss: 0.7125 - val_acc: 0.7111\n",
      "Epoch 129/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7090 - acc: 0.7093 - val_loss: 0.7106 - val_acc: 0.7130\n",
      "Epoch 130/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7081 - acc: 0.7103 - val_loss: 0.7090 - val_acc: 0.7131\n",
      "Epoch 131/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7065 - acc: 0.7108 - val_loss: 0.7088 - val_acc: 0.7129\n",
      "Epoch 132/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7051 - acc: 0.7098 - val_loss: 0.7072 - val_acc: 0.7138\n",
      "Epoch 133/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7034 - acc: 0.7115 - val_loss: 0.7054 - val_acc: 0.7151\n",
      "Epoch 134/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7016 - acc: 0.7122 - val_loss: 0.7055 - val_acc: 0.7143\n",
      "Epoch 135/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.7009 - acc: 0.7127 - val_loss: 0.7040 - val_acc: 0.7171\n",
      "Epoch 136/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6989 - acc: 0.7138 - val_loss: 0.7030 - val_acc: 0.7156\n",
      "Epoch 137/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6972 - acc: 0.7146 - val_loss: 0.7013 - val_acc: 0.7165\n",
      "Epoch 138/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6966 - acc: 0.7145 - val_loss: 0.7002 - val_acc: 0.7168\n",
      "Epoch 139/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6943 - acc: 0.7154 - val_loss: 0.6999 - val_acc: 0.7164\n",
      "Epoch 140/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6935 - acc: 0.7152 - val_loss: 0.6975 - val_acc: 0.7182\n",
      "Epoch 141/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6908 - acc: 0.7164 - val_loss: 0.6964 - val_acc: 0.7201\n",
      "Epoch 142/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6905 - acc: 0.7168 - val_loss: 0.6948 - val_acc: 0.7204\n",
      "Epoch 143/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6888 - acc: 0.7176 - val_loss: 0.6922 - val_acc: 0.7231\n",
      "Epoch 144/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6865 - acc: 0.7191 - val_loss: 0.6917 - val_acc: 0.7222\n",
      "Epoch 145/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6863 - acc: 0.7189 - val_loss: 0.6915 - val_acc: 0.7214\n",
      "Epoch 146/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6838 - acc: 0.7204 - val_loss: 0.6891 - val_acc: 0.7238\n",
      "Epoch 147/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6847 - acc: 0.7195 - val_loss: 0.6895 - val_acc: 0.7231\n",
      "Epoch 148/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6823 - acc: 0.7212 - val_loss: 0.6861 - val_acc: 0.7241\n",
      "Epoch 149/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6800 - acc: 0.7213 - val_loss: 0.6864 - val_acc: 0.7224\n",
      "Epoch 150/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6797 - acc: 0.7216 - val_loss: 0.6848 - val_acc: 0.7238\n",
      "Epoch 151/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6775 - acc: 0.7232 - val_loss: 0.6838 - val_acc: 0.7265\n",
      "Epoch 152/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6769 - acc: 0.7235 - val_loss: 0.6813 - val_acc: 0.7263\n",
      "Epoch 153/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6749 - acc: 0.7235 - val_loss: 0.6824 - val_acc: 0.7258\n",
      "Epoch 154/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6734 - acc: 0.7243 - val_loss: 0.6807 - val_acc: 0.7245\n",
      "Epoch 155/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6721 - acc: 0.7259 - val_loss: 0.6788 - val_acc: 0.7277\n",
      "Epoch 156/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6711 - acc: 0.7260 - val_loss: 0.6763 - val_acc: 0.7284\n",
      "Epoch 157/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6688 - acc: 0.7270 - val_loss: 0.6757 - val_acc: 0.7290\n",
      "Epoch 158/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.6673 - acc: 0.7275 - val_loss: 0.6761 - val_acc: 0.7291\n",
      "Epoch 159/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6667 - acc: 0.7273 - val_loss: 0.6740 - val_acc: 0.7297\n",
      "Epoch 160/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6662 - acc: 0.7277 - val_loss: 0.6724 - val_acc: 0.7309\n",
      "Epoch 161/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6638 - acc: 0.7277 - val_loss: 0.6737 - val_acc: 0.7314\n",
      "Epoch 162/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6627 - acc: 0.7292 - val_loss: 0.6700 - val_acc: 0.7323\n",
      "Epoch 163/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6609 - acc: 0.7297 - val_loss: 0.6679 - val_acc: 0.7332\n",
      "Epoch 164/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6595 - acc: 0.7300 - val_loss: 0.6675 - val_acc: 0.7323\n",
      "Epoch 165/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6578 - acc: 0.7313 - val_loss: 0.6669 - val_acc: 0.7333\n",
      "Epoch 166/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6575 - acc: 0.7315 - val_loss: 0.6676 - val_acc: 0.7341\n",
      "Epoch 167/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6565 - acc: 0.7317 - val_loss: 0.6645 - val_acc: 0.7362\n",
      "Epoch 168/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6547 - acc: 0.7332 - val_loss: 0.6650 - val_acc: 0.7351\n",
      "Epoch 169/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6527 - acc: 0.7345 - val_loss: 0.6632 - val_acc: 0.7374\n",
      "Epoch 170/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6510 - acc: 0.7336 - val_loss: 0.6613 - val_acc: 0.7367\n",
      "Epoch 171/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6506 - acc: 0.7345 - val_loss: 0.6608 - val_acc: 0.7373\n",
      "Epoch 172/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6488 - acc: 0.7355 - val_loss: 0.6603 - val_acc: 0.7369\n",
      "Epoch 173/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6479 - acc: 0.7357 - val_loss: 0.6577 - val_acc: 0.7377\n",
      "Epoch 174/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6472 - acc: 0.7351 - val_loss: 0.6574 - val_acc: 0.7395\n",
      "Epoch 175/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6463 - acc: 0.7364 - val_loss: 0.6587 - val_acc: 0.7377\n",
      "Epoch 176/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6449 - acc: 0.7360 - val_loss: 0.6551 - val_acc: 0.7402\n",
      "Epoch 177/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6430 - acc: 0.7381 - val_loss: 0.6565 - val_acc: 0.7384\n",
      "Epoch 178/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6409 - acc: 0.7376 - val_loss: 0.6528 - val_acc: 0.7421\n",
      "Epoch 179/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6387 - acc: 0.7392 - val_loss: 0.6517 - val_acc: 0.7429\n",
      "Epoch 180/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6378 - acc: 0.7400 - val_loss: 0.6505 - val_acc: 0.7422\n",
      "Epoch 181/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6369 - acc: 0.7408 - val_loss: 0.6496 - val_acc: 0.7436\n",
      "Epoch 182/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6363 - acc: 0.7401 - val_loss: 0.6499 - val_acc: 0.7424\n",
      "Epoch 183/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6337 - acc: 0.7409 - val_loss: 0.6483 - val_acc: 0.7445\n",
      "Epoch 184/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6343 - acc: 0.7412 - val_loss: 0.6475 - val_acc: 0.7426\n",
      "Epoch 185/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6329 - acc: 0.7412 - val_loss: 0.6447 - val_acc: 0.7462\n",
      "Epoch 186/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6309 - acc: 0.7419 - val_loss: 0.6466 - val_acc: 0.7450\n",
      "Epoch 187/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6281 - acc: 0.7432 - val_loss: 0.6447 - val_acc: 0.7453\n",
      "Epoch 188/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6283 - acc: 0.7437 - val_loss: 0.6428 - val_acc: 0.7458\n",
      "Epoch 189/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6266 - acc: 0.7450 - val_loss: 0.6428 - val_acc: 0.7463\n",
      "Epoch 190/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6254 - acc: 0.7455 - val_loss: 0.6423 - val_acc: 0.7477\n",
      "Epoch 191/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6250 - acc: 0.7458 - val_loss: 0.6398 - val_acc: 0.7488\n",
      "Epoch 192/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6235 - acc: 0.7451 - val_loss: 0.6406 - val_acc: 0.7497\n",
      "Epoch 193/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6220 - acc: 0.7468 - val_loss: 0.6385 - val_acc: 0.7497\n",
      "Epoch 194/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6214 - acc: 0.7465 - val_loss: 0.6378 - val_acc: 0.7502\n",
      "Epoch 195/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6192 - acc: 0.7477 - val_loss: 0.6359 - val_acc: 0.7510\n",
      "Epoch 196/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6167 - acc: 0.7486 - val_loss: 0.6352 - val_acc: 0.7501\n",
      "Epoch 197/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6153 - acc: 0.7489 - val_loss: 0.6330 - val_acc: 0.7506\n",
      "Epoch 198/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6155 - acc: 0.7485 - val_loss: 0.6320 - val_acc: 0.7523\n",
      "Epoch 199/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6132 - acc: 0.7505 - val_loss: 0.6344 - val_acc: 0.7497\n",
      "Epoch 200/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6116 - acc: 0.7504 - val_loss: 0.6323 - val_acc: 0.7529\n",
      "Epoch 201/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6112 - acc: 0.7513 - val_loss: 0.6303 - val_acc: 0.7533\n",
      "Epoch 202/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.6105 - acc: 0.7506 - val_loss: 0.6312 - val_acc: 0.7531\n",
      "Epoch 203/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6089 - acc: 0.7520 - val_loss: 0.6300 - val_acc: 0.7524\n",
      "Epoch 204/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6064 - acc: 0.7526 - val_loss: 0.6292 - val_acc: 0.7534\n",
      "Epoch 205/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6076 - acc: 0.7519 - val_loss: 0.6288 - val_acc: 0.7548\n",
      "Epoch 206/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6046 - acc: 0.7539 - val_loss: 0.6260 - val_acc: 0.7560\n",
      "Epoch 207/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6040 - acc: 0.7541 - val_loss: 0.6270 - val_acc: 0.7544\n",
      "Epoch 208/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6034 - acc: 0.7542 - val_loss: 0.6244 - val_acc: 0.7572\n",
      "Epoch 209/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6030 - acc: 0.7539 - val_loss: 0.6231 - val_acc: 0.7567\n",
      "Epoch 210/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6001 - acc: 0.7553 - val_loss: 0.6241 - val_acc: 0.7564\n",
      "Epoch 211/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.6001 - acc: 0.7552 - val_loss: 0.6216 - val_acc: 0.7579\n",
      "Epoch 212/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5979 - acc: 0.7557 - val_loss: 0.6208 - val_acc: 0.7577\n",
      "Epoch 213/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5953 - acc: 0.7570 - val_loss: 0.6197 - val_acc: 0.7593\n",
      "Epoch 214/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5958 - acc: 0.7570 - val_loss: 0.6205 - val_acc: 0.7588\n",
      "Epoch 215/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5941 - acc: 0.7577 - val_loss: 0.6203 - val_acc: 0.7594\n",
      "Epoch 216/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5923 - acc: 0.7581 - val_loss: 0.6172 - val_acc: 0.7618\n",
      "Epoch 217/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5930 - acc: 0.7583 - val_loss: 0.6170 - val_acc: 0.7610\n",
      "Epoch 218/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5916 - acc: 0.7591 - val_loss: 0.6152 - val_acc: 0.7622\n",
      "Epoch 219/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5891 - acc: 0.7598 - val_loss: 0.6154 - val_acc: 0.7627\n",
      "Epoch 220/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5869 - acc: 0.7598 - val_loss: 0.6158 - val_acc: 0.7622\n",
      "Epoch 221/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5882 - acc: 0.7609 - val_loss: 0.6139 - val_acc: 0.7640\n",
      "Epoch 222/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5860 - acc: 0.7612 - val_loss: 0.6131 - val_acc: 0.7640\n",
      "Epoch 223/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5852 - acc: 0.7612 - val_loss: 0.6103 - val_acc: 0.7647\n",
      "Epoch 224/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5834 - acc: 0.7616 - val_loss: 0.6090 - val_acc: 0.7657\n",
      "Epoch 225/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5827 - acc: 0.7624 - val_loss: 0.6089 - val_acc: 0.7663\n",
      "Epoch 226/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5820 - acc: 0.7638 - val_loss: 0.6104 - val_acc: 0.7630\n",
      "Epoch 227/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5789 - acc: 0.7639 - val_loss: 0.6073 - val_acc: 0.7660\n",
      "Epoch 228/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5776 - acc: 0.7657 - val_loss: 0.6072 - val_acc: 0.7676\n",
      "Epoch 229/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5775 - acc: 0.7652 - val_loss: 0.6064 - val_acc: 0.7682\n",
      "Epoch 230/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5765 - acc: 0.7653 - val_loss: 0.6056 - val_acc: 0.7688\n",
      "Epoch 231/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5751 - acc: 0.7654 - val_loss: 0.6064 - val_acc: 0.7659\n",
      "Epoch 232/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5747 - acc: 0.7655 - val_loss: 0.6056 - val_acc: 0.7684\n",
      "Epoch 233/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5748 - acc: 0.7663 - val_loss: 0.6045 - val_acc: 0.7689\n",
      "Epoch 234/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5726 - acc: 0.7663 - val_loss: 0.6068 - val_acc: 0.7682\n",
      "Epoch 235/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5686 - acc: 0.7681 - val_loss: 0.6006 - val_acc: 0.7712\n",
      "Epoch 236/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5698 - acc: 0.7688 - val_loss: 0.6020 - val_acc: 0.7708\n",
      "Epoch 237/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5687 - acc: 0.7682 - val_loss: 0.5999 - val_acc: 0.7714\n",
      "Epoch 238/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5675 - acc: 0.7698 - val_loss: 0.6001 - val_acc: 0.7709\n",
      "Epoch 239/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5665 - acc: 0.7696 - val_loss: 0.5976 - val_acc: 0.7721\n",
      "Epoch 240/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5639 - acc: 0.7707 - val_loss: 0.5980 - val_acc: 0.7717\n",
      "Epoch 241/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5642 - acc: 0.7705 - val_loss: 0.5948 - val_acc: 0.7748\n",
      "Epoch 242/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5642 - acc: 0.7694 - val_loss: 0.5972 - val_acc: 0.7737\n",
      "Epoch 243/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5613 - acc: 0.7713 - val_loss: 0.5949 - val_acc: 0.7740\n",
      "Epoch 244/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5596 - acc: 0.7724 - val_loss: 0.5950 - val_acc: 0.7765\n",
      "Epoch 245/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5583 - acc: 0.7729 - val_loss: 0.5934 - val_acc: 0.7773\n",
      "Epoch 246/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.5580 - acc: 0.7731 - val_loss: 0.5916 - val_acc: 0.7779\n",
      "Epoch 247/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5559 - acc: 0.7732 - val_loss: 0.5933 - val_acc: 0.7743\n",
      "Epoch 248/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5572 - acc: 0.7732 - val_loss: 0.5901 - val_acc: 0.7768\n",
      "Epoch 249/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5552 - acc: 0.7735 - val_loss: 0.5901 - val_acc: 0.7774\n",
      "Epoch 250/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5541 - acc: 0.7743 - val_loss: 0.5910 - val_acc: 0.7770\n",
      "Epoch 251/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5521 - acc: 0.7754 - val_loss: 0.5906 - val_acc: 0.7774\n",
      "Epoch 252/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5509 - acc: 0.7753 - val_loss: 0.5882 - val_acc: 0.7772\n",
      "Epoch 253/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5517 - acc: 0.7753 - val_loss: 0.5882 - val_acc: 0.7793\n",
      "Epoch 254/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5489 - acc: 0.7769 - val_loss: 0.5867 - val_acc: 0.7807\n",
      "Epoch 255/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5493 - acc: 0.7764 - val_loss: 0.5876 - val_acc: 0.7800\n",
      "Epoch 256/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5467 - acc: 0.7774 - val_loss: 0.5846 - val_acc: 0.7809\n",
      "Epoch 257/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5471 - acc: 0.7769 - val_loss: 0.5837 - val_acc: 0.7823\n",
      "Epoch 258/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5454 - acc: 0.7781 - val_loss: 0.5824 - val_acc: 0.7816\n",
      "Epoch 259/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5436 - acc: 0.7785 - val_loss: 0.5852 - val_acc: 0.7803\n",
      "Epoch 260/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5442 - acc: 0.7784 - val_loss: 0.5819 - val_acc: 0.7818\n",
      "Epoch 261/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5418 - acc: 0.7799 - val_loss: 0.5817 - val_acc: 0.7830\n",
      "Epoch 262/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5411 - acc: 0.7790 - val_loss: 0.5819 - val_acc: 0.7835\n",
      "Epoch 263/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5388 - acc: 0.7803 - val_loss: 0.5791 - val_acc: 0.7861\n",
      "Epoch 264/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5389 - acc: 0.7803 - val_loss: 0.5816 - val_acc: 0.7829\n",
      "Epoch 265/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5374 - acc: 0.7806 - val_loss: 0.5801 - val_acc: 0.7845\n",
      "Epoch 266/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5365 - acc: 0.7825 - val_loss: 0.5793 - val_acc: 0.7833\n",
      "Epoch 267/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5356 - acc: 0.7822 - val_loss: 0.5787 - val_acc: 0.7874\n",
      "Epoch 268/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5362 - acc: 0.7825 - val_loss: 0.5780 - val_acc: 0.7860\n",
      "Epoch 269/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5338 - acc: 0.7824 - val_loss: 0.5785 - val_acc: 0.7860\n",
      "Epoch 270/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5340 - acc: 0.7824 - val_loss: 0.5774 - val_acc: 0.7866\n",
      "Epoch 271/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.5322 - acc: 0.7838 - val_loss: 0.5769 - val_acc: 0.7860\n",
      "Epoch 272/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5317 - acc: 0.7830 - val_loss: 0.5760 - val_acc: 0.7868\n",
      "Epoch 273/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5289 - acc: 0.7846 - val_loss: 0.5754 - val_acc: 0.7877\n",
      "Epoch 274/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5291 - acc: 0.7859 - val_loss: 0.5749 - val_acc: 0.7887\n",
      "Epoch 275/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5274 - acc: 0.7842 - val_loss: 0.5730 - val_acc: 0.7893\n",
      "Epoch 276/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5247 - acc: 0.7867 - val_loss: 0.5738 - val_acc: 0.7895\n",
      "Epoch 277/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5263 - acc: 0.7865 - val_loss: 0.5726 - val_acc: 0.7917\n",
      "Epoch 278/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5241 - acc: 0.7866 - val_loss: 0.5746 - val_acc: 0.7882\n",
      "Epoch 279/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5249 - acc: 0.7866 - val_loss: 0.5749 - val_acc: 0.7890\n",
      "Epoch 280/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5225 - acc: 0.7876 - val_loss: 0.5692 - val_acc: 0.7925\n",
      "Epoch 281/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5223 - acc: 0.7885 - val_loss: 0.5718 - val_acc: 0.7922\n",
      "Epoch 282/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5218 - acc: 0.7876 - val_loss: 0.5710 - val_acc: 0.7912\n",
      "Epoch 283/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5207 - acc: 0.7881 - val_loss: 0.5699 - val_acc: 0.7917\n",
      "Epoch 284/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5190 - acc: 0.7891 - val_loss: 0.5698 - val_acc: 0.7918\n",
      "Epoch 285/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5178 - acc: 0.7893 - val_loss: 0.5680 - val_acc: 0.7950\n",
      "Epoch 286/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5167 - acc: 0.7895 - val_loss: 0.5688 - val_acc: 0.7922\n",
      "Epoch 287/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5162 - acc: 0.7893 - val_loss: 0.5662 - val_acc: 0.7941\n",
      "Epoch 288/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5146 - acc: 0.7898 - val_loss: 0.5648 - val_acc: 0.7960\n",
      "Epoch 289/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.5132 - acc: 0.7914 - val_loss: 0.5660 - val_acc: 0.7958\n",
      "Epoch 290/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5129 - acc: 0.7914 - val_loss: 0.5660 - val_acc: 0.7954\n",
      "Epoch 291/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5110 - acc: 0.7913 - val_loss: 0.5654 - val_acc: 0.7973\n",
      "Epoch 292/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5102 - acc: 0.7928 - val_loss: 0.5653 - val_acc: 0.7947\n",
      "Epoch 293/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5112 - acc: 0.7916 - val_loss: 0.5652 - val_acc: 0.7942\n",
      "Epoch 294/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5107 - acc: 0.7924 - val_loss: 0.5656 - val_acc: 0.7944\n",
      "Epoch 295/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5093 - acc: 0.7932 - val_loss: 0.5622 - val_acc: 0.7961\n",
      "Epoch 296/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5074 - acc: 0.7940 - val_loss: 0.5624 - val_acc: 0.7974\n",
      "Epoch 297/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5054 - acc: 0.7947 - val_loss: 0.5600 - val_acc: 0.7992\n",
      "Epoch 298/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5063 - acc: 0.7944 - val_loss: 0.5618 - val_acc: 0.7986\n",
      "Epoch 299/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5051 - acc: 0.7944 - val_loss: 0.5617 - val_acc: 0.7994\n",
      "Epoch 300/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5045 - acc: 0.7951 - val_loss: 0.5592 - val_acc: 0.8000\n",
      "Epoch 301/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5006 - acc: 0.7959 - val_loss: 0.5607 - val_acc: 0.7980\n",
      "Epoch 302/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5013 - acc: 0.7959 - val_loss: 0.5590 - val_acc: 0.7997\n",
      "Epoch 303/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5021 - acc: 0.7966 - val_loss: 0.5608 - val_acc: 0.8002\n",
      "Epoch 304/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.5010 - acc: 0.7961 - val_loss: 0.5583 - val_acc: 0.7994\n",
      "Epoch 305/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4998 - acc: 0.7970 - val_loss: 0.5610 - val_acc: 0.7980\n",
      "Epoch 306/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4986 - acc: 0.7976 - val_loss: 0.5578 - val_acc: 0.8014\n",
      "Epoch 307/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4967 - acc: 0.7985 - val_loss: 0.5547 - val_acc: 0.8024\n",
      "Epoch 308/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4953 - acc: 0.7992 - val_loss: 0.5579 - val_acc: 0.8004\n",
      "Epoch 309/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4958 - acc: 0.7987 - val_loss: 0.5539 - val_acc: 0.8026\n",
      "Epoch 310/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.4946 - acc: 0.7989 - val_loss: 0.5576 - val_acc: 0.8001\n",
      "Epoch 311/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4929 - acc: 0.7995 - val_loss: 0.5542 - val_acc: 0.8035\n",
      "Epoch 312/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4925 - acc: 0.8000 - val_loss: 0.5540 - val_acc: 0.8019\n",
      "Epoch 313/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4923 - acc: 0.8000 - val_loss: 0.5525 - val_acc: 0.8040\n",
      "Epoch 314/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4893 - acc: 0.8014 - val_loss: 0.5533 - val_acc: 0.8048\n",
      "Epoch 315/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4905 - acc: 0.8011 - val_loss: 0.5529 - val_acc: 0.8058\n",
      "Epoch 316/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.4886 - acc: 0.8020 - val_loss: 0.5509 - val_acc: 0.8065\n",
      "Epoch 317/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4893 - acc: 0.8020 - val_loss: 0.5515 - val_acc: 0.8063\n",
      "Epoch 318/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4882 - acc: 0.8020 - val_loss: 0.5509 - val_acc: 0.8062\n",
      "Epoch 319/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4882 - acc: 0.8018 - val_loss: 0.5488 - val_acc: 0.8071\n",
      "Epoch 320/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4866 - acc: 0.8025 - val_loss: 0.5499 - val_acc: 0.8069\n",
      "Epoch 321/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4837 - acc: 0.8037 - val_loss: 0.5514 - val_acc: 0.8051\n",
      "Epoch 322/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4831 - acc: 0.8043 - val_loss: 0.5483 - val_acc: 0.8078\n",
      "Epoch 323/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4821 - acc: 0.8048 - val_loss: 0.5499 - val_acc: 0.8088\n",
      "Epoch 324/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4829 - acc: 0.8044 - val_loss: 0.5483 - val_acc: 0.8083\n",
      "Epoch 325/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4833 - acc: 0.8037 - val_loss: 0.5482 - val_acc: 0.8086\n",
      "Epoch 326/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.4807 - acc: 0.8047 - val_loss: 0.5472 - val_acc: 0.8095\n",
      "Epoch 327/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4787 - acc: 0.8047 - val_loss: 0.5478 - val_acc: 0.8094\n",
      "Epoch 328/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4801 - acc: 0.8057 - val_loss: 0.5460 - val_acc: 0.8087\n",
      "Epoch 329/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4775 - acc: 0.8070 - val_loss: 0.5470 - val_acc: 0.8107\n",
      "Epoch 330/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4785 - acc: 0.8056 - val_loss: 0.5469 - val_acc: 0.8091\n",
      "Epoch 331/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4776 - acc: 0.8063 - val_loss: 0.5481 - val_acc: 0.8079\n",
      "Epoch 332/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4759 - acc: 0.8071 - val_loss: 0.5440 - val_acc: 0.8116\n",
      "Epoch 333/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4756 - acc: 0.8072 - val_loss: 0.5448 - val_acc: 0.8106\n",
      "Epoch 334/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4750 - acc: 0.8070 - val_loss: 0.5446 - val_acc: 0.8110\n",
      "Epoch 335/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4754 - acc: 0.8077 - val_loss: 0.5423 - val_acc: 0.8108\n",
      "Epoch 336/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4713 - acc: 0.8087 - val_loss: 0.5420 - val_acc: 0.8138\n",
      "Epoch 337/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4731 - acc: 0.8082 - val_loss: 0.5431 - val_acc: 0.8115\n",
      "Epoch 338/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4708 - acc: 0.8093 - val_loss: 0.5457 - val_acc: 0.8102\n",
      "Epoch 339/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4703 - acc: 0.8095 - val_loss: 0.5411 - val_acc: 0.8131\n",
      "Epoch 340/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4683 - acc: 0.8094 - val_loss: 0.5410 - val_acc: 0.8148\n",
      "Epoch 341/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4688 - acc: 0.8098 - val_loss: 0.5415 - val_acc: 0.8138\n",
      "Epoch 342/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4675 - acc: 0.8096 - val_loss: 0.5419 - val_acc: 0.8135\n",
      "Epoch 343/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4663 - acc: 0.8105 - val_loss: 0.5416 - val_acc: 0.8146\n",
      "Epoch 344/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4663 - acc: 0.8104 - val_loss: 0.5402 - val_acc: 0.8136\n",
      "Epoch 345/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4639 - acc: 0.8120 - val_loss: 0.5391 - val_acc: 0.8148\n",
      "Epoch 346/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4640 - acc: 0.8124 - val_loss: 0.5400 - val_acc: 0.8153\n",
      "Epoch 347/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4633 - acc: 0.8129 - val_loss: 0.5396 - val_acc: 0.8150\n",
      "Epoch 348/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.4627 - acc: 0.8122 - val_loss: 0.5391 - val_acc: 0.8166\n",
      "Epoch 349/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4642 - acc: 0.8118 - val_loss: 0.5373 - val_acc: 0.8164\n",
      "Epoch 350/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4607 - acc: 0.8132 - val_loss: 0.5402 - val_acc: 0.8145\n",
      "Epoch 351/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4607 - acc: 0.8131 - val_loss: 0.5369 - val_acc: 0.8182\n",
      "Epoch 352/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4597 - acc: 0.8133 - val_loss: 0.5376 - val_acc: 0.8175\n",
      "Epoch 353/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4588 - acc: 0.8142 - val_loss: 0.5381 - val_acc: 0.8164\n",
      "Epoch 354/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4590 - acc: 0.8138 - val_loss: 0.5367 - val_acc: 0.8185\n",
      "Epoch 355/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4579 - acc: 0.8135 - val_loss: 0.5386 - val_acc: 0.8160\n",
      "Epoch 356/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4567 - acc: 0.8148 - val_loss: 0.5375 - val_acc: 0.8177\n",
      "Epoch 357/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4564 - acc: 0.8151 - val_loss: 0.5363 - val_acc: 0.8186\n",
      "Epoch 358/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4564 - acc: 0.8152 - val_loss: 0.5368 - val_acc: 0.8159\n",
      "Epoch 359/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4561 - acc: 0.8153 - val_loss: 0.5358 - val_acc: 0.8184\n",
      "Epoch 360/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4533 - acc: 0.8165 - val_loss: 0.5361 - val_acc: 0.8191\n",
      "Epoch 361/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4525 - acc: 0.8165 - val_loss: 0.5366 - val_acc: 0.8190\n",
      "Epoch 362/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4519 - acc: 0.8163 - val_loss: 0.5331 - val_acc: 0.8222\n",
      "Epoch 363/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4543 - acc: 0.8157 - val_loss: 0.5346 - val_acc: 0.8188\n",
      "Epoch 364/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4532 - acc: 0.8168 - val_loss: 0.5344 - val_acc: 0.8201\n",
      "Epoch 365/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4497 - acc: 0.8179 - val_loss: 0.5335 - val_acc: 0.8214\n",
      "Epoch 366/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4476 - acc: 0.8190 - val_loss: 0.5324 - val_acc: 0.8213\n",
      "Epoch 367/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4490 - acc: 0.8185 - val_loss: 0.5312 - val_acc: 0.8221\n",
      "Epoch 368/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4494 - acc: 0.8180 - val_loss: 0.5352 - val_acc: 0.8207\n",
      "Epoch 369/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4469 - acc: 0.8191 - val_loss: 0.5345 - val_acc: 0.8208\n",
      "Epoch 370/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4464 - acc: 0.8195 - val_loss: 0.5311 - val_acc: 0.8216\n",
      "Epoch 371/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4483 - acc: 0.8181 - val_loss: 0.5306 - val_acc: 0.8242\n",
      "Epoch 372/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4456 - acc: 0.8190 - val_loss: 0.5313 - val_acc: 0.8220\n",
      "Epoch 373/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4475 - acc: 0.8192 - val_loss: 0.5315 - val_acc: 0.8224\n",
      "Epoch 374/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4443 - acc: 0.8203 - val_loss: 0.5307 - val_acc: 0.8239\n",
      "Epoch 375/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4450 - acc: 0.8196 - val_loss: 0.5286 - val_acc: 0.8243\n",
      "Epoch 376/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4435 - acc: 0.8198 - val_loss: 0.5323 - val_acc: 0.8220\n",
      "Epoch 377/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4432 - acc: 0.8205 - val_loss: 0.5289 - val_acc: 0.8237\n",
      "Epoch 378/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4416 - acc: 0.8217 - val_loss: 0.5307 - val_acc: 0.8256\n",
      "Epoch 379/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4410 - acc: 0.8216 - val_loss: 0.5270 - val_acc: 0.8249\n",
      "Epoch 380/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4421 - acc: 0.8214 - val_loss: 0.5257 - val_acc: 0.8254\n",
      "Epoch 381/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4391 - acc: 0.8217 - val_loss: 0.5265 - val_acc: 0.8269\n",
      "Epoch 382/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4397 - acc: 0.8227 - val_loss: 0.5292 - val_acc: 0.8222\n",
      "Epoch 383/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4396 - acc: 0.8224 - val_loss: 0.5263 - val_acc: 0.8252\n",
      "Epoch 384/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4388 - acc: 0.8225 - val_loss: 0.5269 - val_acc: 0.8260\n",
      "Epoch 385/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4387 - acc: 0.8235 - val_loss: 0.5267 - val_acc: 0.8253\n",
      "Epoch 386/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4372 - acc: 0.8235 - val_loss: 0.5278 - val_acc: 0.8261\n",
      "Epoch 387/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4365 - acc: 0.8226 - val_loss: 0.5264 - val_acc: 0.8264\n",
      "Epoch 388/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4364 - acc: 0.8231 - val_loss: 0.5277 - val_acc: 0.8256\n",
      "Epoch 389/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4368 - acc: 0.8246 - val_loss: 0.5292 - val_acc: 0.8247\n",
      "Epoch 390/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4353 - acc: 0.8246 - val_loss: 0.5255 - val_acc: 0.8282\n",
      "Epoch 391/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4334 - acc: 0.8245 - val_loss: 0.5257 - val_acc: 0.8268\n",
      "Epoch 392/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4323 - acc: 0.8251 - val_loss: 0.5255 - val_acc: 0.8272\n",
      "Epoch 393/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4347 - acc: 0.8240 - val_loss: 0.5247 - val_acc: 0.8276\n",
      "Epoch 394/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4321 - acc: 0.8258 - val_loss: 0.5260 - val_acc: 0.8275\n",
      "Epoch 395/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4300 - acc: 0.8260 - val_loss: 0.5246 - val_acc: 0.8286\n",
      "Epoch 396/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.4300 - acc: 0.8255 - val_loss: 0.5273 - val_acc: 0.8270\n",
      "Epoch 397/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4290 - acc: 0.8264 - val_loss: 0.5265 - val_acc: 0.8302\n",
      "Epoch 398/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4293 - acc: 0.8269 - val_loss: 0.5258 - val_acc: 0.8298\n",
      "Epoch 399/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4279 - acc: 0.8275 - val_loss: 0.5277 - val_acc: 0.8282\n",
      "Epoch 400/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4285 - acc: 0.8263 - val_loss: 0.5231 - val_acc: 0.8314\n",
      "Epoch 401/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4257 - acc: 0.8282 - val_loss: 0.5252 - val_acc: 0.8301\n",
      "Epoch 402/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4287 - acc: 0.8270 - val_loss: 0.5231 - val_acc: 0.8314\n",
      "Epoch 403/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4283 - acc: 0.8273 - val_loss: 0.5249 - val_acc: 0.8294\n",
      "Epoch 404/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4260 - acc: 0.8284 - val_loss: 0.5237 - val_acc: 0.8299\n",
      "Epoch 405/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4226 - acc: 0.8301 - val_loss: 0.5248 - val_acc: 0.8317\n",
      "Epoch 406/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4233 - acc: 0.8302 - val_loss: 0.5232 - val_acc: 0.8322\n",
      "Epoch 407/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4241 - acc: 0.8289 - val_loss: 0.5232 - val_acc: 0.8322\n",
      "Epoch 408/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4241 - acc: 0.8287 - val_loss: 0.5241 - val_acc: 0.8320\n",
      "Epoch 409/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4231 - acc: 0.8294 - val_loss: 0.5231 - val_acc: 0.8345\n",
      "Epoch 410/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4213 - acc: 0.8299 - val_loss: 0.5239 - val_acc: 0.8324\n",
      "Epoch 411/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4200 - acc: 0.8301 - val_loss: 0.5226 - val_acc: 0.8318\n",
      "Epoch 412/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4201 - acc: 0.8303 - val_loss: 0.5228 - val_acc: 0.8336\n",
      "Epoch 413/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4207 - acc: 0.8297 - val_loss: 0.5227 - val_acc: 0.8333\n",
      "Epoch 414/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4210 - acc: 0.8297 - val_loss: 0.5229 - val_acc: 0.8328\n",
      "Epoch 415/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4174 - acc: 0.8322 - val_loss: 0.5199 - val_acc: 0.8352\n",
      "Epoch 416/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4202 - acc: 0.8304 - val_loss: 0.5198 - val_acc: 0.8345\n",
      "Epoch 417/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4178 - acc: 0.8316 - val_loss: 0.5203 - val_acc: 0.8336\n",
      "Epoch 418/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4162 - acc: 0.8317 - val_loss: 0.5203 - val_acc: 0.8342\n",
      "Epoch 419/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4169 - acc: 0.8318 - val_loss: 0.5221 - val_acc: 0.8351\n",
      "Epoch 420/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4166 - acc: 0.8317 - val_loss: 0.5209 - val_acc: 0.8333\n",
      "Epoch 421/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4157 - acc: 0.8325 - val_loss: 0.5211 - val_acc: 0.8340\n",
      "Epoch 422/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4139 - acc: 0.8332 - val_loss: 0.5219 - val_acc: 0.8333\n",
      "Epoch 423/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4151 - acc: 0.8322 - val_loss: 0.5212 - val_acc: 0.8353\n",
      "Epoch 424/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4153 - acc: 0.8327 - val_loss: 0.5195 - val_acc: 0.8353\n",
      "Epoch 425/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4133 - acc: 0.8335 - val_loss: 0.5200 - val_acc: 0.8339\n",
      "Epoch 426/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4120 - acc: 0.8345 - val_loss: 0.5195 - val_acc: 0.8372\n",
      "Epoch 427/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4123 - acc: 0.8337 - val_loss: 0.5200 - val_acc: 0.8348\n",
      "Epoch 428/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4128 - acc: 0.8345 - val_loss: 0.5193 - val_acc: 0.8358\n",
      "Epoch 429/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4100 - acc: 0.8352 - val_loss: 0.5185 - val_acc: 0.8351\n",
      "Epoch 430/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.4114 - acc: 0.8332 - val_loss: 0.5169 - val_acc: 0.8383\n",
      "Epoch 431/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4085 - acc: 0.8353 - val_loss: 0.5186 - val_acc: 0.8353\n",
      "Epoch 432/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4106 - acc: 0.8350 - val_loss: 0.5179 - val_acc: 0.8350\n",
      "Epoch 433/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4103 - acc: 0.8350 - val_loss: 0.5166 - val_acc: 0.8351\n",
      "Epoch 434/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4072 - acc: 0.8364 - val_loss: 0.5203 - val_acc: 0.8338\n",
      "Epoch 435/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4070 - acc: 0.8368 - val_loss: 0.5217 - val_acc: 0.8355\n",
      "Epoch 436/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4063 - acc: 0.8372 - val_loss: 0.5182 - val_acc: 0.8362\n",
      "Epoch 437/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4067 - acc: 0.8367 - val_loss: 0.5192 - val_acc: 0.8364\n",
      "Epoch 438/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4062 - acc: 0.8366 - val_loss: 0.5166 - val_acc: 0.8379\n",
      "Epoch 439/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4060 - acc: 0.8367 - val_loss: 0.5185 - val_acc: 0.8352\n",
      "Epoch 440/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4072 - acc: 0.8360 - val_loss: 0.5175 - val_acc: 0.8363\n",
      "Epoch 441/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4053 - acc: 0.8360 - val_loss: 0.5161 - val_acc: 0.8376\n",
      "Epoch 442/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4050 - acc: 0.8375 - val_loss: 0.5144 - val_acc: 0.8395\n",
      "Epoch 443/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4054 - acc: 0.8373 - val_loss: 0.5149 - val_acc: 0.8406\n",
      "Epoch 444/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4020 - acc: 0.8382 - val_loss: 0.5145 - val_acc: 0.8397\n",
      "Epoch 445/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4042 - acc: 0.8368 - val_loss: 0.5155 - val_acc: 0.8384\n",
      "Epoch 446/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4014 - acc: 0.8386 - val_loss: 0.5161 - val_acc: 0.8390\n",
      "Epoch 447/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.4018 - acc: 0.8387 - val_loss: 0.5165 - val_acc: 0.8399\n",
      "Epoch 448/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4012 - acc: 0.8389 - val_loss: 0.5162 - val_acc: 0.8396\n",
      "Epoch 449/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4006 - acc: 0.8398 - val_loss: 0.5171 - val_acc: 0.8388\n",
      "Epoch 450/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3996 - acc: 0.8387 - val_loss: 0.5156 - val_acc: 0.8387\n",
      "Epoch 451/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3994 - acc: 0.8392 - val_loss: 0.5154 - val_acc: 0.8415\n",
      "Epoch 452/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.4009 - acc: 0.8387 - val_loss: 0.5142 - val_acc: 0.8407\n",
      "Epoch 453/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3986 - acc: 0.8401 - val_loss: 0.5152 - val_acc: 0.8395\n",
      "Epoch 454/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3962 - acc: 0.8406 - val_loss: 0.5132 - val_acc: 0.8412\n",
      "Epoch 455/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3982 - acc: 0.8394 - val_loss: 0.5155 - val_acc: 0.8417\n",
      "Epoch 456/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3966 - acc: 0.8397 - val_loss: 0.5170 - val_acc: 0.8388\n",
      "Epoch 457/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3965 - acc: 0.8400 - val_loss: 0.5158 - val_acc: 0.8394\n",
      "Epoch 458/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3971 - acc: 0.8405 - val_loss: 0.5145 - val_acc: 0.8414\n",
      "Epoch 459/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3969 - acc: 0.8409 - val_loss: 0.5136 - val_acc: 0.8423\n",
      "Epoch 460/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3963 - acc: 0.8408 - val_loss: 0.5146 - val_acc: 0.8411\n",
      "Epoch 461/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3957 - acc: 0.8413 - val_loss: 0.5158 - val_acc: 0.8401\n",
      "Epoch 462/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3954 - acc: 0.8409 - val_loss: 0.5127 - val_acc: 0.8417\n",
      "Epoch 463/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3935 - acc: 0.8413 - val_loss: 0.5136 - val_acc: 0.8428\n",
      "Epoch 464/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3935 - acc: 0.8427 - val_loss: 0.5143 - val_acc: 0.8420\n",
      "Epoch 465/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3925 - acc: 0.8420 - val_loss: 0.5151 - val_acc: 0.8425\n",
      "Epoch 466/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3930 - acc: 0.8422 - val_loss: 0.5148 - val_acc: 0.8430\n",
      "Epoch 467/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3932 - acc: 0.8419 - val_loss: 0.5130 - val_acc: 0.8421\n",
      "Epoch 468/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3926 - acc: 0.8430 - val_loss: 0.5112 - val_acc: 0.8425\n",
      "Epoch 469/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3918 - acc: 0.8432 - val_loss: 0.5135 - val_acc: 0.8419\n",
      "Epoch 470/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3908 - acc: 0.8427 - val_loss: 0.5126 - val_acc: 0.8428\n",
      "Epoch 471/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3912 - acc: 0.8424 - val_loss: 0.5152 - val_acc: 0.8432\n",
      "Epoch 472/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3889 - acc: 0.8435 - val_loss: 0.5148 - val_acc: 0.8416\n",
      "Epoch 473/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3915 - acc: 0.8421 - val_loss: 0.5113 - val_acc: 0.8424\n",
      "Epoch 474/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3894 - acc: 0.8437 - val_loss: 0.5111 - val_acc: 0.8439\n",
      "Epoch 475/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3901 - acc: 0.8431 - val_loss: 0.5089 - val_acc: 0.8435\n",
      "Epoch 476/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3881 - acc: 0.8441 - val_loss: 0.5115 - val_acc: 0.8431\n",
      "Epoch 477/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3885 - acc: 0.8437 - val_loss: 0.5111 - val_acc: 0.8435\n",
      "Epoch 478/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3880 - acc: 0.8449 - val_loss: 0.5130 - val_acc: 0.8431\n",
      "Epoch 479/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3892 - acc: 0.8443 - val_loss: 0.5136 - val_acc: 0.8432\n",
      "Epoch 480/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.3860 - acc: 0.8447 - val_loss: 0.5112 - val_acc: 0.8454\n",
      "Epoch 481/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3875 - acc: 0.8455 - val_loss: 0.5110 - val_acc: 0.8456\n",
      "Epoch 482/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3878 - acc: 0.8442 - val_loss: 0.5102 - val_acc: 0.8445\n",
      "Epoch 483/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3855 - acc: 0.8450 - val_loss: 0.5100 - val_acc: 0.8455\n",
      "Epoch 484/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3845 - acc: 0.8454 - val_loss: 0.5114 - val_acc: 0.8457\n",
      "Epoch 485/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3845 - acc: 0.8460 - val_loss: 0.5106 - val_acc: 0.8440\n",
      "Epoch 486/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3840 - acc: 0.8463 - val_loss: 0.5112 - val_acc: 0.8459\n",
      "Epoch 487/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3821 - acc: 0.8471 - val_loss: 0.5114 - val_acc: 0.8455\n",
      "Epoch 488/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3828 - acc: 0.8463 - val_loss: 0.5136 - val_acc: 0.8451\n",
      "Epoch 489/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3818 - acc: 0.8470 - val_loss: 0.5108 - val_acc: 0.8472\n",
      "Epoch 490/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3829 - acc: 0.8468 - val_loss: 0.5110 - val_acc: 0.8468\n",
      "Epoch 491/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3805 - acc: 0.8470 - val_loss: 0.5107 - val_acc: 0.8450\n",
      "Epoch 492/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3810 - acc: 0.8466 - val_loss: 0.5114 - val_acc: 0.8443\n",
      "Epoch 493/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3811 - acc: 0.8468 - val_loss: 0.5084 - val_acc: 0.8465\n",
      "Epoch 494/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3817 - acc: 0.8471 - val_loss: 0.5113 - val_acc: 0.8449\n",
      "Epoch 495/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3818 - acc: 0.8466 - val_loss: 0.5093 - val_acc: 0.8460\n",
      "Epoch 496/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3817 - acc: 0.8473 - val_loss: 0.5084 - val_acc: 0.8471\n",
      "Epoch 497/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3789 - acc: 0.8475 - val_loss: 0.5129 - val_acc: 0.8453\n",
      "Epoch 498/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3797 - acc: 0.8481 - val_loss: 0.5103 - val_acc: 0.8462\n",
      "Epoch 499/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3808 - acc: 0.8473 - val_loss: 0.5111 - val_acc: 0.8450\n",
      "Epoch 500/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3786 - acc: 0.8482 - val_loss: 0.5125 - val_acc: 0.8453\n",
      "Epoch 501/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3796 - acc: 0.8481 - val_loss: 0.5119 - val_acc: 0.8460\n",
      "Epoch 502/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3753 - acc: 0.8493 - val_loss: 0.5108 - val_acc: 0.8466\n",
      "Epoch 503/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3744 - acc: 0.8506 - val_loss: 0.5125 - val_acc: 0.8486\n",
      "Epoch 504/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3782 - acc: 0.8483 - val_loss: 0.5102 - val_acc: 0.8464\n",
      "Epoch 505/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3764 - acc: 0.8495 - val_loss: 0.5128 - val_acc: 0.8477\n",
      "Epoch 506/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3758 - acc: 0.8494 - val_loss: 0.5094 - val_acc: 0.8485\n",
      "Epoch 507/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3732 - acc: 0.8500 - val_loss: 0.5103 - val_acc: 0.8475\n",
      "Epoch 508/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3730 - acc: 0.8503 - val_loss: 0.5086 - val_acc: 0.8489\n",
      "Epoch 509/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3738 - acc: 0.8503 - val_loss: 0.5098 - val_acc: 0.8483\n",
      "Epoch 510/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3728 - acc: 0.8510 - val_loss: 0.5129 - val_acc: 0.8464\n",
      "Epoch 511/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3754 - acc: 0.8494 - val_loss: 0.5103 - val_acc: 0.8477\n",
      "Epoch 512/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3728 - acc: 0.8508 - val_loss: 0.5100 - val_acc: 0.8486\n",
      "Epoch 513/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3748 - acc: 0.8500 - val_loss: 0.5114 - val_acc: 0.8466\n",
      "Epoch 514/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3722 - acc: 0.8509 - val_loss: 0.5110 - val_acc: 0.8487\n",
      "Epoch 515/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3718 - acc: 0.8517 - val_loss: 0.5096 - val_acc: 0.8496\n",
      "Epoch 516/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3734 - acc: 0.8509 - val_loss: 0.5104 - val_acc: 0.8485\n",
      "Epoch 517/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.3700 - acc: 0.8520 - val_loss: 0.5098 - val_acc: 0.8489\n",
      "Epoch 518/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3704 - acc: 0.8525 - val_loss: 0.5110 - val_acc: 0.8473\n",
      "Epoch 519/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3716 - acc: 0.8520 - val_loss: 0.5112 - val_acc: 0.8484\n",
      "Epoch 520/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3709 - acc: 0.8508 - val_loss: 0.5107 - val_acc: 0.8493\n",
      "Epoch 521/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3714 - acc: 0.8521 - val_loss: 0.5113 - val_acc: 0.8490\n",
      "Epoch 522/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3695 - acc: 0.8525 - val_loss: 0.5093 - val_acc: 0.8488\n",
      "Epoch 523/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3694 - acc: 0.8523 - val_loss: 0.5082 - val_acc: 0.8488\n",
      "Epoch 524/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3687 - acc: 0.8517 - val_loss: 0.5094 - val_acc: 0.8493\n",
      "Epoch 525/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3671 - acc: 0.8534 - val_loss: 0.5080 - val_acc: 0.8482\n",
      "Epoch 526/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3666 - acc: 0.8528 - val_loss: 0.5098 - val_acc: 0.8484\n",
      "Epoch 527/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3687 - acc: 0.8529 - val_loss: 0.5104 - val_acc: 0.8501\n",
      "Epoch 528/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3679 - acc: 0.8534 - val_loss: 0.5079 - val_acc: 0.8492\n",
      "Epoch 529/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3651 - acc: 0.8539 - val_loss: 0.5079 - val_acc: 0.8497\n",
      "Epoch 530/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3675 - acc: 0.8540 - val_loss: 0.5098 - val_acc: 0.8510\n",
      "Epoch 531/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3677 - acc: 0.8527 - val_loss: 0.5101 - val_acc: 0.8483\n",
      "Epoch 532/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3661 - acc: 0.8543 - val_loss: 0.5082 - val_acc: 0.8503\n",
      "Epoch 533/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3689 - acc: 0.8528 - val_loss: 0.5082 - val_acc: 0.8501\n",
      "Epoch 534/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3641 - acc: 0.8553 - val_loss: 0.5086 - val_acc: 0.8506\n",
      "Epoch 535/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3652 - acc: 0.8540 - val_loss: 0.5081 - val_acc: 0.8502\n",
      "Epoch 536/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3636 - acc: 0.8546 - val_loss: 0.5070 - val_acc: 0.8516\n",
      "Epoch 537/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3648 - acc: 0.8547 - val_loss: 0.5065 - val_acc: 0.8511\n",
      "Epoch 538/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3649 - acc: 0.8546 - val_loss: 0.5079 - val_acc: 0.8514\n",
      "Epoch 539/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3653 - acc: 0.8539 - val_loss: 0.5079 - val_acc: 0.8516\n",
      "Epoch 540/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3625 - acc: 0.8560 - val_loss: 0.5100 - val_acc: 0.8500\n",
      "Epoch 541/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3644 - acc: 0.8548 - val_loss: 0.5081 - val_acc: 0.8509\n",
      "Epoch 542/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3638 - acc: 0.8551 - val_loss: 0.5094 - val_acc: 0.8502\n",
      "Epoch 543/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3644 - acc: 0.8551 - val_loss: 0.5080 - val_acc: 0.8513\n",
      "Epoch 544/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3605 - acc: 0.8563 - val_loss: 0.5058 - val_acc: 0.8521\n",
      "Epoch 545/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3612 - acc: 0.8564 - val_loss: 0.5093 - val_acc: 0.8521\n",
      "Epoch 546/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3599 - acc: 0.8569 - val_loss: 0.5083 - val_acc: 0.8526\n",
      "Epoch 547/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3606 - acc: 0.8562 - val_loss: 0.5103 - val_acc: 0.8521\n",
      "Epoch 548/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3596 - acc: 0.8573 - val_loss: 0.5090 - val_acc: 0.8527\n",
      "Epoch 549/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3618 - acc: 0.8561 - val_loss: 0.5095 - val_acc: 0.8511\n",
      "Epoch 550/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3591 - acc: 0.8574 - val_loss: 0.5093 - val_acc: 0.8511\n",
      "Epoch 551/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3600 - acc: 0.8567 - val_loss: 0.5092 - val_acc: 0.8523\n",
      "Epoch 552/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3590 - acc: 0.8564 - val_loss: 0.5094 - val_acc: 0.8522\n",
      "Epoch 553/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3599 - acc: 0.8564 - val_loss: 0.5100 - val_acc: 0.8515\n",
      "Epoch 554/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3596 - acc: 0.8568 - val_loss: 0.5091 - val_acc: 0.8504\n",
      "Epoch 555/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3583 - acc: 0.8567 - val_loss: 0.5078 - val_acc: 0.8512\n",
      "Epoch 556/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3577 - acc: 0.8577 - val_loss: 0.5089 - val_acc: 0.8519\n",
      "Epoch 557/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3574 - acc: 0.8579 - val_loss: 0.5094 - val_acc: 0.8510\n",
      "Epoch 558/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3582 - acc: 0.8567 - val_loss: 0.5089 - val_acc: 0.8516\n",
      "Epoch 559/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3562 - acc: 0.8584 - val_loss: 0.5062 - val_acc: 0.8536\n",
      "Epoch 560/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3575 - acc: 0.8579 - val_loss: 0.5094 - val_acc: 0.8519\n",
      "Epoch 561/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3560 - acc: 0.8581 - val_loss: 0.5081 - val_acc: 0.8518\n",
      "Epoch 562/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3573 - acc: 0.8587 - val_loss: 0.5078 - val_acc: 0.8537\n",
      "Epoch 563/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3534 - acc: 0.8590 - val_loss: 0.5061 - val_acc: 0.8541\n",
      "Epoch 564/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3571 - acc: 0.8571 - val_loss: 0.5038 - val_acc: 0.8540\n",
      "Epoch 565/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3541 - acc: 0.8590 - val_loss: 0.5050 - val_acc: 0.8536\n",
      "Epoch 566/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3550 - acc: 0.8586 - val_loss: 0.5066 - val_acc: 0.8544\n",
      "Epoch 567/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3549 - acc: 0.8579 - val_loss: 0.5083 - val_acc: 0.8539\n",
      "Epoch 568/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3525 - acc: 0.8589 - val_loss: 0.5089 - val_acc: 0.8536\n",
      "Epoch 569/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3537 - acc: 0.8606 - val_loss: 0.5041 - val_acc: 0.8558\n",
      "Epoch 570/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3551 - acc: 0.8581 - val_loss: 0.5071 - val_acc: 0.8533\n",
      "Epoch 571/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3521 - acc: 0.8604 - val_loss: 0.5067 - val_acc: 0.8546\n",
      "Epoch 572/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3507 - acc: 0.8605 - val_loss: 0.5061 - val_acc: 0.8547\n",
      "Epoch 573/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3510 - acc: 0.8600 - val_loss: 0.5067 - val_acc: 0.8538\n",
      "Epoch 574/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3533 - acc: 0.8594 - val_loss: 0.5069 - val_acc: 0.8521\n",
      "Epoch 575/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3525 - acc: 0.8598 - val_loss: 0.5060 - val_acc: 0.8535\n",
      "Epoch 576/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3510 - acc: 0.8605 - val_loss: 0.5051 - val_acc: 0.8557\n",
      "Epoch 577/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3514 - acc: 0.8607 - val_loss: 0.5095 - val_acc: 0.8527\n",
      "Epoch 578/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3516 - acc: 0.8603 - val_loss: 0.5050 - val_acc: 0.8551\n",
      "Epoch 579/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3515 - acc: 0.8607 - val_loss: 0.5073 - val_acc: 0.8540\n",
      "Epoch 580/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3496 - acc: 0.8614 - val_loss: 0.5054 - val_acc: 0.8558\n",
      "Epoch 581/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3502 - acc: 0.8610 - val_loss: 0.5075 - val_acc: 0.8548\n",
      "Epoch 582/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3495 - acc: 0.8608 - val_loss: 0.5032 - val_acc: 0.8529\n",
      "Epoch 583/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3471 - acc: 0.8623 - val_loss: 0.5039 - val_acc: 0.8570\n",
      "Epoch 584/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3491 - acc: 0.8611 - val_loss: 0.5049 - val_acc: 0.8538\n",
      "Epoch 585/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3496 - acc: 0.8618 - val_loss: 0.5047 - val_acc: 0.8554\n",
      "Epoch 586/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3484 - acc: 0.8618 - val_loss: 0.5042 - val_acc: 0.8564\n",
      "Epoch 587/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3459 - acc: 0.8622 - val_loss: 0.5072 - val_acc: 0.8548\n",
      "Epoch 588/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3479 - acc: 0.8619 - val_loss: 0.5052 - val_acc: 0.8559\n",
      "Epoch 589/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3462 - acc: 0.8622 - val_loss: 0.5084 - val_acc: 0.8538\n",
      "Epoch 590/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3444 - acc: 0.8635 - val_loss: 0.5069 - val_acc: 0.8565\n",
      "Epoch 591/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3482 - acc: 0.8618 - val_loss: 0.5050 - val_acc: 0.8571\n",
      "Epoch 592/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3481 - acc: 0.8617 - val_loss: 0.5072 - val_acc: 0.8571\n",
      "Epoch 593/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3471 - acc: 0.8628 - val_loss: 0.5045 - val_acc: 0.8552\n",
      "Epoch 594/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3478 - acc: 0.8620 - val_loss: 0.5051 - val_acc: 0.8556\n",
      "Epoch 595/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3461 - acc: 0.8625 - val_loss: 0.5048 - val_acc: 0.8565\n",
      "Epoch 596/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3478 - acc: 0.8615 - val_loss: 0.5045 - val_acc: 0.8572\n",
      "Epoch 597/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3438 - acc: 0.8635 - val_loss: 0.5033 - val_acc: 0.8558\n",
      "Epoch 598/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3459 - acc: 0.8624 - val_loss: 0.5065 - val_acc: 0.8560\n",
      "Epoch 599/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3438 - acc: 0.8637 - val_loss: 0.5026 - val_acc: 0.8559\n",
      "Epoch 600/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3436 - acc: 0.8635 - val_loss: 0.5053 - val_acc: 0.8566\n",
      "Epoch 601/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3470 - acc: 0.8628 - val_loss: 0.5021 - val_acc: 0.8555\n",
      "Epoch 602/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3430 - acc: 0.8642 - val_loss: 0.5054 - val_acc: 0.8548\n",
      "Epoch 603/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3424 - acc: 0.8652 - val_loss: 0.5049 - val_acc: 0.8564\n",
      "Epoch 604/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3426 - acc: 0.8639 - val_loss: 0.5073 - val_acc: 0.8552\n",
      "Epoch 605/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3444 - acc: 0.8633 - val_loss: 0.5031 - val_acc: 0.8562\n",
      "Epoch 606/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3430 - acc: 0.8645 - val_loss: 0.5040 - val_acc: 0.8564\n",
      "Epoch 607/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3428 - acc: 0.8640 - val_loss: 0.5040 - val_acc: 0.8570\n",
      "Epoch 608/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3429 - acc: 0.8638 - val_loss: 0.5093 - val_acc: 0.8545\n",
      "Epoch 609/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3424 - acc: 0.8642 - val_loss: 0.5079 - val_acc: 0.8567\n",
      "Epoch 610/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3413 - acc: 0.8641 - val_loss: 0.5054 - val_acc: 0.8566\n",
      "Epoch 611/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3405 - acc: 0.8641 - val_loss: 0.5046 - val_acc: 0.8583\n",
      "Epoch 612/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3412 - acc: 0.8647 - val_loss: 0.5074 - val_acc: 0.8555\n",
      "Epoch 613/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3415 - acc: 0.8652 - val_loss: 0.5089 - val_acc: 0.8545\n",
      "Epoch 614/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3407 - acc: 0.8660 - val_loss: 0.5073 - val_acc: 0.8563\n",
      "Epoch 615/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3392 - acc: 0.8654 - val_loss: 0.5076 - val_acc: 0.8561\n",
      "Epoch 616/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3401 - acc: 0.8652 - val_loss: 0.5080 - val_acc: 0.8579\n",
      "Epoch 617/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3401 - acc: 0.8648 - val_loss: 0.5049 - val_acc: 0.8577\n",
      "Epoch 618/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3401 - acc: 0.8653 - val_loss: 0.5057 - val_acc: 0.8579\n",
      "Epoch 619/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3375 - acc: 0.8667 - val_loss: 0.5047 - val_acc: 0.8574\n",
      "Epoch 620/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3401 - acc: 0.8655 - val_loss: 0.5047 - val_acc: 0.8586\n",
      "Epoch 621/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3396 - acc: 0.8662 - val_loss: 0.5014 - val_acc: 0.8576\n",
      "Epoch 622/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3369 - acc: 0.8665 - val_loss: 0.5039 - val_acc: 0.8578\n",
      "Epoch 623/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3386 - acc: 0.8653 - val_loss: 0.5047 - val_acc: 0.8578\n",
      "Epoch 624/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3376 - acc: 0.8667 - val_loss: 0.5044 - val_acc: 0.8574\n",
      "Epoch 625/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3389 - acc: 0.8660 - val_loss: 0.5035 - val_acc: 0.8578\n",
      "Epoch 626/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3366 - acc: 0.8657 - val_loss: 0.5069 - val_acc: 0.8582\n",
      "Epoch 627/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3370 - acc: 0.8666 - val_loss: 0.5051 - val_acc: 0.8572\n",
      "Epoch 628/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3381 - acc: 0.8659 - val_loss: 0.5069 - val_acc: 0.8570\n",
      "Epoch 629/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3361 - acc: 0.8663 - val_loss: 0.5038 - val_acc: 0.8576\n",
      "Epoch 630/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3374 - acc: 0.8663 - val_loss: 0.5018 - val_acc: 0.8575\n",
      "Epoch 631/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3365 - acc: 0.8673 - val_loss: 0.5053 - val_acc: 0.8587\n",
      "Epoch 632/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3370 - acc: 0.8671 - val_loss: 0.5081 - val_acc: 0.8579\n",
      "Epoch 633/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3368 - acc: 0.8662 - val_loss: 0.5080 - val_acc: 0.8573\n",
      "Epoch 634/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3346 - acc: 0.8672 - val_loss: 0.5058 - val_acc: 0.8578\n",
      "Epoch 635/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3342 - acc: 0.8684 - val_loss: 0.5078 - val_acc: 0.8582\n",
      "Epoch 636/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3343 - acc: 0.8674 - val_loss: 0.5067 - val_acc: 0.8582\n",
      "Epoch 637/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3345 - acc: 0.8678 - val_loss: 0.5036 - val_acc: 0.8588\n",
      "Epoch 638/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3350 - acc: 0.8679 - val_loss: 0.5044 - val_acc: 0.8575\n",
      "Epoch 639/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3333 - acc: 0.8688 - val_loss: 0.5057 - val_acc: 0.8599\n",
      "Epoch 640/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3338 - acc: 0.8675 - val_loss: 0.5060 - val_acc: 0.8585\n",
      "Epoch 641/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3340 - acc: 0.8677 - val_loss: 0.5079 - val_acc: 0.8579\n",
      "Epoch 642/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3317 - acc: 0.8683 - val_loss: 0.5051 - val_acc: 0.8601\n",
      "Epoch 643/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3333 - acc: 0.8682 - val_loss: 0.5058 - val_acc: 0.8587\n",
      "Epoch 644/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3329 - acc: 0.8679 - val_loss: 0.5054 - val_acc: 0.8574\n",
      "Epoch 645/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3344 - acc: 0.8672 - val_loss: 0.5042 - val_acc: 0.8595\n",
      "Epoch 646/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3322 - acc: 0.8693 - val_loss: 0.5052 - val_acc: 0.8592\n",
      "Epoch 647/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3330 - acc: 0.8680 - val_loss: 0.5052 - val_acc: 0.8598\n",
      "Epoch 648/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3333 - acc: 0.8682 - val_loss: 0.5054 - val_acc: 0.8596\n",
      "Epoch 649/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3308 - acc: 0.8695 - val_loss: 0.5052 - val_acc: 0.8589\n",
      "Epoch 650/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3317 - acc: 0.8679 - val_loss: 0.5054 - val_acc: 0.8597\n",
      "Epoch 651/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3321 - acc: 0.8696 - val_loss: 0.5081 - val_acc: 0.8596\n",
      "Epoch 652/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3317 - acc: 0.8697 - val_loss: 0.5064 - val_acc: 0.8589\n",
      "Epoch 653/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3313 - acc: 0.8686 - val_loss: 0.5074 - val_acc: 0.8596\n",
      "Epoch 654/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3303 - acc: 0.8699 - val_loss: 0.5092 - val_acc: 0.8596\n",
      "Epoch 655/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3300 - acc: 0.8700 - val_loss: 0.5068 - val_acc: 0.8589\n",
      "Epoch 656/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3283 - acc: 0.8704 - val_loss: 0.5058 - val_acc: 0.8602\n",
      "Epoch 657/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3296 - acc: 0.8696 - val_loss: 0.5051 - val_acc: 0.8592\n",
      "Epoch 658/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3319 - acc: 0.8691 - val_loss: 0.5022 - val_acc: 0.8590\n",
      "Epoch 659/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3309 - acc: 0.8686 - val_loss: 0.5049 - val_acc: 0.8612\n",
      "Epoch 660/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3322 - acc: 0.8690 - val_loss: 0.5033 - val_acc: 0.8594\n",
      "Epoch 661/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3295 - acc: 0.8697 - val_loss: 0.5026 - val_acc: 0.8595\n",
      "Epoch 662/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3278 - acc: 0.8708 - val_loss: 0.5000 - val_acc: 0.8602\n",
      "Epoch 663/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.3270 - acc: 0.8710 - val_loss: 0.5070 - val_acc: 0.8593\n",
      "Epoch 664/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3288 - acc: 0.8701 - val_loss: 0.5038 - val_acc: 0.8605\n",
      "Epoch 665/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3288 - acc: 0.8700 - val_loss: 0.5044 - val_acc: 0.8604\n",
      "Epoch 666/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3295 - acc: 0.8703 - val_loss: 0.5052 - val_acc: 0.8601\n",
      "Epoch 667/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3280 - acc: 0.8711 - val_loss: 0.5052 - val_acc: 0.8588\n",
      "Epoch 668/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3249 - acc: 0.8718 - val_loss: 0.5044 - val_acc: 0.8593\n",
      "Epoch 669/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3278 - acc: 0.8709 - val_loss: 0.5050 - val_acc: 0.8587\n",
      "Epoch 670/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3255 - acc: 0.8716 - val_loss: 0.5029 - val_acc: 0.8611\n",
      "Epoch 671/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3283 - acc: 0.8708 - val_loss: 0.5058 - val_acc: 0.8617\n",
      "Epoch 672/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3269 - acc: 0.8721 - val_loss: 0.5037 - val_acc: 0.8598\n",
      "Epoch 673/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3253 - acc: 0.8717 - val_loss: 0.5049 - val_acc: 0.8595\n",
      "Epoch 674/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3251 - acc: 0.8708 - val_loss: 0.5051 - val_acc: 0.8616\n",
      "Epoch 675/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3262 - acc: 0.8706 - val_loss: 0.5066 - val_acc: 0.8606\n",
      "Epoch 676/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3247 - acc: 0.8723 - val_loss: 0.5051 - val_acc: 0.8589\n",
      "Epoch 677/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3262 - acc: 0.8718 - val_loss: 0.5065 - val_acc: 0.8593\n",
      "Epoch 678/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3237 - acc: 0.8725 - val_loss: 0.5047 - val_acc: 0.8607\n",
      "Epoch 679/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3256 - acc: 0.8716 - val_loss: 0.5030 - val_acc: 0.8609\n",
      "Epoch 680/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3256 - acc: 0.8717 - val_loss: 0.4993 - val_acc: 0.8623\n",
      "Epoch 681/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3223 - acc: 0.8728 - val_loss: 0.5054 - val_acc: 0.8618\n",
      "Epoch 682/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3237 - acc: 0.8719 - val_loss: 0.5033 - val_acc: 0.8599\n",
      "Epoch 683/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3251 - acc: 0.8712 - val_loss: 0.5044 - val_acc: 0.8598\n",
      "Epoch 684/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3221 - acc: 0.8735 - val_loss: 0.5064 - val_acc: 0.8617\n",
      "Epoch 685/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3250 - acc: 0.8726 - val_loss: 0.5037 - val_acc: 0.8599\n",
      "Epoch 686/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3227 - acc: 0.8730 - val_loss: 0.5068 - val_acc: 0.8611\n",
      "Epoch 687/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3234 - acc: 0.8729 - val_loss: 0.5093 - val_acc: 0.8607\n",
      "Epoch 688/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3238 - acc: 0.8722 - val_loss: 0.5033 - val_acc: 0.8624\n",
      "Epoch 689/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3238 - acc: 0.8727 - val_loss: 0.5042 - val_acc: 0.8621\n",
      "Epoch 690/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3218 - acc: 0.8731 - val_loss: 0.5019 - val_acc: 0.8622\n",
      "Epoch 691/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3217 - acc: 0.8734 - val_loss: 0.5056 - val_acc: 0.8614\n",
      "Epoch 692/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3219 - acc: 0.8724 - val_loss: 0.5046 - val_acc: 0.8607\n",
      "Epoch 693/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3205 - acc: 0.8748 - val_loss: 0.5014 - val_acc: 0.8614\n",
      "Epoch 694/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3229 - acc: 0.8739 - val_loss: 0.5024 - val_acc: 0.8621\n",
      "Epoch 695/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3214 - acc: 0.8733 - val_loss: 0.5044 - val_acc: 0.8618\n",
      "Epoch 696/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3228 - acc: 0.8737 - val_loss: 0.5023 - val_acc: 0.8616\n",
      "Epoch 697/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3196 - acc: 0.8738 - val_loss: 0.5027 - val_acc: 0.8619\n",
      "Epoch 698/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3213 - acc: 0.8729 - val_loss: 0.5040 - val_acc: 0.8613\n",
      "Epoch 699/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3225 - acc: 0.8734 - val_loss: 0.5011 - val_acc: 0.8630\n",
      "Epoch 700/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3190 - acc: 0.8745 - val_loss: 0.5046 - val_acc: 0.8627\n",
      "Epoch 701/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3216 - acc: 0.8729 - val_loss: 0.5027 - val_acc: 0.8623\n",
      "Epoch 702/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3180 - acc: 0.8753 - val_loss: 0.5045 - val_acc: 0.8619\n",
      "Epoch 703/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.3200 - acc: 0.8739 - val_loss: 0.5038 - val_acc: 0.8610\n",
      "Epoch 704/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3203 - acc: 0.8740 - val_loss: 0.5009 - val_acc: 0.8619\n",
      "Epoch 705/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3185 - acc: 0.8746 - val_loss: 0.5038 - val_acc: 0.8641\n",
      "Epoch 706/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3177 - acc: 0.8754 - val_loss: 0.5036 - val_acc: 0.8629\n",
      "Epoch 707/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3193 - acc: 0.8751 - val_loss: 0.5015 - val_acc: 0.8627\n",
      "Epoch 708/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3170 - acc: 0.8756 - val_loss: 0.5059 - val_acc: 0.8618\n",
      "Epoch 709/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3171 - acc: 0.8749 - val_loss: 0.5025 - val_acc: 0.8621\n",
      "Epoch 710/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3180 - acc: 0.8749 - val_loss: 0.5042 - val_acc: 0.8616\n",
      "Epoch 711/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3173 - acc: 0.8755 - val_loss: 0.5071 - val_acc: 0.8613\n",
      "Epoch 712/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3194 - acc: 0.8750 - val_loss: 0.5042 - val_acc: 0.8617\n",
      "Epoch 713/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3177 - acc: 0.8748 - val_loss: 0.5036 - val_acc: 0.8627\n",
      "Epoch 714/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3182 - acc: 0.8745 - val_loss: 0.5042 - val_acc: 0.8629\n",
      "Epoch 715/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3188 - acc: 0.8745 - val_loss: 0.5021 - val_acc: 0.8638\n",
      "Epoch 716/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3173 - acc: 0.8753 - val_loss: 0.5065 - val_acc: 0.8627\n",
      "Epoch 717/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3170 - acc: 0.8751 - val_loss: 0.5036 - val_acc: 0.8626\n",
      "Epoch 718/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3167 - acc: 0.8753 - val_loss: 0.5052 - val_acc: 0.8628\n",
      "Epoch 719/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3165 - acc: 0.8754 - val_loss: 0.5050 - val_acc: 0.8621\n",
      "Epoch 720/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3194 - acc: 0.8743 - val_loss: 0.5042 - val_acc: 0.8624\n",
      "Epoch 721/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3159 - acc: 0.8764 - val_loss: 0.5035 - val_acc: 0.8623\n",
      "Epoch 722/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3165 - acc: 0.8753 - val_loss: 0.5040 - val_acc: 0.8634\n",
      "Epoch 723/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3154 - acc: 0.8761 - val_loss: 0.5043 - val_acc: 0.8636\n",
      "Epoch 724/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3164 - acc: 0.8756 - val_loss: 0.5066 - val_acc: 0.8621\n",
      "Epoch 725/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3162 - acc: 0.8757 - val_loss: 0.5018 - val_acc: 0.8643\n",
      "Epoch 726/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3160 - acc: 0.8762 - val_loss: 0.5024 - val_acc: 0.8628\n",
      "Epoch 727/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3139 - acc: 0.8769 - val_loss: 0.5041 - val_acc: 0.8645\n",
      "Epoch 728/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3150 - acc: 0.8759 - val_loss: 0.5060 - val_acc: 0.8632\n",
      "Epoch 729/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3164 - acc: 0.8755 - val_loss: 0.5040 - val_acc: 0.8619\n",
      "Epoch 730/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3133 - acc: 0.8763 - val_loss: 0.5088 - val_acc: 0.8629\n",
      "Epoch 731/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3126 - acc: 0.8770 - val_loss: 0.5036 - val_acc: 0.8635\n",
      "Epoch 732/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3143 - acc: 0.8761 - val_loss: 0.5029 - val_acc: 0.8621\n",
      "Epoch 733/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3132 - acc: 0.8764 - val_loss: 0.5052 - val_acc: 0.8628\n",
      "Epoch 734/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3158 - acc: 0.8766 - val_loss: 0.5046 - val_acc: 0.8636\n",
      "Epoch 735/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3132 - acc: 0.8775 - val_loss: 0.5068 - val_acc: 0.8631\n",
      "Epoch 736/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3129 - acc: 0.8777 - val_loss: 0.5032 - val_acc: 0.8636\n",
      "Epoch 737/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3142 - acc: 0.8765 - val_loss: 0.5024 - val_acc: 0.8632\n",
      "Epoch 738/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3135 - acc: 0.8774 - val_loss: 0.5053 - val_acc: 0.8628\n",
      "Epoch 739/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3145 - acc: 0.8772 - val_loss: 0.5038 - val_acc: 0.8642\n",
      "Epoch 740/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3142 - acc: 0.8766 - val_loss: 0.5046 - val_acc: 0.8631\n",
      "Epoch 741/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3108 - acc: 0.8781 - val_loss: 0.5044 - val_acc: 0.8624\n",
      "Epoch 742/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3126 - acc: 0.8766 - val_loss: 0.5044 - val_acc: 0.8643\n",
      "Epoch 743/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3120 - acc: 0.8780 - val_loss: 0.5076 - val_acc: 0.8631\n",
      "Epoch 744/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3122 - acc: 0.8774 - val_loss: 0.5066 - val_acc: 0.8646\n",
      "Epoch 745/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3113 - acc: 0.8782 - val_loss: 0.5039 - val_acc: 0.8643\n",
      "Epoch 746/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3119 - acc: 0.8771 - val_loss: 0.5072 - val_acc: 0.8635\n",
      "Epoch 747/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3111 - acc: 0.8774 - val_loss: 0.5048 - val_acc: 0.8646\n",
      "Epoch 748/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3085 - acc: 0.8794 - val_loss: 0.5046 - val_acc: 0.8636\n",
      "Epoch 749/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3118 - acc: 0.8779 - val_loss: 0.5062 - val_acc: 0.8620\n",
      "Epoch 750/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3107 - acc: 0.8777 - val_loss: 0.5040 - val_acc: 0.8642\n",
      "Epoch 751/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3100 - acc: 0.8782 - val_loss: 0.5019 - val_acc: 0.8648\n",
      "Epoch 752/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3102 - acc: 0.8784 - val_loss: 0.5033 - val_acc: 0.8656\n",
      "Epoch 753/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3103 - acc: 0.8794 - val_loss: 0.5046 - val_acc: 0.8648\n",
      "Epoch 754/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3116 - acc: 0.8782 - val_loss: 0.5057 - val_acc: 0.8628\n",
      "Epoch 755/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3117 - acc: 0.8777 - val_loss: 0.5038 - val_acc: 0.8639\n",
      "Epoch 756/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3085 - acc: 0.8796 - val_loss: 0.5054 - val_acc: 0.8641\n",
      "Epoch 757/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3087 - acc: 0.8785 - val_loss: 0.5052 - val_acc: 0.8657\n",
      "Epoch 758/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3102 - acc: 0.8778 - val_loss: 0.5069 - val_acc: 0.8640\n",
      "Epoch 759/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3096 - acc: 0.8778 - val_loss: 0.5046 - val_acc: 0.8653\n",
      "Epoch 760/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3103 - acc: 0.8781 - val_loss: 0.5042 - val_acc: 0.8639\n",
      "Epoch 761/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3086 - acc: 0.8793 - val_loss: 0.5040 - val_acc: 0.8628\n",
      "Epoch 762/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3096 - acc: 0.8782 - val_loss: 0.5034 - val_acc: 0.8657\n",
      "Epoch 763/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3074 - acc: 0.8790 - val_loss: 0.5031 - val_acc: 0.8652\n",
      "Epoch 764/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3112 - acc: 0.8780 - val_loss: 0.5025 - val_acc: 0.8654\n",
      "Epoch 765/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3109 - acc: 0.8783 - val_loss: 0.5008 - val_acc: 0.8657\n",
      "Epoch 766/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3089 - acc: 0.8788 - val_loss: 0.5030 - val_acc: 0.8653\n",
      "Epoch 767/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3062 - acc: 0.8805 - val_loss: 0.5038 - val_acc: 0.8650\n",
      "Epoch 768/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3078 - acc: 0.8799 - val_loss: 0.5022 - val_acc: 0.8645\n",
      "Epoch 769/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.3072 - acc: 0.8798 - val_loss: 0.5055 - val_acc: 0.8647\n",
      "Epoch 770/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.3077 - acc: 0.8790 - val_loss: 0.5059 - val_acc: 0.8634\n",
      "Epoch 771/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3072 - acc: 0.8802 - val_loss: 0.5007 - val_acc: 0.8643\n",
      "Epoch 772/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3086 - acc: 0.8788 - val_loss: 0.5048 - val_acc: 0.8638\n",
      "Epoch 773/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3071 - acc: 0.8796 - val_loss: 0.5066 - val_acc: 0.8645\n",
      "Epoch 774/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3065 - acc: 0.8796 - val_loss: 0.5035 - val_acc: 0.8665\n",
      "Epoch 775/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3050 - acc: 0.8803 - val_loss: 0.5015 - val_acc: 0.8660\n",
      "Epoch 776/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3071 - acc: 0.8800 - val_loss: 0.5044 - val_acc: 0.8649\n",
      "Epoch 777/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3064 - acc: 0.8798 - val_loss: 0.5032 - val_acc: 0.8652\n",
      "Epoch 778/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3058 - acc: 0.8799 - val_loss: 0.5051 - val_acc: 0.8652\n",
      "Epoch 779/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3066 - acc: 0.8800 - val_loss: 0.5023 - val_acc: 0.8647\n",
      "Epoch 780/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3061 - acc: 0.8798 - val_loss: 0.5049 - val_acc: 0.8654\n",
      "Epoch 781/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3066 - acc: 0.8802 - val_loss: 0.5035 - val_acc: 0.8657\n",
      "Epoch 782/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3038 - acc: 0.8811 - val_loss: 0.5038 - val_acc: 0.8648\n",
      "Epoch 783/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3058 - acc: 0.8799 - val_loss: 0.5057 - val_acc: 0.8658\n",
      "Epoch 784/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3051 - acc: 0.8810 - val_loss: 0.5030 - val_acc: 0.8646\n",
      "Epoch 785/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3047 - acc: 0.8807 - val_loss: 0.5030 - val_acc: 0.8651\n",
      "Epoch 786/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3044 - acc: 0.8807 - val_loss: 0.4992 - val_acc: 0.8672\n",
      "Epoch 787/800\n",
      "219561/219561 [==============================] - 12s 54us/step - loss: 0.3040 - acc: 0.8813 - val_loss: 0.5028 - val_acc: 0.8652\n",
      "Epoch 788/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3025 - acc: 0.8818 - val_loss: 0.5017 - val_acc: 0.8659\n",
      "Epoch 789/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3036 - acc: 0.8814 - val_loss: 0.5004 - val_acc: 0.8662\n",
      "Epoch 790/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3036 - acc: 0.8811 - val_loss: 0.5015 - val_acc: 0.8663\n",
      "Epoch 791/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3033 - acc: 0.8816 - val_loss: 0.5067 - val_acc: 0.8647\n",
      "Epoch 792/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3049 - acc: 0.8804 - val_loss: 0.5031 - val_acc: 0.8665\n",
      "Epoch 793/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3035 - acc: 0.8807 - val_loss: 0.5049 - val_acc: 0.8662\n",
      "Epoch 794/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3048 - acc: 0.8814 - val_loss: 0.5020 - val_acc: 0.8649\n",
      "Epoch 795/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3041 - acc: 0.8810 - val_loss: 0.5034 - val_acc: 0.8647\n",
      "Epoch 796/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3027 - acc: 0.8813 - val_loss: 0.5028 - val_acc: 0.8655\n",
      "Epoch 797/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3030 - acc: 0.8818 - val_loss: 0.5052 - val_acc: 0.8662\n",
      "Epoch 798/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3055 - acc: 0.8811 - val_loss: 0.5055 - val_acc: 0.8652\n",
      "Epoch 799/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3017 - acc: 0.8820 - val_loss: 0.5090 - val_acc: 0.8654\n",
      "Epoch 800/800\n",
      "219561/219561 [==============================] - 12s 53us/step - loss: 0.3025 - acc: 0.8825 - val_loss: 0.5043 - val_acc: 0.8639\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "sys.path.append(os.path.realpath(\"../../\"))\n",
    "import ptetaphi_nn\n",
    "import tools\n",
    "\n",
    "# get data file path\n",
    "with open(\"/home/cmccracken/start_tf/bbb/filepath.txt\", 'r') as f:\n",
    "    filename = f.read()\n",
    "    \n",
    "s_table = tools.open_file(filename, sort_by=\"tag\")\n",
    "\n",
    "# filter for events with 3 b tags\n",
    "nt3 = s_table.nbtags==3 \n",
    "events = s_table[nt3]\n",
    "print(len(events))\n",
    "\n",
    "cutoff = 10  # not many events have >10 jets\n",
    "# \"pad\" = ensure all events have same length, cut off ends if needed\n",
    "events = tools.pad(events, cutoff)\n",
    "\n",
    "# make and train network\n",
    "nn = ptetaphi_nn.PtEtaPhiNN(events, chop=0, print_summary=True)\n",
    "nn.learn(epochs=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62732/62732 [00:00<00:00, 110239.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 86.08 percent\n",
      "ignoring 2.69 percent (1686 events) of 62732 events\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(savename=\"best_with_all_jets_nofilter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the architecture string to a file\n",
    "models_dir = \"/home/cmccracken/start_tf/bbb/models/\"\n",
    "with open(models_dir+'architecture_06_07_2020.json', 'w') as arch_file:\n",
    "    arch_file.write(nn.model.to_json())\n",
    "# now save the weights as an HDF5 file\n",
    "nn.model.save_weights(models_dir+'weights_06_07_2020.h5')\n",
    "# use nn_tester to get csv!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}