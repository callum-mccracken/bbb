{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Fold 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777150 total events found\n",
      "sorting data by tag\n",
      "287645\n",
      "k-folding: every 5th element starting at 1\n",
      "creating default model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 700)               21700     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 408       \n",
      "=================================================================\n",
      "Total params: 558,988\n",
      "Trainable params: 558,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230116 samples, validate on 57529 samples\n",
      "Epoch 1/800\n",
      "230116/230116 [==============================] - 14s 61us/step - loss: 1.0115 - acc: 0.6047 - val_loss: 0.8052 - val_acc: 0.6345\n",
      "Epoch 2/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.7787 - acc: 0.6390 - val_loss: 0.7495 - val_acc: 0.6494\n",
      "Epoch 3/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.7417 - acc: 0.6506 - val_loss: 0.7231 - val_acc: 0.6638\n",
      "Epoch 4/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.7230 - acc: 0.6617 - val_loss: 0.7069 - val_acc: 0.6727\n",
      "Epoch 5/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.7070 - acc: 0.6709 - val_loss: 0.6907 - val_acc: 0.6825\n",
      "Epoch 6/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.6947 - acc: 0.6797 - val_loss: 0.6797 - val_acc: 0.6894\n",
      "Epoch 7/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6841 - acc: 0.6866 - val_loss: 0.6721 - val_acc: 0.6922\n",
      "Epoch 8/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.6759 - acc: 0.6904 - val_loss: 0.6643 - val_acc: 0.6971\n",
      "Epoch 9/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.6687 - acc: 0.6939 - val_loss: 0.6590 - val_acc: 0.6999\n",
      "Epoch 10/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.6626 - acc: 0.6970 - val_loss: 0.6535 - val_acc: 0.7021\n",
      "Epoch 11/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6577 - acc: 0.6991 - val_loss: 0.6479 - val_acc: 0.7053\n",
      "Epoch 12/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6518 - acc: 0.7020 - val_loss: 0.6431 - val_acc: 0.7078\n",
      "Epoch 13/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6469 - acc: 0.7047 - val_loss: 0.6391 - val_acc: 0.7090\n",
      "Epoch 14/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6416 - acc: 0.7068 - val_loss: 0.6332 - val_acc: 0.7113\n",
      "Epoch 15/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6365 - acc: 0.7094 - val_loss: 0.6278 - val_acc: 0.7147\n",
      "Epoch 16/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.6320 - acc: 0.7118 - val_loss: 0.6251 - val_acc: 0.7160\n",
      "Epoch 17/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.6278 - acc: 0.7140 - val_loss: 0.6206 - val_acc: 0.7180\n",
      "Epoch 18/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6229 - acc: 0.7163 - val_loss: 0.6150 - val_acc: 0.7219\n",
      "Epoch 19/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.6193 - acc: 0.7174 - val_loss: 0.6113 - val_acc: 0.7236\n",
      "Epoch 20/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.6153 - acc: 0.7196 - val_loss: 0.6091 - val_acc: 0.7252\n",
      "Epoch 21/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6113 - acc: 0.7221 - val_loss: 0.6036 - val_acc: 0.7288\n",
      "Epoch 22/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.6074 - acc: 0.7237 - val_loss: 0.6014 - val_acc: 0.7303\n",
      "Epoch 23/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6034 - acc: 0.7259 - val_loss: 0.5968 - val_acc: 0.7333\n",
      "Epoch 24/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6000 - acc: 0.7278 - val_loss: 0.5965 - val_acc: 0.7314\n",
      "Epoch 25/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5968 - acc: 0.7294 - val_loss: 0.5891 - val_acc: 0.7374\n",
      "Epoch 26/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5922 - acc: 0.7316 - val_loss: 0.5854 - val_acc: 0.7399\n",
      "Epoch 27/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5894 - acc: 0.7337 - val_loss: 0.5818 - val_acc: 0.7412\n",
      "Epoch 28/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5853 - acc: 0.7358 - val_loss: 0.5784 - val_acc: 0.7433\n",
      "Epoch 29/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5824 - acc: 0.7374 - val_loss: 0.5752 - val_acc: 0.7458\n",
      "Epoch 30/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5789 - acc: 0.7392 - val_loss: 0.5729 - val_acc: 0.7460\n",
      "Epoch 31/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5754 - acc: 0.7417 - val_loss: 0.5710 - val_acc: 0.7464\n",
      "Epoch 32/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5728 - acc: 0.7424 - val_loss: 0.5678 - val_acc: 0.7491\n",
      "Epoch 33/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5699 - acc: 0.7444 - val_loss: 0.5650 - val_acc: 0.7496\n",
      "Epoch 34/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5672 - acc: 0.7455 - val_loss: 0.5634 - val_acc: 0.7513\n",
      "Epoch 35/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5648 - acc: 0.7465 - val_loss: 0.5612 - val_acc: 0.7522\n",
      "Epoch 36/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5623 - acc: 0.7481 - val_loss: 0.5582 - val_acc: 0.7534\n",
      "Epoch 37/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5598 - acc: 0.7488 - val_loss: 0.5558 - val_acc: 0.7554\n",
      "Epoch 38/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5570 - acc: 0.7502 - val_loss: 0.5538 - val_acc: 0.7550\n",
      "Epoch 39/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5548 - acc: 0.7518 - val_loss: 0.5515 - val_acc: 0.7579\n",
      "Epoch 40/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5527 - acc: 0.7532 - val_loss: 0.5499 - val_acc: 0.7580\n",
      "Epoch 41/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5494 - acc: 0.7543 - val_loss: 0.5486 - val_acc: 0.7589\n",
      "Epoch 42/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5481 - acc: 0.7551 - val_loss: 0.5463 - val_acc: 0.7596\n",
      "Epoch 43/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5454 - acc: 0.7564 - val_loss: 0.5455 - val_acc: 0.7605\n",
      "Epoch 44/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5441 - acc: 0.7572 - val_loss: 0.5443 - val_acc: 0.7607\n",
      "Epoch 45/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5418 - acc: 0.7582 - val_loss: 0.5417 - val_acc: 0.7621\n",
      "Epoch 46/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5396 - acc: 0.7589 - val_loss: 0.5401 - val_acc: 0.7635\n",
      "Epoch 47/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5377 - acc: 0.7600 - val_loss: 0.5385 - val_acc: 0.7646\n",
      "Epoch 48/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5356 - acc: 0.7615 - val_loss: 0.5376 - val_acc: 0.7644\n",
      "Epoch 49/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5331 - acc: 0.7627 - val_loss: 0.5357 - val_acc: 0.7659\n",
      "Epoch 50/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5321 - acc: 0.7639 - val_loss: 0.5350 - val_acc: 0.7655\n",
      "Epoch 51/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5301 - acc: 0.7650 - val_loss: 0.5329 - val_acc: 0.7674\n",
      "Epoch 52/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5280 - acc: 0.7663 - val_loss: 0.5311 - val_acc: 0.7683\n",
      "Epoch 53/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5260 - acc: 0.7666 - val_loss: 0.5311 - val_acc: 0.7676\n",
      "Epoch 54/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5238 - acc: 0.7679 - val_loss: 0.5306 - val_acc: 0.7684\n",
      "Epoch 55/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5230 - acc: 0.7686 - val_loss: 0.5255 - val_acc: 0.7718\n",
      "Epoch 56/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5208 - acc: 0.7693 - val_loss: 0.5260 - val_acc: 0.7710\n",
      "Epoch 57/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5200 - acc: 0.7707 - val_loss: 0.5249 - val_acc: 0.7710\n",
      "Epoch 58/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5175 - acc: 0.7713 - val_loss: 0.5229 - val_acc: 0.7728\n",
      "Epoch 59/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5152 - acc: 0.7734 - val_loss: 0.5216 - val_acc: 0.7732\n",
      "Epoch 60/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5145 - acc: 0.7729 - val_loss: 0.5211 - val_acc: 0.7736\n",
      "Epoch 61/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5121 - acc: 0.7743 - val_loss: 0.5193 - val_acc: 0.7755\n",
      "Epoch 62/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5110 - acc: 0.7748 - val_loss: 0.5180 - val_acc: 0.7749\n",
      "Epoch 63/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5089 - acc: 0.7769 - val_loss: 0.5162 - val_acc: 0.7770\n",
      "Epoch 64/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5071 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7758\n",
      "Epoch 65/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5060 - acc: 0.7785 - val_loss: 0.5169 - val_acc: 0.7759\n",
      "Epoch 66/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5041 - acc: 0.7786 - val_loss: 0.5137 - val_acc: 0.7779\n",
      "Epoch 67/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5022 - acc: 0.7797 - val_loss: 0.5129 - val_acc: 0.7786\n",
      "Epoch 68/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.5013 - acc: 0.7807 - val_loss: 0.5113 - val_acc: 0.7802\n",
      "Epoch 69/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4994 - acc: 0.7817 - val_loss: 0.5108 - val_acc: 0.7790\n",
      "Epoch 70/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4977 - acc: 0.7825 - val_loss: 0.5099 - val_acc: 0.7801\n",
      "Epoch 71/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4958 - acc: 0.7830 - val_loss: 0.5100 - val_acc: 0.7808\n",
      "Epoch 72/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4949 - acc: 0.7845 - val_loss: 0.5085 - val_acc: 0.7812\n",
      "Epoch 73/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4934 - acc: 0.7846 - val_loss: 0.5066 - val_acc: 0.7820\n",
      "Epoch 74/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4923 - acc: 0.7850 - val_loss: 0.5061 - val_acc: 0.7833\n",
      "Epoch 75/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4905 - acc: 0.7866 - val_loss: 0.5064 - val_acc: 0.7824\n",
      "Epoch 76/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4883 - acc: 0.7871 - val_loss: 0.5054 - val_acc: 0.7837\n",
      "Epoch 77/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4871 - acc: 0.7880 - val_loss: 0.5050 - val_acc: 0.7836\n",
      "Epoch 78/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4867 - acc: 0.7885 - val_loss: 0.5027 - val_acc: 0.7843\n",
      "Epoch 79/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4846 - acc: 0.7899 - val_loss: 0.5022 - val_acc: 0.7850\n",
      "Epoch 80/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4828 - acc: 0.7905 - val_loss: 0.5025 - val_acc: 0.7842\n",
      "Epoch 81/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4811 - acc: 0.7914 - val_loss: 0.4996 - val_acc: 0.7863\n",
      "Epoch 82/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4800 - acc: 0.7924 - val_loss: 0.4994 - val_acc: 0.7863\n",
      "Epoch 83/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4793 - acc: 0.7922 - val_loss: 0.4990 - val_acc: 0.7868\n",
      "Epoch 84/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4769 - acc: 0.7934 - val_loss: 0.4987 - val_acc: 0.7882\n",
      "Epoch 85/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4759 - acc: 0.7944 - val_loss: 0.4988 - val_acc: 0.7870\n",
      "Epoch 86/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4754 - acc: 0.7944 - val_loss: 0.4961 - val_acc: 0.7885\n",
      "Epoch 87/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4736 - acc: 0.7956 - val_loss: 0.4960 - val_acc: 0.7893\n",
      "Epoch 88/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4726 - acc: 0.7961 - val_loss: 0.4944 - val_acc: 0.7888\n",
      "Epoch 89/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4718 - acc: 0.7969 - val_loss: 0.4935 - val_acc: 0.7900\n",
      "Epoch 90/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4699 - acc: 0.7974 - val_loss: 0.4933 - val_acc: 0.7911\n",
      "Epoch 91/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4683 - acc: 0.7982 - val_loss: 0.4934 - val_acc: 0.7915\n",
      "Epoch 92/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4680 - acc: 0.7981 - val_loss: 0.4921 - val_acc: 0.7913\n",
      "Epoch 93/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4663 - acc: 0.7996 - val_loss: 0.4917 - val_acc: 0.7921\n",
      "Epoch 94/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4652 - acc: 0.7999 - val_loss: 0.4924 - val_acc: 0.7914\n",
      "Epoch 95/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4641 - acc: 0.8000 - val_loss: 0.4964 - val_acc: 0.7891\n",
      "Epoch 96/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4633 - acc: 0.8012 - val_loss: 0.4920 - val_acc: 0.7918\n",
      "Epoch 97/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4607 - acc: 0.8022 - val_loss: 0.4903 - val_acc: 0.7934\n",
      "Epoch 98/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4592 - acc: 0.8028 - val_loss: 0.4918 - val_acc: 0.7923\n",
      "Epoch 99/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4592 - acc: 0.8032 - val_loss: 0.4892 - val_acc: 0.7936\n",
      "Epoch 100/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4575 - acc: 0.8037 - val_loss: 0.4901 - val_acc: 0.7940\n",
      "Epoch 101/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4554 - acc: 0.8043 - val_loss: 0.4899 - val_acc: 0.7941\n",
      "Epoch 102/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4561 - acc: 0.8052 - val_loss: 0.4892 - val_acc: 0.7949\n",
      "Epoch 103/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4542 - acc: 0.8063 - val_loss: 0.4913 - val_acc: 0.7923\n",
      "Epoch 104/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4526 - acc: 0.8061 - val_loss: 0.4895 - val_acc: 0.7943\n",
      "Epoch 105/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4517 - acc: 0.8062 - val_loss: 0.4889 - val_acc: 0.7964\n",
      "Epoch 106/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4513 - acc: 0.8076 - val_loss: 0.4896 - val_acc: 0.7954\n",
      "Epoch 107/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4500 - acc: 0.8071 - val_loss: 0.4895 - val_acc: 0.7946\n",
      "Epoch 108/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4480 - acc: 0.8085 - val_loss: 0.4906 - val_acc: 0.7958\n",
      "Epoch 109/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4469 - acc: 0.8093 - val_loss: 0.4884 - val_acc: 0.7954\n",
      "Epoch 110/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4467 - acc: 0.8092 - val_loss: 0.4873 - val_acc: 0.7971\n",
      "Epoch 111/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4451 - acc: 0.8103 - val_loss: 0.4872 - val_acc: 0.7970\n",
      "Epoch 112/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4436 - acc: 0.8110 - val_loss: 0.4867 - val_acc: 0.7975\n",
      "Epoch 113/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4433 - acc: 0.8115 - val_loss: 0.4874 - val_acc: 0.7963\n",
      "Epoch 114/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4422 - acc: 0.8116 - val_loss: 0.4885 - val_acc: 0.7962\n",
      "Epoch 115/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4410 - acc: 0.8119 - val_loss: 0.4873 - val_acc: 0.7973\n",
      "Epoch 116/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4398 - acc: 0.8128 - val_loss: 0.4864 - val_acc: 0.7970\n",
      "Epoch 117/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4387 - acc: 0.8133 - val_loss: 0.4877 - val_acc: 0.7969\n",
      "Epoch 118/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4380 - acc: 0.8140 - val_loss: 0.4871 - val_acc: 0.7977\n",
      "Epoch 119/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4371 - acc: 0.8139 - val_loss: 0.4863 - val_acc: 0.7982\n",
      "Epoch 120/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4358 - acc: 0.8150 - val_loss: 0.4866 - val_acc: 0.7976\n",
      "Epoch 121/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4344 - acc: 0.8148 - val_loss: 0.4880 - val_acc: 0.7979\n",
      "Epoch 122/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4342 - acc: 0.8149 - val_loss: 0.4871 - val_acc: 0.7980\n",
      "Epoch 123/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4328 - acc: 0.8164 - val_loss: 0.4873 - val_acc: 0.7983\n",
      "Epoch 124/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4313 - acc: 0.8170 - val_loss: 0.4866 - val_acc: 0.7979\n",
      "Epoch 125/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4311 - acc: 0.8170 - val_loss: 0.4886 - val_acc: 0.7959\n",
      "Epoch 126/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4306 - acc: 0.8169 - val_loss: 0.4878 - val_acc: 0.7992\n",
      "Epoch 127/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4280 - acc: 0.8179 - val_loss: 0.4903 - val_acc: 0.7975\n",
      "Epoch 128/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4270 - acc: 0.8190 - val_loss: 0.4875 - val_acc: 0.7976\n",
      "Epoch 129/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4277 - acc: 0.8185 - val_loss: 0.4876 - val_acc: 0.7982\n",
      "Epoch 130/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4241 - acc: 0.8201 - val_loss: 0.4903 - val_acc: 0.7987\n",
      "Epoch 131/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4245 - acc: 0.8202 - val_loss: 0.4893 - val_acc: 0.7994\n",
      "Epoch 132/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4242 - acc: 0.8200 - val_loss: 0.4891 - val_acc: 0.7982\n",
      "Epoch 133/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4232 - acc: 0.8206 - val_loss: 0.4889 - val_acc: 0.7995\n",
      "Epoch 134/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4219 - acc: 0.8219 - val_loss: 0.4886 - val_acc: 0.7991\n",
      "Epoch 135/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4199 - acc: 0.8228 - val_loss: 0.4906 - val_acc: 0.7989\n",
      "Epoch 136/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4197 - acc: 0.8227 - val_loss: 0.4909 - val_acc: 0.7981\n",
      "Epoch 137/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4191 - acc: 0.8234 - val_loss: 0.4915 - val_acc: 0.7990\n",
      "Epoch 138/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4180 - acc: 0.8227 - val_loss: 0.4917 - val_acc: 0.7974\n",
      "Epoch 139/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4173 - acc: 0.8236 - val_loss: 0.4906 - val_acc: 0.7975\n",
      "Epoch 140/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4169 - acc: 0.8237 - val_loss: 0.4900 - val_acc: 0.7993\n",
      "Epoch 141/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4150 - acc: 0.8252 - val_loss: 0.4931 - val_acc: 0.7977\n",
      "Epoch 142/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4139 - acc: 0.8253 - val_loss: 0.4924 - val_acc: 0.7980\n",
      "Epoch 143/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4128 - acc: 0.8256 - val_loss: 0.4934 - val_acc: 0.7989\n",
      "Epoch 144/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4123 - acc: 0.8267 - val_loss: 0.4917 - val_acc: 0.7980\n",
      "Epoch 145/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4117 - acc: 0.8260 - val_loss: 0.4919 - val_acc: 0.7974\n",
      "Epoch 146/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4103 - acc: 0.8263 - val_loss: 0.4946 - val_acc: 0.7996\n",
      "Epoch 147/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4105 - acc: 0.8261 - val_loss: 0.4931 - val_acc: 0.7993\n",
      "Epoch 148/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4087 - acc: 0.8273 - val_loss: 0.4933 - val_acc: 0.7977\n",
      "Epoch 149/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4078 - acc: 0.8274 - val_loss: 0.4945 - val_acc: 0.7959\n",
      "Epoch 150/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4063 - acc: 0.8287 - val_loss: 0.4946 - val_acc: 0.7970\n",
      "Epoch 151/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4059 - acc: 0.8285 - val_loss: 0.4957 - val_acc: 0.7983\n",
      "Epoch 152/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4042 - acc: 0.8291 - val_loss: 0.4967 - val_acc: 0.7974\n",
      "Epoch 153/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4040 - acc: 0.8297 - val_loss: 0.4956 - val_acc: 0.7986\n",
      "Epoch 154/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4034 - acc: 0.8294 - val_loss: 0.4955 - val_acc: 0.7981\n",
      "Epoch 155/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4028 - acc: 0.8297 - val_loss: 0.4953 - val_acc: 0.7969\n",
      "Epoch 156/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4015 - acc: 0.8300 - val_loss: 0.4977 - val_acc: 0.7974\n",
      "Epoch 157/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4000 - acc: 0.8316 - val_loss: 0.4979 - val_acc: 0.7966\n",
      "Epoch 158/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3987 - acc: 0.8313 - val_loss: 0.4985 - val_acc: 0.7973\n",
      "Epoch 159/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3984 - acc: 0.8321 - val_loss: 0.4983 - val_acc: 0.7978\n",
      "Epoch 160/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3974 - acc: 0.8316 - val_loss: 0.5004 - val_acc: 0.7979\n",
      "Epoch 161/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3960 - acc: 0.8335 - val_loss: 0.4990 - val_acc: 0.7958\n",
      "Epoch 162/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3962 - acc: 0.8335 - val_loss: 0.5012 - val_acc: 0.7980\n",
      "Epoch 163/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3945 - acc: 0.8341 - val_loss: 0.5011 - val_acc: 0.7985\n",
      "Epoch 164/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3940 - acc: 0.8345 - val_loss: 0.5032 - val_acc: 0.7965\n",
      "Epoch 165/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3926 - acc: 0.8349 - val_loss: 0.5003 - val_acc: 0.7957\n",
      "Epoch 166/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3911 - acc: 0.8355 - val_loss: 0.5010 - val_acc: 0.7958\n",
      "Epoch 167/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3908 - acc: 0.8360 - val_loss: 0.5029 - val_acc: 0.7972\n",
      "Epoch 168/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3900 - acc: 0.8354 - val_loss: 0.5054 - val_acc: 0.7958\n",
      "Epoch 169/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3889 - acc: 0.8365 - val_loss: 0.5057 - val_acc: 0.7954\n",
      "Epoch 170/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3881 - acc: 0.8365 - val_loss: 0.5052 - val_acc: 0.7948\n",
      "Epoch 171/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3859 - acc: 0.8381 - val_loss: 0.5057 - val_acc: 0.7953\n",
      "Epoch 172/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3870 - acc: 0.8367 - val_loss: 0.5066 - val_acc: 0.7961\n",
      "Epoch 173/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3855 - acc: 0.8385 - val_loss: 0.5068 - val_acc: 0.7956\n",
      "Epoch 174/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3844 - acc: 0.8386 - val_loss: 0.5059 - val_acc: 0.7959\n",
      "Epoch 175/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3833 - acc: 0.8390 - val_loss: 0.5058 - val_acc: 0.7947\n",
      "Epoch 176/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3831 - acc: 0.8386 - val_loss: 0.5079 - val_acc: 0.7956\n",
      "Epoch 177/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3818 - acc: 0.8399 - val_loss: 0.5089 - val_acc: 0.7965\n",
      "Epoch 178/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3809 - acc: 0.8395 - val_loss: 0.5091 - val_acc: 0.7959\n",
      "Epoch 179/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3791 - acc: 0.8414 - val_loss: 0.5096 - val_acc: 0.7949\n",
      "Epoch 180/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3790 - acc: 0.8414 - val_loss: 0.5115 - val_acc: 0.7942\n",
      "Epoch 181/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3780 - acc: 0.8422 - val_loss: 0.5120 - val_acc: 0.7961\n",
      "Epoch 182/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3782 - acc: 0.8413 - val_loss: 0.5142 - val_acc: 0.7949\n",
      "Epoch 183/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3769 - acc: 0.8420 - val_loss: 0.5137 - val_acc: 0.7943\n",
      "Epoch 184/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3765 - acc: 0.8416 - val_loss: 0.5136 - val_acc: 0.7954\n",
      "Epoch 185/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3737 - acc: 0.8432 - val_loss: 0.5156 - val_acc: 0.7963\n",
      "Epoch 186/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3731 - acc: 0.8435 - val_loss: 0.5147 - val_acc: 0.7945\n",
      "Epoch 187/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3726 - acc: 0.8438 - val_loss: 0.5137 - val_acc: 0.7941\n",
      "Epoch 188/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3724 - acc: 0.8442 - val_loss: 0.5191 - val_acc: 0.7942\n",
      "Epoch 189/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3722 - acc: 0.8445 - val_loss: 0.5155 - val_acc: 0.7933\n",
      "Epoch 190/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3699 - acc: 0.8456 - val_loss: 0.5168 - val_acc: 0.7952\n",
      "Epoch 191/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3678 - acc: 0.8458 - val_loss: 0.5222 - val_acc: 0.7956\n",
      "Epoch 192/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3674 - acc: 0.8464 - val_loss: 0.5194 - val_acc: 0.7952\n",
      "Epoch 193/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3674 - acc: 0.8459 - val_loss: 0.5195 - val_acc: 0.7925\n",
      "Epoch 194/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3668 - acc: 0.8466 - val_loss: 0.5235 - val_acc: 0.7939\n",
      "Epoch 195/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3660 - acc: 0.8462 - val_loss: 0.5247 - val_acc: 0.7935\n",
      "Epoch 196/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3653 - acc: 0.8471 - val_loss: 0.5212 - val_acc: 0.7937\n",
      "Epoch 197/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3633 - acc: 0.8481 - val_loss: 0.5238 - val_acc: 0.7937\n",
      "Epoch 198/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3638 - acc: 0.8482 - val_loss: 0.5217 - val_acc: 0.7940\n",
      "Epoch 199/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3630 - acc: 0.8479 - val_loss: 0.5241 - val_acc: 0.7927\n",
      "Epoch 200/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3628 - acc: 0.8489 - val_loss: 0.5235 - val_acc: 0.7941\n",
      "Epoch 201/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3610 - acc: 0.8486 - val_loss: 0.5273 - val_acc: 0.7935\n",
      "Epoch 202/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3593 - acc: 0.8498 - val_loss: 0.5262 - val_acc: 0.7943\n",
      "Epoch 203/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3588 - acc: 0.8502 - val_loss: 0.5312 - val_acc: 0.7942\n",
      "Epoch 204/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3578 - acc: 0.8506 - val_loss: 0.5273 - val_acc: 0.7944\n",
      "Epoch 205/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3575 - acc: 0.8510 - val_loss: 0.5297 - val_acc: 0.7929\n",
      "Epoch 206/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3565 - acc: 0.8508 - val_loss: 0.5280 - val_acc: 0.7934\n",
      "Epoch 207/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3554 - acc: 0.8519 - val_loss: 0.5340 - val_acc: 0.7942\n",
      "Epoch 208/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3552 - acc: 0.8513 - val_loss: 0.5313 - val_acc: 0.7933\n",
      "Epoch 209/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3542 - acc: 0.8524 - val_loss: 0.5325 - val_acc: 0.7933\n",
      "Epoch 210/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3533 - acc: 0.8527 - val_loss: 0.5326 - val_acc: 0.7935\n",
      "Epoch 211/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3515 - acc: 0.8546 - val_loss: 0.5336 - val_acc: 0.7939\n",
      "Epoch 212/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3519 - acc: 0.8531 - val_loss: 0.5348 - val_acc: 0.7943\n",
      "Epoch 213/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3510 - acc: 0.8542 - val_loss: 0.5371 - val_acc: 0.7956\n",
      "Epoch 214/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3497 - acc: 0.8544 - val_loss: 0.5375 - val_acc: 0.7945\n",
      "Epoch 215/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3488 - acc: 0.8545 - val_loss: 0.5378 - val_acc: 0.7938\n",
      "Epoch 216/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3470 - acc: 0.8556 - val_loss: 0.5381 - val_acc: 0.7914\n",
      "Epoch 217/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3465 - acc: 0.8561 - val_loss: 0.5391 - val_acc: 0.7923\n",
      "Epoch 218/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3465 - acc: 0.8556 - val_loss: 0.5397 - val_acc: 0.7919\n",
      "Epoch 219/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3463 - acc: 0.8560 - val_loss: 0.5422 - val_acc: 0.7921\n",
      "Epoch 220/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3441 - acc: 0.8567 - val_loss: 0.5414 - val_acc: 0.7929\n",
      "Epoch 221/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3440 - acc: 0.8566 - val_loss: 0.5391 - val_acc: 0.7921\n",
      "Epoch 222/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3423 - acc: 0.8581 - val_loss: 0.5465 - val_acc: 0.7927\n",
      "Epoch 223/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3420 - acc: 0.8573 - val_loss: 0.5435 - val_acc: 0.7922\n",
      "Epoch 224/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3413 - acc: 0.8591 - val_loss: 0.5467 - val_acc: 0.7927\n",
      "Epoch 225/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3408 - acc: 0.8577 - val_loss: 0.5446 - val_acc: 0.7924\n",
      "Epoch 226/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3393 - acc: 0.8590 - val_loss: 0.5452 - val_acc: 0.7912\n",
      "Epoch 227/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3390 - acc: 0.8585 - val_loss: 0.5507 - val_acc: 0.7903\n",
      "Epoch 228/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3381 - acc: 0.8591 - val_loss: 0.5500 - val_acc: 0.7921\n",
      "Epoch 229/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3376 - acc: 0.8599 - val_loss: 0.5493 - val_acc: 0.7903\n",
      "Epoch 230/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3363 - acc: 0.8601 - val_loss: 0.5507 - val_acc: 0.7901\n",
      "Epoch 231/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3360 - acc: 0.8598 - val_loss: 0.5506 - val_acc: 0.7923\n",
      "Epoch 232/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3361 - acc: 0.8607 - val_loss: 0.5509 - val_acc: 0.7912\n",
      "Epoch 233/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3343 - acc: 0.8610 - val_loss: 0.5590 - val_acc: 0.7926\n",
      "Epoch 234/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3325 - acc: 0.8621 - val_loss: 0.5581 - val_acc: 0.7914\n",
      "Epoch 235/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3322 - acc: 0.8625 - val_loss: 0.5548 - val_acc: 0.7908\n",
      "Epoch 236/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3325 - acc: 0.8620 - val_loss: 0.5537 - val_acc: 0.7921\n",
      "Epoch 237/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3308 - acc: 0.8629 - val_loss: 0.5523 - val_acc: 0.7905\n",
      "Epoch 238/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3297 - acc: 0.8637 - val_loss: 0.5562 - val_acc: 0.7922\n",
      "Epoch 239/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3292 - acc: 0.8628 - val_loss: 0.5544 - val_acc: 0.7903\n",
      "Epoch 240/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3296 - acc: 0.8634 - val_loss: 0.5586 - val_acc: 0.7915\n",
      "Epoch 241/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3278 - acc: 0.8640 - val_loss: 0.5613 - val_acc: 0.7880\n",
      "Epoch 242/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3267 - acc: 0.8642 - val_loss: 0.5591 - val_acc: 0.7900\n",
      "Epoch 243/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3270 - acc: 0.8646 - val_loss: 0.5639 - val_acc: 0.7906\n",
      "Epoch 244/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3254 - acc: 0.8652 - val_loss: 0.5633 - val_acc: 0.7913\n",
      "Epoch 245/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3255 - acc: 0.8657 - val_loss: 0.5701 - val_acc: 0.7909\n",
      "Epoch 246/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.3244 - acc: 0.8656 - val_loss: 0.5680 - val_acc: 0.7901\n",
      "Epoch 247/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.3233 - acc: 0.8659 - val_loss: 0.5668 - val_acc: 0.7894\n",
      "Epoch 248/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.3229 - acc: 0.8663 - val_loss: 0.5668 - val_acc: 0.7913\n",
      "Epoch 249/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3220 - acc: 0.8661 - val_loss: 0.5693 - val_acc: 0.7893\n",
      "Epoch 250/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3205 - acc: 0.8678 - val_loss: 0.5714 - val_acc: 0.7893\n",
      "Epoch 251/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3195 - acc: 0.8677 - val_loss: 0.5713 - val_acc: 0.7908\n",
      "Epoch 252/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3194 - acc: 0.8677 - val_loss: 0.5726 - val_acc: 0.7898\n",
      "Epoch 253/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3194 - acc: 0.8676 - val_loss: 0.5714 - val_acc: 0.7895\n",
      "Epoch 254/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3179 - acc: 0.8681 - val_loss: 0.5762 - val_acc: 0.7905\n",
      "Epoch 255/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3173 - acc: 0.8690 - val_loss: 0.5774 - val_acc: 0.7895\n",
      "Epoch 256/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3153 - acc: 0.8691 - val_loss: 0.5765 - val_acc: 0.7895\n",
      "Epoch 257/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3160 - acc: 0.8689 - val_loss: 0.5761 - val_acc: 0.7889\n",
      "Epoch 258/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3153 - acc: 0.8693 - val_loss: 0.5796 - val_acc: 0.7897\n",
      "Epoch 259/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3149 - acc: 0.8697 - val_loss: 0.5809 - val_acc: 0.7900\n",
      "Epoch 260/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3134 - acc: 0.8706 - val_loss: 0.5798 - val_acc: 0.7899\n",
      "Epoch 261/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3137 - acc: 0.8695 - val_loss: 0.5799 - val_acc: 0.7893\n",
      "Epoch 262/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3117 - acc: 0.8716 - val_loss: 0.5800 - val_acc: 0.7883\n",
      "Epoch 263/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3116 - acc: 0.8710 - val_loss: 0.5873 - val_acc: 0.7899\n",
      "Epoch 264/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3106 - acc: 0.8722 - val_loss: 0.5823 - val_acc: 0.7892\n",
      "Epoch 265/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3101 - acc: 0.8715 - val_loss: 0.5868 - val_acc: 0.7902\n",
      "Epoch 266/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3099 - acc: 0.8723 - val_loss: 0.5864 - val_acc: 0.7866\n",
      "Epoch 267/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3075 - acc: 0.8729 - val_loss: 0.5897 - val_acc: 0.7902\n",
      "Epoch 268/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3073 - acc: 0.8739 - val_loss: 0.5887 - val_acc: 0.7870\n",
      "Epoch 269/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3078 - acc: 0.8734 - val_loss: 0.5893 - val_acc: 0.7891\n",
      "Epoch 270/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3064 - acc: 0.8734 - val_loss: 0.5913 - val_acc: 0.7889\n",
      "Epoch 271/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3049 - acc: 0.8743 - val_loss: 0.5942 - val_acc: 0.7882\n",
      "Epoch 272/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3042 - acc: 0.8738 - val_loss: 0.5977 - val_acc: 0.7884\n",
      "Epoch 273/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3041 - acc: 0.8748 - val_loss: 0.5971 - val_acc: 0.7892\n",
      "Epoch 274/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3035 - acc: 0.8752 - val_loss: 0.5942 - val_acc: 0.7882\n",
      "Epoch 275/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3030 - acc: 0.8757 - val_loss: 0.5950 - val_acc: 0.7870\n",
      "Epoch 276/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3021 - acc: 0.8751 - val_loss: 0.5906 - val_acc: 0.7879\n",
      "Epoch 277/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.3008 - acc: 0.8754 - val_loss: 0.5951 - val_acc: 0.7880\n",
      "Epoch 278/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.3007 - acc: 0.8757 - val_loss: 0.6014 - val_acc: 0.7884\n",
      "Epoch 279/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2992 - acc: 0.8765 - val_loss: 0.6015 - val_acc: 0.7869\n",
      "Epoch 280/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2998 - acc: 0.8763 - val_loss: 0.6019 - val_acc: 0.7880\n",
      "Epoch 281/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2978 - acc: 0.8775 - val_loss: 0.6011 - val_acc: 0.7867\n",
      "Epoch 282/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2989 - acc: 0.8766 - val_loss: 0.6028 - val_acc: 0.7887\n",
      "Epoch 283/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2972 - acc: 0.8775 - val_loss: 0.6023 - val_acc: 0.7869\n",
      "Epoch 284/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2967 - acc: 0.8780 - val_loss: 0.6030 - val_acc: 0.7876\n",
      "Epoch 285/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2970 - acc: 0.8781 - val_loss: 0.6019 - val_acc: 0.7862\n",
      "Epoch 286/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2948 - acc: 0.8783 - val_loss: 0.6112 - val_acc: 0.7872\n",
      "Epoch 287/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2941 - acc: 0.8786 - val_loss: 0.6049 - val_acc: 0.7860\n",
      "Epoch 288/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2946 - acc: 0.8787 - val_loss: 0.6082 - val_acc: 0.7864\n",
      "Epoch 289/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2932 - acc: 0.8798 - val_loss: 0.6148 - val_acc: 0.7877\n",
      "Epoch 290/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2936 - acc: 0.8791 - val_loss: 0.6110 - val_acc: 0.7862\n",
      "Epoch 291/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2914 - acc: 0.8804 - val_loss: 0.6057 - val_acc: 0.7868\n",
      "Epoch 292/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2913 - acc: 0.8807 - val_loss: 0.6074 - val_acc: 0.7861\n",
      "Epoch 293/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2906 - acc: 0.8803 - val_loss: 0.6082 - val_acc: 0.7861\n",
      "Epoch 294/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2912 - acc: 0.8803 - val_loss: 0.6128 - val_acc: 0.7863\n",
      "Epoch 295/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2905 - acc: 0.8806 - val_loss: 0.6083 - val_acc: 0.7860\n",
      "Epoch 296/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2900 - acc: 0.8814 - val_loss: 0.6093 - val_acc: 0.7868\n",
      "Epoch 297/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2886 - acc: 0.8816 - val_loss: 0.6109 - val_acc: 0.7846\n",
      "Epoch 298/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2867 - acc: 0.8819 - val_loss: 0.6165 - val_acc: 0.7846\n",
      "Epoch 299/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2860 - acc: 0.8827 - val_loss: 0.6227 - val_acc: 0.7861\n",
      "Epoch 300/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2867 - acc: 0.8821 - val_loss: 0.6203 - val_acc: 0.7855\n",
      "Epoch 301/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2861 - acc: 0.8822 - val_loss: 0.6175 - val_acc: 0.7851\n",
      "Epoch 302/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2844 - acc: 0.8836 - val_loss: 0.6269 - val_acc: 0.7864\n",
      "Epoch 303/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2847 - acc: 0.8828 - val_loss: 0.6217 - val_acc: 0.7854\n",
      "Epoch 304/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2825 - acc: 0.8839 - val_loss: 0.6199 - val_acc: 0.7849\n",
      "Epoch 305/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2835 - acc: 0.8835 - val_loss: 0.6222 - val_acc: 0.7865\n",
      "Epoch 306/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2822 - acc: 0.8839 - val_loss: 0.6279 - val_acc: 0.7864\n",
      "Epoch 307/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2816 - acc: 0.8842 - val_loss: 0.6250 - val_acc: 0.7875\n",
      "Epoch 308/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2811 - acc: 0.8843 - val_loss: 0.6286 - val_acc: 0.7852\n",
      "Epoch 309/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2806 - acc: 0.8843 - val_loss: 0.6276 - val_acc: 0.7852\n",
      "Epoch 310/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2802 - acc: 0.8852 - val_loss: 0.6347 - val_acc: 0.7868\n",
      "Epoch 311/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2788 - acc: 0.8863 - val_loss: 0.6281 - val_acc: 0.7844\n",
      "Epoch 312/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.2791 - acc: 0.8852 - val_loss: 0.6315 - val_acc: 0.7852\n",
      "Epoch 313/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2796 - acc: 0.8851 - val_loss: 0.6293 - val_acc: 0.7865\n",
      "Epoch 314/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2786 - acc: 0.8860 - val_loss: 0.6230 - val_acc: 0.7847\n",
      "Epoch 315/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2782 - acc: 0.8862 - val_loss: 0.6319 - val_acc: 0.7848\n",
      "Epoch 316/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2768 - acc: 0.8871 - val_loss: 0.6351 - val_acc: 0.7867\n",
      "Epoch 317/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2773 - acc: 0.8866 - val_loss: 0.6310 - val_acc: 0.7848\n",
      "Epoch 318/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2743 - acc: 0.8876 - val_loss: 0.6409 - val_acc: 0.7849\n",
      "Epoch 319/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2741 - acc: 0.8873 - val_loss: 0.6382 - val_acc: 0.7862\n",
      "Epoch 320/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2752 - acc: 0.8874 - val_loss: 0.6378 - val_acc: 0.7855\n",
      "Epoch 321/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2762 - acc: 0.8870 - val_loss: 0.6444 - val_acc: 0.7868\n",
      "Epoch 322/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2720 - acc: 0.8886 - val_loss: 0.6406 - val_acc: 0.7860\n",
      "Epoch 323/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2718 - acc: 0.8890 - val_loss: 0.6408 - val_acc: 0.7842\n",
      "Epoch 324/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2728 - acc: 0.8875 - val_loss: 0.6396 - val_acc: 0.7849\n",
      "Epoch 325/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2709 - acc: 0.8894 - val_loss: 0.6473 - val_acc: 0.7861\n",
      "Epoch 326/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.2703 - acc: 0.8904 - val_loss: 0.6423 - val_acc: 0.7855\n",
      "Epoch 327/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2707 - acc: 0.8889 - val_loss: 0.6421 - val_acc: 0.7847\n",
      "Epoch 328/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2706 - acc: 0.8892 - val_loss: 0.6482 - val_acc: 0.7844\n",
      "Epoch 329/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2698 - acc: 0.8894 - val_loss: 0.6427 - val_acc: 0.7856\n",
      "Epoch 330/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2682 - acc: 0.8905 - val_loss: 0.6451 - val_acc: 0.7841\n",
      "Epoch 331/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2684 - acc: 0.8907 - val_loss: 0.6497 - val_acc: 0.7862\n",
      "Epoch 332/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2675 - acc: 0.8909 - val_loss: 0.6501 - val_acc: 0.7859\n",
      "Epoch 333/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2663 - acc: 0.8917 - val_loss: 0.6459 - val_acc: 0.7834\n",
      "Epoch 334/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2673 - acc: 0.8909 - val_loss: 0.6499 - val_acc: 0.7840\n",
      "Epoch 335/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2655 - acc: 0.8916 - val_loss: 0.6537 - val_acc: 0.7839\n",
      "Epoch 336/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2661 - acc: 0.8912 - val_loss: 0.6508 - val_acc: 0.7849\n",
      "Epoch 337/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2645 - acc: 0.8925 - val_loss: 0.6545 - val_acc: 0.7844\n",
      "Epoch 338/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2641 - acc: 0.8919 - val_loss: 0.6543 - val_acc: 0.7825\n",
      "Epoch 339/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2641 - acc: 0.8925 - val_loss: 0.6589 - val_acc: 0.7841\n",
      "Epoch 340/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2642 - acc: 0.8922 - val_loss: 0.6612 - val_acc: 0.7855\n",
      "Epoch 341/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2637 - acc: 0.8921 - val_loss: 0.6587 - val_acc: 0.7852\n",
      "Epoch 342/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2617 - acc: 0.8929 - val_loss: 0.6688 - val_acc: 0.7853\n",
      "Epoch 343/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2606 - acc: 0.8942 - val_loss: 0.6647 - val_acc: 0.7848\n",
      "Epoch 344/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2616 - acc: 0.8930 - val_loss: 0.6613 - val_acc: 0.7845\n",
      "Epoch 345/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2605 - acc: 0.8933 - val_loss: 0.6629 - val_acc: 0.7841\n",
      "Epoch 346/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2601 - acc: 0.8936 - val_loss: 0.6636 - val_acc: 0.7855\n",
      "Epoch 347/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2605 - acc: 0.8935 - val_loss: 0.6661 - val_acc: 0.7854\n",
      "Epoch 348/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2599 - acc: 0.8936 - val_loss: 0.6645 - val_acc: 0.7836\n",
      "Epoch 349/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2572 - acc: 0.8953 - val_loss: 0.6691 - val_acc: 0.7843\n",
      "Epoch 350/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2587 - acc: 0.8945 - val_loss: 0.6683 - val_acc: 0.7837\n",
      "Epoch 351/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2606 - acc: 0.8932 - val_loss: 0.6635 - val_acc: 0.7831\n",
      "Epoch 352/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2585 - acc: 0.8945 - val_loss: 0.6706 - val_acc: 0.7840\n",
      "Epoch 353/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2581 - acc: 0.8946 - val_loss: 0.6669 - val_acc: 0.7820\n",
      "Epoch 354/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2562 - acc: 0.8959 - val_loss: 0.6695 - val_acc: 0.7842\n",
      "Epoch 355/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2565 - acc: 0.8953 - val_loss: 0.6744 - val_acc: 0.7835\n",
      "Epoch 356/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2563 - acc: 0.8950 - val_loss: 0.6633 - val_acc: 0.7840\n",
      "Epoch 357/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2551 - acc: 0.8968 - val_loss: 0.6675 - val_acc: 0.7823\n",
      "Epoch 358/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2542 - acc: 0.8968 - val_loss: 0.6743 - val_acc: 0.7837\n",
      "Epoch 359/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2556 - acc: 0.8952 - val_loss: 0.6754 - val_acc: 0.7844\n",
      "Epoch 360/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.2542 - acc: 0.8965 - val_loss: 0.6773 - val_acc: 0.7844\n",
      "Epoch 361/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2534 - acc: 0.8968 - val_loss: 0.6731 - val_acc: 0.7819\n",
      "Epoch 362/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2528 - acc: 0.8975 - val_loss: 0.6727 - val_acc: 0.7830\n",
      "Epoch 363/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2514 - acc: 0.8976 - val_loss: 0.6816 - val_acc: 0.7816\n",
      "Epoch 364/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2507 - acc: 0.8976 - val_loss: 0.6805 - val_acc: 0.7834\n",
      "Epoch 365/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2510 - acc: 0.8976 - val_loss: 0.6773 - val_acc: 0.7825\n",
      "Epoch 366/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2484 - acc: 0.8987 - val_loss: 0.6851 - val_acc: 0.7831\n",
      "Epoch 367/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2501 - acc: 0.8981 - val_loss: 0.6826 - val_acc: 0.7842\n",
      "Epoch 368/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.2515 - acc: 0.8971 - val_loss: 0.6762 - val_acc: 0.7823\n",
      "Epoch 369/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2484 - acc: 0.8993 - val_loss: 0.6823 - val_acc: 0.7839\n",
      "Epoch 370/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2495 - acc: 0.8984 - val_loss: 0.6886 - val_acc: 0.7838\n",
      "Epoch 371/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2497 - acc: 0.8988 - val_loss: 0.6864 - val_acc: 0.7822\n",
      "Epoch 372/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2488 - acc: 0.8990 - val_loss: 0.6798 - val_acc: 0.7839\n",
      "Epoch 373/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2494 - acc: 0.8984 - val_loss: 0.6836 - val_acc: 0.7823\n",
      "Epoch 374/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2479 - acc: 0.8991 - val_loss: 0.6819 - val_acc: 0.7809\n",
      "Epoch 375/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2456 - acc: 0.9004 - val_loss: 0.6855 - val_acc: 0.7822\n",
      "Epoch 376/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2461 - acc: 0.8995 - val_loss: 0.6935 - val_acc: 0.7822\n",
      "Epoch 377/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.2463 - acc: 0.9001 - val_loss: 0.6906 - val_acc: 0.7822\n",
      "Epoch 378/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.2451 - acc: 0.9001 - val_loss: 0.6899 - val_acc: 0.7836\n",
      "Epoch 379/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2480 - acc: 0.8994 - val_loss: 0.6915 - val_acc: 0.7851\n",
      "Epoch 380/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2439 - acc: 0.9001 - val_loss: 0.6878 - val_acc: 0.7813\n",
      "Epoch 381/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2437 - acc: 0.9013 - val_loss: 0.6964 - val_acc: 0.7825\n",
      "Epoch 382/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2442 - acc: 0.9008 - val_loss: 0.6890 - val_acc: 0.7824\n",
      "Epoch 383/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2441 - acc: 0.9010 - val_loss: 0.6904 - val_acc: 0.7822\n",
      "Epoch 384/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2434 - acc: 0.9007 - val_loss: 0.6956 - val_acc: 0.7822\n",
      "Epoch 385/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2417 - acc: 0.9014 - val_loss: 0.6946 - val_acc: 0.7833\n",
      "Epoch 386/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2415 - acc: 0.9024 - val_loss: 0.7006 - val_acc: 0.7822\n",
      "Epoch 387/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2426 - acc: 0.9012 - val_loss: 0.6922 - val_acc: 0.7820\n",
      "Epoch 388/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2419 - acc: 0.9017 - val_loss: 0.6941 - val_acc: 0.7814\n",
      "Epoch 389/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2407 - acc: 0.9024 - val_loss: 0.6953 - val_acc: 0.7835\n",
      "Epoch 390/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.2397 - acc: 0.9028 - val_loss: 0.7010 - val_acc: 0.7826\n",
      "Epoch 391/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2394 - acc: 0.9031 - val_loss: 0.7010 - val_acc: 0.7816\n",
      "Epoch 392/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2386 - acc: 0.9031 - val_loss: 0.7040 - val_acc: 0.7838\n",
      "Epoch 393/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2394 - acc: 0.9027 - val_loss: 0.7010 - val_acc: 0.7833\n",
      "Epoch 394/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2400 - acc: 0.9023 - val_loss: 0.7003 - val_acc: 0.7818\n",
      "Epoch 395/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2383 - acc: 0.9033 - val_loss: 0.7047 - val_acc: 0.7821\n",
      "Epoch 396/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2369 - acc: 0.9040 - val_loss: 0.7069 - val_acc: 0.7840\n",
      "Epoch 397/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2372 - acc: 0.9036 - val_loss: 0.7055 - val_acc: 0.7816\n",
      "Epoch 398/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2386 - acc: 0.9027 - val_loss: 0.7015 - val_acc: 0.7818\n",
      "Epoch 399/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2349 - acc: 0.9045 - val_loss: 0.7037 - val_acc: 0.7831\n",
      "Epoch 400/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2355 - acc: 0.9039 - val_loss: 0.7067 - val_acc: 0.7831\n",
      "Epoch 401/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2364 - acc: 0.9041 - val_loss: 0.7072 - val_acc: 0.7823\n",
      "Epoch 402/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.2369 - acc: 0.9033 - val_loss: 0.7096 - val_acc: 0.7821\n",
      "Epoch 403/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2357 - acc: 0.9048 - val_loss: 0.7087 - val_acc: 0.7824\n",
      "Epoch 404/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2346 - acc: 0.9051 - val_loss: 0.7045 - val_acc: 0.7834\n",
      "Epoch 405/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2341 - acc: 0.9049 - val_loss: 0.7100 - val_acc: 0.7817\n",
      "Epoch 406/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2324 - acc: 0.9061 - val_loss: 0.7103 - val_acc: 0.7827\n",
      "Epoch 407/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2340 - acc: 0.9055 - val_loss: 0.7114 - val_acc: 0.7827\n",
      "Epoch 408/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2340 - acc: 0.9049 - val_loss: 0.7124 - val_acc: 0.7810\n",
      "Epoch 409/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2327 - acc: 0.9057 - val_loss: 0.7182 - val_acc: 0.7821\n",
      "Epoch 410/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2332 - acc: 0.9052 - val_loss: 0.7108 - val_acc: 0.7804\n",
      "Epoch 411/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2302 - acc: 0.9059 - val_loss: 0.7222 - val_acc: 0.7804\n",
      "Epoch 412/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2319 - acc: 0.9061 - val_loss: 0.7180 - val_acc: 0.7810\n",
      "Epoch 413/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2301 - acc: 0.9064 - val_loss: 0.7222 - val_acc: 0.7822\n",
      "Epoch 414/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2283 - acc: 0.9078 - val_loss: 0.7219 - val_acc: 0.7809\n",
      "Epoch 415/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2304 - acc: 0.9067 - val_loss: 0.7160 - val_acc: 0.7838\n",
      "Epoch 416/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2302 - acc: 0.9063 - val_loss: 0.7180 - val_acc: 0.7826\n",
      "Epoch 417/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2311 - acc: 0.9060 - val_loss: 0.7159 - val_acc: 0.7813\n",
      "Epoch 418/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2297 - acc: 0.9068 - val_loss: 0.7168 - val_acc: 0.7832\n",
      "Epoch 419/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2283 - acc: 0.9078 - val_loss: 0.7234 - val_acc: 0.7814\n",
      "Epoch 420/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2285 - acc: 0.9075 - val_loss: 0.7222 - val_acc: 0.7812\n",
      "Epoch 421/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2281 - acc: 0.9075 - val_loss: 0.7273 - val_acc: 0.7828\n",
      "Epoch 422/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2272 - acc: 0.9083 - val_loss: 0.7210 - val_acc: 0.7812\n",
      "Epoch 423/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2276 - acc: 0.9081 - val_loss: 0.7242 - val_acc: 0.7834\n",
      "Epoch 424/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2275 - acc: 0.9083 - val_loss: 0.7287 - val_acc: 0.7816\n",
      "Epoch 425/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2282 - acc: 0.9084 - val_loss: 0.7262 - val_acc: 0.7811\n",
      "Epoch 426/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2274 - acc: 0.9077 - val_loss: 0.7295 - val_acc: 0.7815\n",
      "Epoch 427/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2257 - acc: 0.9088 - val_loss: 0.7267 - val_acc: 0.7818\n",
      "Epoch 428/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2263 - acc: 0.9086 - val_loss: 0.7233 - val_acc: 0.7799\n",
      "Epoch 429/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2254 - acc: 0.9088 - val_loss: 0.7304 - val_acc: 0.7809\n",
      "Epoch 430/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2258 - acc: 0.9083 - val_loss: 0.7253 - val_acc: 0.7815\n",
      "Epoch 431/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2256 - acc: 0.9086 - val_loss: 0.7271 - val_acc: 0.7811\n",
      "Epoch 432/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2243 - acc: 0.9095 - val_loss: 0.7326 - val_acc: 0.7806\n",
      "Epoch 433/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2236 - acc: 0.9097 - val_loss: 0.7270 - val_acc: 0.7812\n",
      "Epoch 434/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.2240 - acc: 0.9094 - val_loss: 0.7301 - val_acc: 0.7806\n",
      "Epoch 435/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2238 - acc: 0.9090 - val_loss: 0.7352 - val_acc: 0.7817\n",
      "Epoch 436/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2232 - acc: 0.9097 - val_loss: 0.7372 - val_acc: 0.7831\n",
      "Epoch 437/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2230 - acc: 0.9097 - val_loss: 0.7354 - val_acc: 0.7812\n",
      "Epoch 438/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2231 - acc: 0.9094 - val_loss: 0.7340 - val_acc: 0.7823\n",
      "Epoch 439/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2213 - acc: 0.9111 - val_loss: 0.7385 - val_acc: 0.7825\n",
      "Epoch 440/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2229 - acc: 0.9101 - val_loss: 0.7368 - val_acc: 0.7821\n",
      "Epoch 441/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2228 - acc: 0.9103 - val_loss: 0.7349 - val_acc: 0.7812\n",
      "Epoch 442/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2215 - acc: 0.9101 - val_loss: 0.7365 - val_acc: 0.7773\n",
      "Epoch 443/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2213 - acc: 0.9111 - val_loss: 0.7271 - val_acc: 0.7789\n",
      "Epoch 444/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2199 - acc: 0.9117 - val_loss: 0.7432 - val_acc: 0.7819\n",
      "Epoch 445/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2197 - acc: 0.9112 - val_loss: 0.7390 - val_acc: 0.7800\n",
      "Epoch 446/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2205 - acc: 0.9111 - val_loss: 0.7463 - val_acc: 0.7818\n",
      "Epoch 447/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2188 - acc: 0.9119 - val_loss: 0.7458 - val_acc: 0.7807\n",
      "Epoch 448/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2190 - acc: 0.9112 - val_loss: 0.7464 - val_acc: 0.7794\n",
      "Epoch 449/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2187 - acc: 0.9115 - val_loss: 0.7435 - val_acc: 0.7800\n",
      "Epoch 450/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2194 - acc: 0.9117 - val_loss: 0.7398 - val_acc: 0.7812\n",
      "Epoch 451/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2176 - acc: 0.9115 - val_loss: 0.7479 - val_acc: 0.7797\n",
      "Epoch 452/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2192 - acc: 0.9114 - val_loss: 0.7397 - val_acc: 0.7794\n",
      "Epoch 453/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2170 - acc: 0.9127 - val_loss: 0.7418 - val_acc: 0.7801\n",
      "Epoch 454/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2174 - acc: 0.9121 - val_loss: 0.7408 - val_acc: 0.7802\n",
      "Epoch 455/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2175 - acc: 0.9120 - val_loss: 0.7411 - val_acc: 0.7798\n",
      "Epoch 456/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2165 - acc: 0.9127 - val_loss: 0.7443 - val_acc: 0.7793\n",
      "Epoch 457/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2166 - acc: 0.9126 - val_loss: 0.7430 - val_acc: 0.7797\n",
      "Epoch 458/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2155 - acc: 0.9132 - val_loss: 0.7536 - val_acc: 0.7812\n",
      "Epoch 459/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2159 - acc: 0.9128 - val_loss: 0.7511 - val_acc: 0.7792\n",
      "Epoch 460/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2148 - acc: 0.9137 - val_loss: 0.7472 - val_acc: 0.7805\n",
      "Epoch 461/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2162 - acc: 0.9131 - val_loss: 0.7459 - val_acc: 0.7810\n",
      "Epoch 462/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2153 - acc: 0.9124 - val_loss: 0.7506 - val_acc: 0.7792\n",
      "Epoch 463/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2146 - acc: 0.9133 - val_loss: 0.7490 - val_acc: 0.7808\n",
      "Epoch 464/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2136 - acc: 0.9139 - val_loss: 0.7504 - val_acc: 0.7814\n",
      "Epoch 465/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2141 - acc: 0.9130 - val_loss: 0.7508 - val_acc: 0.7798\n",
      "Epoch 466/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2134 - acc: 0.9136 - val_loss: 0.7535 - val_acc: 0.7794\n",
      "Epoch 467/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2150 - acc: 0.9134 - val_loss: 0.7512 - val_acc: 0.7812\n",
      "Epoch 468/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2137 - acc: 0.9141 - val_loss: 0.7573 - val_acc: 0.7818\n",
      "Epoch 469/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2130 - acc: 0.9140 - val_loss: 0.7594 - val_acc: 0.7800\n",
      "Epoch 470/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2114 - acc: 0.9149 - val_loss: 0.7593 - val_acc: 0.7808\n",
      "Epoch 471/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2118 - acc: 0.9144 - val_loss: 0.7618 - val_acc: 0.7802\n",
      "Epoch 472/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2119 - acc: 0.9145 - val_loss: 0.7607 - val_acc: 0.7797\n",
      "Epoch 473/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2121 - acc: 0.9144 - val_loss: 0.7618 - val_acc: 0.7781\n",
      "Epoch 474/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2099 - acc: 0.9152 - val_loss: 0.7679 - val_acc: 0.7797\n",
      "Epoch 475/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2117 - acc: 0.9146 - val_loss: 0.7612 - val_acc: 0.7802\n",
      "Epoch 476/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2129 - acc: 0.9138 - val_loss: 0.7605 - val_acc: 0.7790\n",
      "Epoch 477/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2103 - acc: 0.9154 - val_loss: 0.7606 - val_acc: 0.7804\n",
      "Epoch 478/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2104 - acc: 0.9153 - val_loss: 0.7649 - val_acc: 0.7799\n",
      "Epoch 479/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2092 - acc: 0.9158 - val_loss: 0.7669 - val_acc: 0.7800\n",
      "Epoch 480/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2092 - acc: 0.9159 - val_loss: 0.7613 - val_acc: 0.7803\n",
      "Epoch 481/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2088 - acc: 0.9157 - val_loss: 0.7534 - val_acc: 0.7800\n",
      "Epoch 482/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2087 - acc: 0.9162 - val_loss: 0.7573 - val_acc: 0.7793\n",
      "Epoch 483/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2087 - acc: 0.9157 - val_loss: 0.7581 - val_acc: 0.7804\n",
      "Epoch 484/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2073 - acc: 0.9160 - val_loss: 0.7662 - val_acc: 0.7805\n",
      "Epoch 485/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.2087 - acc: 0.9159 - val_loss: 0.7667 - val_acc: 0.7815\n",
      "Epoch 486/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2071 - acc: 0.9168 - val_loss: 0.7726 - val_acc: 0.7811\n",
      "Epoch 487/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.2058 - acc: 0.9165 - val_loss: 0.7733 - val_acc: 0.7787\n",
      "Epoch 488/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2092 - acc: 0.9156 - val_loss: 0.7637 - val_acc: 0.7804\n",
      "Epoch 489/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2060 - acc: 0.9169 - val_loss: 0.7720 - val_acc: 0.7806\n",
      "Epoch 490/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.2095 - acc: 0.9153 - val_loss: 0.7631 - val_acc: 0.7812\n",
      "Epoch 491/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.2068 - acc: 0.9173 - val_loss: 0.7661 - val_acc: 0.7805\n",
      "Epoch 492/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2053 - acc: 0.9172 - val_loss: 0.7693 - val_acc: 0.7784\n",
      "Epoch 493/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2072 - acc: 0.9164 - val_loss: 0.7739 - val_acc: 0.7801\n",
      "Epoch 494/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2048 - acc: 0.9177 - val_loss: 0.7764 - val_acc: 0.7792\n",
      "Epoch 495/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2058 - acc: 0.9174 - val_loss: 0.7716 - val_acc: 0.7802\n",
      "Epoch 496/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2053 - acc: 0.9171 - val_loss: 0.7749 - val_acc: 0.7792\n",
      "Epoch 497/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2055 - acc: 0.9174 - val_loss: 0.7688 - val_acc: 0.7803\n",
      "Epoch 498/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2045 - acc: 0.9172 - val_loss: 0.7734 - val_acc: 0.7798\n",
      "Epoch 499/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2054 - acc: 0.9180 - val_loss: 0.7739 - val_acc: 0.7803\n",
      "Epoch 500/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2036 - acc: 0.9183 - val_loss: 0.7727 - val_acc: 0.7795\n",
      "Epoch 501/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.2043 - acc: 0.9178 - val_loss: 0.7686 - val_acc: 0.7800\n",
      "Epoch 502/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2033 - acc: 0.9183 - val_loss: 0.7823 - val_acc: 0.7797\n",
      "Epoch 503/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2031 - acc: 0.9186 - val_loss: 0.7737 - val_acc: 0.7813\n",
      "Epoch 504/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2030 - acc: 0.9185 - val_loss: 0.7797 - val_acc: 0.7810\n",
      "Epoch 505/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2030 - acc: 0.9185 - val_loss: 0.7742 - val_acc: 0.7795\n",
      "Epoch 506/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2039 - acc: 0.9182 - val_loss: 0.7767 - val_acc: 0.7775\n",
      "Epoch 507/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2035 - acc: 0.9184 - val_loss: 0.7806 - val_acc: 0.7799\n",
      "Epoch 508/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2022 - acc: 0.9185 - val_loss: 0.7736 - val_acc: 0.7792\n",
      "Epoch 509/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2021 - acc: 0.9187 - val_loss: 0.7730 - val_acc: 0.7772\n",
      "Epoch 510/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2027 - acc: 0.9180 - val_loss: 0.7814 - val_acc: 0.7794\n",
      "Epoch 511/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2012 - acc: 0.9197 - val_loss: 0.7798 - val_acc: 0.7774\n",
      "Epoch 512/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2009 - acc: 0.9196 - val_loss: 0.7899 - val_acc: 0.7815\n",
      "Epoch 513/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2006 - acc: 0.9197 - val_loss: 0.7802 - val_acc: 0.7806\n",
      "Epoch 514/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1994 - acc: 0.9203 - val_loss: 0.7869 - val_acc: 0.7813\n",
      "Epoch 515/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2003 - acc: 0.9191 - val_loss: 0.7819 - val_acc: 0.7779\n",
      "Epoch 516/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2004 - acc: 0.9201 - val_loss: 0.7831 - val_acc: 0.7792\n",
      "Epoch 517/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.2009 - acc: 0.9191 - val_loss: 0.7785 - val_acc: 0.7798\n",
      "Epoch 518/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2007 - acc: 0.9195 - val_loss: 0.7844 - val_acc: 0.7801\n",
      "Epoch 519/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1996 - acc: 0.9200 - val_loss: 0.7875 - val_acc: 0.7790\n",
      "Epoch 520/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.2011 - acc: 0.9194 - val_loss: 0.7837 - val_acc: 0.7790\n",
      "Epoch 521/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1995 - acc: 0.9200 - val_loss: 0.7775 - val_acc: 0.7782\n",
      "Epoch 522/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1999 - acc: 0.9202 - val_loss: 0.7831 - val_acc: 0.7797\n",
      "Epoch 523/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1997 - acc: 0.9199 - val_loss: 0.7846 - val_acc: 0.7793\n",
      "Epoch 524/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1982 - acc: 0.9207 - val_loss: 0.7867 - val_acc: 0.7775\n",
      "Epoch 525/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1982 - acc: 0.9211 - val_loss: 0.7905 - val_acc: 0.7786\n",
      "Epoch 526/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1976 - acc: 0.9210 - val_loss: 0.7862 - val_acc: 0.7806\n",
      "Epoch 527/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1968 - acc: 0.9217 - val_loss: 0.7910 - val_acc: 0.7801\n",
      "Epoch 528/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1972 - acc: 0.9214 - val_loss: 0.7874 - val_acc: 0.7772\n",
      "Epoch 529/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1972 - acc: 0.9212 - val_loss: 0.7853 - val_acc: 0.7777\n",
      "Epoch 530/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1970 - acc: 0.9215 - val_loss: 0.7872 - val_acc: 0.7788\n",
      "Epoch 531/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1968 - acc: 0.9211 - val_loss: 0.7855 - val_acc: 0.7778\n",
      "Epoch 532/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1971 - acc: 0.9205 - val_loss: 0.7940 - val_acc: 0.7785\n",
      "Epoch 533/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1975 - acc: 0.9212 - val_loss: 0.8000 - val_acc: 0.7788\n",
      "Epoch 534/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1954 - acc: 0.9219 - val_loss: 0.7888 - val_acc: 0.7778\n",
      "Epoch 535/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1963 - acc: 0.9214 - val_loss: 0.7984 - val_acc: 0.7788\n",
      "Epoch 536/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1958 - acc: 0.9219 - val_loss: 0.7936 - val_acc: 0.7771\n",
      "Epoch 537/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1948 - acc: 0.9223 - val_loss: 0.7929 - val_acc: 0.7793\n",
      "Epoch 538/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1961 - acc: 0.9213 - val_loss: 0.7937 - val_acc: 0.7794\n",
      "Epoch 539/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1946 - acc: 0.9227 - val_loss: 0.7960 - val_acc: 0.7787\n",
      "Epoch 540/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1949 - acc: 0.9223 - val_loss: 0.7980 - val_acc: 0.7773\n",
      "Epoch 541/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1943 - acc: 0.9224 - val_loss: 0.7934 - val_acc: 0.7800\n",
      "Epoch 542/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1942 - acc: 0.9229 - val_loss: 0.7964 - val_acc: 0.7805\n",
      "Epoch 543/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1944 - acc: 0.9221 - val_loss: 0.7912 - val_acc: 0.7782\n",
      "Epoch 544/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1936 - acc: 0.9219 - val_loss: 0.7989 - val_acc: 0.7795\n",
      "Epoch 545/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1927 - acc: 0.9228 - val_loss: 0.8018 - val_acc: 0.7793\n",
      "Epoch 546/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1930 - acc: 0.9227 - val_loss: 0.8027 - val_acc: 0.7787\n",
      "Epoch 547/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1918 - acc: 0.9231 - val_loss: 0.8021 - val_acc: 0.7771\n",
      "Epoch 548/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1935 - acc: 0.9224 - val_loss: 0.7994 - val_acc: 0.7778\n",
      "Epoch 549/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1916 - acc: 0.9237 - val_loss: 0.8025 - val_acc: 0.7780\n",
      "Epoch 550/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1930 - acc: 0.9225 - val_loss: 0.8067 - val_acc: 0.7792\n",
      "Epoch 551/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1925 - acc: 0.9227 - val_loss: 0.8033 - val_acc: 0.7766\n",
      "Epoch 552/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1916 - acc: 0.9235 - val_loss: 0.8081 - val_acc: 0.7779\n",
      "Epoch 553/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1932 - acc: 0.9230 - val_loss: 0.7993 - val_acc: 0.7788\n",
      "Epoch 554/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1904 - acc: 0.9245 - val_loss: 0.8086 - val_acc: 0.7773\n",
      "Epoch 555/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1907 - acc: 0.9237 - val_loss: 0.8020 - val_acc: 0.7775\n",
      "Epoch 556/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.1921 - acc: 0.9239 - val_loss: 0.7994 - val_acc: 0.7795\n",
      "Epoch 557/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1927 - acc: 0.9231 - val_loss: 0.8108 - val_acc: 0.7793\n",
      "Epoch 558/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1903 - acc: 0.9242 - val_loss: 0.8044 - val_acc: 0.7785\n",
      "Epoch 559/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1903 - acc: 0.9241 - val_loss: 0.8040 - val_acc: 0.7779\n",
      "Epoch 560/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1917 - acc: 0.9233 - val_loss: 0.8049 - val_acc: 0.7784\n",
      "Epoch 561/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1905 - acc: 0.9235 - val_loss: 0.8043 - val_acc: 0.7769\n",
      "Epoch 562/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1897 - acc: 0.9248 - val_loss: 0.8051 - val_acc: 0.7773\n",
      "Epoch 563/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1898 - acc: 0.9244 - val_loss: 0.8115 - val_acc: 0.7773\n",
      "Epoch 564/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1888 - acc: 0.9247 - val_loss: 0.8093 - val_acc: 0.7782\n",
      "Epoch 565/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1923 - acc: 0.9229 - val_loss: 0.8036 - val_acc: 0.7781\n",
      "Epoch 566/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1888 - acc: 0.9253 - val_loss: 0.8072 - val_acc: 0.7759\n",
      "Epoch 567/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1891 - acc: 0.9243 - val_loss: 0.8102 - val_acc: 0.7784\n",
      "Epoch 568/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1896 - acc: 0.9245 - val_loss: 0.8116 - val_acc: 0.7771\n",
      "Epoch 569/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1879 - acc: 0.9246 - val_loss: 0.8059 - val_acc: 0.7775\n",
      "Epoch 570/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1861 - acc: 0.9256 - val_loss: 0.8168 - val_acc: 0.7767\n",
      "Epoch 571/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1900 - acc: 0.9244 - val_loss: 0.8139 - val_acc: 0.7766\n",
      "Epoch 572/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1874 - acc: 0.9256 - val_loss: 0.8093 - val_acc: 0.7771\n",
      "Epoch 573/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1875 - acc: 0.9255 - val_loss: 0.8126 - val_acc: 0.7782\n",
      "Epoch 574/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1869 - acc: 0.9254 - val_loss: 0.8120 - val_acc: 0.7771\n",
      "Epoch 575/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1871 - acc: 0.9256 - val_loss: 0.8121 - val_acc: 0.7781\n",
      "Epoch 576/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1874 - acc: 0.9252 - val_loss: 0.8120 - val_acc: 0.7769\n",
      "Epoch 577/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1879 - acc: 0.9252 - val_loss: 0.8088 - val_acc: 0.7772\n",
      "Epoch 578/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.1878 - acc: 0.9251 - val_loss: 0.8112 - val_acc: 0.7769\n",
      "Epoch 579/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1879 - acc: 0.9251 - val_loss: 0.8114 - val_acc: 0.7780\n",
      "Epoch 580/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1860 - acc: 0.9260 - val_loss: 0.8150 - val_acc: 0.7764\n",
      "Epoch 581/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1877 - acc: 0.9246 - val_loss: 0.8152 - val_acc: 0.7768\n",
      "Epoch 582/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1875 - acc: 0.9252 - val_loss: 0.8126 - val_acc: 0.7773\n",
      "Epoch 583/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1850 - acc: 0.9262 - val_loss: 0.8238 - val_acc: 0.7764\n",
      "Epoch 584/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1872 - acc: 0.9257 - val_loss: 0.8130 - val_acc: 0.7769\n",
      "Epoch 585/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1855 - acc: 0.9264 - val_loss: 0.8209 - val_acc: 0.7769\n",
      "Epoch 586/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1855 - acc: 0.9264 - val_loss: 0.8156 - val_acc: 0.7788\n",
      "Epoch 587/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1849 - acc: 0.9265 - val_loss: 0.8206 - val_acc: 0.7786\n",
      "Epoch 588/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1858 - acc: 0.9258 - val_loss: 0.8263 - val_acc: 0.7772\n",
      "Epoch 589/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1854 - acc: 0.9260 - val_loss: 0.8196 - val_acc: 0.7767\n",
      "Epoch 590/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1844 - acc: 0.9268 - val_loss: 0.8179 - val_acc: 0.7780\n",
      "Epoch 591/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1847 - acc: 0.9265 - val_loss: 0.8188 - val_acc: 0.7760\n",
      "Epoch 592/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1844 - acc: 0.9266 - val_loss: 0.8227 - val_acc: 0.7780\n",
      "Epoch 593/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1846 - acc: 0.9267 - val_loss: 0.8182 - val_acc: 0.7771\n",
      "Epoch 594/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1840 - acc: 0.9270 - val_loss: 0.8218 - val_acc: 0.7780\n",
      "Epoch 595/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1843 - acc: 0.9266 - val_loss: 0.8190 - val_acc: 0.7784\n",
      "Epoch 596/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1834 - acc: 0.9273 - val_loss: 0.8247 - val_acc: 0.7795\n",
      "Epoch 597/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.1833 - acc: 0.9273 - val_loss: 0.8243 - val_acc: 0.7773\n",
      "Epoch 598/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1818 - acc: 0.9278 - val_loss: 0.8228 - val_acc: 0.7772\n",
      "Epoch 599/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1839 - acc: 0.9273 - val_loss: 0.8242 - val_acc: 0.7768\n",
      "Epoch 600/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1827 - acc: 0.9273 - val_loss: 0.8273 - val_acc: 0.7774\n",
      "Epoch 601/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1826 - acc: 0.9278 - val_loss: 0.8219 - val_acc: 0.7767\n",
      "Epoch 602/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1817 - acc: 0.9272 - val_loss: 0.8209 - val_acc: 0.7771\n",
      "Epoch 603/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1826 - acc: 0.9274 - val_loss: 0.8256 - val_acc: 0.7782\n",
      "Epoch 604/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1806 - acc: 0.9279 - val_loss: 0.8308 - val_acc: 0.7762\n",
      "Epoch 605/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1817 - acc: 0.9284 - val_loss: 0.8263 - val_acc: 0.7763\n",
      "Epoch 606/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1813 - acc: 0.9276 - val_loss: 0.8307 - val_acc: 0.7774\n",
      "Epoch 607/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1812 - acc: 0.9278 - val_loss: 0.8313 - val_acc: 0.7782\n",
      "Epoch 608/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1817 - acc: 0.9273 - val_loss: 0.8261 - val_acc: 0.7767\n",
      "Epoch 609/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1809 - acc: 0.9285 - val_loss: 0.8190 - val_acc: 0.7766\n",
      "Epoch 610/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1791 - acc: 0.9283 - val_loss: 0.8411 - val_acc: 0.7778\n",
      "Epoch 611/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1794 - acc: 0.9290 - val_loss: 0.8348 - val_acc: 0.7765\n",
      "Epoch 612/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1811 - acc: 0.9278 - val_loss: 0.8339 - val_acc: 0.7773\n",
      "Epoch 613/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1795 - acc: 0.9282 - val_loss: 0.8320 - val_acc: 0.7785\n",
      "Epoch 614/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1800 - acc: 0.9287 - val_loss: 0.8427 - val_acc: 0.7780\n",
      "Epoch 615/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1789 - acc: 0.9292 - val_loss: 0.8362 - val_acc: 0.7796\n",
      "Epoch 616/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1811 - acc: 0.9284 - val_loss: 0.8400 - val_acc: 0.7780\n",
      "Epoch 617/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1796 - acc: 0.9286 - val_loss: 0.8328 - val_acc: 0.7769\n",
      "Epoch 618/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1782 - acc: 0.9293 - val_loss: 0.8319 - val_acc: 0.7758\n",
      "Epoch 619/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1797 - acc: 0.9289 - val_loss: 0.8289 - val_acc: 0.7741\n",
      "Epoch 620/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1789 - acc: 0.9291 - val_loss: 0.8374 - val_acc: 0.7766\n",
      "Epoch 621/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1789 - acc: 0.9289 - val_loss: 0.8368 - val_acc: 0.7760\n",
      "Epoch 622/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1790 - acc: 0.9292 - val_loss: 0.8327 - val_acc: 0.7779\n",
      "Epoch 623/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1785 - acc: 0.9292 - val_loss: 0.8344 - val_acc: 0.7768\n",
      "Epoch 624/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1777 - acc: 0.9296 - val_loss: 0.8384 - val_acc: 0.7770\n",
      "Epoch 625/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1781 - acc: 0.9290 - val_loss: 0.8370 - val_acc: 0.7768\n",
      "Epoch 626/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1781 - acc: 0.9293 - val_loss: 0.8435 - val_acc: 0.7762\n",
      "Epoch 627/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1773 - acc: 0.9294 - val_loss: 0.8424 - val_acc: 0.7775\n",
      "Epoch 628/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1783 - acc: 0.9293 - val_loss: 0.8410 - val_acc: 0.7771\n",
      "Epoch 629/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1777 - acc: 0.9295 - val_loss: 0.8411 - val_acc: 0.7763\n",
      "Epoch 630/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1780 - acc: 0.9292 - val_loss: 0.8354 - val_acc: 0.7764\n",
      "Epoch 631/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1773 - acc: 0.9298 - val_loss: 0.8372 - val_acc: 0.7762\n",
      "Epoch 632/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1759 - acc: 0.9303 - val_loss: 0.8470 - val_acc: 0.7781\n",
      "Epoch 633/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.1763 - acc: 0.9304 - val_loss: 0.8461 - val_acc: 0.7764\n",
      "Epoch 634/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1790 - acc: 0.9287 - val_loss: 0.8353 - val_acc: 0.7777\n",
      "Epoch 635/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1755 - acc: 0.9308 - val_loss: 0.8449 - val_acc: 0.7781\n",
      "Epoch 636/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1763 - acc: 0.9308 - val_loss: 0.8474 - val_acc: 0.7747\n",
      "Epoch 637/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1762 - acc: 0.9308 - val_loss: 0.8425 - val_acc: 0.7756\n",
      "Epoch 638/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1747 - acc: 0.9307 - val_loss: 0.8458 - val_acc: 0.7787\n",
      "Epoch 639/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.1758 - acc: 0.9306 - val_loss: 0.8470 - val_acc: 0.7761\n",
      "Epoch 640/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1749 - acc: 0.9306 - val_loss: 0.8463 - val_acc: 0.7775\n",
      "Epoch 641/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.1738 - acc: 0.9313 - val_loss: 0.8535 - val_acc: 0.7768\n",
      "Epoch 642/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.1757 - acc: 0.9307 - val_loss: 0.8496 - val_acc: 0.7763\n",
      "Epoch 643/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1760 - acc: 0.9301 - val_loss: 0.8408 - val_acc: 0.7784\n",
      "Epoch 644/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1761 - acc: 0.9303 - val_loss: 0.8501 - val_acc: 0.7771\n",
      "Epoch 645/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.1756 - acc: 0.9301 - val_loss: 0.8465 - val_acc: 0.7771\n",
      "Epoch 646/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1745 - acc: 0.9310 - val_loss: 0.8373 - val_acc: 0.7765\n",
      "Epoch 647/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.1752 - acc: 0.9308 - val_loss: 0.8430 - val_acc: 0.7777\n",
      "Epoch 648/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1743 - acc: 0.9313 - val_loss: 0.8510 - val_acc: 0.7776\n",
      "Epoch 649/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.1740 - acc: 0.9310 - val_loss: 0.8464 - val_acc: 0.7767\n",
      "Epoch 650/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1740 - acc: 0.9314 - val_loss: 0.8477 - val_acc: 0.7751\n",
      "Epoch 651/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1750 - acc: 0.9304 - val_loss: 0.8425 - val_acc: 0.7763\n",
      "Epoch 652/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1742 - acc: 0.9310 - val_loss: 0.8526 - val_acc: 0.7765\n",
      "Epoch 653/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1736 - acc: 0.9309 - val_loss: 0.8511 - val_acc: 0.7760\n",
      "Epoch 654/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1733 - acc: 0.9312 - val_loss: 0.8518 - val_acc: 0.7751\n",
      "Epoch 655/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1738 - acc: 0.9314 - val_loss: 0.8438 - val_acc: 0.7773\n",
      "Epoch 656/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1735 - acc: 0.9317 - val_loss: 0.8500 - val_acc: 0.7763\n",
      "Epoch 657/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1745 - acc: 0.9306 - val_loss: 0.8429 - val_acc: 0.7768\n",
      "Epoch 658/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1722 - acc: 0.9323 - val_loss: 0.8477 - val_acc: 0.7756\n",
      "Epoch 659/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1736 - acc: 0.9307 - val_loss: 0.8513 - val_acc: 0.7761\n",
      "Epoch 660/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1727 - acc: 0.9314 - val_loss: 0.8442 - val_acc: 0.7764\n",
      "Epoch 661/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1741 - acc: 0.9308 - val_loss: 0.8419 - val_acc: 0.7763\n",
      "Epoch 662/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1731 - acc: 0.9316 - val_loss: 0.8556 - val_acc: 0.7764\n",
      "Epoch 663/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1730 - acc: 0.9316 - val_loss: 0.8549 - val_acc: 0.7775\n",
      "Epoch 664/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1709 - acc: 0.9322 - val_loss: 0.8603 - val_acc: 0.7763\n",
      "Epoch 665/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1720 - acc: 0.9321 - val_loss: 0.8484 - val_acc: 0.7766\n",
      "Epoch 666/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1730 - acc: 0.9315 - val_loss: 0.8524 - val_acc: 0.7766\n",
      "Epoch 667/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1709 - acc: 0.9328 - val_loss: 0.8542 - val_acc: 0.7763\n",
      "Epoch 668/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1707 - acc: 0.9325 - val_loss: 0.8565 - val_acc: 0.7753\n",
      "Epoch 669/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1719 - acc: 0.9326 - val_loss: 0.8507 - val_acc: 0.7762\n",
      "Epoch 670/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1710 - acc: 0.9328 - val_loss: 0.8571 - val_acc: 0.7749\n",
      "Epoch 671/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1691 - acc: 0.9332 - val_loss: 0.8614 - val_acc: 0.7754\n",
      "Epoch 672/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1716 - acc: 0.9322 - val_loss: 0.8592 - val_acc: 0.7768\n",
      "Epoch 673/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1711 - acc: 0.9327 - val_loss: 0.8540 - val_acc: 0.7767\n",
      "Epoch 674/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1701 - acc: 0.9330 - val_loss: 0.8585 - val_acc: 0.7760\n",
      "Epoch 675/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1693 - acc: 0.9328 - val_loss: 0.8601 - val_acc: 0.7760\n",
      "Epoch 676/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1692 - acc: 0.9329 - val_loss: 0.8613 - val_acc: 0.7768\n",
      "Epoch 677/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1708 - acc: 0.9326 - val_loss: 0.8531 - val_acc: 0.7750\n",
      "Epoch 678/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.1697 - acc: 0.9327 - val_loss: 0.8560 - val_acc: 0.7769\n",
      "Epoch 679/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1701 - acc: 0.9331 - val_loss: 0.8531 - val_acc: 0.7752\n",
      "Epoch 680/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1690 - acc: 0.9333 - val_loss: 0.8586 - val_acc: 0.7776\n",
      "Epoch 681/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1698 - acc: 0.9336 - val_loss: 0.8523 - val_acc: 0.7777\n",
      "Epoch 682/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1689 - acc: 0.9336 - val_loss: 0.8687 - val_acc: 0.7775\n",
      "Epoch 683/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1684 - acc: 0.9333 - val_loss: 0.8605 - val_acc: 0.7761\n",
      "Epoch 684/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1689 - acc: 0.9338 - val_loss: 0.8627 - val_acc: 0.7767\n",
      "Epoch 685/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1683 - acc: 0.9335 - val_loss: 0.8697 - val_acc: 0.7757\n",
      "Epoch 686/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1680 - acc: 0.9342 - val_loss: 0.8664 - val_acc: 0.7758\n",
      "Epoch 687/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1691 - acc: 0.9335 - val_loss: 0.8548 - val_acc: 0.7762\n",
      "Epoch 688/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1679 - acc: 0.9336 - val_loss: 0.8645 - val_acc: 0.7779\n",
      "Epoch 689/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1675 - acc: 0.9342 - val_loss: 0.8527 - val_acc: 0.7757\n",
      "Epoch 690/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1682 - acc: 0.9336 - val_loss: 0.8629 - val_acc: 0.7747\n",
      "Epoch 691/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1687 - acc: 0.9335 - val_loss: 0.8562 - val_acc: 0.7741\n",
      "Epoch 692/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1680 - acc: 0.9344 - val_loss: 0.8658 - val_acc: 0.7762\n",
      "Epoch 693/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1668 - acc: 0.9348 - val_loss: 0.8687 - val_acc: 0.7779\n",
      "Epoch 694/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1679 - acc: 0.9342 - val_loss: 0.8634 - val_acc: 0.7751\n",
      "Epoch 695/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1661 - acc: 0.9345 - val_loss: 0.8672 - val_acc: 0.7761\n",
      "Epoch 696/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1697 - acc: 0.9334 - val_loss: 0.8583 - val_acc: 0.7762\n",
      "Epoch 697/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1682 - acc: 0.9341 - val_loss: 0.8615 - val_acc: 0.7765\n",
      "Epoch 698/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1663 - acc: 0.9346 - val_loss: 0.8672 - val_acc: 0.7745\n",
      "Epoch 699/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.1673 - acc: 0.9342 - val_loss: 0.8611 - val_acc: 0.7749\n",
      "Epoch 700/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1671 - acc: 0.9344 - val_loss: 0.8611 - val_acc: 0.7755\n",
      "Epoch 701/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1678 - acc: 0.9340 - val_loss: 0.8635 - val_acc: 0.7771\n",
      "Epoch 702/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1668 - acc: 0.9342 - val_loss: 0.8708 - val_acc: 0.7770\n",
      "Epoch 703/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1668 - acc: 0.9341 - val_loss: 0.8631 - val_acc: 0.7776\n",
      "Epoch 704/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1670 - acc: 0.9343 - val_loss: 0.8646 - val_acc: 0.7773\n",
      "Epoch 705/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1655 - acc: 0.9349 - val_loss: 0.8669 - val_acc: 0.7760\n",
      "Epoch 706/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1661 - acc: 0.9348 - val_loss: 0.8683 - val_acc: 0.7768\n",
      "Epoch 707/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1639 - acc: 0.9361 - val_loss: 0.8743 - val_acc: 0.7754\n",
      "Epoch 708/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1653 - acc: 0.9352 - val_loss: 0.8715 - val_acc: 0.7761\n",
      "Epoch 709/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1657 - acc: 0.9349 - val_loss: 0.8649 - val_acc: 0.7755\n",
      "Epoch 710/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.1648 - acc: 0.9353 - val_loss: 0.8680 - val_acc: 0.7747\n",
      "Epoch 711/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1653 - acc: 0.9350 - val_loss: 0.8774 - val_acc: 0.7756\n",
      "Epoch 712/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1663 - acc: 0.9343 - val_loss: 0.8685 - val_acc: 0.7748\n",
      "Epoch 713/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1646 - acc: 0.9349 - val_loss: 0.8721 - val_acc: 0.7734\n",
      "Epoch 714/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1649 - acc: 0.9352 - val_loss: 0.8654 - val_acc: 0.7743\n",
      "Epoch 715/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1648 - acc: 0.9350 - val_loss: 0.8678 - val_acc: 0.7765\n",
      "Epoch 716/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1657 - acc: 0.9350 - val_loss: 0.8710 - val_acc: 0.7769\n",
      "Epoch 717/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1651 - acc: 0.9353 - val_loss: 0.8686 - val_acc: 0.7764\n",
      "Epoch 718/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1652 - acc: 0.9354 - val_loss: 0.8652 - val_acc: 0.7762\n",
      "Epoch 719/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1657 - acc: 0.9348 - val_loss: 0.8724 - val_acc: 0.7760\n",
      "Epoch 720/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1638 - acc: 0.9356 - val_loss: 0.8730 - val_acc: 0.7759\n",
      "Epoch 721/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1636 - acc: 0.9357 - val_loss: 0.8729 - val_acc: 0.7752\n",
      "Epoch 722/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1657 - acc: 0.9348 - val_loss: 0.8684 - val_acc: 0.7766\n",
      "Epoch 723/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1649 - acc: 0.9356 - val_loss: 0.8749 - val_acc: 0.7755\n",
      "Epoch 724/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1633 - acc: 0.9354 - val_loss: 0.8745 - val_acc: 0.7764\n",
      "Epoch 725/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1635 - acc: 0.9354 - val_loss: 0.8720 - val_acc: 0.7753\n",
      "Epoch 726/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1639 - acc: 0.9357 - val_loss: 0.8735 - val_acc: 0.7757\n",
      "Epoch 727/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1635 - acc: 0.9360 - val_loss: 0.8772 - val_acc: 0.7760\n",
      "Epoch 728/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1633 - acc: 0.9359 - val_loss: 0.8749 - val_acc: 0.7766\n",
      "Epoch 729/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1626 - acc: 0.9364 - val_loss: 0.8767 - val_acc: 0.7763\n",
      "Epoch 730/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1633 - acc: 0.9356 - val_loss: 0.8809 - val_acc: 0.7767\n",
      "Epoch 731/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1630 - acc: 0.9357 - val_loss: 0.8706 - val_acc: 0.7757\n",
      "Epoch 732/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1622 - acc: 0.9369 - val_loss: 0.8793 - val_acc: 0.7761\n",
      "Epoch 733/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1612 - acc: 0.9365 - val_loss: 0.8799 - val_acc: 0.7751\n",
      "Epoch 734/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1638 - acc: 0.9357 - val_loss: 0.8684 - val_acc: 0.7749\n",
      "Epoch 735/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1621 - acc: 0.9361 - val_loss: 0.8690 - val_acc: 0.7766\n",
      "Epoch 736/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1613 - acc: 0.9367 - val_loss: 0.8772 - val_acc: 0.7763\n",
      "Epoch 737/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1623 - acc: 0.9360 - val_loss: 0.8782 - val_acc: 0.7753\n",
      "Epoch 738/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1622 - acc: 0.9369 - val_loss: 0.8718 - val_acc: 0.7760\n",
      "Epoch 739/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1623 - acc: 0.9366 - val_loss: 0.8799 - val_acc: 0.7761\n",
      "Epoch 740/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1621 - acc: 0.9364 - val_loss: 0.8792 - val_acc: 0.7761\n",
      "Epoch 741/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1609 - acc: 0.9369 - val_loss: 0.8778 - val_acc: 0.7764\n",
      "Epoch 742/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1617 - acc: 0.9364 - val_loss: 0.8807 - val_acc: 0.7763\n",
      "Epoch 743/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1628 - acc: 0.9363 - val_loss: 0.8829 - val_acc: 0.7756\n",
      "Epoch 744/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1620 - acc: 0.9361 - val_loss: 0.8753 - val_acc: 0.7756\n",
      "Epoch 745/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1620 - acc: 0.9369 - val_loss: 0.8722 - val_acc: 0.7768\n",
      "Epoch 746/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1619 - acc: 0.9365 - val_loss: 0.8739 - val_acc: 0.7760\n",
      "Epoch 747/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1610 - acc: 0.9370 - val_loss: 0.8874 - val_acc: 0.7752\n",
      "Epoch 748/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1602 - acc: 0.9373 - val_loss: 0.8834 - val_acc: 0.7763\n",
      "Epoch 749/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1631 - acc: 0.9358 - val_loss: 0.8724 - val_acc: 0.7764\n",
      "Epoch 750/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1614 - acc: 0.9369 - val_loss: 0.8788 - val_acc: 0.7755\n",
      "Epoch 751/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1598 - acc: 0.9374 - val_loss: 0.8797 - val_acc: 0.7746\n",
      "Epoch 752/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1604 - acc: 0.9376 - val_loss: 0.8823 - val_acc: 0.7763\n",
      "Epoch 753/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1588 - acc: 0.9374 - val_loss: 0.8829 - val_acc: 0.7766\n",
      "Epoch 754/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1621 - acc: 0.9370 - val_loss: 0.8707 - val_acc: 0.7744\n",
      "Epoch 755/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1594 - acc: 0.9379 - val_loss: 0.8756 - val_acc: 0.7756\n",
      "Epoch 756/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.1606 - acc: 0.9368 - val_loss: 0.8748 - val_acc: 0.7767\n",
      "Epoch 757/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1603 - acc: 0.9377 - val_loss: 0.8788 - val_acc: 0.7762\n",
      "Epoch 758/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1600 - acc: 0.9376 - val_loss: 0.8789 - val_acc: 0.7758\n",
      "Epoch 759/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1609 - acc: 0.9375 - val_loss: 0.8754 - val_acc: 0.7756\n",
      "Epoch 760/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1588 - acc: 0.9380 - val_loss: 0.8792 - val_acc: 0.7748\n",
      "Epoch 761/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1592 - acc: 0.9374 - val_loss: 0.8732 - val_acc: 0.7769\n",
      "Epoch 762/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.1589 - acc: 0.9378 - val_loss: 0.8897 - val_acc: 0.7773\n",
      "Epoch 763/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1599 - acc: 0.9379 - val_loss: 0.8827 - val_acc: 0.7752\n",
      "Epoch 764/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1608 - acc: 0.9370 - val_loss: 0.8715 - val_acc: 0.7763\n",
      "Epoch 765/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1598 - acc: 0.9376 - val_loss: 0.8737 - val_acc: 0.7765\n",
      "Epoch 766/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1586 - acc: 0.9380 - val_loss: 0.8811 - val_acc: 0.7760\n",
      "Epoch 767/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1593 - acc: 0.9379 - val_loss: 0.8796 - val_acc: 0.7758\n",
      "Epoch 768/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1590 - acc: 0.9376 - val_loss: 0.8903 - val_acc: 0.7765\n",
      "Epoch 769/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1565 - acc: 0.9392 - val_loss: 0.8877 - val_acc: 0.7760\n",
      "Epoch 770/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1589 - acc: 0.9378 - val_loss: 0.8822 - val_acc: 0.7744\n",
      "Epoch 771/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1579 - acc: 0.9384 - val_loss: 0.8867 - val_acc: 0.7755\n",
      "Epoch 772/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1566 - acc: 0.9385 - val_loss: 0.8886 - val_acc: 0.7763\n",
      "Epoch 773/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1578 - acc: 0.9383 - val_loss: 0.8887 - val_acc: 0.7764\n",
      "Epoch 774/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1579 - acc: 0.9381 - val_loss: 0.8838 - val_acc: 0.7772\n",
      "Epoch 775/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1581 - acc: 0.9382 - val_loss: 0.8843 - val_acc: 0.7766\n",
      "Epoch 776/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1573 - acc: 0.9385 - val_loss: 0.8799 - val_acc: 0.7761\n",
      "Epoch 777/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1563 - acc: 0.9389 - val_loss: 0.8893 - val_acc: 0.7740\n",
      "Epoch 778/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1573 - acc: 0.9387 - val_loss: 0.8885 - val_acc: 0.7757\n",
      "Epoch 779/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1593 - acc: 0.9380 - val_loss: 0.8914 - val_acc: 0.7746\n",
      "Epoch 780/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1573 - acc: 0.9380 - val_loss: 0.8908 - val_acc: 0.7756\n",
      "Epoch 781/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.1561 - acc: 0.9385 - val_loss: 0.8928 - val_acc: 0.7744\n",
      "Epoch 782/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1573 - acc: 0.9381 - val_loss: 0.8991 - val_acc: 0.7761\n",
      "Epoch 783/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1562 - acc: 0.9388 - val_loss: 0.8911 - val_acc: 0.7753\n",
      "Epoch 784/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1563 - acc: 0.9390 - val_loss: 0.8878 - val_acc: 0.7761\n",
      "Epoch 785/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1563 - acc: 0.9383 - val_loss: 0.8884 - val_acc: 0.7757\n",
      "Epoch 786/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1561 - acc: 0.9395 - val_loss: 0.8824 - val_acc: 0.7742\n",
      "Epoch 787/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1552 - acc: 0.9395 - val_loss: 0.8910 - val_acc: 0.7761\n",
      "Epoch 788/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1551 - acc: 0.9401 - val_loss: 0.9008 - val_acc: 0.7764\n",
      "Epoch 789/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1548 - acc: 0.9398 - val_loss: 0.8894 - val_acc: 0.7755\n",
      "Epoch 790/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1554 - acc: 0.9392 - val_loss: 0.8921 - val_acc: 0.7761\n",
      "Epoch 791/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1551 - acc: 0.9398 - val_loss: 0.8944 - val_acc: 0.7755\n",
      "Epoch 792/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1559 - acc: 0.9394 - val_loss: 0.8989 - val_acc: 0.7746\n",
      "Epoch 793/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1564 - acc: 0.9389 - val_loss: 0.8964 - val_acc: 0.7749\n",
      "Epoch 794/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1574 - acc: 0.9389 - val_loss: 0.8836 - val_acc: 0.7766\n",
      "Epoch 795/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1554 - acc: 0.9399 - val_loss: 0.8963 - val_acc: 0.7758\n",
      "Epoch 796/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.1545 - acc: 0.9395 - val_loss: 0.8897 - val_acc: 0.7753\n",
      "Epoch 797/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1553 - acc: 0.9392 - val_loss: 0.9008 - val_acc: 0.7765\n",
      "Epoch 798/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1553 - acc: 0.9395 - val_loss: 0.8967 - val_acc: 0.7743\n",
      "Epoch 799/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1554 - acc: 0.9394 - val_loss: 0.8922 - val_acc: 0.7745\n",
      "Epoch 800/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.1554 - acc: 0.9400 - val_loss: 0.8944 - val_acc: 0.7758\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "sys.path.append(os.path.realpath(\"../\"))\n",
    "import ptetaphi_nn\n",
    "import tools\n",
    "\n",
    "# get data file path\n",
    "with open(\"/home/cmccracken/start_tf/bbb/filepath.txt\", 'r') as f:\n",
    "    filename = f.read()\n",
    "    \n",
    "s_table = tools.open_file(filename, sort_by=\"tag\", pt_cut=40, eta_cut=2.5)\n",
    "\n",
    "# filter for events with 3 b tags\n",
    "nt3 = s_table.nbtags==3 \n",
    "events = s_table[nt3]\n",
    "print(len(events))\n",
    "\n",
    "cutoff = 10  # not many events have >10 jets\n",
    "# \"pad\" = ensure all events have same length, cut off ends if needed\n",
    "events = tools.pad(events, cutoff)\n",
    "\n",
    "# make and train network\n",
    "nn = ptetaphi_nn.PtEtaPhiNN(events, chop=0, print_summary=True, fold=1)\n",
    "nn.learn(epochs=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57529/57529 [00:00<00:00, 79914.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 76.79 percent\n",
      "ignoring 1.42 percent (817 events) of 57529 events\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(savename=\"fold_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the architecture string to a file\n",
    "models_dir = \"/home/cmccracken/start_tf/bbb/models/\"\n",
    "with open(models_dir+'architecture_fold_1.json', 'w') as arch_file:\n",
    "    arch_file.write(nn.model.to_json())\n",
    "# now save the weights as an HDF5 file\n",
    "nn.model.save_weights(models_dir+'weights_fold_1.h5')\n",
    "# use nn_tester to get csv!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
