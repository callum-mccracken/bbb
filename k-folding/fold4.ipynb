{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Fold 4\n",
    "\n",
    "10 jets, #nofilter, PtEtaPhi network, restricted dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777150 total events found\n",
      "sorting data by tag\n",
      "287645\n",
      "k-folding: every 5th element starting at 4\n",
      "creating default model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 700)               21700     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 408       \n",
      "=================================================================\n",
      "Total params: 558,988\n",
      "Trainable params: 558,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230116 samples, validate on 57529 samples\n",
      "Epoch 1/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.9940 - acc: 0.6028 - val_loss: 0.8107 - val_acc: 0.6266\n",
      "Epoch 2/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.7822 - acc: 0.6366 - val_loss: 0.7462 - val_acc: 0.6549\n",
      "Epoch 3/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.7350 - acc: 0.6601 - val_loss: 0.7126 - val_acc: 0.6741\n",
      "Epoch 4/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.7109 - acc: 0.6742 - val_loss: 0.6966 - val_acc: 0.6817\n",
      "Epoch 5/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6963 - acc: 0.6811 - val_loss: 0.6838 - val_acc: 0.6892\n",
      "Epoch 6/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6861 - acc: 0.6861 - val_loss: 0.6747 - val_acc: 0.6918\n",
      "Epoch 7/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.6774 - acc: 0.6903 - val_loss: 0.6682 - val_acc: 0.6949\n",
      "Epoch 8/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6699 - acc: 0.6935 - val_loss: 0.6618 - val_acc: 0.6977\n",
      "Epoch 9/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6640 - acc: 0.6962 - val_loss: 0.6587 - val_acc: 0.6979\n",
      "Epoch 10/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6584 - acc: 0.6988 - val_loss: 0.6512 - val_acc: 0.7022\n",
      "Epoch 11/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6533 - acc: 0.7005 - val_loss: 0.6469 - val_acc: 0.7041\n",
      "Epoch 12/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6486 - acc: 0.7022 - val_loss: 0.6439 - val_acc: 0.7039\n",
      "Epoch 13/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.6441 - acc: 0.7047 - val_loss: 0.6407 - val_acc: 0.7061\n",
      "Epoch 14/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6398 - acc: 0.7062 - val_loss: 0.6344 - val_acc: 0.7078\n",
      "Epoch 15/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6359 - acc: 0.7086 - val_loss: 0.6313 - val_acc: 0.7098\n",
      "Epoch 16/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.6315 - acc: 0.7104 - val_loss: 0.6288 - val_acc: 0.7112\n",
      "Epoch 17/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6277 - acc: 0.7119 - val_loss: 0.6248 - val_acc: 0.7139\n",
      "Epoch 18/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6242 - acc: 0.7145 - val_loss: 0.6209 - val_acc: 0.7155\n",
      "Epoch 19/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.6209 - acc: 0.7149 - val_loss: 0.6173 - val_acc: 0.7173\n",
      "Epoch 20/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6173 - acc: 0.7178 - val_loss: 0.6175 - val_acc: 0.7172\n",
      "Epoch 21/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6140 - acc: 0.7195 - val_loss: 0.6115 - val_acc: 0.7209\n",
      "Epoch 22/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6113 - acc: 0.7210 - val_loss: 0.6079 - val_acc: 0.7232\n",
      "Epoch 23/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6074 - acc: 0.7234 - val_loss: 0.6063 - val_acc: 0.7234\n",
      "Epoch 24/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6047 - acc: 0.7245 - val_loss: 0.6052 - val_acc: 0.7235\n",
      "Epoch 25/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.6012 - acc: 0.7268 - val_loss: 0.5992 - val_acc: 0.7279\n",
      "Epoch 26/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5982 - acc: 0.7282 - val_loss: 0.5963 - val_acc: 0.7287\n",
      "Epoch 27/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5952 - acc: 0.7301 - val_loss: 0.5934 - val_acc: 0.7302\n",
      "Epoch 28/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5922 - acc: 0.7314 - val_loss: 0.5900 - val_acc: 0.7325\n",
      "Epoch 29/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5887 - acc: 0.7336 - val_loss: 0.5886 - val_acc: 0.7322\n",
      "Epoch 30/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5851 - acc: 0.7355 - val_loss: 0.5838 - val_acc: 0.7358\n",
      "Epoch 31/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.5825 - acc: 0.7375 - val_loss: 0.5801 - val_acc: 0.7375\n",
      "Epoch 32/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5795 - acc: 0.7391 - val_loss: 0.5775 - val_acc: 0.7391\n",
      "Epoch 33/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5764 - acc: 0.7394 - val_loss: 0.5750 - val_acc: 0.7411\n",
      "Epoch 34/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5741 - acc: 0.7416 - val_loss: 0.5717 - val_acc: 0.7418\n",
      "Epoch 35/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5721 - acc: 0.7426 - val_loss: 0.5707 - val_acc: 0.7428\n",
      "Epoch 36/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5696 - acc: 0.7443 - val_loss: 0.5675 - val_acc: 0.7454\n",
      "Epoch 37/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5666 - acc: 0.7458 - val_loss: 0.5685 - val_acc: 0.7449\n",
      "Epoch 38/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5638 - acc: 0.7468 - val_loss: 0.5637 - val_acc: 0.7478\n",
      "Epoch 39/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5610 - acc: 0.7484 - val_loss: 0.5606 - val_acc: 0.7498\n",
      "Epoch 40/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5594 - acc: 0.7497 - val_loss: 0.5585 - val_acc: 0.7496\n",
      "Epoch 41/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5570 - acc: 0.7507 - val_loss: 0.5574 - val_acc: 0.7504\n",
      "Epoch 42/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.5543 - acc: 0.7528 - val_loss: 0.5560 - val_acc: 0.7525\n",
      "Epoch 43/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5522 - acc: 0.7530 - val_loss: 0.5522 - val_acc: 0.7547\n",
      "Epoch 44/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5495 - acc: 0.7546 - val_loss: 0.5514 - val_acc: 0.7543\n",
      "Epoch 45/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5476 - acc: 0.7563 - val_loss: 0.5493 - val_acc: 0.7564\n",
      "Epoch 46/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5451 - acc: 0.7576 - val_loss: 0.5485 - val_acc: 0.7565\n",
      "Epoch 47/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5429 - acc: 0.7579 - val_loss: 0.5455 - val_acc: 0.7579\n",
      "Epoch 48/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.5406 - acc: 0.7595 - val_loss: 0.5457 - val_acc: 0.7580\n",
      "Epoch 49/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5383 - acc: 0.7611 - val_loss: 0.5440 - val_acc: 0.7582\n",
      "Epoch 50/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5368 - acc: 0.7618 - val_loss: 0.5408 - val_acc: 0.7616\n",
      "Epoch 51/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5346 - acc: 0.7630 - val_loss: 0.5388 - val_acc: 0.7626\n",
      "Epoch 52/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5329 - acc: 0.7637 - val_loss: 0.5374 - val_acc: 0.7630\n",
      "Epoch 53/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5299 - acc: 0.7653 - val_loss: 0.5359 - val_acc: 0.7632\n",
      "Epoch 54/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5284 - acc: 0.7661 - val_loss: 0.5338 - val_acc: 0.7649\n",
      "Epoch 55/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5262 - acc: 0.7674 - val_loss: 0.5316 - val_acc: 0.7669\n",
      "Epoch 56/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5236 - acc: 0.7687 - val_loss: 0.5300 - val_acc: 0.7663\n",
      "Epoch 57/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5220 - acc: 0.7698 - val_loss: 0.5295 - val_acc: 0.7668\n",
      "Epoch 58/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5197 - acc: 0.7708 - val_loss: 0.5266 - val_acc: 0.7699\n",
      "Epoch 59/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5176 - acc: 0.7718 - val_loss: 0.5282 - val_acc: 0.7671\n",
      "Epoch 60/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.5153 - acc: 0.7734 - val_loss: 0.5248 - val_acc: 0.7705\n",
      "Epoch 61/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5131 - acc: 0.7744 - val_loss: 0.5219 - val_acc: 0.7728\n",
      "Epoch 62/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.5112 - acc: 0.7757 - val_loss: 0.5211 - val_acc: 0.7724\n",
      "Epoch 63/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.5102 - acc: 0.7760 - val_loss: 0.5230 - val_acc: 0.7714\n",
      "Epoch 64/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5076 - acc: 0.7771 - val_loss: 0.5182 - val_acc: 0.7740\n",
      "Epoch 65/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.5057 - acc: 0.7782 - val_loss: 0.5178 - val_acc: 0.7744\n",
      "Epoch 66/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5036 - acc: 0.7797 - val_loss: 0.5152 - val_acc: 0.7756\n",
      "Epoch 67/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.5025 - acc: 0.7811 - val_loss: 0.5155 - val_acc: 0.7754\n",
      "Epoch 68/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4999 - acc: 0.7819 - val_loss: 0.5133 - val_acc: 0.7776\n",
      "Epoch 69/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4985 - acc: 0.7829 - val_loss: 0.5125 - val_acc: 0.7772\n",
      "Epoch 70/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4965 - acc: 0.7836 - val_loss: 0.5106 - val_acc: 0.7789\n",
      "Epoch 71/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4944 - acc: 0.7849 - val_loss: 0.5104 - val_acc: 0.7789\n",
      "Epoch 72/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4935 - acc: 0.7856 - val_loss: 0.5084 - val_acc: 0.7801\n",
      "Epoch 73/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4915 - acc: 0.7871 - val_loss: 0.5073 - val_acc: 0.7815\n",
      "Epoch 74/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4892 - acc: 0.7878 - val_loss: 0.5060 - val_acc: 0.7820\n",
      "Epoch 75/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4879 - acc: 0.7885 - val_loss: 0.5039 - val_acc: 0.7830\n",
      "Epoch 76/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4847 - acc: 0.7905 - val_loss: 0.5023 - val_acc: 0.7828\n",
      "Epoch 77/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4832 - acc: 0.7909 - val_loss: 0.5027 - val_acc: 0.7833\n",
      "Epoch 78/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4821 - acc: 0.7914 - val_loss: 0.4999 - val_acc: 0.7861\n",
      "Epoch 79/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4804 - acc: 0.7931 - val_loss: 0.4996 - val_acc: 0.7860\n",
      "Epoch 80/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4787 - acc: 0.7935 - val_loss: 0.4988 - val_acc: 0.7856\n",
      "Epoch 81/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4770 - acc: 0.7942 - val_loss: 0.4983 - val_acc: 0.7861\n",
      "Epoch 82/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4753 - acc: 0.7951 - val_loss: 0.4968 - val_acc: 0.7875\n",
      "Epoch 83/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4741 - acc: 0.7961 - val_loss: 0.4968 - val_acc: 0.7883\n",
      "Epoch 84/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4727 - acc: 0.7965 - val_loss: 0.4945 - val_acc: 0.7880\n",
      "Epoch 85/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4704 - acc: 0.7975 - val_loss: 0.4957 - val_acc: 0.7896\n",
      "Epoch 86/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4688 - acc: 0.7986 - val_loss: 0.4943 - val_acc: 0.7906\n",
      "Epoch 87/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4682 - acc: 0.7992 - val_loss: 0.4946 - val_acc: 0.7892\n",
      "Epoch 88/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4661 - acc: 0.8002 - val_loss: 0.4919 - val_acc: 0.7913\n",
      "Epoch 89/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4649 - acc: 0.8002 - val_loss: 0.4919 - val_acc: 0.7898\n",
      "Epoch 90/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4634 - acc: 0.8019 - val_loss: 0.4914 - val_acc: 0.7915\n",
      "Epoch 91/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4620 - acc: 0.8023 - val_loss: 0.4930 - val_acc: 0.7918\n",
      "Epoch 92/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4618 - acc: 0.8029 - val_loss: 0.4903 - val_acc: 0.7922\n",
      "Epoch 93/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4597 - acc: 0.8030 - val_loss: 0.4918 - val_acc: 0.7908\n",
      "Epoch 94/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4589 - acc: 0.8032 - val_loss: 0.4891 - val_acc: 0.7928\n",
      "Epoch 95/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4569 - acc: 0.8046 - val_loss: 0.4901 - val_acc: 0.7936\n",
      "Epoch 96/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4564 - acc: 0.8046 - val_loss: 0.4884 - val_acc: 0.7948\n",
      "Epoch 97/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4552 - acc: 0.8056 - val_loss: 0.4891 - val_acc: 0.7933\n",
      "Epoch 98/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4536 - acc: 0.8071 - val_loss: 0.4880 - val_acc: 0.7934\n",
      "Epoch 99/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4528 - acc: 0.8058 - val_loss: 0.4874 - val_acc: 0.7937\n",
      "Epoch 100/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4515 - acc: 0.8072 - val_loss: 0.4889 - val_acc: 0.7941\n",
      "Epoch 101/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4500 - acc: 0.8079 - val_loss: 0.4897 - val_acc: 0.7928\n",
      "Epoch 102/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4498 - acc: 0.8077 - val_loss: 0.4879 - val_acc: 0.7944\n",
      "Epoch 103/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4477 - acc: 0.8088 - val_loss: 0.4869 - val_acc: 0.7944\n",
      "Epoch 104/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4464 - acc: 0.8100 - val_loss: 0.4899 - val_acc: 0.7954\n",
      "Epoch 105/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4450 - acc: 0.8105 - val_loss: 0.4875 - val_acc: 0.7957\n",
      "Epoch 106/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4449 - acc: 0.8114 - val_loss: 0.4884 - val_acc: 0.7954\n",
      "Epoch 107/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4440 - acc: 0.8115 - val_loss: 0.4859 - val_acc: 0.7958\n",
      "Epoch 108/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4418 - acc: 0.8118 - val_loss: 0.4869 - val_acc: 0.7947\n",
      "Epoch 109/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4404 - acc: 0.8133 - val_loss: 0.4855 - val_acc: 0.7966\n",
      "Epoch 110/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4401 - acc: 0.8136 - val_loss: 0.4857 - val_acc: 0.7961\n",
      "Epoch 111/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4388 - acc: 0.8137 - val_loss: 0.4846 - val_acc: 0.7973\n",
      "Epoch 112/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4369 - acc: 0.8141 - val_loss: 0.4872 - val_acc: 0.7966\n",
      "Epoch 113/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4368 - acc: 0.8148 - val_loss: 0.4861 - val_acc: 0.7945\n",
      "Epoch 114/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4356 - acc: 0.8149 - val_loss: 0.4856 - val_acc: 0.7965\n",
      "Epoch 115/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4351 - acc: 0.8149 - val_loss: 0.4878 - val_acc: 0.7942\n",
      "Epoch 116/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4343 - acc: 0.8158 - val_loss: 0.4878 - val_acc: 0.7956\n",
      "Epoch 117/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4329 - acc: 0.8167 - val_loss: 0.4871 - val_acc: 0.7966\n",
      "Epoch 118/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4315 - acc: 0.8169 - val_loss: 0.4885 - val_acc: 0.7970\n",
      "Epoch 119/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4300 - acc: 0.8182 - val_loss: 0.4852 - val_acc: 0.7977\n",
      "Epoch 120/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4301 - acc: 0.8176 - val_loss: 0.4856 - val_acc: 0.7967\n",
      "Epoch 121/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4280 - acc: 0.8190 - val_loss: 0.4872 - val_acc: 0.7978\n",
      "Epoch 122/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4274 - acc: 0.8189 - val_loss: 0.4871 - val_acc: 0.7987\n",
      "Epoch 123/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4257 - acc: 0.8197 - val_loss: 0.4872 - val_acc: 0.7973\n",
      "Epoch 124/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4248 - acc: 0.8198 - val_loss: 0.4888 - val_acc: 0.7954\n",
      "Epoch 125/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4241 - acc: 0.8206 - val_loss: 0.4887 - val_acc: 0.7971\n",
      "Epoch 126/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4238 - acc: 0.8207 - val_loss: 0.4865 - val_acc: 0.7981\n",
      "Epoch 127/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4226 - acc: 0.8221 - val_loss: 0.4894 - val_acc: 0.7985\n",
      "Epoch 128/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4213 - acc: 0.8220 - val_loss: 0.4882 - val_acc: 0.7990\n",
      "Epoch 129/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4209 - acc: 0.8221 - val_loss: 0.4884 - val_acc: 0.7970\n",
      "Epoch 130/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4187 - acc: 0.8228 - val_loss: 0.4913 - val_acc: 0.7959\n",
      "Epoch 131/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4183 - acc: 0.8238 - val_loss: 0.4867 - val_acc: 0.7978\n",
      "Epoch 132/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4176 - acc: 0.8241 - val_loss: 0.4887 - val_acc: 0.7968\n",
      "Epoch 133/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4163 - acc: 0.8237 - val_loss: 0.4896 - val_acc: 0.7985\n",
      "Epoch 134/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4154 - acc: 0.8239 - val_loss: 0.4901 - val_acc: 0.7972\n",
      "Epoch 135/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4143 - acc: 0.8254 - val_loss: 0.4878 - val_acc: 0.7959\n",
      "Epoch 136/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4125 - acc: 0.8257 - val_loss: 0.4891 - val_acc: 0.7968\n",
      "Epoch 137/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4114 - acc: 0.8265 - val_loss: 0.4910 - val_acc: 0.7957\n",
      "Epoch 138/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4115 - acc: 0.8258 - val_loss: 0.4910 - val_acc: 0.7970\n",
      "Epoch 139/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4109 - acc: 0.8258 - val_loss: 0.4913 - val_acc: 0.7965\n",
      "Epoch 140/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4089 - acc: 0.8280 - val_loss: 0.4914 - val_acc: 0.7974\n",
      "Epoch 141/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4084 - acc: 0.8278 - val_loss: 0.4912 - val_acc: 0.7966\n",
      "Epoch 142/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4079 - acc: 0.8274 - val_loss: 0.4917 - val_acc: 0.7956\n",
      "Epoch 143/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4069 - acc: 0.8278 - val_loss: 0.4950 - val_acc: 0.7967\n",
      "Epoch 144/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4058 - acc: 0.8289 - val_loss: 0.4944 - val_acc: 0.7963\n",
      "Epoch 145/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4045 - acc: 0.8293 - val_loss: 0.4933 - val_acc: 0.7950\n",
      "Epoch 146/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.4030 - acc: 0.8305 - val_loss: 0.4952 - val_acc: 0.7971\n",
      "Epoch 147/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4024 - acc: 0.8307 - val_loss: 0.4951 - val_acc: 0.7965\n",
      "Epoch 148/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4026 - acc: 0.8306 - val_loss: 0.4945 - val_acc: 0.7970\n",
      "Epoch 149/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.4017 - acc: 0.8314 - val_loss: 0.4938 - val_acc: 0.7975\n",
      "Epoch 150/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3999 - acc: 0.8311 - val_loss: 0.4956 - val_acc: 0.7975\n",
      "Epoch 151/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3995 - acc: 0.8321 - val_loss: 0.4964 - val_acc: 0.7965\n",
      "Epoch 152/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3976 - acc: 0.8324 - val_loss: 0.4971 - val_acc: 0.7958\n",
      "Epoch 153/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3974 - acc: 0.8330 - val_loss: 0.4981 - val_acc: 0.7948\n",
      "Epoch 154/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3950 - acc: 0.8343 - val_loss: 0.5008 - val_acc: 0.7954\n",
      "Epoch 155/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.3952 - acc: 0.8337 - val_loss: 0.4974 - val_acc: 0.7944\n",
      "Epoch 156/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.3947 - acc: 0.8346 - val_loss: 0.4982 - val_acc: 0.7962\n",
      "Epoch 157/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3934 - acc: 0.8349 - val_loss: 0.4977 - val_acc: 0.7962\n",
      "Epoch 158/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3926 - acc: 0.8347 - val_loss: 0.4990 - val_acc: 0.7950\n",
      "Epoch 159/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3909 - acc: 0.8364 - val_loss: 0.5000 - val_acc: 0.7962\n",
      "Epoch 160/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.3906 - acc: 0.8354 - val_loss: 0.5021 - val_acc: 0.7959\n",
      "Epoch 161/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3902 - acc: 0.8363 - val_loss: 0.4997 - val_acc: 0.7952\n",
      "Epoch 162/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3888 - acc: 0.8374 - val_loss: 0.5018 - val_acc: 0.7946\n",
      "Epoch 163/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.3877 - acc: 0.8368 - val_loss: 0.5009 - val_acc: 0.7951\n",
      "Epoch 164/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3864 - acc: 0.8371 - val_loss: 0.5038 - val_acc: 0.7950\n",
      "Epoch 165/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3853 - acc: 0.8386 - val_loss: 0.5056 - val_acc: 0.7967\n",
      "Epoch 166/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3851 - acc: 0.8378 - val_loss: 0.5034 - val_acc: 0.7957\n",
      "Epoch 167/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3831 - acc: 0.8392 - val_loss: 0.5042 - val_acc: 0.7958\n",
      "Epoch 168/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3828 - acc: 0.8394 - val_loss: 0.5041 - val_acc: 0.7975\n",
      "Epoch 169/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3811 - acc: 0.8411 - val_loss: 0.5077 - val_acc: 0.7957\n",
      "Epoch 170/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3810 - acc: 0.8395 - val_loss: 0.5068 - val_acc: 0.7964\n",
      "Epoch 171/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3798 - acc: 0.8412 - val_loss: 0.5067 - val_acc: 0.7953\n",
      "Epoch 172/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3795 - acc: 0.8412 - val_loss: 0.5077 - val_acc: 0.7935\n",
      "Epoch 173/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3787 - acc: 0.8415 - val_loss: 0.5079 - val_acc: 0.7956\n",
      "Epoch 174/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3779 - acc: 0.8421 - val_loss: 0.5079 - val_acc: 0.7947\n",
      "Epoch 175/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3771 - acc: 0.8418 - val_loss: 0.5120 - val_acc: 0.7946\n",
      "Epoch 176/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3750 - acc: 0.8431 - val_loss: 0.5086 - val_acc: 0.7943\n",
      "Epoch 177/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3752 - acc: 0.8427 - val_loss: 0.5098 - val_acc: 0.7954\n",
      "Epoch 178/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3743 - acc: 0.8437 - val_loss: 0.5112 - val_acc: 0.7946\n",
      "Epoch 179/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3718 - acc: 0.8451 - val_loss: 0.5122 - val_acc: 0.7941\n",
      "Epoch 180/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3722 - acc: 0.8443 - val_loss: 0.5173 - val_acc: 0.7944\n",
      "Epoch 181/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.3711 - acc: 0.8449 - val_loss: 0.5160 - val_acc: 0.7941\n",
      "Epoch 182/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3704 - acc: 0.8451 - val_loss: 0.5130 - val_acc: 0.7931\n",
      "Epoch 183/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3699 - acc: 0.8463 - val_loss: 0.5145 - val_acc: 0.7955\n",
      "Epoch 184/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3684 - acc: 0.8464 - val_loss: 0.5152 - val_acc: 0.7953\n",
      "Epoch 185/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3668 - acc: 0.8471 - val_loss: 0.5160 - val_acc: 0.7941\n",
      "Epoch 186/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3668 - acc: 0.8467 - val_loss: 0.5167 - val_acc: 0.7940\n",
      "Epoch 187/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3661 - acc: 0.8470 - val_loss: 0.5163 - val_acc: 0.7927\n",
      "Epoch 188/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3652 - acc: 0.8476 - val_loss: 0.5177 - val_acc: 0.7934\n",
      "Epoch 189/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.3640 - acc: 0.8476 - val_loss: 0.5213 - val_acc: 0.7922\n",
      "Epoch 190/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3638 - acc: 0.8481 - val_loss: 0.5186 - val_acc: 0.7937\n",
      "Epoch 191/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3610 - acc: 0.8491 - val_loss: 0.5216 - val_acc: 0.7925\n",
      "Epoch 192/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3619 - acc: 0.8496 - val_loss: 0.5199 - val_acc: 0.7932\n",
      "Epoch 193/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3607 - acc: 0.8494 - val_loss: 0.5218 - val_acc: 0.7947\n",
      "Epoch 194/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3602 - acc: 0.8491 - val_loss: 0.5249 - val_acc: 0.7939\n",
      "Epoch 195/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3583 - acc: 0.8508 - val_loss: 0.5245 - val_acc: 0.7930\n",
      "Epoch 196/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3568 - acc: 0.8516 - val_loss: 0.5260 - val_acc: 0.7938\n",
      "Epoch 197/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3574 - acc: 0.8509 - val_loss: 0.5267 - val_acc: 0.7922\n",
      "Epoch 198/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.3561 - acc: 0.8513 - val_loss: 0.5246 - val_acc: 0.7930\n",
      "Epoch 199/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3540 - acc: 0.8530 - val_loss: 0.5264 - val_acc: 0.7926\n",
      "Epoch 200/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3535 - acc: 0.8531 - val_loss: 0.5293 - val_acc: 0.7921\n",
      "Epoch 201/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3527 - acc: 0.8537 - val_loss: 0.5334 - val_acc: 0.7912\n",
      "Epoch 202/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.3516 - acc: 0.8544 - val_loss: 0.5308 - val_acc: 0.7937\n",
      "Epoch 203/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3507 - acc: 0.8541 - val_loss: 0.5339 - val_acc: 0.7929\n",
      "Epoch 204/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3502 - acc: 0.8543 - val_loss: 0.5306 - val_acc: 0.7920\n",
      "Epoch 205/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3487 - acc: 0.8550 - val_loss: 0.5327 - val_acc: 0.7919\n",
      "Epoch 206/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3486 - acc: 0.8551 - val_loss: 0.5342 - val_acc: 0.7920\n",
      "Epoch 207/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3475 - acc: 0.8556 - val_loss: 0.5364 - val_acc: 0.7922\n",
      "Epoch 208/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3481 - acc: 0.8558 - val_loss: 0.5361 - val_acc: 0.7916\n",
      "Epoch 209/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3481 - acc: 0.8552 - val_loss: 0.5374 - val_acc: 0.7921\n",
      "Epoch 210/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3456 - acc: 0.8562 - val_loss: 0.5384 - val_acc: 0.7923\n",
      "Epoch 211/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3442 - acc: 0.8569 - val_loss: 0.5390 - val_acc: 0.7922\n",
      "Epoch 212/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3452 - acc: 0.8566 - val_loss: 0.5402 - val_acc: 0.7923\n",
      "Epoch 213/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.3434 - acc: 0.8581 - val_loss: 0.5423 - val_acc: 0.7924\n",
      "Epoch 214/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3419 - acc: 0.8581 - val_loss: 0.5406 - val_acc: 0.7916\n",
      "Epoch 215/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3412 - acc: 0.8581 - val_loss: 0.5431 - val_acc: 0.7904\n",
      "Epoch 216/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3414 - acc: 0.8591 - val_loss: 0.5419 - val_acc: 0.7905\n",
      "Epoch 217/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3403 - acc: 0.8591 - val_loss: 0.5417 - val_acc: 0.7925\n",
      "Epoch 218/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3381 - acc: 0.8601 - val_loss: 0.5463 - val_acc: 0.7910\n",
      "Epoch 219/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3368 - acc: 0.8606 - val_loss: 0.5471 - val_acc: 0.7912\n",
      "Epoch 220/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3361 - acc: 0.8606 - val_loss: 0.5474 - val_acc: 0.7914\n",
      "Epoch 221/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3359 - acc: 0.8605 - val_loss: 0.5504 - val_acc: 0.7924\n",
      "Epoch 222/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3373 - acc: 0.8604 - val_loss: 0.5468 - val_acc: 0.7923\n",
      "Epoch 223/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3352 - acc: 0.8611 - val_loss: 0.5507 - val_acc: 0.7901\n",
      "Epoch 224/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3333 - acc: 0.8617 - val_loss: 0.5538 - val_acc: 0.7926\n",
      "Epoch 225/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3328 - acc: 0.8619 - val_loss: 0.5552 - val_acc: 0.7921\n",
      "Epoch 226/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3318 - acc: 0.8629 - val_loss: 0.5562 - val_acc: 0.7910\n",
      "Epoch 227/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3311 - acc: 0.8630 - val_loss: 0.5581 - val_acc: 0.7910\n",
      "Epoch 228/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.3312 - acc: 0.8631 - val_loss: 0.5577 - val_acc: 0.7906\n",
      "Epoch 229/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3312 - acc: 0.8638 - val_loss: 0.5563 - val_acc: 0.7921\n",
      "Epoch 230/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3289 - acc: 0.8650 - val_loss: 0.5571 - val_acc: 0.7912\n",
      "Epoch 231/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3279 - acc: 0.8649 - val_loss: 0.5570 - val_acc: 0.7901\n",
      "Epoch 232/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3271 - acc: 0.8646 - val_loss: 0.5595 - val_acc: 0.7907\n",
      "Epoch 233/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3270 - acc: 0.8657 - val_loss: 0.5631 - val_acc: 0.7908\n",
      "Epoch 234/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3265 - acc: 0.8647 - val_loss: 0.5648 - val_acc: 0.7913\n",
      "Epoch 235/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3239 - acc: 0.8667 - val_loss: 0.5583 - val_acc: 0.7911\n",
      "Epoch 236/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3243 - acc: 0.8658 - val_loss: 0.5633 - val_acc: 0.7903\n",
      "Epoch 237/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3234 - acc: 0.8663 - val_loss: 0.5607 - val_acc: 0.7884\n",
      "Epoch 238/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3230 - acc: 0.8666 - val_loss: 0.5632 - val_acc: 0.7905\n",
      "Epoch 239/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3230 - acc: 0.8659 - val_loss: 0.5653 - val_acc: 0.7902\n",
      "Epoch 240/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3217 - acc: 0.8668 - val_loss: 0.5645 - val_acc: 0.7885\n",
      "Epoch 241/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3207 - acc: 0.8680 - val_loss: 0.5654 - val_acc: 0.7909\n",
      "Epoch 242/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3204 - acc: 0.8681 - val_loss: 0.5692 - val_acc: 0.7898\n",
      "Epoch 243/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3201 - acc: 0.8677 - val_loss: 0.5665 - val_acc: 0.7900\n",
      "Epoch 244/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3185 - acc: 0.8687 - val_loss: 0.5693 - val_acc: 0.7888\n",
      "Epoch 245/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3179 - acc: 0.8690 - val_loss: 0.5666 - val_acc: 0.7894\n",
      "Epoch 246/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3173 - acc: 0.8691 - val_loss: 0.5687 - val_acc: 0.7898\n",
      "Epoch 247/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3160 - acc: 0.8702 - val_loss: 0.5717 - val_acc: 0.7895\n",
      "Epoch 248/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3156 - acc: 0.8694 - val_loss: 0.5717 - val_acc: 0.7896\n",
      "Epoch 249/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3143 - acc: 0.8711 - val_loss: 0.5797 - val_acc: 0.7902\n",
      "Epoch 250/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3133 - acc: 0.8711 - val_loss: 0.5765 - val_acc: 0.7901\n",
      "Epoch 251/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3140 - acc: 0.8699 - val_loss: 0.5762 - val_acc: 0.7909\n",
      "Epoch 252/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3139 - acc: 0.8710 - val_loss: 0.5788 - val_acc: 0.7894\n",
      "Epoch 253/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3110 - acc: 0.8720 - val_loss: 0.5788 - val_acc: 0.7893\n",
      "Epoch 254/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3103 - acc: 0.8721 - val_loss: 0.5802 - val_acc: 0.7902\n",
      "Epoch 255/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3099 - acc: 0.8726 - val_loss: 0.5838 - val_acc: 0.7894\n",
      "Epoch 256/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3093 - acc: 0.8728 - val_loss: 0.5869 - val_acc: 0.7890\n",
      "Epoch 257/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3082 - acc: 0.8735 - val_loss: 0.5863 - val_acc: 0.7886\n",
      "Epoch 258/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3082 - acc: 0.8719 - val_loss: 0.5897 - val_acc: 0.7886\n",
      "Epoch 259/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3066 - acc: 0.8735 - val_loss: 0.5881 - val_acc: 0.7890\n",
      "Epoch 260/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3077 - acc: 0.8733 - val_loss: 0.5881 - val_acc: 0.7900\n",
      "Epoch 261/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3079 - acc: 0.8734 - val_loss: 0.5911 - val_acc: 0.7882\n",
      "Epoch 262/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3065 - acc: 0.8739 - val_loss: 0.5903 - val_acc: 0.7890\n",
      "Epoch 263/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3052 - acc: 0.8748 - val_loss: 0.5917 - val_acc: 0.7894\n",
      "Epoch 264/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3038 - acc: 0.8749 - val_loss: 0.5932 - val_acc: 0.7878\n",
      "Epoch 265/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3033 - acc: 0.8757 - val_loss: 0.5938 - val_acc: 0.7901\n",
      "Epoch 266/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3047 - acc: 0.8745 - val_loss: 0.5958 - val_acc: 0.7888\n",
      "Epoch 267/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3024 - acc: 0.8756 - val_loss: 0.5987 - val_acc: 0.7873\n",
      "Epoch 268/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3005 - acc: 0.8766 - val_loss: 0.5981 - val_acc: 0.7905\n",
      "Epoch 269/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3007 - acc: 0.8767 - val_loss: 0.5940 - val_acc: 0.7890\n",
      "Epoch 270/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3000 - acc: 0.8774 - val_loss: 0.6009 - val_acc: 0.7905\n",
      "Epoch 271/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.3005 - acc: 0.8774 - val_loss: 0.6009 - val_acc: 0.7883\n",
      "Epoch 272/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2983 - acc: 0.8772 - val_loss: 0.6000 - val_acc: 0.7881\n",
      "Epoch 273/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2976 - acc: 0.8775 - val_loss: 0.6031 - val_acc: 0.7867\n",
      "Epoch 274/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2969 - acc: 0.8788 - val_loss: 0.6059 - val_acc: 0.7890\n",
      "Epoch 275/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2973 - acc: 0.8781 - val_loss: 0.6026 - val_acc: 0.7878\n",
      "Epoch 276/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2955 - acc: 0.8785 - val_loss: 0.5997 - val_acc: 0.7882\n",
      "Epoch 277/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2949 - acc: 0.8793 - val_loss: 0.6029 - val_acc: 0.7882\n",
      "Epoch 278/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2939 - acc: 0.8793 - val_loss: 0.6081 - val_acc: 0.7877\n",
      "Epoch 279/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2939 - acc: 0.8796 - val_loss: 0.6059 - val_acc: 0.7870\n",
      "Epoch 280/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2930 - acc: 0.8796 - val_loss: 0.6150 - val_acc: 0.7881\n",
      "Epoch 281/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2942 - acc: 0.8786 - val_loss: 0.6142 - val_acc: 0.7879\n",
      "Epoch 282/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2925 - acc: 0.8797 - val_loss: 0.6087 - val_acc: 0.7870\n",
      "Epoch 283/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2916 - acc: 0.8802 - val_loss: 0.6130 - val_acc: 0.7871\n",
      "Epoch 284/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2919 - acc: 0.8802 - val_loss: 0.6064 - val_acc: 0.7874\n",
      "Epoch 285/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2905 - acc: 0.8812 - val_loss: 0.6128 - val_acc: 0.7883\n",
      "Epoch 286/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2891 - acc: 0.8815 - val_loss: 0.6134 - val_acc: 0.7878\n",
      "Epoch 287/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2904 - acc: 0.8814 - val_loss: 0.6169 - val_acc: 0.7856\n",
      "Epoch 288/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2880 - acc: 0.8829 - val_loss: 0.6174 - val_acc: 0.7870\n",
      "Epoch 289/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2887 - acc: 0.8818 - val_loss: 0.6112 - val_acc: 0.7869\n",
      "Epoch 290/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2873 - acc: 0.8819 - val_loss: 0.6166 - val_acc: 0.7873\n",
      "Epoch 291/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2873 - acc: 0.8819 - val_loss: 0.6182 - val_acc: 0.7862\n",
      "Epoch 292/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2850 - acc: 0.8831 - val_loss: 0.6232 - val_acc: 0.7856\n",
      "Epoch 293/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2856 - acc: 0.8829 - val_loss: 0.6209 - val_acc: 0.7866\n",
      "Epoch 294/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2835 - acc: 0.8836 - val_loss: 0.6225 - val_acc: 0.7866\n",
      "Epoch 295/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2840 - acc: 0.8833 - val_loss: 0.6220 - val_acc: 0.7867\n",
      "Epoch 296/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2840 - acc: 0.8836 - val_loss: 0.6210 - val_acc: 0.7866\n",
      "Epoch 297/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2821 - acc: 0.8837 - val_loss: 0.6224 - val_acc: 0.7866\n",
      "Epoch 298/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2828 - acc: 0.8836 - val_loss: 0.6241 - val_acc: 0.7873\n",
      "Epoch 299/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2817 - acc: 0.8843 - val_loss: 0.6305 - val_acc: 0.7856\n",
      "Epoch 300/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2813 - acc: 0.8850 - val_loss: 0.6265 - val_acc: 0.7868\n",
      "Epoch 301/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2803 - acc: 0.8856 - val_loss: 0.6339 - val_acc: 0.7873\n",
      "Epoch 302/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2790 - acc: 0.8864 - val_loss: 0.6304 - val_acc: 0.7868\n",
      "Epoch 303/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2785 - acc: 0.8860 - val_loss: 0.6342 - val_acc: 0.7877\n",
      "Epoch 304/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2779 - acc: 0.8865 - val_loss: 0.6301 - val_acc: 0.7872\n",
      "Epoch 305/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2794 - acc: 0.8855 - val_loss: 0.6340 - val_acc: 0.7883\n",
      "Epoch 306/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2774 - acc: 0.8862 - val_loss: 0.6372 - val_acc: 0.7871\n",
      "Epoch 307/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2768 - acc: 0.8864 - val_loss: 0.6365 - val_acc: 0.7870\n",
      "Epoch 308/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2757 - acc: 0.8868 - val_loss: 0.6373 - val_acc: 0.7877\n",
      "Epoch 309/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2753 - acc: 0.8877 - val_loss: 0.6370 - val_acc: 0.7872\n",
      "Epoch 310/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2769 - acc: 0.8868 - val_loss: 0.6358 - val_acc: 0.7869\n",
      "Epoch 311/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2736 - acc: 0.8878 - val_loss: 0.6372 - val_acc: 0.7864\n",
      "Epoch 312/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2737 - acc: 0.8875 - val_loss: 0.6370 - val_acc: 0.7871\n",
      "Epoch 313/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2740 - acc: 0.8880 - val_loss: 0.6374 - val_acc: 0.7864\n",
      "Epoch 314/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2730 - acc: 0.8875 - val_loss: 0.6411 - val_acc: 0.7858\n",
      "Epoch 315/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2717 - acc: 0.8897 - val_loss: 0.6455 - val_acc: 0.7867\n",
      "Epoch 316/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2714 - acc: 0.8890 - val_loss: 0.6403 - val_acc: 0.7850\n",
      "Epoch 317/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2707 - acc: 0.8898 - val_loss: 0.6464 - val_acc: 0.7857\n",
      "Epoch 318/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2710 - acc: 0.8895 - val_loss: 0.6437 - val_acc: 0.7846\n",
      "Epoch 319/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2701 - acc: 0.8902 - val_loss: 0.6477 - val_acc: 0.7861\n",
      "Epoch 320/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2695 - acc: 0.8895 - val_loss: 0.6467 - val_acc: 0.7859\n",
      "Epoch 321/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2709 - acc: 0.8884 - val_loss: 0.6511 - val_acc: 0.7852\n",
      "Epoch 322/800\n",
      "230116/230116 [==============================] - 12s 52us/step - loss: 0.2678 - acc: 0.8907 - val_loss: 0.6473 - val_acc: 0.7861\n",
      "Epoch 323/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2683 - acc: 0.8897 - val_loss: 0.6494 - val_acc: 0.7853\n",
      "Epoch 324/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2684 - acc: 0.8907 - val_loss: 0.6468 - val_acc: 0.7848\n",
      "Epoch 325/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2671 - acc: 0.8909 - val_loss: 0.6512 - val_acc: 0.7853\n",
      "Epoch 326/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2658 - acc: 0.8913 - val_loss: 0.6517 - val_acc: 0.7863\n",
      "Epoch 327/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2670 - acc: 0.8903 - val_loss: 0.6520 - val_acc: 0.7846\n",
      "Epoch 328/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2654 - acc: 0.8915 - val_loss: 0.6522 - val_acc: 0.7848\n",
      "Epoch 329/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2656 - acc: 0.8919 - val_loss: 0.6540 - val_acc: 0.7856\n",
      "Epoch 330/800\n",
      "230116/230116 [==============================] - 12s 52us/step - loss: 0.2651 - acc: 0.8916 - val_loss: 0.6557 - val_acc: 0.7845\n",
      "Epoch 331/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2637 - acc: 0.8925 - val_loss: 0.6549 - val_acc: 0.7846\n",
      "Epoch 332/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2634 - acc: 0.8918 - val_loss: 0.6593 - val_acc: 0.7851\n",
      "Epoch 333/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2617 - acc: 0.8929 - val_loss: 0.6594 - val_acc: 0.7846\n",
      "Epoch 334/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2609 - acc: 0.8933 - val_loss: 0.6632 - val_acc: 0.7842\n",
      "Epoch 335/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2595 - acc: 0.8941 - val_loss: 0.6623 - val_acc: 0.7835\n",
      "Epoch 336/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2621 - acc: 0.8929 - val_loss: 0.6622 - val_acc: 0.7827\n",
      "Epoch 337/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2598 - acc: 0.8937 - val_loss: 0.6697 - val_acc: 0.7849\n",
      "Epoch 338/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2605 - acc: 0.8936 - val_loss: 0.6642 - val_acc: 0.7848\n",
      "Epoch 339/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2601 - acc: 0.8935 - val_loss: 0.6668 - val_acc: 0.7849\n",
      "Epoch 340/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2574 - acc: 0.8953 - val_loss: 0.6658 - val_acc: 0.7848\n",
      "Epoch 341/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2592 - acc: 0.8939 - val_loss: 0.6709 - val_acc: 0.7850\n",
      "Epoch 342/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2580 - acc: 0.8946 - val_loss: 0.6624 - val_acc: 0.7853\n",
      "Epoch 343/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2580 - acc: 0.8947 - val_loss: 0.6708 - val_acc: 0.7854\n",
      "Epoch 344/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2589 - acc: 0.8945 - val_loss: 0.6667 - val_acc: 0.7860\n",
      "Epoch 345/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2567 - acc: 0.8957 - val_loss: 0.6716 - val_acc: 0.7836\n",
      "Epoch 346/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2573 - acc: 0.8950 - val_loss: 0.6729 - val_acc: 0.7838\n",
      "Epoch 347/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2569 - acc: 0.8959 - val_loss: 0.6761 - val_acc: 0.7846\n",
      "Epoch 348/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2557 - acc: 0.8958 - val_loss: 0.6746 - val_acc: 0.7831\n",
      "Epoch 349/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2546 - acc: 0.8969 - val_loss: 0.6679 - val_acc: 0.7843\n",
      "Epoch 350/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2550 - acc: 0.8963 - val_loss: 0.6690 - val_acc: 0.7839\n",
      "Epoch 351/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2561 - acc: 0.8952 - val_loss: 0.6733 - val_acc: 0.7853\n",
      "Epoch 352/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2529 - acc: 0.8976 - val_loss: 0.6801 - val_acc: 0.7840\n",
      "Epoch 353/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2530 - acc: 0.8969 - val_loss: 0.6777 - val_acc: 0.7831\n",
      "Epoch 354/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2518 - acc: 0.8972 - val_loss: 0.6821 - val_acc: 0.7827\n",
      "Epoch 355/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2528 - acc: 0.8969 - val_loss: 0.6848 - val_acc: 0.7844\n",
      "Epoch 356/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2524 - acc: 0.8971 - val_loss: 0.6825 - val_acc: 0.7834\n",
      "Epoch 357/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2509 - acc: 0.8978 - val_loss: 0.6865 - val_acc: 0.7821\n",
      "Epoch 358/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2506 - acc: 0.8979 - val_loss: 0.6822 - val_acc: 0.7829\n",
      "Epoch 359/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2492 - acc: 0.8981 - val_loss: 0.6822 - val_acc: 0.7834\n",
      "Epoch 360/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2486 - acc: 0.8988 - val_loss: 0.6876 - val_acc: 0.7851\n",
      "Epoch 361/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2491 - acc: 0.8981 - val_loss: 0.6831 - val_acc: 0.7842\n",
      "Epoch 362/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2481 - acc: 0.8988 - val_loss: 0.6929 - val_acc: 0.7840\n",
      "Epoch 363/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2492 - acc: 0.8988 - val_loss: 0.6904 - val_acc: 0.7840\n",
      "Epoch 364/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2476 - acc: 0.8993 - val_loss: 0.6878 - val_acc: 0.7840\n",
      "Epoch 365/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2489 - acc: 0.8986 - val_loss: 0.6877 - val_acc: 0.7827\n",
      "Epoch 366/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2466 - acc: 0.8996 - val_loss: 0.6996 - val_acc: 0.7847\n",
      "Epoch 367/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2470 - acc: 0.8996 - val_loss: 0.6964 - val_acc: 0.7839\n",
      "Epoch 368/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2479 - acc: 0.8995 - val_loss: 0.6899 - val_acc: 0.7845\n",
      "Epoch 369/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2448 - acc: 0.9005 - val_loss: 0.6961 - val_acc: 0.7821\n",
      "Epoch 370/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2451 - acc: 0.9005 - val_loss: 0.6992 - val_acc: 0.7835\n",
      "Epoch 371/800\n",
      "230116/230116 [==============================] - 12s 52us/step - loss: 0.2441 - acc: 0.9008 - val_loss: 0.6979 - val_acc: 0.7839\n",
      "Epoch 372/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2444 - acc: 0.9005 - val_loss: 0.6919 - val_acc: 0.7838\n",
      "Epoch 373/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2432 - acc: 0.9008 - val_loss: 0.7001 - val_acc: 0.7840\n",
      "Epoch 374/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2428 - acc: 0.9010 - val_loss: 0.6998 - val_acc: 0.7828\n",
      "Epoch 375/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2432 - acc: 0.9009 - val_loss: 0.7043 - val_acc: 0.7841\n",
      "Epoch 376/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2428 - acc: 0.9009 - val_loss: 0.6997 - val_acc: 0.7836\n",
      "Epoch 377/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2413 - acc: 0.9019 - val_loss: 0.7025 - val_acc: 0.7821\n",
      "Epoch 378/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2433 - acc: 0.9011 - val_loss: 0.7066 - val_acc: 0.7814\n",
      "Epoch 379/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2420 - acc: 0.9021 - val_loss: 0.6959 - val_acc: 0.7814\n",
      "Epoch 380/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2407 - acc: 0.9020 - val_loss: 0.7044 - val_acc: 0.7824\n",
      "Epoch 381/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2392 - acc: 0.9025 - val_loss: 0.7009 - val_acc: 0.7823\n",
      "Epoch 382/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2417 - acc: 0.9018 - val_loss: 0.7009 - val_acc: 0.7816\n",
      "Epoch 383/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2407 - acc: 0.9021 - val_loss: 0.6995 - val_acc: 0.7824\n",
      "Epoch 384/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2384 - acc: 0.9036 - val_loss: 0.7097 - val_acc: 0.7824\n",
      "Epoch 385/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2386 - acc: 0.9026 - val_loss: 0.7040 - val_acc: 0.7820\n",
      "Epoch 386/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2388 - acc: 0.9033 - val_loss: 0.7106 - val_acc: 0.7823\n",
      "Epoch 387/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2362 - acc: 0.9048 - val_loss: 0.7088 - val_acc: 0.7826\n",
      "Epoch 388/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2374 - acc: 0.9035 - val_loss: 0.7074 - val_acc: 0.7823\n",
      "Epoch 389/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2382 - acc: 0.9034 - val_loss: 0.7112 - val_acc: 0.7822\n",
      "Epoch 390/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2379 - acc: 0.9037 - val_loss: 0.7034 - val_acc: 0.7829\n",
      "Epoch 391/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2363 - acc: 0.9045 - val_loss: 0.7082 - val_acc: 0.7839\n",
      "Epoch 392/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2367 - acc: 0.9038 - val_loss: 0.7081 - val_acc: 0.7825\n",
      "Epoch 393/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2343 - acc: 0.9047 - val_loss: 0.7125 - val_acc: 0.7820\n",
      "Epoch 394/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2360 - acc: 0.9048 - val_loss: 0.7153 - val_acc: 0.7818\n",
      "Epoch 395/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2343 - acc: 0.9047 - val_loss: 0.7180 - val_acc: 0.7838\n",
      "Epoch 396/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2335 - acc: 0.9051 - val_loss: 0.7160 - val_acc: 0.7814\n",
      "Epoch 397/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2336 - acc: 0.9054 - val_loss: 0.7220 - val_acc: 0.7834\n",
      "Epoch 398/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2339 - acc: 0.9051 - val_loss: 0.7179 - val_acc: 0.7820\n",
      "Epoch 399/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2341 - acc: 0.9051 - val_loss: 0.7162 - val_acc: 0.7835\n",
      "Epoch 400/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2331 - acc: 0.9056 - val_loss: 0.7162 - val_acc: 0.7819\n",
      "Epoch 401/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2326 - acc: 0.9055 - val_loss: 0.7225 - val_acc: 0.7823\n",
      "Epoch 402/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2322 - acc: 0.9058 - val_loss: 0.7195 - val_acc: 0.7806\n",
      "Epoch 403/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2315 - acc: 0.9067 - val_loss: 0.7218 - val_acc: 0.7812\n",
      "Epoch 404/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2309 - acc: 0.9061 - val_loss: 0.7243 - val_acc: 0.7788\n",
      "Epoch 405/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2303 - acc: 0.9065 - val_loss: 0.7275 - val_acc: 0.7833\n",
      "Epoch 406/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2308 - acc: 0.9071 - val_loss: 0.7280 - val_acc: 0.7822\n",
      "Epoch 407/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2307 - acc: 0.9063 - val_loss: 0.7221 - val_acc: 0.7821\n",
      "Epoch 408/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2287 - acc: 0.9077 - val_loss: 0.7304 - val_acc: 0.7807\n",
      "Epoch 409/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2299 - acc: 0.9072 - val_loss: 0.7262 - val_acc: 0.7806\n",
      "Epoch 410/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2309 - acc: 0.9065 - val_loss: 0.7281 - val_acc: 0.7791\n",
      "Epoch 411/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2284 - acc: 0.9075 - val_loss: 0.7340 - val_acc: 0.7829\n",
      "Epoch 412/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2278 - acc: 0.9079 - val_loss: 0.7278 - val_acc: 0.7811\n",
      "Epoch 413/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2273 - acc: 0.9085 - val_loss: 0.7313 - val_acc: 0.7803\n",
      "Epoch 414/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2288 - acc: 0.9074 - val_loss: 0.7295 - val_acc: 0.7804\n",
      "Epoch 415/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2257 - acc: 0.9080 - val_loss: 0.7403 - val_acc: 0.7813\n",
      "Epoch 416/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2279 - acc: 0.9074 - val_loss: 0.7437 - val_acc: 0.7821\n",
      "Epoch 417/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2279 - acc: 0.9080 - val_loss: 0.7352 - val_acc: 0.7811\n",
      "Epoch 418/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2262 - acc: 0.9081 - val_loss: 0.7357 - val_acc: 0.7806\n",
      "Epoch 419/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2268 - acc: 0.9083 - val_loss: 0.7345 - val_acc: 0.7816\n",
      "Epoch 420/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2247 - acc: 0.9083 - val_loss: 0.7340 - val_acc: 0.7810\n",
      "Epoch 421/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2237 - acc: 0.9100 - val_loss: 0.7397 - val_acc: 0.7804\n",
      "Epoch 422/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2250 - acc: 0.9092 - val_loss: 0.7344 - val_acc: 0.7805\n",
      "Epoch 423/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2242 - acc: 0.9093 - val_loss: 0.7337 - val_acc: 0.7804\n",
      "Epoch 424/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2245 - acc: 0.9090 - val_loss: 0.7395 - val_acc: 0.7810\n",
      "Epoch 425/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2245 - acc: 0.9089 - val_loss: 0.7425 - val_acc: 0.7814\n",
      "Epoch 426/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2244 - acc: 0.9088 - val_loss: 0.7401 - val_acc: 0.7808\n",
      "Epoch 427/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2235 - acc: 0.9097 - val_loss: 0.7359 - val_acc: 0.7802\n",
      "Epoch 428/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2213 - acc: 0.9109 - val_loss: 0.7377 - val_acc: 0.7827\n",
      "Epoch 429/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2225 - acc: 0.9101 - val_loss: 0.7459 - val_acc: 0.7800\n",
      "Epoch 430/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2222 - acc: 0.9101 - val_loss: 0.7406 - val_acc: 0.7814\n",
      "Epoch 431/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2227 - acc: 0.9100 - val_loss: 0.7433 - val_acc: 0.7790\n",
      "Epoch 432/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2209 - acc: 0.9112 - val_loss: 0.7439 - val_acc: 0.7805\n",
      "Epoch 433/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2210 - acc: 0.9108 - val_loss: 0.7491 - val_acc: 0.7807\n",
      "Epoch 434/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2198 - acc: 0.9108 - val_loss: 0.7471 - val_acc: 0.7798\n",
      "Epoch 435/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2212 - acc: 0.9108 - val_loss: 0.7442 - val_acc: 0.7815\n",
      "Epoch 436/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2216 - acc: 0.9104 - val_loss: 0.7396 - val_acc: 0.7820\n",
      "Epoch 437/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2203 - acc: 0.9103 - val_loss: 0.7433 - val_acc: 0.7806\n",
      "Epoch 438/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2191 - acc: 0.9118 - val_loss: 0.7482 - val_acc: 0.7812\n",
      "Epoch 439/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2202 - acc: 0.9108 - val_loss: 0.7429 - val_acc: 0.7818\n",
      "Epoch 440/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2180 - acc: 0.9114 - val_loss: 0.7477 - val_acc: 0.7818\n",
      "Epoch 441/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2183 - acc: 0.9115 - val_loss: 0.7516 - val_acc: 0.7804\n",
      "Epoch 442/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2175 - acc: 0.9121 - val_loss: 0.7565 - val_acc: 0.7812\n",
      "Epoch 443/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2176 - acc: 0.9119 - val_loss: 0.7500 - val_acc: 0.7801\n",
      "Epoch 444/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2176 - acc: 0.9116 - val_loss: 0.7487 - val_acc: 0.7791\n",
      "Epoch 445/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2165 - acc: 0.9125 - val_loss: 0.7461 - val_acc: 0.7798\n",
      "Epoch 446/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2163 - acc: 0.9125 - val_loss: 0.7508 - val_acc: 0.7809\n",
      "Epoch 447/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2160 - acc: 0.9129 - val_loss: 0.7574 - val_acc: 0.7802\n",
      "Epoch 448/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2166 - acc: 0.9118 - val_loss: 0.7597 - val_acc: 0.7814\n",
      "Epoch 449/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2167 - acc: 0.9121 - val_loss: 0.7540 - val_acc: 0.7799\n",
      "Epoch 450/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2157 - acc: 0.9128 - val_loss: 0.7597 - val_acc: 0.7806\n",
      "Epoch 451/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2160 - acc: 0.9126 - val_loss: 0.7539 - val_acc: 0.7820\n",
      "Epoch 452/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2150 - acc: 0.9135 - val_loss: 0.7526 - val_acc: 0.7806\n",
      "Epoch 453/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2140 - acc: 0.9133 - val_loss: 0.7532 - val_acc: 0.7797\n",
      "Epoch 454/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2160 - acc: 0.9135 - val_loss: 0.7603 - val_acc: 0.7809\n",
      "Epoch 455/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2122 - acc: 0.9140 - val_loss: 0.7654 - val_acc: 0.7811\n",
      "Epoch 456/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2140 - acc: 0.9139 - val_loss: 0.7631 - val_acc: 0.7793\n",
      "Epoch 457/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2128 - acc: 0.9144 - val_loss: 0.7651 - val_acc: 0.7803\n",
      "Epoch 458/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2138 - acc: 0.9138 - val_loss: 0.7635 - val_acc: 0.7793\n",
      "Epoch 459/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2140 - acc: 0.9129 - val_loss: 0.7616 - val_acc: 0.7796\n",
      "Epoch 460/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2134 - acc: 0.9139 - val_loss: 0.7552 - val_acc: 0.7794\n",
      "Epoch 461/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2135 - acc: 0.9137 - val_loss: 0.7551 - val_acc: 0.7803\n",
      "Epoch 462/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2128 - acc: 0.9142 - val_loss: 0.7655 - val_acc: 0.7810\n",
      "Epoch 463/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2120 - acc: 0.9143 - val_loss: 0.7609 - val_acc: 0.7798\n",
      "Epoch 464/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2121 - acc: 0.9136 - val_loss: 0.7590 - val_acc: 0.7811\n",
      "Epoch 465/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2110 - acc: 0.9148 - val_loss: 0.7626 - val_acc: 0.7803\n",
      "Epoch 466/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2102 - acc: 0.9155 - val_loss: 0.7659 - val_acc: 0.7795\n",
      "Epoch 467/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2104 - acc: 0.9153 - val_loss: 0.7647 - val_acc: 0.7798\n",
      "Epoch 468/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2113 - acc: 0.9152 - val_loss: 0.7618 - val_acc: 0.7811\n",
      "Epoch 469/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2104 - acc: 0.9156 - val_loss: 0.7679 - val_acc: 0.7802\n",
      "Epoch 470/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2090 - acc: 0.9156 - val_loss: 0.7693 - val_acc: 0.7773\n",
      "Epoch 471/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2106 - acc: 0.9149 - val_loss: 0.7692 - val_acc: 0.7795\n",
      "Epoch 472/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2083 - acc: 0.9160 - val_loss: 0.7704 - val_acc: 0.7789\n",
      "Epoch 473/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2096 - acc: 0.9158 - val_loss: 0.7686 - val_acc: 0.7781\n",
      "Epoch 474/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2079 - acc: 0.9163 - val_loss: 0.7740 - val_acc: 0.7806\n",
      "Epoch 475/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2079 - acc: 0.9165 - val_loss: 0.7664 - val_acc: 0.7786\n",
      "Epoch 476/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2082 - acc: 0.9167 - val_loss: 0.7758 - val_acc: 0.7775\n",
      "Epoch 477/800\n",
      "230116/230116 [==============================] - 12s 52us/step - loss: 0.2081 - acc: 0.9163 - val_loss: 0.7693 - val_acc: 0.7805\n",
      "Epoch 478/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2079 - acc: 0.9162 - val_loss: 0.7683 - val_acc: 0.7788\n",
      "Epoch 479/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2058 - acc: 0.9173 - val_loss: 0.7736 - val_acc: 0.7798\n",
      "Epoch 480/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2063 - acc: 0.9164 - val_loss: 0.7745 - val_acc: 0.7788\n",
      "Epoch 481/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2068 - acc: 0.9169 - val_loss: 0.7759 - val_acc: 0.7786\n",
      "Epoch 482/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2079 - acc: 0.9165 - val_loss: 0.7729 - val_acc: 0.7801\n",
      "Epoch 483/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2064 - acc: 0.9169 - val_loss: 0.7732 - val_acc: 0.7799\n",
      "Epoch 484/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2059 - acc: 0.9169 - val_loss: 0.7784 - val_acc: 0.7795\n",
      "Epoch 485/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2058 - acc: 0.9174 - val_loss: 0.7822 - val_acc: 0.7811\n",
      "Epoch 486/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2047 - acc: 0.9180 - val_loss: 0.7755 - val_acc: 0.7786\n",
      "Epoch 487/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2053 - acc: 0.9176 - val_loss: 0.7779 - val_acc: 0.7782\n",
      "Epoch 488/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2054 - acc: 0.9176 - val_loss: 0.7809 - val_acc: 0.7797\n",
      "Epoch 489/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2054 - acc: 0.9179 - val_loss: 0.7750 - val_acc: 0.7777\n",
      "Epoch 490/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2043 - acc: 0.9185 - val_loss: 0.7803 - val_acc: 0.7790\n",
      "Epoch 491/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2036 - acc: 0.9185 - val_loss: 0.7779 - val_acc: 0.7796\n",
      "Epoch 492/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2053 - acc: 0.9179 - val_loss: 0.7831 - val_acc: 0.7792\n",
      "Epoch 493/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2048 - acc: 0.9177 - val_loss: 0.7796 - val_acc: 0.7801\n",
      "Epoch 494/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2045 - acc: 0.9181 - val_loss: 0.7819 - val_acc: 0.7803\n",
      "Epoch 495/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2031 - acc: 0.9186 - val_loss: 0.7862 - val_acc: 0.7799\n",
      "Epoch 496/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2022 - acc: 0.9186 - val_loss: 0.7787 - val_acc: 0.7781\n",
      "Epoch 497/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2032 - acc: 0.9189 - val_loss: 0.7751 - val_acc: 0.7788\n",
      "Epoch 498/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2019 - acc: 0.9187 - val_loss: 0.7809 - val_acc: 0.7795\n",
      "Epoch 499/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2009 - acc: 0.9196 - val_loss: 0.7893 - val_acc: 0.7784\n",
      "Epoch 500/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2007 - acc: 0.9197 - val_loss: 0.7894 - val_acc: 0.7791\n",
      "Epoch 501/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2029 - acc: 0.9187 - val_loss: 0.7836 - val_acc: 0.7799\n",
      "Epoch 502/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2011 - acc: 0.9189 - val_loss: 0.7839 - val_acc: 0.7787\n",
      "Epoch 503/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2011 - acc: 0.9194 - val_loss: 0.7944 - val_acc: 0.7780\n",
      "Epoch 504/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2011 - acc: 0.9195 - val_loss: 0.7816 - val_acc: 0.7788\n",
      "Epoch 505/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2008 - acc: 0.9191 - val_loss: 0.7871 - val_acc: 0.7784\n",
      "Epoch 506/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1994 - acc: 0.9200 - val_loss: 0.7962 - val_acc: 0.7797\n",
      "Epoch 507/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2003 - acc: 0.9199 - val_loss: 0.7859 - val_acc: 0.7782\n",
      "Epoch 508/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2004 - acc: 0.9194 - val_loss: 0.7951 - val_acc: 0.7792\n",
      "Epoch 509/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1991 - acc: 0.9199 - val_loss: 0.7910 - val_acc: 0.7777\n",
      "Epoch 510/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1990 - acc: 0.9204 - val_loss: 0.7930 - val_acc: 0.7787\n",
      "Epoch 511/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2008 - acc: 0.9189 - val_loss: 0.7892 - val_acc: 0.7800\n",
      "Epoch 512/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1996 - acc: 0.9204 - val_loss: 0.7892 - val_acc: 0.7788\n",
      "Epoch 513/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1983 - acc: 0.9206 - val_loss: 0.8000 - val_acc: 0.7792\n",
      "Epoch 514/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1989 - acc: 0.9208 - val_loss: 0.7952 - val_acc: 0.7797\n",
      "Epoch 515/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1968 - acc: 0.9213 - val_loss: 0.8046 - val_acc: 0.7803\n",
      "Epoch 516/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1981 - acc: 0.9209 - val_loss: 0.7963 - val_acc: 0.7781\n",
      "Epoch 517/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1977 - acc: 0.9208 - val_loss: 0.7940 - val_acc: 0.7776\n",
      "Epoch 518/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1968 - acc: 0.9216 - val_loss: 0.7990 - val_acc: 0.7793\n",
      "Epoch 519/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1973 - acc: 0.9217 - val_loss: 0.8007 - val_acc: 0.7790\n",
      "Epoch 520/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1965 - acc: 0.9210 - val_loss: 0.7987 - val_acc: 0.7788\n",
      "Epoch 521/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1958 - acc: 0.9211 - val_loss: 0.8009 - val_acc: 0.7797\n",
      "Epoch 522/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1961 - acc: 0.9219 - val_loss: 0.8024 - val_acc: 0.7772\n",
      "Epoch 523/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1962 - acc: 0.9217 - val_loss: 0.7969 - val_acc: 0.7791\n",
      "Epoch 524/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1941 - acc: 0.9223 - val_loss: 0.8002 - val_acc: 0.7779\n",
      "Epoch 525/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1958 - acc: 0.9213 - val_loss: 0.8003 - val_acc: 0.7792\n",
      "Epoch 526/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1953 - acc: 0.9219 - val_loss: 0.7957 - val_acc: 0.7779\n",
      "Epoch 527/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1958 - acc: 0.9217 - val_loss: 0.8045 - val_acc: 0.7792\n",
      "Epoch 528/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1948 - acc: 0.9221 - val_loss: 0.7998 - val_acc: 0.7785\n",
      "Epoch 529/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1960 - acc: 0.9216 - val_loss: 0.8042 - val_acc: 0.7788\n",
      "Epoch 530/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1966 - acc: 0.9212 - val_loss: 0.7969 - val_acc: 0.7788\n",
      "Epoch 531/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1920 - acc: 0.9234 - val_loss: 0.8058 - val_acc: 0.7797\n",
      "Epoch 532/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1951 - acc: 0.9214 - val_loss: 0.8012 - val_acc: 0.7786\n",
      "Epoch 533/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1926 - acc: 0.9233 - val_loss: 0.7938 - val_acc: 0.7788\n",
      "Epoch 534/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1929 - acc: 0.9232 - val_loss: 0.8046 - val_acc: 0.7798\n",
      "Epoch 535/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1936 - acc: 0.9229 - val_loss: 0.8125 - val_acc: 0.7780\n",
      "Epoch 536/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1929 - acc: 0.9238 - val_loss: 0.8056 - val_acc: 0.7777\n",
      "Epoch 537/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1930 - acc: 0.9231 - val_loss: 0.8055 - val_acc: 0.7769\n",
      "Epoch 538/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1926 - acc: 0.9226 - val_loss: 0.8035 - val_acc: 0.7791\n",
      "Epoch 539/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1930 - acc: 0.9226 - val_loss: 0.8069 - val_acc: 0.7803\n",
      "Epoch 540/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1914 - acc: 0.9232 - val_loss: 0.8047 - val_acc: 0.7780\n",
      "Epoch 541/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1918 - acc: 0.9230 - val_loss: 0.8047 - val_acc: 0.7781\n",
      "Epoch 542/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1912 - acc: 0.9236 - val_loss: 0.8154 - val_acc: 0.7787\n",
      "Epoch 543/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1913 - acc: 0.9236 - val_loss: 0.8091 - val_acc: 0.7789\n",
      "Epoch 544/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1903 - acc: 0.9246 - val_loss: 0.8104 - val_acc: 0.7782\n",
      "Epoch 545/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1909 - acc: 0.9240 - val_loss: 0.8136 - val_acc: 0.7788\n",
      "Epoch 546/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1914 - acc: 0.9234 - val_loss: 0.8125 - val_acc: 0.7790\n",
      "Epoch 547/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1894 - acc: 0.9244 - val_loss: 0.8182 - val_acc: 0.7783\n",
      "Epoch 548/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1908 - acc: 0.9239 - val_loss: 0.8136 - val_acc: 0.7792\n",
      "Epoch 549/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1898 - acc: 0.9243 - val_loss: 0.8173 - val_acc: 0.7798\n",
      "Epoch 550/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1904 - acc: 0.9238 - val_loss: 0.8092 - val_acc: 0.7778\n",
      "Epoch 551/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1899 - acc: 0.9239 - val_loss: 0.8036 - val_acc: 0.7782\n",
      "Epoch 552/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1908 - acc: 0.9245 - val_loss: 0.8085 - val_acc: 0.7792\n",
      "Epoch 553/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1887 - acc: 0.9246 - val_loss: 0.8175 - val_acc: 0.7778\n",
      "Epoch 554/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1887 - acc: 0.9254 - val_loss: 0.8134 - val_acc: 0.7779\n",
      "Epoch 555/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1898 - acc: 0.9241 - val_loss: 0.8062 - val_acc: 0.7785\n",
      "Epoch 556/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1880 - acc: 0.9245 - val_loss: 0.8109 - val_acc: 0.7801\n",
      "Epoch 557/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1894 - acc: 0.9242 - val_loss: 0.8031 - val_acc: 0.7786\n",
      "Epoch 558/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1878 - acc: 0.9247 - val_loss: 0.8151 - val_acc: 0.7779\n",
      "Epoch 559/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1879 - acc: 0.9249 - val_loss: 0.8259 - val_acc: 0.7800\n",
      "Epoch 560/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1888 - acc: 0.9250 - val_loss: 0.8218 - val_acc: 0.7776\n",
      "Epoch 561/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1882 - acc: 0.9250 - val_loss: 0.8203 - val_acc: 0.7777\n",
      "Epoch 562/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1891 - acc: 0.9245 - val_loss: 0.8152 - val_acc: 0.7789\n",
      "Epoch 563/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1865 - acc: 0.9256 - val_loss: 0.8236 - val_acc: 0.7785\n",
      "Epoch 564/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1854 - acc: 0.9262 - val_loss: 0.8190 - val_acc: 0.7779\n",
      "Epoch 565/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1871 - acc: 0.9251 - val_loss: 0.8282 - val_acc: 0.7789\n",
      "Epoch 566/800\n",
      "230116/230116 [==============================] - 12s 52us/step - loss: 0.1855 - acc: 0.9268 - val_loss: 0.8100 - val_acc: 0.7783\n",
      "Epoch 567/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1867 - acc: 0.9255 - val_loss: 0.8182 - val_acc: 0.7790\n",
      "Epoch 568/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1871 - acc: 0.9251 - val_loss: 0.8178 - val_acc: 0.7785\n",
      "Epoch 569/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1862 - acc: 0.9260 - val_loss: 0.8176 - val_acc: 0.7795\n",
      "Epoch 570/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1855 - acc: 0.9267 - val_loss: 0.8208 - val_acc: 0.7781\n",
      "Epoch 571/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1861 - acc: 0.9261 - val_loss: 0.8224 - val_acc: 0.7785\n",
      "Epoch 572/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1881 - acc: 0.9253 - val_loss: 0.8196 - val_acc: 0.7769\n",
      "Epoch 573/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1860 - acc: 0.9260 - val_loss: 0.8217 - val_acc: 0.7781\n",
      "Epoch 574/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1846 - acc: 0.9265 - val_loss: 0.8305 - val_acc: 0.7793\n",
      "Epoch 575/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1863 - acc: 0.9266 - val_loss: 0.8205 - val_acc: 0.7776\n",
      "Epoch 576/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1839 - acc: 0.9270 - val_loss: 0.8284 - val_acc: 0.7785\n",
      "Epoch 577/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1819 - acc: 0.9281 - val_loss: 0.8310 - val_acc: 0.7789\n",
      "Epoch 578/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1837 - acc: 0.9271 - val_loss: 0.8297 - val_acc: 0.7777\n",
      "Epoch 579/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1849 - acc: 0.9265 - val_loss: 0.8272 - val_acc: 0.7780\n",
      "Epoch 580/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1842 - acc: 0.9268 - val_loss: 0.8315 - val_acc: 0.7783\n",
      "Epoch 581/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1839 - acc: 0.9270 - val_loss: 0.8222 - val_acc: 0.7781\n",
      "Epoch 582/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1824 - acc: 0.9268 - val_loss: 0.8293 - val_acc: 0.7781\n",
      "Epoch 583/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1817 - acc: 0.9279 - val_loss: 0.8303 - val_acc: 0.7772\n",
      "Epoch 584/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1848 - acc: 0.9270 - val_loss: 0.8270 - val_acc: 0.7784\n",
      "Epoch 585/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1832 - acc: 0.9277 - val_loss: 0.8316 - val_acc: 0.7780\n",
      "Epoch 586/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1841 - acc: 0.9272 - val_loss: 0.8276 - val_acc: 0.7775\n",
      "Epoch 587/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1837 - acc: 0.9271 - val_loss: 0.8293 - val_acc: 0.7777\n",
      "Epoch 588/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1819 - acc: 0.9277 - val_loss: 0.8308 - val_acc: 0.7782\n",
      "Epoch 589/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1836 - acc: 0.9269 - val_loss: 0.8343 - val_acc: 0.7775\n",
      "Epoch 590/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1836 - acc: 0.9273 - val_loss: 0.8278 - val_acc: 0.7769\n",
      "Epoch 591/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1828 - acc: 0.9276 - val_loss: 0.8319 - val_acc: 0.7782\n",
      "Epoch 592/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1810 - acc: 0.9282 - val_loss: 0.8364 - val_acc: 0.7777\n",
      "Epoch 593/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1821 - acc: 0.9271 - val_loss: 0.8266 - val_acc: 0.7762\n",
      "Epoch 594/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1809 - acc: 0.9287 - val_loss: 0.8296 - val_acc: 0.7779\n",
      "Epoch 595/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1805 - acc: 0.9279 - val_loss: 0.8383 - val_acc: 0.7795\n",
      "Epoch 596/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1798 - acc: 0.9286 - val_loss: 0.8287 - val_acc: 0.7775\n",
      "Epoch 597/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1823 - acc: 0.9280 - val_loss: 0.8267 - val_acc: 0.7767\n",
      "Epoch 598/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1795 - acc: 0.9290 - val_loss: 0.8393 - val_acc: 0.7795\n",
      "Epoch 599/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1807 - acc: 0.9284 - val_loss: 0.8338 - val_acc: 0.7771\n",
      "Epoch 600/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1806 - acc: 0.9288 - val_loss: 0.8318 - val_acc: 0.7770\n",
      "Epoch 601/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1789 - acc: 0.9295 - val_loss: 0.8375 - val_acc: 0.7773\n",
      "Epoch 602/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1783 - acc: 0.9294 - val_loss: 0.8287 - val_acc: 0.7764\n",
      "Epoch 603/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1805 - acc: 0.9286 - val_loss: 0.8369 - val_acc: 0.7777\n",
      "Epoch 604/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1802 - acc: 0.9286 - val_loss: 0.8370 - val_acc: 0.7784\n",
      "Epoch 605/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1800 - acc: 0.9283 - val_loss: 0.8320 - val_acc: 0.7787\n",
      "Epoch 606/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1796 - acc: 0.9296 - val_loss: 0.8339 - val_acc: 0.7785\n",
      "Epoch 607/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1785 - acc: 0.9302 - val_loss: 0.8403 - val_acc: 0.7785\n",
      "Epoch 608/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1778 - acc: 0.9293 - val_loss: 0.8413 - val_acc: 0.7768\n",
      "Epoch 609/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1787 - acc: 0.9289 - val_loss: 0.8417 - val_acc: 0.7779\n",
      "Epoch 610/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1790 - acc: 0.9294 - val_loss: 0.8374 - val_acc: 0.7761\n",
      "Epoch 611/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1786 - acc: 0.9290 - val_loss: 0.8326 - val_acc: 0.7760\n",
      "Epoch 612/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1802 - acc: 0.9284 - val_loss: 0.8263 - val_acc: 0.7759\n",
      "Epoch 613/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1786 - acc: 0.9290 - val_loss: 0.8362 - val_acc: 0.7778\n",
      "Epoch 614/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1767 - acc: 0.9307 - val_loss: 0.8429 - val_acc: 0.7781\n",
      "Epoch 615/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1781 - acc: 0.9291 - val_loss: 0.8349 - val_acc: 0.7778\n",
      "Epoch 616/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1767 - acc: 0.9303 - val_loss: 0.8369 - val_acc: 0.7783\n",
      "Epoch 617/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1760 - acc: 0.9299 - val_loss: 0.8403 - val_acc: 0.7799\n",
      "Epoch 618/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1767 - acc: 0.9306 - val_loss: 0.8455 - val_acc: 0.7787\n",
      "Epoch 619/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1760 - acc: 0.9303 - val_loss: 0.8430 - val_acc: 0.7779\n",
      "Epoch 620/800\n",
      "230116/230116 [==============================] - 12s 52us/step - loss: 0.1766 - acc: 0.9300 - val_loss: 0.8475 - val_acc: 0.7783\n",
      "Epoch 621/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1770 - acc: 0.9305 - val_loss: 0.8491 - val_acc: 0.7793\n",
      "Epoch 622/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1765 - acc: 0.9296 - val_loss: 0.8442 - val_acc: 0.7782\n",
      "Epoch 623/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1759 - acc: 0.9308 - val_loss: 0.8487 - val_acc: 0.7780\n",
      "Epoch 624/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1763 - acc: 0.9303 - val_loss: 0.8488 - val_acc: 0.7775\n",
      "Epoch 625/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1753 - acc: 0.9301 - val_loss: 0.8525 - val_acc: 0.7773\n",
      "Epoch 626/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1766 - acc: 0.9302 - val_loss: 0.8450 - val_acc: 0.7784\n",
      "Epoch 627/800\n",
      "230116/230116 [==============================] - 12s 52us/step - loss: 0.1751 - acc: 0.9308 - val_loss: 0.8397 - val_acc: 0.7783\n",
      "Epoch 628/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1738 - acc: 0.9309 - val_loss: 0.8416 - val_acc: 0.7772\n",
      "Epoch 629/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1757 - acc: 0.9302 - val_loss: 0.8536 - val_acc: 0.7794\n",
      "Epoch 630/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1746 - acc: 0.9307 - val_loss: 0.8540 - val_acc: 0.7785\n",
      "Epoch 631/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1761 - acc: 0.9297 - val_loss: 0.8506 - val_acc: 0.7767\n",
      "Epoch 632/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1740 - acc: 0.9316 - val_loss: 0.8506 - val_acc: 0.7785\n",
      "Epoch 633/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1734 - acc: 0.9313 - val_loss: 0.8546 - val_acc: 0.7753\n",
      "Epoch 634/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1744 - acc: 0.9312 - val_loss: 0.8486 - val_acc: 0.7778\n",
      "Epoch 635/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1740 - acc: 0.9310 - val_loss: 0.8464 - val_acc: 0.7761\n",
      "Epoch 636/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1734 - acc: 0.9315 - val_loss: 0.8558 - val_acc: 0.7766\n",
      "Epoch 637/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1729 - acc: 0.9312 - val_loss: 0.8514 - val_acc: 0.7766\n",
      "Epoch 638/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1731 - acc: 0.9310 - val_loss: 0.8415 - val_acc: 0.7777\n",
      "Epoch 639/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1729 - acc: 0.9311 - val_loss: 0.8446 - val_acc: 0.7765\n",
      "Epoch 640/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1722 - acc: 0.9315 - val_loss: 0.8529 - val_acc: 0.7765\n",
      "Epoch 641/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1739 - acc: 0.9315 - val_loss: 0.8479 - val_acc: 0.7773\n",
      "Epoch 642/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1741 - acc: 0.9312 - val_loss: 0.8524 - val_acc: 0.7770\n",
      "Epoch 643/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1723 - acc: 0.9320 - val_loss: 0.8566 - val_acc: 0.7778\n",
      "Epoch 644/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1711 - acc: 0.9326 - val_loss: 0.8538 - val_acc: 0.7783\n",
      "Epoch 645/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1726 - acc: 0.9321 - val_loss: 0.8588 - val_acc: 0.7776\n",
      "Epoch 646/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1725 - acc: 0.9318 - val_loss: 0.8508 - val_acc: 0.7766\n",
      "Epoch 647/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1735 - acc: 0.9322 - val_loss: 0.8532 - val_acc: 0.7761\n",
      "Epoch 648/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1728 - acc: 0.9316 - val_loss: 0.8546 - val_acc: 0.7772\n",
      "Epoch 649/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1722 - acc: 0.9322 - val_loss: 0.8550 - val_acc: 0.7771\n",
      "Epoch 650/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1717 - acc: 0.9324 - val_loss: 0.8544 - val_acc: 0.7773\n",
      "Epoch 651/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1721 - acc: 0.9319 - val_loss: 0.8587 - val_acc: 0.7778\n",
      "Epoch 652/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1701 - acc: 0.9328 - val_loss: 0.8556 - val_acc: 0.7786\n",
      "Epoch 653/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1714 - acc: 0.9321 - val_loss: 0.8559 - val_acc: 0.7771\n",
      "Epoch 654/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1695 - acc: 0.9328 - val_loss: 0.8621 - val_acc: 0.7771\n",
      "Epoch 655/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.1700 - acc: 0.9327 - val_loss: 0.8615 - val_acc: 0.7786\n",
      "Epoch 656/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1698 - acc: 0.9325 - val_loss: 0.8643 - val_acc: 0.7790\n",
      "Epoch 657/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1715 - acc: 0.9319 - val_loss: 0.8562 - val_acc: 0.7767\n",
      "Epoch 658/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1691 - acc: 0.9330 - val_loss: 0.8669 - val_acc: 0.7779\n",
      "Epoch 659/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1697 - acc: 0.9329 - val_loss: 0.8707 - val_acc: 0.7781\n",
      "Epoch 660/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1698 - acc: 0.9330 - val_loss: 0.8647 - val_acc: 0.7802\n",
      "Epoch 661/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1720 - acc: 0.9326 - val_loss: 0.8622 - val_acc: 0.7768\n",
      "Epoch 662/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1701 - acc: 0.9330 - val_loss: 0.8560 - val_acc: 0.7756\n",
      "Epoch 663/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1710 - acc: 0.9329 - val_loss: 0.8535 - val_acc: 0.7762\n",
      "Epoch 664/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1700 - acc: 0.9333 - val_loss: 0.8549 - val_acc: 0.7778\n",
      "Epoch 665/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.1673 - acc: 0.9341 - val_loss: 0.8675 - val_acc: 0.7789\n",
      "Epoch 666/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1692 - acc: 0.9335 - val_loss: 0.8674 - val_acc: 0.7769\n",
      "Epoch 667/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1674 - acc: 0.9339 - val_loss: 0.8641 - val_acc: 0.7755\n",
      "Epoch 668/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1705 - acc: 0.9329 - val_loss: 0.8600 - val_acc: 0.7768\n",
      "Epoch 669/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1683 - acc: 0.9336 - val_loss: 0.8632 - val_acc: 0.7772\n",
      "Epoch 670/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1691 - acc: 0.9334 - val_loss: 0.8646 - val_acc: 0.7756\n",
      "Epoch 671/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1697 - acc: 0.9332 - val_loss: 0.8601 - val_acc: 0.7777\n",
      "Epoch 672/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1684 - acc: 0.9340 - val_loss: 0.8670 - val_acc: 0.7774\n",
      "Epoch 673/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1681 - acc: 0.9336 - val_loss: 0.8632 - val_acc: 0.7764\n",
      "Epoch 674/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1687 - acc: 0.9342 - val_loss: 0.8707 - val_acc: 0.7770\n",
      "Epoch 675/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1683 - acc: 0.9341 - val_loss: 0.8649 - val_acc: 0.7756\n",
      "Epoch 676/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1676 - acc: 0.9344 - val_loss: 0.8624 - val_acc: 0.7759\n",
      "Epoch 677/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1670 - acc: 0.9342 - val_loss: 0.8725 - val_acc: 0.7758\n",
      "Epoch 678/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1680 - acc: 0.9340 - val_loss: 0.8654 - val_acc: 0.7758\n",
      "Epoch 679/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1666 - acc: 0.9343 - val_loss: 0.8690 - val_acc: 0.7764\n",
      "Epoch 680/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1672 - acc: 0.9345 - val_loss: 0.8712 - val_acc: 0.7763\n",
      "Epoch 681/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1664 - acc: 0.9350 - val_loss: 0.8774 - val_acc: 0.7754\n",
      "Epoch 682/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1663 - acc: 0.9346 - val_loss: 0.8718 - val_acc: 0.7754\n",
      "Epoch 683/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1666 - acc: 0.9340 - val_loss: 0.8743 - val_acc: 0.7761\n",
      "Epoch 684/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1667 - acc: 0.9341 - val_loss: 0.8709 - val_acc: 0.7755\n",
      "Epoch 685/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1658 - acc: 0.9349 - val_loss: 0.8686 - val_acc: 0.7764\n",
      "Epoch 686/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1666 - acc: 0.9341 - val_loss: 0.8730 - val_acc: 0.7773\n",
      "Epoch 687/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1671 - acc: 0.9346 - val_loss: 0.8622 - val_acc: 0.7757\n",
      "Epoch 688/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1665 - acc: 0.9352 - val_loss: 0.8725 - val_acc: 0.7778\n",
      "Epoch 689/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1672 - acc: 0.9342 - val_loss: 0.8752 - val_acc: 0.7773\n",
      "Epoch 690/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1663 - acc: 0.9345 - val_loss: 0.8713 - val_acc: 0.7757\n",
      "Epoch 691/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1655 - acc: 0.9351 - val_loss: 0.8753 - val_acc: 0.7769\n",
      "Epoch 692/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1663 - acc: 0.9346 - val_loss: 0.8803 - val_acc: 0.7762\n",
      "Epoch 693/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1663 - acc: 0.9344 - val_loss: 0.8732 - val_acc: 0.7748\n",
      "Epoch 694/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1655 - acc: 0.9348 - val_loss: 0.8692 - val_acc: 0.7745\n",
      "Epoch 695/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1659 - acc: 0.9351 - val_loss: 0.8729 - val_acc: 0.7767\n",
      "Epoch 696/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1668 - acc: 0.9350 - val_loss: 0.8684 - val_acc: 0.7765\n",
      "Epoch 697/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1658 - acc: 0.9352 - val_loss: 0.8718 - val_acc: 0.7753\n",
      "Epoch 698/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1648 - acc: 0.9351 - val_loss: 0.8806 - val_acc: 0.7758\n",
      "Epoch 699/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1644 - acc: 0.9357 - val_loss: 0.8818 - val_acc: 0.7761\n",
      "Epoch 700/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1640 - acc: 0.9354 - val_loss: 0.8710 - val_acc: 0.7770\n",
      "Epoch 701/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1649 - acc: 0.9350 - val_loss: 0.8687 - val_acc: 0.7763\n",
      "Epoch 702/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1646 - acc: 0.9353 - val_loss: 0.8637 - val_acc: 0.7770\n",
      "Epoch 703/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1645 - acc: 0.9358 - val_loss: 0.8732 - val_acc: 0.7769\n",
      "Epoch 704/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1658 - acc: 0.9350 - val_loss: 0.8683 - val_acc: 0.7761\n",
      "Epoch 705/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1633 - acc: 0.9360 - val_loss: 0.8786 - val_acc: 0.7765\n",
      "Epoch 706/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1635 - acc: 0.9356 - val_loss: 0.8797 - val_acc: 0.7764\n",
      "Epoch 707/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1617 - acc: 0.9364 - val_loss: 0.8866 - val_acc: 0.7752\n",
      "Epoch 708/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1641 - acc: 0.9350 - val_loss: 0.8841 - val_acc: 0.7780\n",
      "Epoch 709/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1632 - acc: 0.9364 - val_loss: 0.8844 - val_acc: 0.7769\n",
      "Epoch 710/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1634 - acc: 0.9362 - val_loss: 0.8774 - val_acc: 0.7760\n",
      "Epoch 711/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1626 - acc: 0.9361 - val_loss: 0.8790 - val_acc: 0.7764\n",
      "Epoch 712/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1636 - acc: 0.9359 - val_loss: 0.8844 - val_acc: 0.7775\n",
      "Epoch 713/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1634 - acc: 0.9356 - val_loss: 0.8773 - val_acc: 0.7761\n",
      "Epoch 714/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1638 - acc: 0.9360 - val_loss: 0.8860 - val_acc: 0.7761\n",
      "Epoch 715/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1615 - acc: 0.9371 - val_loss: 0.8793 - val_acc: 0.7764\n",
      "Epoch 716/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1637 - acc: 0.9357 - val_loss: 0.8809 - val_acc: 0.7762\n",
      "Epoch 717/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1616 - acc: 0.9371 - val_loss: 0.8753 - val_acc: 0.7751\n",
      "Epoch 718/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1627 - acc: 0.9362 - val_loss: 0.8808 - val_acc: 0.7770\n",
      "Epoch 719/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1620 - acc: 0.9363 - val_loss: 0.8737 - val_acc: 0.7760\n",
      "Epoch 720/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1625 - acc: 0.9361 - val_loss: 0.8852 - val_acc: 0.7767\n",
      "Epoch 721/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1620 - acc: 0.9367 - val_loss: 0.8797 - val_acc: 0.7763\n",
      "Epoch 722/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1616 - acc: 0.9363 - val_loss: 0.8802 - val_acc: 0.7745\n",
      "Epoch 723/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1621 - acc: 0.9365 - val_loss: 0.8774 - val_acc: 0.7750\n",
      "Epoch 724/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1606 - acc: 0.9370 - val_loss: 0.8938 - val_acc: 0.7762\n",
      "Epoch 725/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1605 - acc: 0.9375 - val_loss: 0.8927 - val_acc: 0.7764\n",
      "Epoch 726/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1610 - acc: 0.9371 - val_loss: 0.8869 - val_acc: 0.7782\n",
      "Epoch 727/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1598 - acc: 0.9373 - val_loss: 0.8828 - val_acc: 0.7767\n",
      "Epoch 728/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1608 - acc: 0.9376 - val_loss: 0.8844 - val_acc: 0.7753\n",
      "Epoch 729/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1605 - acc: 0.9373 - val_loss: 0.8863 - val_acc: 0.7771\n",
      "Epoch 730/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1604 - acc: 0.9371 - val_loss: 0.8835 - val_acc: 0.7749\n",
      "Epoch 731/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1605 - acc: 0.9380 - val_loss: 0.8823 - val_acc: 0.7760\n",
      "Epoch 732/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1612 - acc: 0.9367 - val_loss: 0.8894 - val_acc: 0.7756\n",
      "Epoch 733/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1590 - acc: 0.9379 - val_loss: 0.8864 - val_acc: 0.7761\n",
      "Epoch 734/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1598 - acc: 0.9375 - val_loss: 0.8893 - val_acc: 0.7763\n",
      "Epoch 735/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1595 - acc: 0.9380 - val_loss: 0.8932 - val_acc: 0.7746\n",
      "Epoch 736/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1607 - acc: 0.9377 - val_loss: 0.8903 - val_acc: 0.7758\n",
      "Epoch 737/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1603 - acc: 0.9374 - val_loss: 0.8835 - val_acc: 0.7753\n",
      "Epoch 738/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1579 - acc: 0.9386 - val_loss: 0.8996 - val_acc: 0.7760\n",
      "Epoch 739/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1594 - acc: 0.9375 - val_loss: 0.8946 - val_acc: 0.7759\n",
      "Epoch 740/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1599 - acc: 0.9375 - val_loss: 0.8933 - val_acc: 0.7753\n",
      "Epoch 741/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1600 - acc: 0.9375 - val_loss: 0.8904 - val_acc: 0.7760\n",
      "Epoch 742/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1590 - acc: 0.9382 - val_loss: 0.8899 - val_acc: 0.7761\n",
      "Epoch 743/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1593 - acc: 0.9375 - val_loss: 0.8882 - val_acc: 0.7749\n",
      "Epoch 744/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1583 - acc: 0.9379 - val_loss: 0.8923 - val_acc: 0.7764\n",
      "Epoch 745/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1590 - acc: 0.9375 - val_loss: 0.8859 - val_acc: 0.7756\n",
      "Epoch 746/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1591 - acc: 0.9377 - val_loss: 0.8994 - val_acc: 0.7761\n",
      "Epoch 747/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1595 - acc: 0.9379 - val_loss: 0.8894 - val_acc: 0.7765\n",
      "Epoch 748/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1591 - acc: 0.9380 - val_loss: 0.8875 - val_acc: 0.7760\n",
      "Epoch 749/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1585 - acc: 0.9380 - val_loss: 0.8884 - val_acc: 0.7765\n",
      "Epoch 750/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1585 - acc: 0.9379 - val_loss: 0.8893 - val_acc: 0.7751\n",
      "Epoch 751/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1581 - acc: 0.9382 - val_loss: 0.8936 - val_acc: 0.7754\n",
      "Epoch 752/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1580 - acc: 0.9380 - val_loss: 0.8917 - val_acc: 0.7744\n",
      "Epoch 753/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1568 - acc: 0.9389 - val_loss: 0.8901 - val_acc: 0.7747\n",
      "Epoch 754/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1574 - acc: 0.9388 - val_loss: 0.8944 - val_acc: 0.7748\n",
      "Epoch 755/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1573 - acc: 0.9382 - val_loss: 0.8960 - val_acc: 0.7762\n",
      "Epoch 756/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1581 - acc: 0.9377 - val_loss: 0.8872 - val_acc: 0.7756\n",
      "Epoch 757/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1574 - acc: 0.9383 - val_loss: 0.8947 - val_acc: 0.7763\n",
      "Epoch 758/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1583 - acc: 0.9383 - val_loss: 0.8976 - val_acc: 0.7764\n",
      "Epoch 759/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1575 - acc: 0.9383 - val_loss: 0.8933 - val_acc: 0.7764\n",
      "Epoch 760/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1548 - acc: 0.9397 - val_loss: 0.9032 - val_acc: 0.7762\n",
      "Epoch 761/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1555 - acc: 0.9393 - val_loss: 0.8989 - val_acc: 0.7756\n",
      "Epoch 762/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1566 - acc: 0.9387 - val_loss: 0.8915 - val_acc: 0.7751\n",
      "Epoch 763/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1556 - acc: 0.9393 - val_loss: 0.9004 - val_acc: 0.7753\n",
      "Epoch 764/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1572 - acc: 0.9385 - val_loss: 0.8953 - val_acc: 0.7755\n",
      "Epoch 765/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1572 - acc: 0.9388 - val_loss: 0.8963 - val_acc: 0.7753\n",
      "Epoch 766/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1574 - acc: 0.9386 - val_loss: 0.9007 - val_acc: 0.7750\n",
      "Epoch 767/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1572 - acc: 0.9388 - val_loss: 0.8948 - val_acc: 0.7766\n",
      "Epoch 768/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1572 - acc: 0.9391 - val_loss: 0.8903 - val_acc: 0.7745\n",
      "Epoch 769/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1554 - acc: 0.9394 - val_loss: 0.9048 - val_acc: 0.7757\n",
      "Epoch 770/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1561 - acc: 0.9392 - val_loss: 0.8972 - val_acc: 0.7767\n",
      "Epoch 771/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1566 - acc: 0.9393 - val_loss: 0.8910 - val_acc: 0.7752\n",
      "Epoch 772/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1571 - acc: 0.9382 - val_loss: 0.8999 - val_acc: 0.7748\n",
      "Epoch 773/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1566 - acc: 0.9386 - val_loss: 0.8935 - val_acc: 0.7744\n",
      "Epoch 774/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1566 - acc: 0.9390 - val_loss: 0.9041 - val_acc: 0.7749\n",
      "Epoch 775/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1561 - acc: 0.9391 - val_loss: 0.9005 - val_acc: 0.7755\n",
      "Epoch 776/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1569 - acc: 0.9393 - val_loss: 0.9007 - val_acc: 0.7749\n",
      "Epoch 777/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.1558 - acc: 0.9393 - val_loss: 0.9054 - val_acc: 0.7749\n",
      "Epoch 778/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1554 - acc: 0.9395 - val_loss: 0.8977 - val_acc: 0.7737\n",
      "Epoch 779/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1549 - acc: 0.9392 - val_loss: 0.8983 - val_acc: 0.7746\n",
      "Epoch 780/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1540 - acc: 0.9403 - val_loss: 0.9091 - val_acc: 0.7739\n",
      "Epoch 781/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1541 - acc: 0.9402 - val_loss: 0.8980 - val_acc: 0.7759\n",
      "Epoch 782/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1536 - acc: 0.9398 - val_loss: 0.9086 - val_acc: 0.7758\n",
      "Epoch 783/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1552 - acc: 0.9398 - val_loss: 0.9018 - val_acc: 0.7765\n",
      "Epoch 784/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1549 - acc: 0.9399 - val_loss: 0.9013 - val_acc: 0.7755\n",
      "Epoch 785/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1542 - acc: 0.9405 - val_loss: 0.9071 - val_acc: 0.7740\n",
      "Epoch 786/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1547 - acc: 0.9402 - val_loss: 0.9009 - val_acc: 0.7749\n",
      "Epoch 787/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1538 - acc: 0.9404 - val_loss: 0.9055 - val_acc: 0.7760\n",
      "Epoch 788/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1539 - acc: 0.9407 - val_loss: 0.9048 - val_acc: 0.7739\n",
      "Epoch 789/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1534 - acc: 0.9405 - val_loss: 0.9085 - val_acc: 0.7747\n",
      "Epoch 790/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1554 - acc: 0.9394 - val_loss: 0.8916 - val_acc: 0.7753\n",
      "Epoch 791/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1540 - acc: 0.9399 - val_loss: 0.8987 - val_acc: 0.7754\n",
      "Epoch 792/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1527 - acc: 0.9404 - val_loss: 0.9012 - val_acc: 0.7763\n",
      "Epoch 793/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1527 - acc: 0.9405 - val_loss: 0.9030 - val_acc: 0.7743\n",
      "Epoch 794/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1519 - acc: 0.9409 - val_loss: 0.9136 - val_acc: 0.7740\n",
      "Epoch 795/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1531 - acc: 0.9407 - val_loss: 0.9034 - val_acc: 0.7745\n",
      "Epoch 796/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.1536 - acc: 0.9399 - val_loss: 0.9000 - val_acc: 0.7739\n",
      "Epoch 797/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1526 - acc: 0.9407 - val_loss: 0.9000 - val_acc: 0.7750\n",
      "Epoch 798/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1552 - acc: 0.9401 - val_loss: 0.8963 - val_acc: 0.7745\n",
      "Epoch 799/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1524 - acc: 0.9405 - val_loss: 0.9084 - val_acc: 0.7749\n",
      "Epoch 800/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1510 - acc: 0.9409 - val_loss: 0.9106 - val_acc: 0.7753\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "sys.path.append(os.path.realpath(\"../\"))\n",
    "import ptetaphi_nn\n",
    "import tools\n",
    "\n",
    "# get data file path\n",
    "with open(\"/home/cmccracken/start_tf/bbb/filepath.txt\", 'r') as f:\n",
    "    filename = f.read()\n",
    "    \n",
    "s_table = tools.open_file(filename, sort_by=\"tag\", pt_cut=40, eta_cut=2.5)\n",
    "\n",
    "# filter for events with 3 b tags\n",
    "nt3 = s_table.nbtags==3 \n",
    "events = s_table[nt3]\n",
    "print(len(events))\n",
    "\n",
    "cutoff = 10  # not many events have >10 jets\n",
    "# \"pad\" = ensure all events have same length, cut off ends if needed\n",
    "events = tools.pad(events, cutoff)\n",
    "\n",
    "# make and train network\n",
    "nn = ptetaphi_nn.PtEtaPhiNN(events, chop=0, print_summary=True, fold=4)\n",
    "nn.learn(epochs=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 57529/57529 [00:00<00:00, 75647.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 76.70 percent\n",
      "ignoring 1.49 percent (860 events) of 57529 events\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(savename=\"fold_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the architecture string to a file\n",
    "models_dir = \"/home/cmccracken/start_tf/bbb/models/\"\n",
    "with open(models_dir+'architecture_fold_4.json', 'w') as arch_file:\n",
    "    arch_file.write(nn.model.to_json())\n",
    "# now save the weights as an HDF5 file\n",
    "nn.model.save_weights(models_dir+'weights_fold_4.h5')\n",
    "# use nn_tester to get csv!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
