{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Fold 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777150 total events found\n",
      "sorting data by tag\n",
      "287645\n",
      "k-folding: every 5th element starting at 3\n",
      "creating default model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 700)               21700     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 408       \n",
      "=================================================================\n",
      "Total params: 558,988\n",
      "Trainable params: 558,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230116 samples, validate on 57529 samples\n",
      "Epoch 1/800\n",
      "230116/230116 [==============================] - 14s 61us/step - loss: 1.0011 - acc: 0.6105 - val_loss: 0.8047 - val_acc: 0.6380\n",
      "Epoch 2/800\n",
      "230116/230116 [==============================] - 13s 59us/step - loss: 0.7754 - acc: 0.6495 - val_loss: 0.7403 - val_acc: 0.6645\n",
      "Epoch 3/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.7367 - acc: 0.6627 - val_loss: 0.7195 - val_acc: 0.6673\n",
      "Epoch 4/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.7172 - acc: 0.6715 - val_loss: 0.6986 - val_acc: 0.6809\n",
      "Epoch 5/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.7025 - acc: 0.6783 - val_loss: 0.6884 - val_acc: 0.6848\n",
      "Epoch 6/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.6906 - acc: 0.6850 - val_loss: 0.6770 - val_acc: 0.6893\n",
      "Epoch 7/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6812 - acc: 0.6894 - val_loss: 0.6686 - val_acc: 0.6951\n",
      "Epoch 8/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.6736 - acc: 0.6931 - val_loss: 0.6616 - val_acc: 0.6977\n",
      "Epoch 9/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6669 - acc: 0.6966 - val_loss: 0.6577 - val_acc: 0.7001\n",
      "Epoch 10/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6609 - acc: 0.6987 - val_loss: 0.6519 - val_acc: 0.7035\n",
      "Epoch 11/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6558 - acc: 0.7012 - val_loss: 0.6460 - val_acc: 0.7056\n",
      "Epoch 12/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6510 - acc: 0.7032 - val_loss: 0.6421 - val_acc: 0.7086\n",
      "Epoch 13/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.6463 - acc: 0.7062 - val_loss: 0.6421 - val_acc: 0.7073\n",
      "Epoch 14/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6414 - acc: 0.7076 - val_loss: 0.6339 - val_acc: 0.7113\n",
      "Epoch 15/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.6370 - acc: 0.7099 - val_loss: 0.6306 - val_acc: 0.7121\n",
      "Epoch 16/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6321 - acc: 0.7116 - val_loss: 0.6256 - val_acc: 0.7145\n",
      "Epoch 17/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.6284 - acc: 0.7139 - val_loss: 0.6227 - val_acc: 0.7165\n",
      "Epoch 18/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6241 - acc: 0.7157 - val_loss: 0.6179 - val_acc: 0.7190\n",
      "Epoch 19/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6203 - acc: 0.7176 - val_loss: 0.6156 - val_acc: 0.7192\n",
      "Epoch 20/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6161 - acc: 0.7201 - val_loss: 0.6123 - val_acc: 0.7209\n",
      "Epoch 21/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6123 - acc: 0.7215 - val_loss: 0.6071 - val_acc: 0.7247\n",
      "Epoch 22/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6091 - acc: 0.7236 - val_loss: 0.6041 - val_acc: 0.7250\n",
      "Epoch 23/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.6056 - acc: 0.7257 - val_loss: 0.6012 - val_acc: 0.7279\n",
      "Epoch 24/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.6024 - acc: 0.7280 - val_loss: 0.5985 - val_acc: 0.7285\n",
      "Epoch 25/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5986 - acc: 0.7298 - val_loss: 0.5951 - val_acc: 0.7302\n",
      "Epoch 26/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.5963 - acc: 0.7306 - val_loss: 0.5928 - val_acc: 0.7318\n",
      "Epoch 27/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.5926 - acc: 0.7331 - val_loss: 0.5896 - val_acc: 0.7330\n",
      "Epoch 28/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.5899 - acc: 0.7338 - val_loss: 0.5861 - val_acc: 0.7358\n",
      "Epoch 29/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5867 - acc: 0.7359 - val_loss: 0.5838 - val_acc: 0.7364\n",
      "Epoch 30/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5832 - acc: 0.7390 - val_loss: 0.5809 - val_acc: 0.7379\n",
      "Epoch 31/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5801 - acc: 0.7398 - val_loss: 0.5794 - val_acc: 0.7393\n",
      "Epoch 32/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5774 - acc: 0.7405 - val_loss: 0.5765 - val_acc: 0.7410\n",
      "Epoch 33/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5748 - acc: 0.7424 - val_loss: 0.5767 - val_acc: 0.7408\n",
      "Epoch 34/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5716 - acc: 0.7431 - val_loss: 0.5726 - val_acc: 0.7437\n",
      "Epoch 35/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5693 - acc: 0.7453 - val_loss: 0.5701 - val_acc: 0.7436\n",
      "Epoch 36/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5668 - acc: 0.7462 - val_loss: 0.5662 - val_acc: 0.7464\n",
      "Epoch 37/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.5633 - acc: 0.7478 - val_loss: 0.5648 - val_acc: 0.7480\n",
      "Epoch 38/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5610 - acc: 0.7489 - val_loss: 0.5619 - val_acc: 0.7490\n",
      "Epoch 39/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5584 - acc: 0.7501 - val_loss: 0.5601 - val_acc: 0.7497\n",
      "Epoch 40/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5560 - acc: 0.7523 - val_loss: 0.5588 - val_acc: 0.7511\n",
      "Epoch 41/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.5542 - acc: 0.7530 - val_loss: 0.5568 - val_acc: 0.7525\n",
      "Epoch 42/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5508 - acc: 0.7551 - val_loss: 0.5543 - val_acc: 0.7537\n",
      "Epoch 43/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5486 - acc: 0.7564 - val_loss: 0.5534 - val_acc: 0.7546\n",
      "Epoch 44/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5456 - acc: 0.7578 - val_loss: 0.5487 - val_acc: 0.7567\n",
      "Epoch 45/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.5430 - acc: 0.7586 - val_loss: 0.5482 - val_acc: 0.7584\n",
      "Epoch 46/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.5408 - acc: 0.7606 - val_loss: 0.5448 - val_acc: 0.7593\n",
      "Epoch 47/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5380 - acc: 0.7624 - val_loss: 0.5431 - val_acc: 0.7617\n",
      "Epoch 48/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5353 - acc: 0.7629 - val_loss: 0.5399 - val_acc: 0.7623\n",
      "Epoch 49/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5326 - acc: 0.7644 - val_loss: 0.5394 - val_acc: 0.7638\n",
      "Epoch 50/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5301 - acc: 0.7670 - val_loss: 0.5394 - val_acc: 0.7622\n",
      "Epoch 51/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5275 - acc: 0.7683 - val_loss: 0.5321 - val_acc: 0.7676\n",
      "Epoch 52/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5250 - acc: 0.7696 - val_loss: 0.5310 - val_acc: 0.7683\n",
      "Epoch 53/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5222 - acc: 0.7709 - val_loss: 0.5273 - val_acc: 0.7699\n",
      "Epoch 54/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5205 - acc: 0.7714 - val_loss: 0.5254 - val_acc: 0.7721\n",
      "Epoch 55/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5179 - acc: 0.7731 - val_loss: 0.5228 - val_acc: 0.7727\n",
      "Epoch 56/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5154 - acc: 0.7750 - val_loss: 0.5207 - val_acc: 0.7743\n",
      "Epoch 57/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5133 - acc: 0.7757 - val_loss: 0.5184 - val_acc: 0.7762\n",
      "Epoch 58/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5106 - acc: 0.7771 - val_loss: 0.5182 - val_acc: 0.7768\n",
      "Epoch 59/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5086 - acc: 0.7786 - val_loss: 0.5161 - val_acc: 0.7781\n",
      "Epoch 60/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5061 - acc: 0.7800 - val_loss: 0.5131 - val_acc: 0.7788\n",
      "Epoch 61/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5036 - acc: 0.7815 - val_loss: 0.5107 - val_acc: 0.7815\n",
      "Epoch 62/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.5016 - acc: 0.7823 - val_loss: 0.5095 - val_acc: 0.7827\n",
      "Epoch 63/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4999 - acc: 0.7835 - val_loss: 0.5079 - val_acc: 0.7835\n",
      "Epoch 64/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4982 - acc: 0.7842 - val_loss: 0.5066 - val_acc: 0.7838\n",
      "Epoch 65/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4954 - acc: 0.7860 - val_loss: 0.5056 - val_acc: 0.7847\n",
      "Epoch 66/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4949 - acc: 0.7864 - val_loss: 0.5036 - val_acc: 0.7852\n",
      "Epoch 67/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4928 - acc: 0.7879 - val_loss: 0.5024 - val_acc: 0.7867\n",
      "Epoch 68/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4909 - acc: 0.7888 - val_loss: 0.5005 - val_acc: 0.7880\n",
      "Epoch 69/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4889 - acc: 0.7896 - val_loss: 0.5004 - val_acc: 0.7878\n",
      "Epoch 70/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4878 - acc: 0.7901 - val_loss: 0.4984 - val_acc: 0.7885\n",
      "Epoch 71/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4856 - acc: 0.7916 - val_loss: 0.4980 - val_acc: 0.7899\n",
      "Epoch 72/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4844 - acc: 0.7923 - val_loss: 0.4981 - val_acc: 0.7887\n",
      "Epoch 73/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4827 - acc: 0.7935 - val_loss: 0.4970 - val_acc: 0.7899\n",
      "Epoch 74/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4812 - acc: 0.7940 - val_loss: 0.4963 - val_acc: 0.7908\n",
      "Epoch 75/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4801 - acc: 0.7945 - val_loss: 0.4947 - val_acc: 0.7920\n",
      "Epoch 76/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4778 - acc: 0.7953 - val_loss: 0.4946 - val_acc: 0.7909\n",
      "Epoch 77/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4762 - acc: 0.7961 - val_loss: 0.4928 - val_acc: 0.7918\n",
      "Epoch 78/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4753 - acc: 0.7967 - val_loss: 0.4928 - val_acc: 0.7928\n",
      "Epoch 79/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4743 - acc: 0.7976 - val_loss: 0.4925 - val_acc: 0.7924\n",
      "Epoch 80/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4728 - acc: 0.7987 - val_loss: 0.4905 - val_acc: 0.7939\n",
      "Epoch 81/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4715 - acc: 0.7987 - val_loss: 0.4911 - val_acc: 0.7940\n",
      "Epoch 82/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4688 - acc: 0.8005 - val_loss: 0.4928 - val_acc: 0.7941\n",
      "Epoch 83/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4691 - acc: 0.8002 - val_loss: 0.4917 - val_acc: 0.7934\n",
      "Epoch 84/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4678 - acc: 0.8010 - val_loss: 0.4897 - val_acc: 0.7951\n",
      "Epoch 85/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4665 - acc: 0.8013 - val_loss: 0.4885 - val_acc: 0.7950\n",
      "Epoch 86/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4651 - acc: 0.8014 - val_loss: 0.4906 - val_acc: 0.7943\n",
      "Epoch 87/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4642 - acc: 0.8015 - val_loss: 0.4877 - val_acc: 0.7964\n",
      "Epoch 88/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4626 - acc: 0.8030 - val_loss: 0.4873 - val_acc: 0.7953\n",
      "Epoch 89/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4629 - acc: 0.8030 - val_loss: 0.4863 - val_acc: 0.7960\n",
      "Epoch 90/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4601 - acc: 0.8038 - val_loss: 0.4876 - val_acc: 0.7943\n",
      "Epoch 91/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4596 - acc: 0.8038 - val_loss: 0.4872 - val_acc: 0.7955\n",
      "Epoch 92/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4586 - acc: 0.8055 - val_loss: 0.4866 - val_acc: 0.7958\n",
      "Epoch 93/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4580 - acc: 0.8059 - val_loss: 0.4878 - val_acc: 0.7965\n",
      "Epoch 94/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4568 - acc: 0.8059 - val_loss: 0.4851 - val_acc: 0.7964\n",
      "Epoch 95/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4552 - acc: 0.8067 - val_loss: 0.4852 - val_acc: 0.7977\n",
      "Epoch 96/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4545 - acc: 0.8072 - val_loss: 0.4877 - val_acc: 0.7966\n",
      "Epoch 97/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.4531 - acc: 0.8075 - val_loss: 0.4860 - val_acc: 0.7962\n",
      "Epoch 98/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4522 - acc: 0.8088 - val_loss: 0.4868 - val_acc: 0.7952\n",
      "Epoch 99/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4504 - acc: 0.8092 - val_loss: 0.4842 - val_acc: 0.7986\n",
      "Epoch 100/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4503 - acc: 0.8097 - val_loss: 0.4854 - val_acc: 0.7974\n",
      "Epoch 101/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4498 - acc: 0.8094 - val_loss: 0.4865 - val_acc: 0.7971\n",
      "Epoch 102/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4479 - acc: 0.8103 - val_loss: 0.4858 - val_acc: 0.7980\n",
      "Epoch 103/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4477 - acc: 0.8104 - val_loss: 0.4844 - val_acc: 0.7980\n",
      "Epoch 104/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4460 - acc: 0.8107 - val_loss: 0.4855 - val_acc: 0.7973\n",
      "Epoch 105/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4458 - acc: 0.8113 - val_loss: 0.4848 - val_acc: 0.7985\n",
      "Epoch 106/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4449 - acc: 0.8117 - val_loss: 0.4833 - val_acc: 0.7987\n",
      "Epoch 107/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4441 - acc: 0.8124 - val_loss: 0.4838 - val_acc: 0.7992\n",
      "Epoch 108/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4424 - acc: 0.8124 - val_loss: 0.4845 - val_acc: 0.7984\n",
      "Epoch 109/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4416 - acc: 0.8128 - val_loss: 0.4842 - val_acc: 0.7984\n",
      "Epoch 110/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4411 - acc: 0.8138 - val_loss: 0.4829 - val_acc: 0.7986\n",
      "Epoch 111/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4402 - acc: 0.8147 - val_loss: 0.4824 - val_acc: 0.7995\n",
      "Epoch 112/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4390 - acc: 0.8145 - val_loss: 0.4831 - val_acc: 0.7997\n",
      "Epoch 113/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4379 - acc: 0.8145 - val_loss: 0.4828 - val_acc: 0.8001\n",
      "Epoch 114/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4365 - acc: 0.8154 - val_loss: 0.4821 - val_acc: 0.7984\n",
      "Epoch 115/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4359 - acc: 0.8164 - val_loss: 0.4826 - val_acc: 0.7992\n",
      "Epoch 116/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4354 - acc: 0.8158 - val_loss: 0.4846 - val_acc: 0.7977\n",
      "Epoch 117/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4338 - acc: 0.8169 - val_loss: 0.4827 - val_acc: 0.8004\n",
      "Epoch 118/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4335 - acc: 0.8170 - val_loss: 0.4828 - val_acc: 0.8008\n",
      "Epoch 119/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4328 - acc: 0.8174 - val_loss: 0.4831 - val_acc: 0.7999\n",
      "Epoch 120/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4317 - acc: 0.8182 - val_loss: 0.4832 - val_acc: 0.7989\n",
      "Epoch 121/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4306 - acc: 0.8183 - val_loss: 0.4840 - val_acc: 0.7992\n",
      "Epoch 122/800\n",
      "230116/230116 [==============================] - 14s 59us/step - loss: 0.4293 - acc: 0.8193 - val_loss: 0.4845 - val_acc: 0.7996\n",
      "Epoch 123/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4282 - acc: 0.8187 - val_loss: 0.4848 - val_acc: 0.8011\n",
      "Epoch 124/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4276 - acc: 0.8194 - val_loss: 0.4833 - val_acc: 0.8002\n",
      "Epoch 125/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4263 - acc: 0.8201 - val_loss: 0.4837 - val_acc: 0.7996\n",
      "Epoch 126/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4263 - acc: 0.8206 - val_loss: 0.4824 - val_acc: 0.7996\n",
      "Epoch 127/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4252 - acc: 0.8208 - val_loss: 0.4845 - val_acc: 0.8007\n",
      "Epoch 128/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4238 - acc: 0.8219 - val_loss: 0.4860 - val_acc: 0.8007\n",
      "Epoch 129/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4235 - acc: 0.8214 - val_loss: 0.4864 - val_acc: 0.7988\n",
      "Epoch 130/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4217 - acc: 0.8224 - val_loss: 0.4876 - val_acc: 0.7996\n",
      "Epoch 131/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4214 - acc: 0.8224 - val_loss: 0.4849 - val_acc: 0.7995\n",
      "Epoch 132/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4211 - acc: 0.8227 - val_loss: 0.4855 - val_acc: 0.8010\n",
      "Epoch 133/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4190 - acc: 0.8235 - val_loss: 0.4850 - val_acc: 0.8005\n",
      "Epoch 134/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4186 - acc: 0.8233 - val_loss: 0.4869 - val_acc: 0.7989\n",
      "Epoch 135/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4167 - acc: 0.8251 - val_loss: 0.4883 - val_acc: 0.8004\n",
      "Epoch 136/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4170 - acc: 0.8250 - val_loss: 0.4877 - val_acc: 0.8002\n",
      "Epoch 137/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4157 - acc: 0.8257 - val_loss: 0.4881 - val_acc: 0.7998\n",
      "Epoch 138/800\n",
      "230116/230116 [==============================] - 13s 58us/step - loss: 0.4146 - acc: 0.8260 - val_loss: 0.4876 - val_acc: 0.8004\n",
      "Epoch 139/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4139 - acc: 0.8257 - val_loss: 0.4869 - val_acc: 0.7999\n",
      "Epoch 140/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4130 - acc: 0.8257 - val_loss: 0.4856 - val_acc: 0.8009\n",
      "Epoch 141/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4126 - acc: 0.8263 - val_loss: 0.4870 - val_acc: 0.7996\n",
      "Epoch 142/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.4117 - acc: 0.8268 - val_loss: 0.4883 - val_acc: 0.7998\n",
      "Epoch 143/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4106 - acc: 0.8274 - val_loss: 0.4879 - val_acc: 0.8012\n",
      "Epoch 144/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4095 - acc: 0.8278 - val_loss: 0.4898 - val_acc: 0.8007\n",
      "Epoch 145/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4095 - acc: 0.8276 - val_loss: 0.4882 - val_acc: 0.8003\n",
      "Epoch 146/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4083 - acc: 0.8281 - val_loss: 0.4897 - val_acc: 0.7993\n",
      "Epoch 147/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4074 - acc: 0.8291 - val_loss: 0.4895 - val_acc: 0.7998\n",
      "Epoch 148/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4059 - acc: 0.8298 - val_loss: 0.4913 - val_acc: 0.7989\n",
      "Epoch 149/800\n",
      "230116/230116 [==============================] - 13s 57us/step - loss: 0.4050 - acc: 0.8298 - val_loss: 0.4919 - val_acc: 0.7993\n",
      "Epoch 150/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4036 - acc: 0.8298 - val_loss: 0.4933 - val_acc: 0.7979\n",
      "Epoch 151/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.4034 - acc: 0.8313 - val_loss: 0.4930 - val_acc: 0.7992\n",
      "Epoch 152/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.4019 - acc: 0.8313 - val_loss: 0.4923 - val_acc: 0.7991\n",
      "Epoch 153/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.4008 - acc: 0.8320 - val_loss: 0.4951 - val_acc: 0.7997\n",
      "Epoch 154/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4016 - acc: 0.8315 - val_loss: 0.4954 - val_acc: 0.7986\n",
      "Epoch 155/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.4001 - acc: 0.8322 - val_loss: 0.4932 - val_acc: 0.7987\n",
      "Epoch 156/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3987 - acc: 0.8327 - val_loss: 0.4943 - val_acc: 0.7982\n",
      "Epoch 157/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3983 - acc: 0.8334 - val_loss: 0.4955 - val_acc: 0.7996\n",
      "Epoch 158/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3977 - acc: 0.8330 - val_loss: 0.4946 - val_acc: 0.8005\n",
      "Epoch 159/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3960 - acc: 0.8335 - val_loss: 0.4967 - val_acc: 0.8000\n",
      "Epoch 160/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3958 - acc: 0.8335 - val_loss: 0.5001 - val_acc: 0.7973\n",
      "Epoch 161/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3945 - acc: 0.8340 - val_loss: 0.4976 - val_acc: 0.7992\n",
      "Epoch 162/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3931 - acc: 0.8353 - val_loss: 0.4999 - val_acc: 0.7980\n",
      "Epoch 163/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3924 - acc: 0.8355 - val_loss: 0.4987 - val_acc: 0.7995\n",
      "Epoch 164/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3914 - acc: 0.8354 - val_loss: 0.4994 - val_acc: 0.7994\n",
      "Epoch 165/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3910 - acc: 0.8355 - val_loss: 0.4995 - val_acc: 0.7987\n",
      "Epoch 166/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3911 - acc: 0.8357 - val_loss: 0.4997 - val_acc: 0.7982\n",
      "Epoch 167/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3902 - acc: 0.8364 - val_loss: 0.4998 - val_acc: 0.7983\n",
      "Epoch 168/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3889 - acc: 0.8368 - val_loss: 0.5018 - val_acc: 0.7988\n",
      "Epoch 169/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3875 - acc: 0.8379 - val_loss: 0.4996 - val_acc: 0.7971\n",
      "Epoch 170/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3858 - acc: 0.8385 - val_loss: 0.5028 - val_acc: 0.7975\n",
      "Epoch 171/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3865 - acc: 0.8383 - val_loss: 0.5033 - val_acc: 0.7982\n",
      "Epoch 172/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3845 - acc: 0.8386 - val_loss: 0.5056 - val_acc: 0.7981\n",
      "Epoch 173/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3844 - acc: 0.8382 - val_loss: 0.5070 - val_acc: 0.7975\n",
      "Epoch 174/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3833 - acc: 0.8390 - val_loss: 0.5057 - val_acc: 0.7972\n",
      "Epoch 175/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3825 - acc: 0.8396 - val_loss: 0.5086 - val_acc: 0.7975\n",
      "Epoch 176/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3817 - acc: 0.8395 - val_loss: 0.5079 - val_acc: 0.7963\n",
      "Epoch 177/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3804 - acc: 0.8405 - val_loss: 0.5108 - val_acc: 0.7964\n",
      "Epoch 178/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3804 - acc: 0.8406 - val_loss: 0.5140 - val_acc: 0.7965\n",
      "Epoch 179/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3783 - acc: 0.8419 - val_loss: 0.5135 - val_acc: 0.7982\n",
      "Epoch 180/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3774 - acc: 0.8419 - val_loss: 0.5095 - val_acc: 0.7972\n",
      "Epoch 181/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3776 - acc: 0.8417 - val_loss: 0.5102 - val_acc: 0.7970\n",
      "Epoch 182/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3758 - acc: 0.8431 - val_loss: 0.5106 - val_acc: 0.7972\n",
      "Epoch 183/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3762 - acc: 0.8434 - val_loss: 0.5120 - val_acc: 0.7965\n",
      "Epoch 184/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3742 - acc: 0.8438 - val_loss: 0.5145 - val_acc: 0.7979\n",
      "Epoch 185/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3746 - acc: 0.8436 - val_loss: 0.5113 - val_acc: 0.7971\n",
      "Epoch 186/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3725 - acc: 0.8444 - val_loss: 0.5131 - val_acc: 0.7950\n",
      "Epoch 187/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3716 - acc: 0.8451 - val_loss: 0.5167 - val_acc: 0.7975\n",
      "Epoch 188/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3713 - acc: 0.8450 - val_loss: 0.5163 - val_acc: 0.7953\n",
      "Epoch 189/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3702 - acc: 0.8455 - val_loss: 0.5137 - val_acc: 0.7960\n",
      "Epoch 190/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3693 - acc: 0.8457 - val_loss: 0.5177 - val_acc: 0.7969\n",
      "Epoch 191/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3683 - acc: 0.8465 - val_loss: 0.5186 - val_acc: 0.7977\n",
      "Epoch 192/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3674 - acc: 0.8467 - val_loss: 0.5230 - val_acc: 0.7963\n",
      "Epoch 193/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3676 - acc: 0.8463 - val_loss: 0.5186 - val_acc: 0.7954\n",
      "Epoch 194/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3666 - acc: 0.8469 - val_loss: 0.5159 - val_acc: 0.7965\n",
      "Epoch 195/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3646 - acc: 0.8477 - val_loss: 0.5208 - val_acc: 0.7962\n",
      "Epoch 196/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3649 - acc: 0.8472 - val_loss: 0.5198 - val_acc: 0.7957\n",
      "Epoch 197/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3643 - acc: 0.8479 - val_loss: 0.5171 - val_acc: 0.7960\n",
      "Epoch 198/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3630 - acc: 0.8483 - val_loss: 0.5243 - val_acc: 0.7962\n",
      "Epoch 199/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3616 - acc: 0.8487 - val_loss: 0.5242 - val_acc: 0.7960\n",
      "Epoch 200/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3614 - acc: 0.8493 - val_loss: 0.5214 - val_acc: 0.7951\n",
      "Epoch 201/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3595 - acc: 0.8503 - val_loss: 0.5249 - val_acc: 0.7949\n",
      "Epoch 202/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3585 - acc: 0.8508 - val_loss: 0.5261 - val_acc: 0.7940\n",
      "Epoch 203/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3577 - acc: 0.8506 - val_loss: 0.5286 - val_acc: 0.7929\n",
      "Epoch 204/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3581 - acc: 0.8510 - val_loss: 0.5267 - val_acc: 0.7963\n",
      "Epoch 205/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3575 - acc: 0.8508 - val_loss: 0.5272 - val_acc: 0.7948\n",
      "Epoch 206/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3555 - acc: 0.8517 - val_loss: 0.5322 - val_acc: 0.7958\n",
      "Epoch 207/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3556 - acc: 0.8516 - val_loss: 0.5291 - val_acc: 0.7939\n",
      "Epoch 208/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3548 - acc: 0.8528 - val_loss: 0.5296 - val_acc: 0.7927\n",
      "Epoch 209/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3542 - acc: 0.8521 - val_loss: 0.5330 - val_acc: 0.7926\n",
      "Epoch 210/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3535 - acc: 0.8526 - val_loss: 0.5361 - val_acc: 0.7921\n",
      "Epoch 211/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3516 - acc: 0.8532 - val_loss: 0.5359 - val_acc: 0.7945\n",
      "Epoch 212/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3526 - acc: 0.8530 - val_loss: 0.5379 - val_acc: 0.7944\n",
      "Epoch 213/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3507 - acc: 0.8540 - val_loss: 0.5343 - val_acc: 0.7939\n",
      "Epoch 214/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3497 - acc: 0.8546 - val_loss: 0.5380 - val_acc: 0.7923\n",
      "Epoch 215/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3490 - acc: 0.8548 - val_loss: 0.5401 - val_acc: 0.7933\n",
      "Epoch 216/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3480 - acc: 0.8555 - val_loss: 0.5408 - val_acc: 0.7919\n",
      "Epoch 217/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3470 - acc: 0.8557 - val_loss: 0.5412 - val_acc: 0.7931\n",
      "Epoch 218/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3456 - acc: 0.8559 - val_loss: 0.5413 - val_acc: 0.7929\n",
      "Epoch 219/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3452 - acc: 0.8564 - val_loss: 0.5411 - val_acc: 0.7921\n",
      "Epoch 220/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3438 - acc: 0.8563 - val_loss: 0.5414 - val_acc: 0.7925\n",
      "Epoch 221/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3432 - acc: 0.8570 - val_loss: 0.5422 - val_acc: 0.7952\n",
      "Epoch 222/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3421 - acc: 0.8578 - val_loss: 0.5447 - val_acc: 0.7935\n",
      "Epoch 223/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3420 - acc: 0.8577 - val_loss: 0.5474 - val_acc: 0.7931\n",
      "Epoch 224/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3416 - acc: 0.8583 - val_loss: 0.5505 - val_acc: 0.7933\n",
      "Epoch 225/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3410 - acc: 0.8581 - val_loss: 0.5463 - val_acc: 0.7918\n",
      "Epoch 226/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3397 - acc: 0.8593 - val_loss: 0.5487 - val_acc: 0.7932\n",
      "Epoch 227/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3406 - acc: 0.8586 - val_loss: 0.5482 - val_acc: 0.7929\n",
      "Epoch 228/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3386 - acc: 0.8600 - val_loss: 0.5495 - val_acc: 0.7938\n",
      "Epoch 229/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3373 - acc: 0.8594 - val_loss: 0.5519 - val_acc: 0.7914\n",
      "Epoch 230/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3366 - acc: 0.8606 - val_loss: 0.5520 - val_acc: 0.7921\n",
      "Epoch 231/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3360 - acc: 0.8603 - val_loss: 0.5539 - val_acc: 0.7917\n",
      "Epoch 232/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3354 - acc: 0.8611 - val_loss: 0.5530 - val_acc: 0.7891\n",
      "Epoch 233/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3344 - acc: 0.8609 - val_loss: 0.5505 - val_acc: 0.7921\n",
      "Epoch 234/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3344 - acc: 0.8613 - val_loss: 0.5556 - val_acc: 0.7929\n",
      "Epoch 235/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3317 - acc: 0.8623 - val_loss: 0.5575 - val_acc: 0.7908\n",
      "Epoch 236/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3313 - acc: 0.8623 - val_loss: 0.5550 - val_acc: 0.7900\n",
      "Epoch 237/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3318 - acc: 0.8621 - val_loss: 0.5524 - val_acc: 0.7911\n",
      "Epoch 238/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3299 - acc: 0.8627 - val_loss: 0.5555 - val_acc: 0.7933\n",
      "Epoch 239/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3290 - acc: 0.8631 - val_loss: 0.5593 - val_acc: 0.7903\n",
      "Epoch 240/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3287 - acc: 0.8639 - val_loss: 0.5642 - val_acc: 0.7919\n",
      "Epoch 241/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3271 - acc: 0.8652 - val_loss: 0.5667 - val_acc: 0.7901\n",
      "Epoch 242/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3271 - acc: 0.8643 - val_loss: 0.5640 - val_acc: 0.7903\n",
      "Epoch 243/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3276 - acc: 0.8642 - val_loss: 0.5622 - val_acc: 0.7911\n",
      "Epoch 244/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3252 - acc: 0.8659 - val_loss: 0.5645 - val_acc: 0.7902\n",
      "Epoch 245/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3255 - acc: 0.8648 - val_loss: 0.5686 - val_acc: 0.7921\n",
      "Epoch 246/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3234 - acc: 0.8664 - val_loss: 0.5683 - val_acc: 0.7927\n",
      "Epoch 247/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3226 - acc: 0.8666 - val_loss: 0.5699 - val_acc: 0.7916\n",
      "Epoch 248/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3221 - acc: 0.8669 - val_loss: 0.5699 - val_acc: 0.7902\n",
      "Epoch 249/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3218 - acc: 0.8673 - val_loss: 0.5728 - val_acc: 0.7918\n",
      "Epoch 250/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3203 - acc: 0.8669 - val_loss: 0.5718 - val_acc: 0.7904\n",
      "Epoch 251/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3205 - acc: 0.8674 - val_loss: 0.5748 - val_acc: 0.7911\n",
      "Epoch 252/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3187 - acc: 0.8679 - val_loss: 0.5731 - val_acc: 0.7895\n",
      "Epoch 253/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3201 - acc: 0.8669 - val_loss: 0.5754 - val_acc: 0.7912\n",
      "Epoch 254/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3183 - acc: 0.8683 - val_loss: 0.5728 - val_acc: 0.7911\n",
      "Epoch 255/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3171 - acc: 0.8686 - val_loss: 0.5764 - val_acc: 0.7896\n",
      "Epoch 256/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3161 - acc: 0.8693 - val_loss: 0.5800 - val_acc: 0.7887\n",
      "Epoch 257/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3156 - acc: 0.8692 - val_loss: 0.5765 - val_acc: 0.7898\n",
      "Epoch 258/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3152 - acc: 0.8699 - val_loss: 0.5795 - val_acc: 0.7909\n",
      "Epoch 259/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3148 - acc: 0.8702 - val_loss: 0.5779 - val_acc: 0.7888\n",
      "Epoch 260/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3137 - acc: 0.8705 - val_loss: 0.5821 - val_acc: 0.7891\n",
      "Epoch 261/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3147 - acc: 0.8699 - val_loss: 0.5781 - val_acc: 0.7899\n",
      "Epoch 262/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3121 - acc: 0.8709 - val_loss: 0.5821 - val_acc: 0.7887\n",
      "Epoch 263/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3113 - acc: 0.8719 - val_loss: 0.5812 - val_acc: 0.7891\n",
      "Epoch 264/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3111 - acc: 0.8720 - val_loss: 0.5869 - val_acc: 0.7904\n",
      "Epoch 265/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3116 - acc: 0.8718 - val_loss: 0.5864 - val_acc: 0.7893\n",
      "Epoch 266/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3086 - acc: 0.8729 - val_loss: 0.5935 - val_acc: 0.7892\n",
      "Epoch 267/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3091 - acc: 0.8718 - val_loss: 0.5905 - val_acc: 0.7868\n",
      "Epoch 268/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3076 - acc: 0.8735 - val_loss: 0.5906 - val_acc: 0.7890\n",
      "Epoch 269/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3081 - acc: 0.8733 - val_loss: 0.5893 - val_acc: 0.7885\n",
      "Epoch 270/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3065 - acc: 0.8735 - val_loss: 0.5926 - val_acc: 0.7885\n",
      "Epoch 271/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3061 - acc: 0.8741 - val_loss: 0.5918 - val_acc: 0.7898\n",
      "Epoch 272/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3058 - acc: 0.8743 - val_loss: 0.5988 - val_acc: 0.7868\n",
      "Epoch 273/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3040 - acc: 0.8750 - val_loss: 0.5937 - val_acc: 0.7901\n",
      "Epoch 274/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3034 - acc: 0.8746 - val_loss: 0.5968 - val_acc: 0.7869\n",
      "Epoch 275/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.3028 - acc: 0.8749 - val_loss: 0.5991 - val_acc: 0.7885\n",
      "Epoch 276/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3031 - acc: 0.8745 - val_loss: 0.5975 - val_acc: 0.7863\n",
      "Epoch 277/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3025 - acc: 0.8761 - val_loss: 0.6014 - val_acc: 0.7871\n",
      "Epoch 278/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3017 - acc: 0.8754 - val_loss: 0.6025 - val_acc: 0.7897\n",
      "Epoch 279/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.3019 - acc: 0.8763 - val_loss: 0.5996 - val_acc: 0.7877\n",
      "Epoch 280/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2995 - acc: 0.8772 - val_loss: 0.6019 - val_acc: 0.7883\n",
      "Epoch 281/800\n",
      "230116/230116 [==============================] - 13s 56us/step - loss: 0.2986 - acc: 0.8768 - val_loss: 0.6117 - val_acc: 0.7872\n",
      "Epoch 282/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2974 - acc: 0.8780 - val_loss: 0.6124 - val_acc: 0.7893\n",
      "Epoch 283/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2980 - acc: 0.8776 - val_loss: 0.6024 - val_acc: 0.7861\n",
      "Epoch 284/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2964 - acc: 0.8782 - val_loss: 0.6094 - val_acc: 0.7876\n",
      "Epoch 285/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2962 - acc: 0.8779 - val_loss: 0.6152 - val_acc: 0.7881\n",
      "Epoch 286/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2982 - acc: 0.8775 - val_loss: 0.6028 - val_acc: 0.7877\n",
      "Epoch 287/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2955 - acc: 0.8773 - val_loss: 0.6121 - val_acc: 0.7876\n",
      "Epoch 288/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2946 - acc: 0.8796 - val_loss: 0.6113 - val_acc: 0.7873\n",
      "Epoch 289/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2923 - acc: 0.8797 - val_loss: 0.6213 - val_acc: 0.7887\n",
      "Epoch 290/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2951 - acc: 0.8788 - val_loss: 0.6134 - val_acc: 0.7860\n",
      "Epoch 291/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2915 - acc: 0.8800 - val_loss: 0.6147 - val_acc: 0.7876\n",
      "Epoch 292/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2907 - acc: 0.8804 - val_loss: 0.6150 - val_acc: 0.7874\n",
      "Epoch 293/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2898 - acc: 0.8809 - val_loss: 0.6187 - val_acc: 0.7873\n",
      "Epoch 294/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2896 - acc: 0.8812 - val_loss: 0.6151 - val_acc: 0.7863\n",
      "Epoch 295/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2895 - acc: 0.8809 - val_loss: 0.6200 - val_acc: 0.7882\n",
      "Epoch 296/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2891 - acc: 0.8813 - val_loss: 0.6175 - val_acc: 0.7872\n",
      "Epoch 297/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2874 - acc: 0.8811 - val_loss: 0.6233 - val_acc: 0.7866\n",
      "Epoch 298/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2880 - acc: 0.8818 - val_loss: 0.6195 - val_acc: 0.7859\n",
      "Epoch 299/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2870 - acc: 0.8825 - val_loss: 0.6190 - val_acc: 0.7870\n",
      "Epoch 300/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2867 - acc: 0.8817 - val_loss: 0.6216 - val_acc: 0.7878\n",
      "Epoch 301/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2846 - acc: 0.8837 - val_loss: 0.6244 - val_acc: 0.7865\n",
      "Epoch 302/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2854 - acc: 0.8829 - val_loss: 0.6270 - val_acc: 0.7848\n",
      "Epoch 303/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2857 - acc: 0.8821 - val_loss: 0.6213 - val_acc: 0.7864\n",
      "Epoch 304/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2833 - acc: 0.8835 - val_loss: 0.6259 - val_acc: 0.7850\n",
      "Epoch 305/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2840 - acc: 0.8835 - val_loss: 0.6230 - val_acc: 0.7870\n",
      "Epoch 306/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2825 - acc: 0.8851 - val_loss: 0.6298 - val_acc: 0.7858\n",
      "Epoch 307/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2810 - acc: 0.8856 - val_loss: 0.6399 - val_acc: 0.7852\n",
      "Epoch 308/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2822 - acc: 0.8846 - val_loss: 0.6330 - val_acc: 0.7837\n",
      "Epoch 309/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2804 - acc: 0.8855 - val_loss: 0.6360 - val_acc: 0.7845\n",
      "Epoch 310/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2803 - acc: 0.8853 - val_loss: 0.6361 - val_acc: 0.7874\n",
      "Epoch 311/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2797 - acc: 0.8850 - val_loss: 0.6361 - val_acc: 0.7852\n",
      "Epoch 312/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2787 - acc: 0.8859 - val_loss: 0.6361 - val_acc: 0.7870\n",
      "Epoch 313/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2805 - acc: 0.8850 - val_loss: 0.6381 - val_acc: 0.7850\n",
      "Epoch 314/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2784 - acc: 0.8854 - val_loss: 0.6345 - val_acc: 0.7859\n",
      "Epoch 315/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2781 - acc: 0.8860 - val_loss: 0.6359 - val_acc: 0.7856\n",
      "Epoch 316/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2769 - acc: 0.8867 - val_loss: 0.6386 - val_acc: 0.7865\n",
      "Epoch 317/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2761 - acc: 0.8874 - val_loss: 0.6400 - val_acc: 0.7837\n",
      "Epoch 318/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2746 - acc: 0.8879 - val_loss: 0.6454 - val_acc: 0.7862\n",
      "Epoch 319/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2753 - acc: 0.8882 - val_loss: 0.6425 - val_acc: 0.7840\n",
      "Epoch 320/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2747 - acc: 0.8873 - val_loss: 0.6411 - val_acc: 0.7846\n",
      "Epoch 321/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2723 - acc: 0.8884 - val_loss: 0.6549 - val_acc: 0.7866\n",
      "Epoch 322/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2731 - acc: 0.8882 - val_loss: 0.6513 - val_acc: 0.7847\n",
      "Epoch 323/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2736 - acc: 0.8882 - val_loss: 0.6471 - val_acc: 0.7856\n",
      "Epoch 324/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2719 - acc: 0.8894 - val_loss: 0.6531 - val_acc: 0.7859\n",
      "Epoch 325/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2726 - acc: 0.8882 - val_loss: 0.6513 - val_acc: 0.7838\n",
      "Epoch 326/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2700 - acc: 0.8899 - val_loss: 0.6490 - val_acc: 0.7848\n",
      "Epoch 327/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2703 - acc: 0.8898 - val_loss: 0.6472 - val_acc: 0.7843\n",
      "Epoch 328/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2681 - acc: 0.8905 - val_loss: 0.6513 - val_acc: 0.7840\n",
      "Epoch 329/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2686 - acc: 0.8899 - val_loss: 0.6499 - val_acc: 0.7842\n",
      "Epoch 330/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2682 - acc: 0.8903 - val_loss: 0.6574 - val_acc: 0.7848\n",
      "Epoch 331/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2690 - acc: 0.8904 - val_loss: 0.6631 - val_acc: 0.7848\n",
      "Epoch 332/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2686 - acc: 0.8897 - val_loss: 0.6598 - val_acc: 0.7857\n",
      "Epoch 333/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2651 - acc: 0.8915 - val_loss: 0.6618 - val_acc: 0.7845\n",
      "Epoch 334/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2656 - acc: 0.8917 - val_loss: 0.6629 - val_acc: 0.7837\n",
      "Epoch 335/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2634 - acc: 0.8931 - val_loss: 0.6635 - val_acc: 0.7857\n",
      "Epoch 336/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2642 - acc: 0.8927 - val_loss: 0.6646 - val_acc: 0.7852\n",
      "Epoch 337/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2643 - acc: 0.8922 - val_loss: 0.6664 - val_acc: 0.7843\n",
      "Epoch 338/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2643 - acc: 0.8917 - val_loss: 0.6632 - val_acc: 0.7844\n",
      "Epoch 339/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2631 - acc: 0.8927 - val_loss: 0.6685 - val_acc: 0.7840\n",
      "Epoch 340/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2635 - acc: 0.8930 - val_loss: 0.6648 - val_acc: 0.7837\n",
      "Epoch 341/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2626 - acc: 0.8931 - val_loss: 0.6678 - val_acc: 0.7850\n",
      "Epoch 342/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2629 - acc: 0.8928 - val_loss: 0.6663 - val_acc: 0.7837\n",
      "Epoch 343/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2625 - acc: 0.8930 - val_loss: 0.6726 - val_acc: 0.7835\n",
      "Epoch 344/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2619 - acc: 0.8929 - val_loss: 0.6633 - val_acc: 0.7836\n",
      "Epoch 345/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2589 - acc: 0.8945 - val_loss: 0.6748 - val_acc: 0.7849\n",
      "Epoch 346/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2595 - acc: 0.8942 - val_loss: 0.6787 - val_acc: 0.7840\n",
      "Epoch 347/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2586 - acc: 0.8946 - val_loss: 0.6678 - val_acc: 0.7833\n",
      "Epoch 348/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2594 - acc: 0.8947 - val_loss: 0.6703 - val_acc: 0.7848\n",
      "Epoch 349/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2576 - acc: 0.8948 - val_loss: 0.6700 - val_acc: 0.7837\n",
      "Epoch 350/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2574 - acc: 0.8956 - val_loss: 0.6714 - val_acc: 0.7828\n",
      "Epoch 351/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2565 - acc: 0.8952 - val_loss: 0.6769 - val_acc: 0.7837\n",
      "Epoch 352/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2582 - acc: 0.8950 - val_loss: 0.6774 - val_acc: 0.7828\n",
      "Epoch 353/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2583 - acc: 0.8949 - val_loss: 0.6805 - val_acc: 0.7832\n",
      "Epoch 354/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2556 - acc: 0.8962 - val_loss: 0.6798 - val_acc: 0.7834\n",
      "Epoch 355/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2560 - acc: 0.8963 - val_loss: 0.6804 - val_acc: 0.7836\n",
      "Epoch 356/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2548 - acc: 0.8965 - val_loss: 0.6805 - val_acc: 0.7832\n",
      "Epoch 357/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2570 - acc: 0.8951 - val_loss: 0.6778 - val_acc: 0.7847\n",
      "Epoch 358/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2544 - acc: 0.8966 - val_loss: 0.6824 - val_acc: 0.7829\n",
      "Epoch 359/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2530 - acc: 0.8967 - val_loss: 0.6773 - val_acc: 0.7830\n",
      "Epoch 360/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2538 - acc: 0.8969 - val_loss: 0.6893 - val_acc: 0.7828\n",
      "Epoch 361/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2519 - acc: 0.8974 - val_loss: 0.6864 - val_acc: 0.7820\n",
      "Epoch 362/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2523 - acc: 0.8976 - val_loss: 0.6827 - val_acc: 0.7829\n",
      "Epoch 363/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2513 - acc: 0.8981 - val_loss: 0.6890 - val_acc: 0.7829\n",
      "Epoch 364/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2502 - acc: 0.8988 - val_loss: 0.6833 - val_acc: 0.7829\n",
      "Epoch 365/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2499 - acc: 0.8987 - val_loss: 0.6879 - val_acc: 0.7842\n",
      "Epoch 366/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2502 - acc: 0.8985 - val_loss: 0.6893 - val_acc: 0.7835\n",
      "Epoch 367/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2512 - acc: 0.8980 - val_loss: 0.6881 - val_acc: 0.7828\n",
      "Epoch 368/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2499 - acc: 0.8990 - val_loss: 0.6862 - val_acc: 0.7829\n",
      "Epoch 369/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2501 - acc: 0.8988 - val_loss: 0.6996 - val_acc: 0.7822\n",
      "Epoch 370/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2491 - acc: 0.8992 - val_loss: 0.6862 - val_acc: 0.7852\n",
      "Epoch 371/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2488 - acc: 0.8988 - val_loss: 0.6876 - val_acc: 0.7842\n",
      "Epoch 372/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2482 - acc: 0.8991 - val_loss: 0.6895 - val_acc: 0.7818\n",
      "Epoch 373/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2465 - acc: 0.8998 - val_loss: 0.6951 - val_acc: 0.7842\n",
      "Epoch 374/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2482 - acc: 0.8993 - val_loss: 0.6878 - val_acc: 0.7823\n",
      "Epoch 375/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2447 - acc: 0.9011 - val_loss: 0.6929 - val_acc: 0.7844\n",
      "Epoch 376/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2457 - acc: 0.9001 - val_loss: 0.6965 - val_acc: 0.7830\n",
      "Epoch 377/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2448 - acc: 0.9010 - val_loss: 0.6983 - val_acc: 0.7814\n",
      "Epoch 378/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2453 - acc: 0.9009 - val_loss: 0.6983 - val_acc: 0.7841\n",
      "Epoch 379/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2450 - acc: 0.9003 - val_loss: 0.6989 - val_acc: 0.7837\n",
      "Epoch 380/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2438 - acc: 0.9011 - val_loss: 0.7002 - val_acc: 0.7821\n",
      "Epoch 381/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2435 - acc: 0.9012 - val_loss: 0.7056 - val_acc: 0.7842\n",
      "Epoch 382/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2436 - acc: 0.9010 - val_loss: 0.6967 - val_acc: 0.7826\n",
      "Epoch 383/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2409 - acc: 0.9031 - val_loss: 0.7050 - val_acc: 0.7821\n",
      "Epoch 384/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2419 - acc: 0.9016 - val_loss: 0.7016 - val_acc: 0.7821\n",
      "Epoch 385/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2407 - acc: 0.9020 - val_loss: 0.6993 - val_acc: 0.7812\n",
      "Epoch 386/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2404 - acc: 0.9029 - val_loss: 0.7033 - val_acc: 0.7833\n",
      "Epoch 387/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2421 - acc: 0.9022 - val_loss: 0.7054 - val_acc: 0.7831\n",
      "Epoch 388/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2401 - acc: 0.9023 - val_loss: 0.7038 - val_acc: 0.7801\n",
      "Epoch 389/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2408 - acc: 0.9019 - val_loss: 0.7085 - val_acc: 0.7820\n",
      "Epoch 390/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2409 - acc: 0.9022 - val_loss: 0.7017 - val_acc: 0.7822\n",
      "Epoch 391/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2402 - acc: 0.9028 - val_loss: 0.7058 - val_acc: 0.7819\n",
      "Epoch 392/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2389 - acc: 0.9032 - val_loss: 0.7073 - val_acc: 0.7813\n",
      "Epoch 393/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2380 - acc: 0.9037 - val_loss: 0.7124 - val_acc: 0.7821\n",
      "Epoch 394/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2382 - acc: 0.9033 - val_loss: 0.7103 - val_acc: 0.7802\n",
      "Epoch 395/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2387 - acc: 0.9039 - val_loss: 0.7116 - val_acc: 0.7814\n",
      "Epoch 396/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2379 - acc: 0.9031 - val_loss: 0.7117 - val_acc: 0.7824\n",
      "Epoch 397/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2368 - acc: 0.9043 - val_loss: 0.7086 - val_acc: 0.7825\n",
      "Epoch 398/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2367 - acc: 0.9038 - val_loss: 0.7127 - val_acc: 0.7825\n",
      "Epoch 399/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2366 - acc: 0.9044 - val_loss: 0.7140 - val_acc: 0.7835\n",
      "Epoch 400/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2370 - acc: 0.9035 - val_loss: 0.7132 - val_acc: 0.7820\n",
      "Epoch 401/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2342 - acc: 0.9051 - val_loss: 0.7140 - val_acc: 0.7816\n",
      "Epoch 402/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2366 - acc: 0.9039 - val_loss: 0.7173 - val_acc: 0.7816\n",
      "Epoch 403/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2327 - acc: 0.9060 - val_loss: 0.7196 - val_acc: 0.7820\n",
      "Epoch 404/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2327 - acc: 0.9054 - val_loss: 0.7156 - val_acc: 0.7806\n",
      "Epoch 405/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2327 - acc: 0.9062 - val_loss: 0.7185 - val_acc: 0.7806\n",
      "Epoch 406/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2337 - acc: 0.9055 - val_loss: 0.7202 - val_acc: 0.7818\n",
      "Epoch 407/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2331 - acc: 0.9062 - val_loss: 0.7210 - val_acc: 0.7824\n",
      "Epoch 408/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2323 - acc: 0.9065 - val_loss: 0.7168 - val_acc: 0.7814\n",
      "Epoch 409/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2323 - acc: 0.9058 - val_loss: 0.7234 - val_acc: 0.7820\n",
      "Epoch 410/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2310 - acc: 0.9068 - val_loss: 0.7203 - val_acc: 0.7816\n",
      "Epoch 411/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2317 - acc: 0.9067 - val_loss: 0.7286 - val_acc: 0.7821\n",
      "Epoch 412/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2295 - acc: 0.9072 - val_loss: 0.7196 - val_acc: 0.7802\n",
      "Epoch 413/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2302 - acc: 0.9078 - val_loss: 0.7250 - val_acc: 0.7795\n",
      "Epoch 414/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2303 - acc: 0.9071 - val_loss: 0.7181 - val_acc: 0.7804\n",
      "Epoch 415/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2292 - acc: 0.9068 - val_loss: 0.7278 - val_acc: 0.7813\n",
      "Epoch 416/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2304 - acc: 0.9077 - val_loss: 0.7235 - val_acc: 0.7819\n",
      "Epoch 417/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2291 - acc: 0.9077 - val_loss: 0.7300 - val_acc: 0.7802\n",
      "Epoch 418/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2290 - acc: 0.9079 - val_loss: 0.7249 - val_acc: 0.7801\n",
      "Epoch 419/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2277 - acc: 0.9084 - val_loss: 0.7263 - val_acc: 0.7815\n",
      "Epoch 420/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2273 - acc: 0.9090 - val_loss: 0.7281 - val_acc: 0.7803\n",
      "Epoch 421/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2259 - acc: 0.9089 - val_loss: 0.7358 - val_acc: 0.7817\n",
      "Epoch 422/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2274 - acc: 0.9087 - val_loss: 0.7341 - val_acc: 0.7816\n",
      "Epoch 423/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2253 - acc: 0.9093 - val_loss: 0.7400 - val_acc: 0.7826\n",
      "Epoch 424/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2255 - acc: 0.9093 - val_loss: 0.7339 - val_acc: 0.7801\n",
      "Epoch 425/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2277 - acc: 0.9080 - val_loss: 0.7301 - val_acc: 0.7803\n",
      "Epoch 426/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2242 - acc: 0.9094 - val_loss: 0.7373 - val_acc: 0.7790\n",
      "Epoch 427/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2242 - acc: 0.9094 - val_loss: 0.7384 - val_acc: 0.7818\n",
      "Epoch 428/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2254 - acc: 0.9087 - val_loss: 0.7288 - val_acc: 0.7805\n",
      "Epoch 429/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2249 - acc: 0.9099 - val_loss: 0.7366 - val_acc: 0.7814\n",
      "Epoch 430/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2250 - acc: 0.9091 - val_loss: 0.7301 - val_acc: 0.7799\n",
      "Epoch 431/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2247 - acc: 0.9098 - val_loss: 0.7419 - val_acc: 0.7815\n",
      "Epoch 432/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2222 - acc: 0.9109 - val_loss: 0.7355 - val_acc: 0.7788\n",
      "Epoch 433/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2237 - acc: 0.9107 - val_loss: 0.7399 - val_acc: 0.7804\n",
      "Epoch 434/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2229 - acc: 0.9105 - val_loss: 0.7415 - val_acc: 0.7793\n",
      "Epoch 435/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2235 - acc: 0.9097 - val_loss: 0.7440 - val_acc: 0.7816\n",
      "Epoch 436/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2226 - acc: 0.9101 - val_loss: 0.7452 - val_acc: 0.7809\n",
      "Epoch 437/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2214 - acc: 0.9112 - val_loss: 0.7427 - val_acc: 0.7802\n",
      "Epoch 438/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2218 - acc: 0.9107 - val_loss: 0.7454 - val_acc: 0.7821\n",
      "Epoch 439/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2219 - acc: 0.9110 - val_loss: 0.7488 - val_acc: 0.7803\n",
      "Epoch 440/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2209 - acc: 0.9119 - val_loss: 0.7409 - val_acc: 0.7805\n",
      "Epoch 441/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2206 - acc: 0.9113 - val_loss: 0.7446 - val_acc: 0.7797\n",
      "Epoch 442/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2202 - acc: 0.9116 - val_loss: 0.7437 - val_acc: 0.7798\n",
      "Epoch 443/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2193 - acc: 0.9121 - val_loss: 0.7494 - val_acc: 0.7803\n",
      "Epoch 444/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2183 - acc: 0.9127 - val_loss: 0.7457 - val_acc: 0.7799\n",
      "Epoch 445/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2193 - acc: 0.9120 - val_loss: 0.7440 - val_acc: 0.7778\n",
      "Epoch 446/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2194 - acc: 0.9123 - val_loss: 0.7448 - val_acc: 0.7801\n",
      "Epoch 447/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2188 - acc: 0.9130 - val_loss: 0.7500 - val_acc: 0.7798\n",
      "Epoch 448/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2176 - acc: 0.9128 - val_loss: 0.7519 - val_acc: 0.7798\n",
      "Epoch 449/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2179 - acc: 0.9130 - val_loss: 0.7560 - val_acc: 0.7812\n",
      "Epoch 450/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2190 - acc: 0.9123 - val_loss: 0.7546 - val_acc: 0.7804\n",
      "Epoch 451/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2166 - acc: 0.9134 - val_loss: 0.7484 - val_acc: 0.7802\n",
      "Epoch 452/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2160 - acc: 0.9136 - val_loss: 0.7558 - val_acc: 0.7791\n",
      "Epoch 453/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2167 - acc: 0.9135 - val_loss: 0.7526 - val_acc: 0.7782\n",
      "Epoch 454/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2168 - acc: 0.9134 - val_loss: 0.7572 - val_acc: 0.7814\n",
      "Epoch 455/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2150 - acc: 0.9136 - val_loss: 0.7560 - val_acc: 0.7809\n",
      "Epoch 456/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2175 - acc: 0.9131 - val_loss: 0.7584 - val_acc: 0.7801\n",
      "Epoch 457/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2155 - acc: 0.9133 - val_loss: 0.7652 - val_acc: 0.7812\n",
      "Epoch 458/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2148 - acc: 0.9140 - val_loss: 0.7572 - val_acc: 0.7797\n",
      "Epoch 459/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2149 - acc: 0.9146 - val_loss: 0.7546 - val_acc: 0.7792\n",
      "Epoch 460/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2125 - acc: 0.9146 - val_loss: 0.7639 - val_acc: 0.7800\n",
      "Epoch 461/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2124 - acc: 0.9151 - val_loss: 0.7702 - val_acc: 0.7797\n",
      "Epoch 462/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2135 - acc: 0.9148 - val_loss: 0.7688 - val_acc: 0.7816\n",
      "Epoch 463/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2127 - acc: 0.9148 - val_loss: 0.7645 - val_acc: 0.7807\n",
      "Epoch 464/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2136 - acc: 0.9145 - val_loss: 0.7591 - val_acc: 0.7806\n",
      "Epoch 465/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2140 - acc: 0.9141 - val_loss: 0.7591 - val_acc: 0.7791\n",
      "Epoch 466/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2121 - acc: 0.9149 - val_loss: 0.7603 - val_acc: 0.7799\n",
      "Epoch 467/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2124 - acc: 0.9152 - val_loss: 0.7624 - val_acc: 0.7792\n",
      "Epoch 468/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2123 - acc: 0.9147 - val_loss: 0.7656 - val_acc: 0.7802\n",
      "Epoch 469/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2113 - acc: 0.9158 - val_loss: 0.7691 - val_acc: 0.7801\n",
      "Epoch 470/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2131 - acc: 0.9149 - val_loss: 0.7590 - val_acc: 0.7808\n",
      "Epoch 471/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2121 - acc: 0.9149 - val_loss: 0.7611 - val_acc: 0.7801\n",
      "Epoch 472/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2109 - acc: 0.9157 - val_loss: 0.7713 - val_acc: 0.7802\n",
      "Epoch 473/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2099 - acc: 0.9162 - val_loss: 0.7733 - val_acc: 0.7800\n",
      "Epoch 474/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2104 - acc: 0.9158 - val_loss: 0.7697 - val_acc: 0.7801\n",
      "Epoch 475/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2090 - acc: 0.9167 - val_loss: 0.7729 - val_acc: 0.7790\n",
      "Epoch 476/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2107 - acc: 0.9154 - val_loss: 0.7737 - val_acc: 0.7796\n",
      "Epoch 477/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2118 - acc: 0.9154 - val_loss: 0.7711 - val_acc: 0.7803\n",
      "Epoch 478/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2091 - acc: 0.9162 - val_loss: 0.7819 - val_acc: 0.7792\n",
      "Epoch 479/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2085 - acc: 0.9172 - val_loss: 0.7725 - val_acc: 0.7789\n",
      "Epoch 480/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2094 - acc: 0.9160 - val_loss: 0.7775 - val_acc: 0.7794\n",
      "Epoch 481/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2082 - acc: 0.9168 - val_loss: 0.7763 - val_acc: 0.7796\n",
      "Epoch 482/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2091 - acc: 0.9165 - val_loss: 0.7717 - val_acc: 0.7797\n",
      "Epoch 483/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2081 - acc: 0.9168 - val_loss: 0.7748 - val_acc: 0.7802\n",
      "Epoch 484/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2076 - acc: 0.9173 - val_loss: 0.7759 - val_acc: 0.7801\n",
      "Epoch 485/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2053 - acc: 0.9182 - val_loss: 0.7789 - val_acc: 0.7787\n",
      "Epoch 486/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2071 - acc: 0.9173 - val_loss: 0.7767 - val_acc: 0.7787\n",
      "Epoch 487/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2059 - acc: 0.9180 - val_loss: 0.7769 - val_acc: 0.7792\n",
      "Epoch 488/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2063 - acc: 0.9175 - val_loss: 0.7749 - val_acc: 0.7779\n",
      "Epoch 489/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2064 - acc: 0.9181 - val_loss: 0.7791 - val_acc: 0.7796\n",
      "Epoch 490/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2053 - acc: 0.9178 - val_loss: 0.7808 - val_acc: 0.7794\n",
      "Epoch 491/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2056 - acc: 0.9176 - val_loss: 0.7795 - val_acc: 0.7792\n",
      "Epoch 492/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2045 - acc: 0.9181 - val_loss: 0.7839 - val_acc: 0.7805\n",
      "Epoch 493/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2037 - acc: 0.9187 - val_loss: 0.7791 - val_acc: 0.7811\n",
      "Epoch 494/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2039 - acc: 0.9188 - val_loss: 0.7844 - val_acc: 0.7792\n",
      "Epoch 495/800\n",
      "230116/230116 [==============================] - 13s 55us/step - loss: 0.2040 - acc: 0.9186 - val_loss: 0.7831 - val_acc: 0.7800\n",
      "Epoch 496/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2045 - acc: 0.9190 - val_loss: 0.7885 - val_acc: 0.7799\n",
      "Epoch 497/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2035 - acc: 0.9194 - val_loss: 0.7841 - val_acc: 0.7792\n",
      "Epoch 498/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.2034 - acc: 0.9195 - val_loss: 0.7830 - val_acc: 0.7793\n",
      "Epoch 499/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2035 - acc: 0.9194 - val_loss: 0.7806 - val_acc: 0.7789\n",
      "Epoch 500/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2033 - acc: 0.9191 - val_loss: 0.7842 - val_acc: 0.7797\n",
      "Epoch 501/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2012 - acc: 0.9189 - val_loss: 0.7855 - val_acc: 0.7787\n",
      "Epoch 502/800\n",
      "230116/230116 [==============================] - 13s 54us/step - loss: 0.2019 - acc: 0.9193 - val_loss: 0.7917 - val_acc: 0.7798\n",
      "Epoch 503/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2020 - acc: 0.9190 - val_loss: 0.7869 - val_acc: 0.7795\n",
      "Epoch 504/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2014 - acc: 0.9200 - val_loss: 0.7944 - val_acc: 0.7800\n",
      "Epoch 505/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2015 - acc: 0.9195 - val_loss: 0.7825 - val_acc: 0.7795\n",
      "Epoch 506/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2019 - acc: 0.9203 - val_loss: 0.7886 - val_acc: 0.7800\n",
      "Epoch 507/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2013 - acc: 0.9198 - val_loss: 0.7827 - val_acc: 0.7796\n",
      "Epoch 508/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2016 - acc: 0.9197 - val_loss: 0.7921 - val_acc: 0.7797\n",
      "Epoch 509/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2007 - acc: 0.9201 - val_loss: 0.7890 - val_acc: 0.7781\n",
      "Epoch 510/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1999 - acc: 0.9206 - val_loss: 0.7866 - val_acc: 0.7789\n",
      "Epoch 511/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1997 - acc: 0.9198 - val_loss: 0.7911 - val_acc: 0.7802\n",
      "Epoch 512/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1990 - acc: 0.9205 - val_loss: 0.7878 - val_acc: 0.7780\n",
      "Epoch 513/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1996 - acc: 0.9205 - val_loss: 0.7894 - val_acc: 0.7801\n",
      "Epoch 514/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.2002 - acc: 0.9201 - val_loss: 0.7921 - val_acc: 0.7767\n",
      "Epoch 515/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1978 - acc: 0.9211 - val_loss: 0.7936 - val_acc: 0.7797\n",
      "Epoch 516/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1989 - acc: 0.9208 - val_loss: 0.7858 - val_acc: 0.7770\n",
      "Epoch 517/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1979 - acc: 0.9210 - val_loss: 0.7980 - val_acc: 0.7780\n",
      "Epoch 518/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1970 - acc: 0.9213 - val_loss: 0.8017 - val_acc: 0.7803\n",
      "Epoch 519/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1976 - acc: 0.9211 - val_loss: 0.8016 - val_acc: 0.7808\n",
      "Epoch 520/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1976 - acc: 0.9215 - val_loss: 0.8034 - val_acc: 0.7790\n",
      "Epoch 521/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1980 - acc: 0.9215 - val_loss: 0.8014 - val_acc: 0.7784\n",
      "Epoch 522/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1969 - acc: 0.9217 - val_loss: 0.8032 - val_acc: 0.7805\n",
      "Epoch 523/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1973 - acc: 0.9215 - val_loss: 0.7945 - val_acc: 0.7804\n",
      "Epoch 524/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1978 - acc: 0.9213 - val_loss: 0.7939 - val_acc: 0.7789\n",
      "Epoch 525/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1970 - acc: 0.9221 - val_loss: 0.7985 - val_acc: 0.7792\n",
      "Epoch 526/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1955 - acc: 0.9223 - val_loss: 0.7945 - val_acc: 0.7797\n",
      "Epoch 527/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1969 - acc: 0.9215 - val_loss: 0.7913 - val_acc: 0.7793\n",
      "Epoch 528/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1960 - acc: 0.9226 - val_loss: 0.8026 - val_acc: 0.7799\n",
      "Epoch 529/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1964 - acc: 0.9215 - val_loss: 0.8007 - val_acc: 0.7784\n",
      "Epoch 530/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1951 - acc: 0.9226 - val_loss: 0.8017 - val_acc: 0.7809\n",
      "Epoch 531/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1945 - acc: 0.9228 - val_loss: 0.7962 - val_acc: 0.7804\n",
      "Epoch 532/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1942 - acc: 0.9230 - val_loss: 0.8017 - val_acc: 0.7789\n",
      "Epoch 533/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1949 - acc: 0.9229 - val_loss: 0.8061 - val_acc: 0.7788\n",
      "Epoch 534/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1943 - acc: 0.9225 - val_loss: 0.8015 - val_acc: 0.7805\n",
      "Epoch 535/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1944 - acc: 0.9232 - val_loss: 0.7979 - val_acc: 0.7775\n",
      "Epoch 536/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1936 - acc: 0.9230 - val_loss: 0.8068 - val_acc: 0.7799\n",
      "Epoch 537/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1927 - acc: 0.9239 - val_loss: 0.8007 - val_acc: 0.7785\n",
      "Epoch 538/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1932 - acc: 0.9234 - val_loss: 0.8042 - val_acc: 0.7774\n",
      "Epoch 539/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1931 - acc: 0.9233 - val_loss: 0.8096 - val_acc: 0.7771\n",
      "Epoch 540/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1931 - acc: 0.9238 - val_loss: 0.8091 - val_acc: 0.7798\n",
      "Epoch 541/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1936 - acc: 0.9228 - val_loss: 0.8154 - val_acc: 0.7798\n",
      "Epoch 542/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1924 - acc: 0.9237 - val_loss: 0.8059 - val_acc: 0.7795\n",
      "Epoch 543/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1920 - acc: 0.9237 - val_loss: 0.8100 - val_acc: 0.7800\n",
      "Epoch 544/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1918 - acc: 0.9236 - val_loss: 0.8048 - val_acc: 0.7785\n",
      "Epoch 545/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1925 - acc: 0.9236 - val_loss: 0.8102 - val_acc: 0.7786\n",
      "Epoch 546/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1911 - acc: 0.9240 - val_loss: 0.8105 - val_acc: 0.7789\n",
      "Epoch 547/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1919 - acc: 0.9235 - val_loss: 0.8116 - val_acc: 0.7782\n",
      "Epoch 548/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1924 - acc: 0.9241 - val_loss: 0.8077 - val_acc: 0.7800\n",
      "Epoch 549/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1906 - acc: 0.9243 - val_loss: 0.8139 - val_acc: 0.7786\n",
      "Epoch 550/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1894 - acc: 0.9253 - val_loss: 0.8211 - val_acc: 0.7795\n",
      "Epoch 551/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1906 - acc: 0.9241 - val_loss: 0.8177 - val_acc: 0.7769\n",
      "Epoch 552/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1906 - acc: 0.9247 - val_loss: 0.8165 - val_acc: 0.7777\n",
      "Epoch 553/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1888 - acc: 0.9252 - val_loss: 0.8192 - val_acc: 0.7784\n",
      "Epoch 554/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1889 - acc: 0.9252 - val_loss: 0.8143 - val_acc: 0.7779\n",
      "Epoch 555/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1888 - acc: 0.9251 - val_loss: 0.8128 - val_acc: 0.7784\n",
      "Epoch 556/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1892 - acc: 0.9250 - val_loss: 0.8109 - val_acc: 0.7797\n",
      "Epoch 557/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1913 - acc: 0.9245 - val_loss: 0.8152 - val_acc: 0.7789\n",
      "Epoch 558/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1882 - acc: 0.9258 - val_loss: 0.8235 - val_acc: 0.7788\n",
      "Epoch 559/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1908 - acc: 0.9245 - val_loss: 0.8111 - val_acc: 0.7786\n",
      "Epoch 560/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1901 - acc: 0.9251 - val_loss: 0.8073 - val_acc: 0.7785\n",
      "Epoch 561/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1891 - acc: 0.9251 - val_loss: 0.8170 - val_acc: 0.7785\n",
      "Epoch 562/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1882 - acc: 0.9249 - val_loss: 0.8118 - val_acc: 0.7771\n",
      "Epoch 563/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1881 - acc: 0.9255 - val_loss: 0.8147 - val_acc: 0.7765\n",
      "Epoch 564/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1883 - acc: 0.9257 - val_loss: 0.8234 - val_acc: 0.7780\n",
      "Epoch 565/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1882 - acc: 0.9253 - val_loss: 0.8199 - val_acc: 0.7784\n",
      "Epoch 566/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1871 - acc: 0.9259 - val_loss: 0.8177 - val_acc: 0.7779\n",
      "Epoch 567/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1877 - acc: 0.9260 - val_loss: 0.8195 - val_acc: 0.7789\n",
      "Epoch 568/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1865 - acc: 0.9258 - val_loss: 0.8204 - val_acc: 0.7762\n",
      "Epoch 569/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1857 - acc: 0.9265 - val_loss: 0.8243 - val_acc: 0.7790\n",
      "Epoch 570/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1865 - acc: 0.9261 - val_loss: 0.8171 - val_acc: 0.7780\n",
      "Epoch 571/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1882 - acc: 0.9258 - val_loss: 0.8191 - val_acc: 0.7767\n",
      "Epoch 572/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1859 - acc: 0.9265 - val_loss: 0.8270 - val_acc: 0.7789\n",
      "Epoch 573/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1867 - acc: 0.9260 - val_loss: 0.8282 - val_acc: 0.7766\n",
      "Epoch 574/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1863 - acc: 0.9262 - val_loss: 0.8197 - val_acc: 0.7783\n",
      "Epoch 575/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1851 - acc: 0.9265 - val_loss: 0.8235 - val_acc: 0.7779\n",
      "Epoch 576/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1853 - acc: 0.9265 - val_loss: 0.8218 - val_acc: 0.7777\n",
      "Epoch 577/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1856 - acc: 0.9262 - val_loss: 0.8212 - val_acc: 0.7759\n",
      "Epoch 578/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1848 - acc: 0.9269 - val_loss: 0.8235 - val_acc: 0.7790\n",
      "Epoch 579/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1833 - acc: 0.9271 - val_loss: 0.8292 - val_acc: 0.7786\n",
      "Epoch 580/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1854 - acc: 0.9268 - val_loss: 0.8249 - val_acc: 0.7791\n",
      "Epoch 581/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1846 - acc: 0.9267 - val_loss: 0.8195 - val_acc: 0.7771\n",
      "Epoch 582/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1843 - acc: 0.9276 - val_loss: 0.8279 - val_acc: 0.7764\n",
      "Epoch 583/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1839 - acc: 0.9272 - val_loss: 0.8235 - val_acc: 0.7773\n",
      "Epoch 584/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1836 - acc: 0.9274 - val_loss: 0.8306 - val_acc: 0.7788\n",
      "Epoch 585/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1850 - acc: 0.9273 - val_loss: 0.8219 - val_acc: 0.7782\n",
      "Epoch 586/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1814 - acc: 0.9284 - val_loss: 0.8283 - val_acc: 0.7769\n",
      "Epoch 587/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1842 - acc: 0.9268 - val_loss: 0.8321 - val_acc: 0.7793\n",
      "Epoch 588/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1835 - acc: 0.9276 - val_loss: 0.8298 - val_acc: 0.7754\n",
      "Epoch 589/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1823 - acc: 0.9283 - val_loss: 0.8359 - val_acc: 0.7777\n",
      "Epoch 590/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1819 - acc: 0.9284 - val_loss: 0.8388 - val_acc: 0.7786\n",
      "Epoch 591/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1825 - acc: 0.9273 - val_loss: 0.8326 - val_acc: 0.7777\n",
      "Epoch 592/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1809 - acc: 0.9286 - val_loss: 0.8335 - val_acc: 0.7776\n",
      "Epoch 593/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1827 - acc: 0.9273 - val_loss: 0.8327 - val_acc: 0.7781\n",
      "Epoch 594/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1819 - acc: 0.9282 - val_loss: 0.8300 - val_acc: 0.7781\n",
      "Epoch 595/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1821 - acc: 0.9283 - val_loss: 0.8325 - val_acc: 0.7759\n",
      "Epoch 596/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1811 - acc: 0.9284 - val_loss: 0.8329 - val_acc: 0.7767\n",
      "Epoch 597/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1810 - acc: 0.9284 - val_loss: 0.8349 - val_acc: 0.7754\n",
      "Epoch 598/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1823 - acc: 0.9278 - val_loss: 0.8272 - val_acc: 0.7769\n",
      "Epoch 599/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1806 - acc: 0.9289 - val_loss: 0.8363 - val_acc: 0.7784\n",
      "Epoch 600/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1799 - acc: 0.9294 - val_loss: 0.8414 - val_acc: 0.7799\n",
      "Epoch 601/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1814 - acc: 0.9279 - val_loss: 0.8348 - val_acc: 0.7780\n",
      "Epoch 602/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1835 - acc: 0.9279 - val_loss: 0.8352 - val_acc: 0.7773\n",
      "Epoch 603/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1786 - acc: 0.9297 - val_loss: 0.8463 - val_acc: 0.7762\n",
      "Epoch 604/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1804 - acc: 0.9283 - val_loss: 0.8423 - val_acc: 0.7778\n",
      "Epoch 605/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1795 - acc: 0.9292 - val_loss: 0.8374 - val_acc: 0.7767\n",
      "Epoch 606/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1803 - acc: 0.9285 - val_loss: 0.8395 - val_acc: 0.7778\n",
      "Epoch 607/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1813 - acc: 0.9289 - val_loss: 0.8307 - val_acc: 0.7760\n",
      "Epoch 608/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1783 - acc: 0.9301 - val_loss: 0.8373 - val_acc: 0.7751\n",
      "Epoch 609/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1792 - acc: 0.9296 - val_loss: 0.8351 - val_acc: 0.7770\n",
      "Epoch 610/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1790 - acc: 0.9292 - val_loss: 0.8358 - val_acc: 0.7766\n",
      "Epoch 611/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1776 - acc: 0.9303 - val_loss: 0.8367 - val_acc: 0.7791\n",
      "Epoch 612/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1790 - acc: 0.9294 - val_loss: 0.8376 - val_acc: 0.7767\n",
      "Epoch 613/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1786 - acc: 0.9298 - val_loss: 0.8343 - val_acc: 0.7765\n",
      "Epoch 614/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1780 - acc: 0.9300 - val_loss: 0.8366 - val_acc: 0.7783\n",
      "Epoch 615/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1794 - acc: 0.9295 - val_loss: 0.8382 - val_acc: 0.7777\n",
      "Epoch 616/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1762 - acc: 0.9310 - val_loss: 0.8413 - val_acc: 0.7771\n",
      "Epoch 617/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1783 - acc: 0.9292 - val_loss: 0.8403 - val_acc: 0.7788\n",
      "Epoch 618/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1758 - acc: 0.9309 - val_loss: 0.8398 - val_acc: 0.7778\n",
      "Epoch 619/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1771 - acc: 0.9302 - val_loss: 0.8459 - val_acc: 0.7793\n",
      "Epoch 620/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1778 - acc: 0.9300 - val_loss: 0.8375 - val_acc: 0.7769\n",
      "Epoch 621/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1769 - acc: 0.9303 - val_loss: 0.8438 - val_acc: 0.7760\n",
      "Epoch 622/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1771 - acc: 0.9304 - val_loss: 0.8440 - val_acc: 0.7759\n",
      "Epoch 623/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1769 - acc: 0.9305 - val_loss: 0.8434 - val_acc: 0.7784\n",
      "Epoch 624/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1775 - acc: 0.9305 - val_loss: 0.8455 - val_acc: 0.7770\n",
      "Epoch 625/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1754 - acc: 0.9310 - val_loss: 0.8462 - val_acc: 0.7768\n",
      "Epoch 626/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1753 - acc: 0.9309 - val_loss: 0.8515 - val_acc: 0.7774\n",
      "Epoch 627/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1757 - acc: 0.9311 - val_loss: 0.8491 - val_acc: 0.7781\n",
      "Epoch 628/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1774 - acc: 0.9308 - val_loss: 0.8385 - val_acc: 0.7768\n",
      "Epoch 629/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1750 - acc: 0.9314 - val_loss: 0.8484 - val_acc: 0.7779\n",
      "Epoch 630/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1760 - acc: 0.9309 - val_loss: 0.8535 - val_acc: 0.7764\n",
      "Epoch 631/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1756 - acc: 0.9314 - val_loss: 0.8458 - val_acc: 0.7768\n",
      "Epoch 632/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1760 - acc: 0.9308 - val_loss: 0.8475 - val_acc: 0.7791\n",
      "Epoch 633/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1753 - acc: 0.9310 - val_loss: 0.8493 - val_acc: 0.7771\n",
      "Epoch 634/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1736 - acc: 0.9320 - val_loss: 0.8589 - val_acc: 0.7775\n",
      "Epoch 635/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1754 - acc: 0.9313 - val_loss: 0.8583 - val_acc: 0.7780\n",
      "Epoch 636/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1740 - acc: 0.9314 - val_loss: 0.8527 - val_acc: 0.7760\n",
      "Epoch 637/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1750 - acc: 0.9312 - val_loss: 0.8477 - val_acc: 0.7757\n",
      "Epoch 638/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1748 - acc: 0.9319 - val_loss: 0.8531 - val_acc: 0.7772\n",
      "Epoch 639/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1727 - acc: 0.9321 - val_loss: 0.8470 - val_acc: 0.7771\n",
      "Epoch 640/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1734 - acc: 0.9314 - val_loss: 0.8550 - val_acc: 0.7777\n",
      "Epoch 641/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1740 - acc: 0.9312 - val_loss: 0.8555 - val_acc: 0.7751\n",
      "Epoch 642/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1734 - acc: 0.9319 - val_loss: 0.8609 - val_acc: 0.7784\n",
      "Epoch 643/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1738 - acc: 0.9319 - val_loss: 0.8627 - val_acc: 0.7772\n",
      "Epoch 644/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1731 - acc: 0.9317 - val_loss: 0.8562 - val_acc: 0.7759\n",
      "Epoch 645/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1724 - acc: 0.9324 - val_loss: 0.8584 - val_acc: 0.7769\n",
      "Epoch 646/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1731 - acc: 0.9320 - val_loss: 0.8535 - val_acc: 0.7763\n",
      "Epoch 647/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1721 - acc: 0.9328 - val_loss: 0.8579 - val_acc: 0.7771\n",
      "Epoch 648/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1722 - acc: 0.9321 - val_loss: 0.8599 - val_acc: 0.7771\n",
      "Epoch 649/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1713 - acc: 0.9329 - val_loss: 0.8643 - val_acc: 0.7765\n",
      "Epoch 650/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1734 - acc: 0.9316 - val_loss: 0.8668 - val_acc: 0.7774\n",
      "Epoch 651/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1723 - acc: 0.9325 - val_loss: 0.8631 - val_acc: 0.7750\n",
      "Epoch 652/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1730 - acc: 0.9322 - val_loss: 0.8582 - val_acc: 0.7765\n",
      "Epoch 653/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1723 - acc: 0.9328 - val_loss: 0.8620 - val_acc: 0.7752\n",
      "Epoch 654/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1726 - acc: 0.9321 - val_loss: 0.8590 - val_acc: 0.7766\n",
      "Epoch 655/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1703 - acc: 0.9334 - val_loss: 0.8570 - val_acc: 0.7751\n",
      "Epoch 656/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1711 - acc: 0.9330 - val_loss: 0.8528 - val_acc: 0.7767\n",
      "Epoch 657/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1709 - acc: 0.9330 - val_loss: 0.8601 - val_acc: 0.7765\n",
      "Epoch 658/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1715 - acc: 0.9328 - val_loss: 0.8582 - val_acc: 0.7754\n",
      "Epoch 659/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1699 - acc: 0.9335 - val_loss: 0.8586 - val_acc: 0.7759\n",
      "Epoch 660/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1706 - acc: 0.9334 - val_loss: 0.8576 - val_acc: 0.7760\n",
      "Epoch 661/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1715 - acc: 0.9328 - val_loss: 0.8584 - val_acc: 0.7764\n",
      "Epoch 662/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1706 - acc: 0.9331 - val_loss: 0.8542 - val_acc: 0.7756\n",
      "Epoch 663/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1716 - acc: 0.9325 - val_loss: 0.8471 - val_acc: 0.7751\n",
      "Epoch 664/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1698 - acc: 0.9336 - val_loss: 0.8600 - val_acc: 0.7766\n",
      "Epoch 665/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1680 - acc: 0.9340 - val_loss: 0.8686 - val_acc: 0.7764\n",
      "Epoch 666/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1691 - acc: 0.9335 - val_loss: 0.8672 - val_acc: 0.7751\n",
      "Epoch 667/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1700 - acc: 0.9331 - val_loss: 0.8615 - val_acc: 0.7771\n",
      "Epoch 668/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1702 - acc: 0.9334 - val_loss: 0.8691 - val_acc: 0.7760\n",
      "Epoch 669/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1697 - acc: 0.9336 - val_loss: 0.8684 - val_acc: 0.7758\n",
      "Epoch 670/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1694 - acc: 0.9339 - val_loss: 0.8603 - val_acc: 0.7753\n",
      "Epoch 671/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1711 - acc: 0.9337 - val_loss: 0.8601 - val_acc: 0.7758\n",
      "Epoch 672/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1711 - acc: 0.9334 - val_loss: 0.8553 - val_acc: 0.7756\n",
      "Epoch 673/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1687 - acc: 0.9337 - val_loss: 0.8676 - val_acc: 0.7759\n",
      "Epoch 674/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1683 - acc: 0.9340 - val_loss: 0.8746 - val_acc: 0.7773\n",
      "Epoch 675/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1697 - acc: 0.9335 - val_loss: 0.8619 - val_acc: 0.7767\n",
      "Epoch 676/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1674 - acc: 0.9348 - val_loss: 0.8651 - val_acc: 0.7775\n",
      "Epoch 677/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1690 - acc: 0.9338 - val_loss: 0.8590 - val_acc: 0.7755\n",
      "Epoch 678/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1688 - acc: 0.9337 - val_loss: 0.8570 - val_acc: 0.7764\n",
      "Epoch 679/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1678 - acc: 0.9342 - val_loss: 0.8580 - val_acc: 0.7750\n",
      "Epoch 680/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1683 - acc: 0.9341 - val_loss: 0.8616 - val_acc: 0.7762\n",
      "Epoch 681/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1694 - acc: 0.9337 - val_loss: 0.8573 - val_acc: 0.7753\n",
      "Epoch 682/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1678 - acc: 0.9338 - val_loss: 0.8569 - val_acc: 0.7746\n",
      "Epoch 683/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1671 - acc: 0.9348 - val_loss: 0.8653 - val_acc: 0.7753\n",
      "Epoch 684/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1669 - acc: 0.9347 - val_loss: 0.8667 - val_acc: 0.7752\n",
      "Epoch 685/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1666 - acc: 0.9350 - val_loss: 0.8578 - val_acc: 0.7747\n",
      "Epoch 686/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1673 - acc: 0.9352 - val_loss: 0.8528 - val_acc: 0.7758\n",
      "Epoch 687/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1675 - acc: 0.9343 - val_loss: 0.8580 - val_acc: 0.7761\n",
      "Epoch 688/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1666 - acc: 0.9346 - val_loss: 0.8648 - val_acc: 0.7750\n",
      "Epoch 689/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1671 - acc: 0.9347 - val_loss: 0.8701 - val_acc: 0.7782\n",
      "Epoch 690/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1673 - acc: 0.9345 - val_loss: 0.8590 - val_acc: 0.7766\n",
      "Epoch 691/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1662 - acc: 0.9349 - val_loss: 0.8623 - val_acc: 0.7766\n",
      "Epoch 692/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1660 - acc: 0.9354 - val_loss: 0.8658 - val_acc: 0.7767\n",
      "Epoch 693/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1662 - acc: 0.9352 - val_loss: 0.8607 - val_acc: 0.7769\n",
      "Epoch 694/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1669 - acc: 0.9349 - val_loss: 0.8679 - val_acc: 0.7760\n",
      "Epoch 695/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1668 - acc: 0.9351 - val_loss: 0.8700 - val_acc: 0.7748\n",
      "Epoch 696/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1650 - acc: 0.9353 - val_loss: 0.8688 - val_acc: 0.7744\n",
      "Epoch 697/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1649 - acc: 0.9355 - val_loss: 0.8704 - val_acc: 0.7764\n",
      "Epoch 698/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1644 - acc: 0.9357 - val_loss: 0.8690 - val_acc: 0.7740\n",
      "Epoch 699/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1646 - acc: 0.9357 - val_loss: 0.8710 - val_acc: 0.7750\n",
      "Epoch 700/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1659 - acc: 0.9350 - val_loss: 0.8786 - val_acc: 0.7750\n",
      "Epoch 701/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1636 - acc: 0.9358 - val_loss: 0.8778 - val_acc: 0.7763\n",
      "Epoch 702/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1634 - acc: 0.9364 - val_loss: 0.8721 - val_acc: 0.7740\n",
      "Epoch 703/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1652 - acc: 0.9357 - val_loss: 0.8781 - val_acc: 0.7749\n",
      "Epoch 704/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1639 - acc: 0.9352 - val_loss: 0.8785 - val_acc: 0.7756\n",
      "Epoch 705/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1643 - acc: 0.9362 - val_loss: 0.8726 - val_acc: 0.7750\n",
      "Epoch 706/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1621 - acc: 0.9370 - val_loss: 0.8774 - val_acc: 0.7756\n",
      "Epoch 707/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1656 - acc: 0.9355 - val_loss: 0.8757 - val_acc: 0.7751\n",
      "Epoch 708/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1653 - acc: 0.9357 - val_loss: 0.8697 - val_acc: 0.7762\n",
      "Epoch 709/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1643 - acc: 0.9358 - val_loss: 0.8768 - val_acc: 0.7758\n",
      "Epoch 710/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1628 - acc: 0.9366 - val_loss: 0.8739 - val_acc: 0.7747\n",
      "Epoch 711/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1626 - acc: 0.9362 - val_loss: 0.8717 - val_acc: 0.7764\n",
      "Epoch 712/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1626 - acc: 0.9369 - val_loss: 0.8759 - val_acc: 0.7753\n",
      "Epoch 713/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1629 - acc: 0.9357 - val_loss: 0.8797 - val_acc: 0.7735\n",
      "Epoch 714/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1629 - acc: 0.9368 - val_loss: 0.8852 - val_acc: 0.7746\n",
      "Epoch 715/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1616 - acc: 0.9369 - val_loss: 0.8781 - val_acc: 0.7750\n",
      "Epoch 716/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1640 - acc: 0.9363 - val_loss: 0.8788 - val_acc: 0.7742\n",
      "Epoch 717/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1641 - acc: 0.9364 - val_loss: 0.8770 - val_acc: 0.7740\n",
      "Epoch 718/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1629 - acc: 0.9366 - val_loss: 0.8800 - val_acc: 0.7763\n",
      "Epoch 719/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1625 - acc: 0.9364 - val_loss: 0.8795 - val_acc: 0.7752\n",
      "Epoch 720/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1644 - acc: 0.9359 - val_loss: 0.8826 - val_acc: 0.7750\n",
      "Epoch 721/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1619 - acc: 0.9365 - val_loss: 0.8854 - val_acc: 0.7766\n",
      "Epoch 722/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1632 - acc: 0.9366 - val_loss: 0.8785 - val_acc: 0.7754\n",
      "Epoch 723/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1621 - acc: 0.9369 - val_loss: 0.8838 - val_acc: 0.7756\n",
      "Epoch 724/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1623 - acc: 0.9365 - val_loss: 0.8754 - val_acc: 0.7745\n",
      "Epoch 725/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1619 - acc: 0.9367 - val_loss: 0.8779 - val_acc: 0.7755\n",
      "Epoch 726/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1616 - acc: 0.9370 - val_loss: 0.8757 - val_acc: 0.7756\n",
      "Epoch 727/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1624 - acc: 0.9365 - val_loss: 0.8748 - val_acc: 0.7758\n",
      "Epoch 728/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1607 - acc: 0.9373 - val_loss: 0.8868 - val_acc: 0.7743\n",
      "Epoch 729/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1622 - acc: 0.9371 - val_loss: 0.8835 - val_acc: 0.7763\n",
      "Epoch 730/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1629 - acc: 0.9366 - val_loss: 0.8793 - val_acc: 0.7753\n",
      "Epoch 731/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1608 - acc: 0.9373 - val_loss: 0.8792 - val_acc: 0.7752\n",
      "Epoch 732/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1615 - acc: 0.9371 - val_loss: 0.8842 - val_acc: 0.7758\n",
      "Epoch 733/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1603 - acc: 0.9373 - val_loss: 0.8834 - val_acc: 0.7756\n",
      "Epoch 734/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1612 - acc: 0.9375 - val_loss: 0.8779 - val_acc: 0.7756\n",
      "Epoch 735/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1608 - acc: 0.9379 - val_loss: 0.8815 - val_acc: 0.7761\n",
      "Epoch 736/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1614 - acc: 0.9378 - val_loss: 0.8859 - val_acc: 0.7762\n",
      "Epoch 737/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1598 - acc: 0.9377 - val_loss: 0.8914 - val_acc: 0.7776\n",
      "Epoch 738/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1598 - acc: 0.9377 - val_loss: 0.8871 - val_acc: 0.7756\n",
      "Epoch 739/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1605 - acc: 0.9377 - val_loss: 0.8876 - val_acc: 0.7776\n",
      "Epoch 740/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1601 - acc: 0.9374 - val_loss: 0.8829 - val_acc: 0.7752\n",
      "Epoch 741/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1589 - acc: 0.9383 - val_loss: 0.8930 - val_acc: 0.7740\n",
      "Epoch 742/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1616 - acc: 0.9372 - val_loss: 0.8794 - val_acc: 0.7747\n",
      "Epoch 743/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1595 - acc: 0.9382 - val_loss: 0.8818 - val_acc: 0.7734\n",
      "Epoch 744/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1585 - acc: 0.9387 - val_loss: 0.8937 - val_acc: 0.7740\n",
      "Epoch 745/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1589 - acc: 0.9385 - val_loss: 0.8890 - val_acc: 0.7752\n",
      "Epoch 746/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1582 - acc: 0.9390 - val_loss: 0.8914 - val_acc: 0.7748\n",
      "Epoch 747/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1587 - acc: 0.9387 - val_loss: 0.8886 - val_acc: 0.7739\n",
      "Epoch 748/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1580 - acc: 0.9386 - val_loss: 0.8886 - val_acc: 0.7739\n",
      "Epoch 749/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1584 - acc: 0.9390 - val_loss: 0.8900 - val_acc: 0.7763\n",
      "Epoch 750/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1582 - acc: 0.9384 - val_loss: 0.8919 - val_acc: 0.7742\n",
      "Epoch 751/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1584 - acc: 0.9386 - val_loss: 0.8948 - val_acc: 0.7749\n",
      "Epoch 752/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1592 - acc: 0.9383 - val_loss: 0.8877 - val_acc: 0.7758\n",
      "Epoch 753/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1581 - acc: 0.9380 - val_loss: 0.8982 - val_acc: 0.7751\n",
      "Epoch 754/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1591 - acc: 0.9380 - val_loss: 0.8870 - val_acc: 0.7730\n",
      "Epoch 755/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1586 - acc: 0.9385 - val_loss: 0.8965 - val_acc: 0.7762\n",
      "Epoch 756/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1590 - acc: 0.9380 - val_loss: 0.8926 - val_acc: 0.7742\n",
      "Epoch 757/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1570 - acc: 0.9396 - val_loss: 0.8995 - val_acc: 0.7751\n",
      "Epoch 758/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1576 - acc: 0.9391 - val_loss: 0.8894 - val_acc: 0.7740\n",
      "Epoch 759/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1581 - acc: 0.9386 - val_loss: 0.8914 - val_acc: 0.7760\n",
      "Epoch 760/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1572 - acc: 0.9391 - val_loss: 0.8922 - val_acc: 0.7734\n",
      "Epoch 761/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1599 - acc: 0.9382 - val_loss: 0.8846 - val_acc: 0.7734\n",
      "Epoch 762/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1577 - acc: 0.9393 - val_loss: 0.8916 - val_acc: 0.7736\n",
      "Epoch 763/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1583 - acc: 0.9384 - val_loss: 0.8894 - val_acc: 0.7741\n",
      "Epoch 764/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1586 - acc: 0.9384 - val_loss: 0.8966 - val_acc: 0.7740\n",
      "Epoch 765/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1567 - acc: 0.9395 - val_loss: 0.8986 - val_acc: 0.7755\n",
      "Epoch 766/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1556 - acc: 0.9397 - val_loss: 0.9029 - val_acc: 0.7749\n",
      "Epoch 767/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1557 - acc: 0.9392 - val_loss: 0.9069 - val_acc: 0.7747\n",
      "Epoch 768/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1553 - acc: 0.9394 - val_loss: 0.9029 - val_acc: 0.7745\n",
      "Epoch 769/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1563 - acc: 0.9392 - val_loss: 0.8984 - val_acc: 0.7748\n",
      "Epoch 770/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1571 - acc: 0.9394 - val_loss: 0.8971 - val_acc: 0.7755\n",
      "Epoch 771/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1560 - acc: 0.9392 - val_loss: 0.8984 - val_acc: 0.7733\n",
      "Epoch 772/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1544 - acc: 0.9401 - val_loss: 0.8983 - val_acc: 0.7748\n",
      "Epoch 773/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1565 - acc: 0.9389 - val_loss: 0.8946 - val_acc: 0.7740\n",
      "Epoch 774/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1583 - acc: 0.9382 - val_loss: 0.8970 - val_acc: 0.7742\n",
      "Epoch 775/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1585 - acc: 0.9387 - val_loss: 0.8844 - val_acc: 0.7744\n",
      "Epoch 776/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1567 - acc: 0.9395 - val_loss: 0.9006 - val_acc: 0.7756\n",
      "Epoch 777/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1551 - acc: 0.9397 - val_loss: 0.8954 - val_acc: 0.7740\n",
      "Epoch 778/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1546 - acc: 0.9395 - val_loss: 0.9045 - val_acc: 0.7729\n",
      "Epoch 779/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1555 - acc: 0.9400 - val_loss: 0.8918 - val_acc: 0.7739\n",
      "Epoch 780/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1569 - acc: 0.9389 - val_loss: 0.8976 - val_acc: 0.7745\n",
      "Epoch 781/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1557 - acc: 0.9397 - val_loss: 0.8953 - val_acc: 0.7736\n",
      "Epoch 782/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1549 - acc: 0.9399 - val_loss: 0.8977 - val_acc: 0.7748\n",
      "Epoch 783/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1548 - acc: 0.9402 - val_loss: 0.8948 - val_acc: 0.7737\n",
      "Epoch 784/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1545 - acc: 0.9398 - val_loss: 0.9053 - val_acc: 0.7757\n",
      "Epoch 785/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1543 - acc: 0.9403 - val_loss: 0.8971 - val_acc: 0.7744\n",
      "Epoch 786/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1545 - acc: 0.9400 - val_loss: 0.9028 - val_acc: 0.7757\n",
      "Epoch 787/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1539 - acc: 0.9408 - val_loss: 0.8970 - val_acc: 0.7739\n",
      "Epoch 788/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1558 - acc: 0.9399 - val_loss: 0.8951 - val_acc: 0.7751\n",
      "Epoch 789/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1545 - acc: 0.9401 - val_loss: 0.9047 - val_acc: 0.7756\n",
      "Epoch 790/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1529 - acc: 0.9411 - val_loss: 0.9061 - val_acc: 0.7740\n",
      "Epoch 791/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1533 - acc: 0.9406 - val_loss: 0.9082 - val_acc: 0.7738\n",
      "Epoch 792/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1529 - acc: 0.9411 - val_loss: 0.9017 - val_acc: 0.7735\n",
      "Epoch 793/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1548 - acc: 0.9397 - val_loss: 0.9056 - val_acc: 0.7731\n",
      "Epoch 794/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1532 - acc: 0.9410 - val_loss: 0.9044 - val_acc: 0.7743\n",
      "Epoch 795/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1539 - acc: 0.9402 - val_loss: 0.8977 - val_acc: 0.7741\n",
      "Epoch 796/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1549 - acc: 0.9403 - val_loss: 0.8991 - val_acc: 0.7739\n",
      "Epoch 797/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1526 - acc: 0.9410 - val_loss: 0.9071 - val_acc: 0.7741\n",
      "Epoch 798/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1532 - acc: 0.9406 - val_loss: 0.9053 - val_acc: 0.7743\n",
      "Epoch 799/800\n",
      "230116/230116 [==============================] - 12s 54us/step - loss: 0.1536 - acc: 0.9406 - val_loss: 0.9053 - val_acc: 0.7761\n",
      "Epoch 800/800\n",
      "230116/230116 [==============================] - 12s 53us/step - loss: 0.1526 - acc: 0.9413 - val_loss: 0.9096 - val_acc: 0.7760\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "sys.path.append(os.path.realpath(\"../\"))\n",
    "import ptetaphi_nn\n",
    "import tools\n",
    "\n",
    "# get data file path\n",
    "with open(\"/home/cmccracken/start_tf/bbb/filepath.txt\", 'r') as f:\n",
    "    filename = f.read()\n",
    "    \n",
    "s_table = tools.open_file(filename, sort_by=\"tag\", pt_cut=40, eta_cut=2.5)\n",
    "\n",
    "# filter for events with 3 b tags\n",
    "nt3 = s_table.nbtags==3 \n",
    "events = s_table[nt3]\n",
    "print(len(events))\n",
    "\n",
    "cutoff = 10  # not many events have >10 jets\n",
    "# \"pad\" = ensure all events have same length, cut off ends if needed\n",
    "events = tools.pad(events, cutoff)\n",
    "\n",
    "# make and train network\n",
    "nn = ptetaphi_nn.PtEtaPhiNN(events, chop=0, print_summary=True, fold=3)\n",
    "nn.learn(epochs=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57529/57529 [00:00<00:00, 85868.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 76.79 percent\n",
      "ignoring 1.39 percent (801 events) of 57529 events\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(savename=\"fold_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the architecture string to a file\n",
    "models_dir = \"/home/cmccracken/start_tf/bbb/models/\"\n",
    "with open(models_dir+'architecture_fold_3.json', 'w') as arch_file:\n",
    "    arch_file.write(nn.model.to_json())\n",
    "# now save the weights as an HDF5 file\n",
    "nn.model.save_weights(models_dir+'weights_fold_3.h5')\n",
    "# use nn_tester to get csv!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
